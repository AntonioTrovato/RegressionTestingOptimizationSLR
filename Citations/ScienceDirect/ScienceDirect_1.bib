@article{CHEN2024,
title = {Trial Factors Associated With Completion of Clinical Trials Evaluating AI: Retrospective Case-Control Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/58578},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005880},
author = {David Chen and Christian Cao and Robert Kloosterman and Rod Parsa and Srinivas Raman},
keywords = {artificial intelligence, clinical trial, completion, AI, cross-sectional study, application, intervention, trial design, logistic regression, Europe, clinical, trials testing, health care, informatics, health information},
abstract = {Background
Evaluation of artificial intelligence (AI) tools in clinical trials remains the gold standard for translation into clinical settings. However, design factors associated with successful trial completion and the common reasons for trial failure are unknown.
Objective
This study aims to compare trial design factors of complete and incomplete clinical trials testing AI tools. We conducted a case-control study of complete (n=485) and incomplete (n=51) clinical trials that evaluated AI as an intervention of ClinicalTrials.gov.
Methods
Trial design factors, including area of clinical application, intended use population, and intended role of AI, were extracted. Trials that did not evaluate AI as an intervention and active trials were excluded. The assessed trial design factors related to AI interventions included the domain of clinical application related to organ systems; intended use population for patients or health care providers; and the role of AI for different applications in patient-facing clinical workflows, such as diagnosis, screening, and treatment. In addition, we also assessed general trial design factors including study type, allocation, intervention model, masking, age, sex, funder, continent, length of time, sample size, number of enrollment sites, and study start year. The main outcome was the completion of the clinical trial. Odds ratio (OR) and 95% CI values were calculated for all trial design factors using propensity-matched, multivariable logistic regression.
Results
We queried ClinicalTrials.gov on December 23, 2023, using AI keywords to identify complete and incomplete trials testing AI technologies as a primary intervention, yielding 485 complete and 51 incomplete trials for inclusion in this study. Our nested propensity-matched, case-control results suggest that trials conducted in Europe were significantly associated with trial completion when compared with North American trials (OR 2.85, 95% CI 1.14-7.10; P=.03), and the trial sample size was positively associated with trial completion (OR 1.00, 95% CI 1.00-1.00; P=.02).
Conclusions
Our case-control study is one of the first to identify trial design factors associated with completion of AI trials and catalog study-reported reasons for AI trial failure. We observed that trial design factors positively associated with trial completion include trials conducted in Europe and sample size. Given the promising clinical use of AI tools in health care, our results suggest that future translational research should prioritize addressing the design factors of AI clinical trials associated with trial incompletion and common reasons for study failure.}
}
@article{MUKHERJEE20211041,
title = {A survey on different approaches for software test case prioritization},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {33},
number = {9},
pages = {1041-1054},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1319157818303616},
author = {Rajendrani Mukherjee and K. Sridhar Patnaik},
keywords = {Regression, Prioritization, Techniques, Program, Fault, Coverage},
abstract = {Testing is the process of evaluating a system by manual or automated means. While Regression Test Selection (RTS) discards test cases and Test Suite Minimization (TSM) shows diminution in fault detection rate, Test Case Prioritization (TCP) does not discard test cases. Test Case Prioritization techniques can be coverage or historical information based or model based. It can also be cost-time aware or requirement-risk aware. GUI/Web applications need special prioritization mechanism. In this paper, 90 scholarly articles ranging from 2001 to 2018 have been reviewed. We have explored IEEE, Wiley, ACM Library, Springer, Taylor & Francis and Elsevier database. We have also described each prioritization method with their findings and subject programs. This paper includes a chronological catalogue listing of the reviewed papers. We have framed three research questions which sum up the frequently used prioritization metrics, regularly used subject programs and the distribution of different prioritization techniques. To the best of our knowledge, this is the first review with a detail report of the last 18 years of TCP techniques. We hope this article will be beneficial for both beginners and seasoned professionals.}
}
@article{SCHWARTZ201661,
title = {Cost-effective regression testing through Adaptive Test Prioritization strategies},
journal = {Journal of Systems and Software},
volume = {115},
pages = {61-81},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216000169},
author = {Amanda Schwartz and Hyunsook Do},
keywords = {Regression testing, Adaptive regression testing strategy, Test case prioritization},
abstract = {Regression testing is an important part of the software development life cycle. It is also very expensive. Many different techniques have been proposed for reducing the cost of regression testing. However, research has shown that the effectiveness of different techniques varies under different testing environments and software change characteristics. In prior work, we developed strategies to investigate ways of choosing the most cost-effective regression testing technique for a particular regression testing session. In this work, we empirically study the existing strategies presented in prior work as well as develop two additional Adaptive Test Prioritization (ATP) strategies using fuzzy analytical hierarchy process (AHP) and the weighted sum model (WSM). We also provide a comparative study examining each of the ATP strategies presented to date. This research will provide researchers and practitioners with strategies to utilize in regression testing plans as well as provide data to use when deciding which of the strategies would best fit their testing needs. The empirical studies provided in this research show that utilizing these strategies can improve the cost-effectiveness of regression testing.}
}
@article{CAMPI2025108574,
title = {Machine learning-based forecast of Helmet-CPAP therapy failure in Acute Respiratory Distress Syndrome patients},
journal = {Computer Methods and Programs in Biomedicine},
volume = {260},
pages = {108574},
year = {2025},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108574},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724005674},
author = {Riccardo Campi and Antonio {De Santis} and Paolo Colombo and Paolo Scarpazza and Marco Masseroli},
keywords = {Acute Respiratory Distress Syndrome, Helmet-Continuous Positive Airway Pressure, Predicting H-CPAP failure in ARDS patients, Machine Learning, COVID-19},
abstract = {Background and Objective:
Helmet-Continuous Positive Airway Pressure (H-CPAP) is a non-invasive respiratory support that is used for the treatment of Acute Respiratory Distress Syndrome (ARDS), a severe medical condition diagnosed when symptoms like profound hypoxemia, pulmonary opacities on radiography, or unexplained respiratory failure are present. It can be classified as mild, moderate or severe. H-CPAP therapy is recommended as the initial treatment approach for mild ARDS. Even though the efficacy of H-CPAP in managing patients with moderate-to-severe hypoxemia remains unclear, its use has increased for these cases in response to the emergence of the COVID-19 Pandemic. Using the electronic medical records (EMR) from the Pulmonology Department of Vimercate Hospital, in this study we develop and evaluate a Machine Learning (ML) system able to predict the failure of H-CPAP therapy on ARDS patients.
Methods:
The Vimercate Hospital EMR provides demographic information, blood tests, and vital parameters of all hospitalizations of patients who are treated with H-CPAP and diagnosed with ARDS. This data is used to create a dataset of 622 records and 38 features, with 70%–30% split between training and test sets. Different ML models such as SVM, XGBoost, Neural Network, Random Forest, and Logistic Regression are iteratively trained in a cross-validation fashion. We also apply a feature selection algorithm to improve predictions quality and reduce the number of features.
Results and Conclusions:
The SVM and Neural Network models proved to be the most effective, achieving final accuracies of 95.19% and 94.65%, respectively. In terms of F1-score, the models scored 88.61% and 87.18%, respectively. Additionally, the SVM and XGBoost models performed well with a reduced number of features (23 and 13, respectively). The PaO2/FiO2 Ratio, C-Reactive Protein, and O2 Saturation resulted as the most important features, followed by Heartbeats, White Blood Cells, and D-Dimer, in accordance with the clinical scientific literature.}
}
@article{PRADHAN201986,
title = {Employing rule mining and multi-objective search for dynamic test case prioritization},
journal = {Journal of Systems and Software},
volume = {153},
pages = {86-104},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.03.064},
url = {https://www.sciencedirect.com/science/article/pii/S016412121930072X},
author = {Dipesh Pradhan and Shuai Wang and Shaukat Ali and Tao Yue and Marius Liaaen},
keywords = {Multi-objective optimization, Rule mining, Dynamic test case prioritization, Search, Black-box regression testing},
abstract = {Test case prioritization (TP) is widely used in regression testing for optimal reordering of test cases to achieve specific criteria (e.g., higher fault detection capability) as early as possible. In our earlier work, we proposed an approach for black-box dynamic TP using rule mining and multi-objective search (named as REMAP) by defining two objectives (fault detection capability and test case reliance score) and considering test case execution results at runtime. In this paper, we conduct an extensive empirical evaluation of REMAP by employing three different rule mining algorithms and three different multi-objective search algorithms, and we also evaluate REMAP with one additional objective (estimated execution time) for a total of 18 different configurations (i.e., 3 rule mining algorithms ×  3 search algorithms ×  2 different set of objectives) of REMAP. Specifically, we empirically evaluated the 18 variants of REMAP with 1) two variants of random search while using two objectives and three objectives, 2) three variants of greedy algorithm based on one objective, two objectives, and three objectives, 3) 18 variants of static search-based prioritization approaches, and 4) six variants of rule-based prioritization approaches using two industrial and three open source case studies. Results showed that the two best variants of REMAP with two objectives and three objectives significantly outperformed the best variants of competing approaches by 84.4% and 88.9%, and managed to achieve on average 14.2% and 18.8% higher Average Percentage of Faults Detected per Cost (APFDc) scores.}
}
@article{CHEN2018107,
title = {Test case prioritization for object-oriented software: An adaptive random sequence approach based on clustering},
journal = {Journal of Systems and Software},
volume = {135},
pages = {107-125},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2017.09.031},
url = {https://www.sciencedirect.com/science/article/pii/S0164121217302170},
author = {Jinfu Chen and Lili Zhu and Tsong Yueh Chen and Dave Towey and Fei-Ching Kuo and Rubing Huang and Yuchi Guo},
keywords = {Object-oriented software, Adaptive random sequence, Test cases prioritization, Cluster analysis, Test cases selection},
abstract = {Test case prioritization (TCP) attempts to improve fault detection effectiveness by scheduling the important test cases to be executed earlier, where the importance is determined by some criteria or strategies. Adaptive random sequences (ARSs) can be used to improve the effectiveness of TCP based on white-box information (such as code coverage information) or black-box information (such as test input information). To improve the testing effectiveness for object-oriented software in regression testing, in this paper, we present an ARS approach based on clustering techniques using black-box information. We use two clustering methods: (1) clustering test cases according to the number of objects and methods, using the K-means and K-medoids clustering algorithms; and (2) clustered based on an object and method invocation sequence similarity metric using the K-medoids clustering algorithm. Our approach can construct ARSs that attempt to make their neighboring test cases as diverse as possible. Experimental studies were also conducted to verify the proposed approach, with the results showing both enhanced probability of earlier fault detection, and higher effectiveness than random prioritization and method coverage TCP technique.}
}
@article{KIM201888,
title = {Association networks in a matched case-control design – Co-occurrence patterns of preexisting chronic medical conditions in patients with major depression versus their matched controls},
journal = {Journal of Biomedical Informatics},
volume = {87},
pages = {88-95},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2018.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S1532046418301941},
author = {Min-hyung Kim and Samprit Banerjee and Yize Zhao and Fei Wang and Yiye Zhang and Yongjun Zhu and Joseph DeFerio and Lauren Evans and Sang Min Park and Jyotishman Pathak},
keywords = {Matched pair analysis, Network analysis, Interaction analysis, Chronic medical conditions, Major depressive disorder},
abstract = {Objective
We present a method for comparing association networks in a matched case-control design, which provides a high-level comparison of co-occurrence patterns of features after adjusting for confounding factors. We demonstrate this approach by examining the differential distribution of chronic medical conditions in patients with major depressive disorder (MDD) compared to the distribution of these conditions in their matched controls.
Materials and methods
Newly diagnosed MDD patients were matched to controls based on their demographic characteristics, socioeconomic status, place of residence, and healthcare service utilization in the Korean National Health Insurance Service’s National Sample Cohort. Differences in the networks of chronic medical conditions in newly diagnosed MDD cases treated with antidepressants, and their matched controls, were prioritized with a permutation test accounting for the false discovery rate. Sensitivity analyses for the associations between prioritized pairs of chronic medical conditions and new MDD diagnosis were performed with regression modeling.
Results
By comparing the association networks of chronic medical conditions in newly diagnosed depression patients and their matched controls, five pairs of such conditions were prioritized among 105 possible pairs after controlling the false discovery rate at 5%. In sensitivity analyses using regression modeling, four out of the five prioritized pairs were statistically significant for the interaction terms.
Conclusion
Association networks in a matched case-control design can provide a high-level comparison of comorbid features after adjusting for confounding factors, thereby supplementing traditional clinical study approaches. We demonstrate the differential co-occurrence pattern of chronic medical conditions in patients with MDD and prioritize the chronic conditions that have statistically significant interactions in regression models for depression.}
}
@article{URRACA20189,
title = {Evaluation of a novel GA-based methodology for model structure selection: The GA-PARSIMONY},
journal = {Neurocomputing},
volume = {271},
pages = {9-17},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.08.154},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217312171},
author = {R. Urraca and E. Sodupe-Ortega and J. Antonanzas and F. Antonanzas-Torres and F.J. Martinez-de-Pison},
keywords = {Genetic algorithms, Parameter tuning, Feature selection, Parsimony criterion, Model comparative},
abstract = {Most proposed metaheuristics for feature selection and model parameter optimization are based on a two-termed Loss+Penalty function. Their main drawback is the need of a manual set of the parameter that balances between the loss and the penalty term. In this paper, a novel methodology referred as the GA-PARSIMONY and specifically designed to overcome this issue is evaluated in detail in thirteen public databases with five regression techniques. It is a GA-based meta-heuristic that splits the classic two-termed minimization functions by making two consecutive ranks of individuals. The first rank is based solely on the generalization error, while the second (named ReRank) is based on the complexity of the models, giving a special weight to the complexity entailed by large number of inputs. For each database, models with lowest testing RMSE and without statistical difference among them were referred as winner models. Within this group, the number of features selected was below 50%, which proves an optimal balance between error minimization and parsimony. Particularly, the most complex algorithms (MLP and SVR) were mostly selected in the group of winner models, while using around40–45% of the available attributes. The most basic IBk, ridge regression (LIN) and M5P were only classified as winner models in the simpler databases, but using less number of features in those cases (up to a 20–25% of the initial inputs).}
}
@article{CUI2024102083,
title = {A label learning approach using competitive population optimization algorithm feature selection to improve multi-label classification algorithms},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {5},
pages = {102083},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102083},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824001721},
author = {Lianhe Cui},
keywords = {Competitive swarm optimizer, Feature selection, Multi-label data, Reconstruction error, Sparse representation},
abstract = {One of the crucial pre-processing stages in data mining and machine learning is feature selection, which is used to choose a subset of representative characteristics and decrease dimensions. By eliminating unnecessary and redundant features, feature selection can improve machine learning tasks’ accuracy. This work presents a novel multi-label classification (MLC) model utilizing a combination of stack regression (RR) and original label space transformation (IPLST) called RR-IPLST (original label space transformation-ridge regression). A novel embedded technique is implemented, utilizing competitive crowding optimizer (CSO) for multi-label feature selection. Particles are first created using this procedure, after which they are split into two equal groups and compete in pairs. The winners advance to the next iteration, while the losers pick up tips from the victors. At the conclusion of each iteration, the objective function for every particle is determined. A local search technique inspired by the gradient descent algorithm is used to find the local structure of the data, and half of the initial population is produced by the similarity between features and labels in order to boost the convergence rate. Ultimately, feature selection is carried out depending on the best particle. Six popular and sophisticated multi-label feature selection techniques are evaluated to see how well the suggested approach performs. According to the simulation results, the application of the suggested solution performs better than comparable techniques in terms of stability, accuracy, precision, convergence, error measurement, and other criteria that have been examined on various data sets. In 93.35% of cases, the test results demonstrate superiority over traditional algorithms.}
}
@article{SANDOVALALCOCER2020102415,
title = {Prioritizing versions for performance regression testing: The Pharo case},
journal = {Science of Computer Programming},
volume = {191},
pages = {102415},
year = {2020},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2020.102415},
url = {https://www.sciencedirect.com/science/article/pii/S0167642320300265},
author = {Juan Pablo {Sandoval Alcocer} and Alexandre Bergel and Marco Tulio Valente},
keywords = {Performance regression, Software performance, Software evolution, Performance regression prediction, Regression benchmarking},
abstract = {Context
Software performance may suffer regressions caused by source code changes. Measuring performance at each new software version is useful for early detection of performance regressions. However, systematically running benchmarks is often impractical (e.g., long running execution, prioritizing functional correctness over non-functional).
Objective
In this article, we propose Horizontal Profiling, a sampling technique to predict when a new revision may cause a regression by analyzing the source code and using run-time information of a previous version. The goal of Horizontal Profiling is to reduce the performance testing overhead by benchmarking just software versions that contain costly source code changes.
Method
We present an evaluation in which we apply Horizontal Profiling to identify performance regressions of 17 software projects written in the Pharo programming language, totaling 1,288 software versions.
Results
Horizontal Profiling detects more than 80% of the regressions by benchmarking less than 20% of the versions. In addition, our experiments show that Horizontal Profiling has better precision and executes the benchmarks in less versions that the state of the art tools, under our benchmarks.
Conclusions
We conclude that by adequately characterizing the run-time information of a previous version, it is possible to determine if a new version is likely to introduce a performance regression or not. As a consequence, a significant fraction of the performance regressions are identified by benchmarking only a small fraction of the software versions.}
}
@article{CAO2024105087,
title = {Transient temperature analysis and engineering application of steel shell immersed tunnel protected by fireproof board},
journal = {Case Studies in Thermal Engineering},
volume = {61},
pages = {105087},
year = {2024},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2024.105087},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X24011183},
author = {Peng Cao and Qingliang Wu and Enlong Liu and Huixian Wang},
keywords = {Fire, Steel-concrete-steel structure, Analytical solution, Thermal resistance, Fireproof board, Regression analysis},
abstract = {Based on the Shenzhen-Zhongshan Link, the transient analytical solution of the steel shell immersed tunnel under the protection of fireproof board was deduced and verified through fire test. Then, the variation of the maximum temperature of the bottom steel shell with the thickness and thermal conductivity of the fireproof board was analyzed and suggestions on the selection of fireproof boards were given. Finally, a fitting formula for the maximum temperature of bottom steel shell was proposed. The results show that: (1) When the thermal contact resistance of the steel-concrete interface and the thermal resistance of cavity are 0.01 m2 °C/W and 0.02 m2 °C/W respectively under the case of 25 mm thick fireproof board, the variation of the analytical solution is consistent with test results, and the peak value is similar. (2) Based on the three-dimensional diagram of d -λ-T, with 300 °C as the fire resistance limit of structure, the range of the fireproof board parameters is obtained: when λ reaches 0.14 and 0.4 respectively, d shall not be less than 10 mm and 28.38 mm (3) The scatter points obtained from analysis were fitted using quadratic polynomials and linear functions respectively. Considering the accuracy and simplicity, the linear fitting formula is given as T = 275.66–7.41*d+644.6*λ.}
}
@article{HU2025102919,
title = {A learning-guided hybrid genetic algorithm and multi-neighborhood search for the integrated process planning and scheduling problem with reconfigurable manufacturing cells},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {93},
pages = {102919},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102919},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524002060},
author = {Yiwen Hu and Hongliang Dong and Jianhua Liu and Cunbo Zhuang and Feng Zhang},
keywords = {Integrated process planning and scheduling, Reconfigurable manufacturing cells, Hybrid algorithm, Neighborhood structure, Learning-guided mechanism},
abstract = {Integrated process planning and scheduling (IPPS) is a crucial component of an intelligent manufacturing system. While most existing studies have focused on the manufacturing workshop, less attention has been given to the assembly and test workshops, which typically include reconfigurable manufacturing cells (RMCs). Therefore, this paper focuses on IPPS with reconfigurable manufacturing cells (IPPS_RMCs) in the context of assembly and test workshops. The objective of IPPS_RMCs is to minimize the makespan and total weighted tardiness, taking into account priority constraints and capability conversion limits of RMCs. To address and optimize this problem, a learning-guided hybrid genetic algorithm (LG_HGA) is proposed, which utilizes chromosome encoding to solve the process planning and scheduling problem synchronously. The LG_HGA incorporates NSGA-II as the global search and employs a learning-guided multi-neighborhood search (LG_MNS) to achieve a better balance between exploration and exploitation. In the global search phase, a problem-based methodology for gene operation is introduced. The LG_MNS consists of four neighborhood structures, based on critical paths and heuristic rules. Additionally, the learning-guided mechanism involves using a decision tree regression model to learn data from the knowledge base and determine how to perform local search. Through case tests of various sizes, the experimental results demonstrate that LG_HGA outperforms several advanced multi-objective evolutionary algorithms due to the proposed improved genetic operations, neighborhood structure, and learning mechanism.}
}
@article{AHMED20222211,
title = {Value-Based Test Case Prioritization for Regression Testing Using Genetic Algorithms},
journal = {Computers, Materials and Continua},
volume = {74},
number = {1},
pages = {2211-2238},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.032664},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822002466},
author = {Farrukh Shahzad Ahmed and Awais Majeed and Tamim Ahmed Khan},
keywords = {Average percentage of fault detection, test case prioritization, regression testing, and value-based testing, value-based test case prioritization, genetic algorithms},
abstract = {Test Case Prioritization (TCP) techniques perform better than other regression test optimization techniques including Test Suite Reduction (TSR) and Test Case Selection (TCS). Many TCP techniques are available, and their performance is usually measured through a metric Average Percentage of Fault Detection (APFD). This metric is value-neutral because it only works well when all test cases have the same cost, and all faults have the same severity. Using APFD for performance evaluation of test case orders where test cases cost or faults severity varies is prone to produce false results. Therefore, using the right metric for performance evaluation of TCP techniques is very important to get reliable and correct results. In this paper, two value-based TCP techniques have been introduced using Genetic Algorithm (GA) including Value-Cognizant Fault Detection-Based TCP (VCFDB-TCP) and Value-Cognizant Requirements Coverage-Based TCP (VCRCB-TCP). Two novel value-based performance evaluation metrics are also introduced for value-based TCP including Average Percentage of Fault Detection per value (APFDv) and Average Percentage of Requirements Coverage per value (APRCv). Two case studies are performed to validate proposed techniques and performance evaluation metrics. The proposed GA-based techniques outperformed the existing state-of-the-art TCP techniques including Original Order (OO), Reverse Order (REV-O), Random Order (RO), and Greedy algorithm.}
}
@article{SINGHAL20226755,
title = {Fault Coverage-Based Test Case Prioritization and Selection Using African Buffalo Optimization},
journal = {Computers, Materials and Continua},
volume = {74},
number = {3},
pages = {6755-6774},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.032308},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822002740},
author = {Shweta Singhal and Nishtha Jatana and Ahmad F Subahi and Charu Gupta and Osamah Ibrahim Khalaf and Youseef Alotaibi},
keywords = {Test case prioritization, regression testing, test case selection, African buffalo optimization, nature-inspired, meta-heuristic},
abstract = {Software needs modifications and requires revisions regularly. Owing to these revisions, retesting software becomes essential to ensure that the enhancements made, have not affected its bug-free functioning. The time and cost incurred in this process, need to be reduced by the method of test case selection and prioritization. It is observed that many nature-inspired techniques are applied in this area. African Buffalo Optimization is one such approach, applied to regression test selection and prioritization. In this paper, the proposed work explains and proves the applicability of the African Buffalo Optimization approach to test case selection and prioritization. The proposed algorithm converges in polynomial time (O(n2)). In this paper, the empirical evaluation of applying African Buffalo Optimization for test case prioritization is done on sample data set with multiple iterations. An astounding 62.5% drop in size and a 48.57% drop in the runtime of the original test suite were recorded. The obtained results are compared with Ant Colony Optimization. The comparative analysis indicates that African Buffalo Optimization and Ant Colony Optimization exhibit similar fault detection capabilities (80%), and a reduction in the overall execution time and size of the resultant test suite. The results and analysis, hence, advocate and encourages the use of African Buffalo Optimization in the area of test case selection and prioritization.}
}
@article{MAHDIEH2020106269,
title = {Incorporating fault-proneness estimations into coverage-based test case prioritization methods},
journal = {Information and Software Technology},
volume = {121},
pages = {106269},
year = {2020},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106269},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920300197},
author = {Mostafa Mahdieh and Seyed-Hassan Mirian-Hosseinabadi and Khashayar Etemadi and Ali Nosrati and Sajad Jalali},
keywords = {Regression testing, Test case prioritization, Defect prediction, Machine learning, Bug history},
abstract = {Context: During the development process of a software program, regression testing is used to ensure that the correct behavior of the software is retained after updates to the source code. This regression testing becomes costly over time as the number of test cases increases and it makes sense to prioritize test cases in order to execute fault-detecting test cases as soon as possible. There are many coverage-based test case prioritization (TCP) methods that only use the code coverage data to prioritize test cases. By incorporating the fault-proneness estimations of code units into the coverage-based TCP methods, we can improve such techniques. Objective: In this paper, we aim to propose an approach which improves coverage-based TCP methods by considering the fault-proneness distribution over code units. Further, we present the results of an empirical study that shows using our proposed approach significantly improves the additional strategy, which is a widely used coverage-based TCP method. Method: The approach presented in this study uses the bug history of the software in order to introduce a defect prediction method to learn a neural network model. This model is then used to estimate fault-proneness of each area of the source code and then the estimations are incorporated into coverage-based TCP methods. Our proposed approach is a general idea that can be applied to many coverage-based methods, such as the additional and total TCP methods. Results: The proposed methods are evaluated on datasets collected from the development history of five real-world projects including 357 versions in total. The experiments show that using an appropriate bug history can improve coverage-based TCP methods. Conclusion: The proposed approach can be applied to various coverage-based TCP methods and the experiments show that it can improve these methods by incorporating estimations of code units fault-proneness.}
}
@article{HAGHIGHATKHAH201880,
title = {Test prioritization in continuous integration environments},
journal = {Journal of Systems and Software},
volume = {146},
pages = {80-98},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.08.061},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301730},
author = {Alireza Haghighatkhah and Mika Mäntylä and Markku Oivo and Pasi Kuvaja},
keywords = {Test case prioritization, Regression testing, Continuous integration, Build history, Test diversity},
abstract = {Two heuristics namely diversity-based (DBTP) and history-based test prioritization (HBTP) have been separately proposed in the literature. Yet, their combination has not been widely studied in continuous integration (CI) environments. The objective of this study is to catch regression faults earlier, allowing developers to integrate and verify their changes more frequently and continuously. To achieve this, we investigated six open-source projects, each of which included several builds over a large time period. Findings indicate that previous failure knowledge seems to have strong predictive power in CI environments and can be used to effectively prioritize tests. HBTP does not necessarily need to have large data, and its effectiveness improves to a certain degree with larger history interval. DBTP can be used effectively during the early stages, when no historical data is available, and also combined with HBTP to improve its effectiveness. Among the investigated techniques, we found that history-based diversity using NCD Multiset is superior in terms of effectiveness but comes with relatively higher overhead in terms of method execution time. Test prioritization in CI environments can be effectively performed with negligible investment using previous failure knowledge, and its effectiveness can be further improved by considering dissimilarities among the tests.}
}
@article{PAN2024102472,
title = {A method for filling missing values in multivariate sequence bidirectional recurrent neural networks based on feature correlations},
journal = {Journal of Computational Science},
volume = {83},
pages = {102472},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102472},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324002655},
author = {Xiaoying Pan and Hao Wang and Mingzhu Lei and Tong Ju and Lin Bai},
keywords = {Multivariate time series, Missing data, Ensemble filling model, Two-way correlation, Variable correlation},
abstract = {Multivariate real-life time series data often contain missing values. These missing values often affect subsequent prediction tasks. Traditional imputation methods generally consider only some of the characteristics of multivariate time series data. This can easily lead to inaccurate filling results. In this paper, a feature correlation-based bidirectional recurrent network (BRNN-FR) is proposed to solve the problem of missing values in multivariate sequence data. First, this method involves the design of a bidirectional prediction network based on time intervals and the use of forward and reverse time series information between data points to obtain the characteristics of data changes with time to the greatest extent. Second, considering the correlation between features, a combined feature selection strategy based on the Pearson correlation coefficient and mutual information was proposed. A multiple regression model was established to predict between features. Finally, a bidirectional network ensemble filling algorithm based on the relationships between features is established to predict missing values. Comprehensive experiments on four public datasets show that the mean absolute error (MAE), root mean square error (RMSE) and maximum R2 value (R2_score) of the BRNN-FR algorithm in the direct imputation test are better than those of the other comparison methods in most cases. BRNN-FR also achieved a better area under the curve (AUC) in the indirect comparison experiment of two classifications of in-hospital death after filling the medical dataset. Using the AIR air quality dataset and the power transformer temperature dataset from the ETTH1 interpolation regression to predict the next 3 hours and 6 hours of average numerical results, most of the optimal regression results are obtained.}
}
@article{GAO2024113119,
title = {Dynamics optimization of small branch pipes in nuclear power plants based on machine learning algorithms},
journal = {Nuclear Engineering and Design},
volume = {422},
pages = {113119},
year = {2024},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2024.113119},
url = {https://www.sciencedirect.com/science/article/pii/S002954932400219X},
author = {Hongbo Gao and Shuai Zhou and Lei Lin and Zhilin Chen and Decheng Xu and Changning Li and XiaoFeng Zhu},
abstract = {Vibration fatigue failure of small branch pipes poses a great threat to the safe operation of nuclear power plants. However, the transient and wide-band vibration problems are not adequately considered in ASME and RCC-M code, resulting in repeated fatigue failures. In addition, the current research mainly focuses on vibration test methods and fatigue analysis methods, neglecting the study of pipeline vibration characteristics. Therefore, innovative approaches were essential for effectively managing complex dynamic loads. In this study, an innovative approach combining backpropagation artificial neural networks (BP-ANN) and non-dominated sorting Genetic Algorithm II (NSGA-II) was proposed to optimize the vibration of these pipes. The goal was mitigating vibration-induced failures by enhancing operational stability. The methodology progressed through several key stages. Firstly, BP-ANN was utilized for regression analysis, correlating pipe characteristics to vibration effects. Through regression analysis, the complex interrelationships governing the pipes' dynamic behavior was revealed. Subsequently, based on the regression model, NSGA-II was used to derive an optimal combination of design parameters to minimize the vibration response. The proposed technique was validated on an L-shaped cantilevered pipe via finite element simulations and physical experiments. The analysis case shows that the BP-ANN model demonstrated excellent accuracy in predicting vibration responses. Meanwhile, NSGA-II successfully revealed the trade-offs between conflicting objectives, generating a Pareto-optimal set balancing stability under different excitation directions. This study highlights the potential of machine learning methods for dynamic optimization of small branch pipes in nuclear power plants, and verifies the accuracy and effectiveness of the method through experiments. The research results provide a new idea for small branch pipe design and vibration control of nuclear power plant, which contributes to enhancing the safety and reliability of small branch pipes.}
}
@article{IQBAL20226324,
title = {Test case prioritization for model transformations},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {8, Part B},
pages = {6324-6338},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002147},
author = {Saqib Iqbal and Issam Al-Azzoni},
keywords = {Model transformations, Model-driven engineering, Regression testing, Test case prioritization},
abstract = {The application of model transformations is a critical component in Model-Driven Engineering (MDE). To ensure the correctness of the generated models, these model transformations need to be extensively tested. However, during the regression testing of these model transformations, it becomes too costly to frequently run a large number of test cases. Test case prioritization techniques are needed to rank the test cases and help the tester during the regression testing to be more efficient. The objective is to rank the fault revealing test cases higher so that a tester can only execute the top ranked test cases and still be able to detect as many faults as possible in the case of limited budget and resources. The aim of this paper is to present a test prioritization approach for the regression testing of model transformations. The approach is based on exploiting the rule coverage information of the test cases. The paper presents an empirical study which compares several techniques introduced by our approach for prioritizing test cases. The approach is complemented with a tool that implements the proposed techniques and can automatically generate test case orderings.}
}
@article{WANG201814,
title = {Using reliability risk analysis to prioritize test cases},
journal = {Journal of Systems and Software},
volume = {139},
pages = {14-31},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.01.033},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218300128},
author = {Ying Wang and Zhiliang Zhu and Bo Yang and Fangda Guo and Hai Yu},
keywords = {Regression testing, Test case prioritization, Probabilistic risk analysis, Information flow, Complex network},
abstract = {In this paper, we present a risk-based test case prioritization (Ri-TCP) algorithm based on the transmission of information flows among software components. Most of the existing approaches rely on the historical code changes or test case execution data, few of them effectively use the system topology information covered by test cases when scheduling the execution of test cases. From the perspective of code structure, the proposed algorithm firstly maps software into an information flow-based directed network model. Then, functional paths covered by each test case are represented by a set of barbell motifs. Finally, combining with probabilistic risk analysis (PRA) and fault tree model, we assign a priority to each test case by calculating the sum of risk indexes of all the barbells covered by it. Experimental results demonstrate that Ri-TCP technique has a higher detection rate of faults with serious risk indicators and performs stably in different systems, compared with the other state-of-the-art algorithms.}
}
@article{HABIB2024200164,
title = {A similarity-based multi-objective test optimization technique using search algorithm},
journal = {Systems and Soft Computing},
volume = {6},
pages = {200164},
year = {2024},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2024.200164},
url = {https://www.sciencedirect.com/science/article/pii/S2772941924000930},
author = {Amir Sohail Habib and Saif Ur Rehman Khan and Shahid Hussain and Naseem Ibrahim and Habib un Nisa and Abdullah Yousafzai},
keywords = {Regression testing, test suite reduction, Multi-objective optimization, Meta-heuristic search algorithms, Grey Wolf Optimizer},
abstract = {Context:
Software undergoes a constant evolution driven by ongoing changes in customer requirements, which enhances the competitive advantage. Regression testing plays a pivotal role by ensuring that modifications have not introduced detrimental effects on the system under test.
Problem:
However, regression testing becomes prohibitively expensive as the software grows in complexity and the size of the test suite also expands. Moreover, keeping the test cases up-to-date and managing the relevant test data can become a laborious and challenging task. Hence, it is required to optimize the test suite by finding a diverse subset of test cases having high code coverage, fault-detection rate, and minimal execution time.
Objective:
To solve the regression test optimization problem, the researchers have proposed various approaches including greedy algorithms, search-based algorithms, and clustering algorithms. However, existing approaches lack in finding the global optimal solution and are mostly focused on the single-objective test optimization problem. Inspired by this, we propose a Similarity-based Multi-Objective Optimization Technique (SMOOT) for test suite reduction using a Grey Wolf Optimizer (GWO) algorithm. The proposed technique employs different similarity metrics, including Cosine Similarity, Euclidean Distance, Jaccard Similarity, Manhattan Distance, and Minkowski Distance, to evaluate the similarity score of the tests. This ensures a comprehensive assessment of test diversity to achieve high code coverage and fault-detection rate while minimizing the test execution cost.
Method:
We evaluated the performance of GWO with state-of-the-art search-based algorithms using three varying types of case studies. Similarly, to evaluate the similarity score of the considered search algorithms, we employed state-of-the-art similarity measures.
Results:
The experimental results revealed that GWO significantly outperformed the considered search algorithms by attaining high code coverage and fault-detection rate while minimizing the test execution time. Moreover, we found that GWO attained a higher similarity score than the other considered search algorithms using the employed similarity measures.
Conclusion:
Based on the attained results, we believe that the proposed technique could be useful for the researchers and practitioners by effectively handling multi-objective regression test optimization problem.}
}
@article{DAS2024100170,
title = {An advantageous charging/discharging scheduling of electric vehicles in a PV energy enhanced power distribution grid},
journal = {Green Energy and Intelligent Transportation},
volume = {3},
number = {2},
pages = {100170},
year = {2024},
issn = {2773-1537},
doi = {https://doi.org/10.1016/j.geits.2024.100170},
url = {https://www.sciencedirect.com/science/article/pii/S2773153724000227},
author = {Pritam Das and Partha Kayal},
keywords = {Charging-discharging scheduling, Electric vehicles, Solar irradiance forecasting, Optimization, Distribution network},
abstract = {Electric vehicles (EVs) are going to overrule the transportation sector due to their pollution-free technology and low running costs. However, charging the EVs causes significant power demand and stress on the power delivery network. The challenge can be tackled well when charging and discharging scheduling are coordinated with intelligent EV routing. In this work, two-stage charging and discharging scheduling are proposed. In the first stage, a time scheduling algorithm is structured to identify EV charging/discharging slots at different hours, and at a later stage, the slots are optimally distributed among different charging stations. Routing of the EVs towards the EVCSs has been designed to enhance the useful participation of the EVs in the charging and discharging program. In this regard, a possible number of EVs in the test region has been forecasted with a regression model. The adequacy of the combined charging-discharging and location scheduling model is tested on a typical PV-enhanced 28-bus Indian distribution network. Three case studies containing three sub-cases in each have been performed incorporating the choice of the EV owners towards charging and discharging in different time slots in a day. The case studies have resulted in a peak-to-average ratio (PAR) of 1.151,0, 1.165,0, 1.196,8, 1.165,0, 1.180,9, 1.196,8, 1.196,8, 1.196,8 and 1.196,8 for the 24-h demand pattern in Case-1a, Case-1b, Case-1c, Case-2a, Case-2b, Case-2c, Case-3a, Case-3b and Case-1c respectively in comparison to a PAR of 1.2 for the 24-h demand in base case.}
}
@article{CHI2020110539,
title = {Relation-based test case prioritization for regression testing},
journal = {Journal of Systems and Software},
volume = {163},
pages = {110539},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110539},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300212},
author = {Jianlei Chi and Yu Qu and Qinghua Zheng and Zijiang Yang and Wuxia Jin and Di Cui and Ting Liu},
keywords = {Software testing, Test case prioritization, Dynamic call sequence},
abstract = {Test case prioritization (TCP), which aims at detecting faults as early as possible is broadly used in program regression testing. Most existing TCP techniques exploit coverage information with the hypothesis that higher coverage has more chance to catch bugs. Static structure information such as function and statement are frequently employed as coverage granularity. However, the former consumes less costs but presents lower capability to detect faults, the latter typically incurs more overhead. In this paper, dynamic function call sequences are argued that can guide TCP effectively. Same set of functions/statements can exhibit very different execution behaviors. Therefore, mapping program behaviors to unit-based (function/statement) coverage may not be enough to predict fault detection capability. We propose a new approach AGC (Additional Greedy method Call sequence). Our approach leverages dynamic relation-based coverage as measurement to extend the original additional greedy coverage algorithm in TCP techniques. We conduct our experiments on eight real-world java open source projects and systematically compare AGC against 22 state-of-the-art TCP techniques with different granularities. Results show that AGC outperforms existing techniques on large programs in terms of bug detection capability, and also achieves the highest mean APFD value. The performance demonstrates a growth trend as the size of the program increases.}
}
@article{ALREFAI2025103343,
title = {Component-based architectural regression test selection for modularized software systems},
journal = {Journal of Systems Architecture},
volume = {160},
pages = {103343},
year = {2025},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2025.103343},
url = {https://www.sciencedirect.com/science/article/pii/S1383762125000153},
author = {Mohammed Al-Refai and Mahmoud M. Hammad},
keywords = {Regression test selection, Static analysis, Component-based architecture, Java platform module system, Software architecture},
abstract = {Regression testing is an essential part of software development, but it can be costly and require significant computational resources. Regression Test Selection (RTS) improves regression testing efficiency by only re-executing the tests that have been affected by code changes. Recently, dynamic and static RTS techniques for Java projects showed that selecting tests at a coarser granularity, class-level, is more effective than selecting tests at a finer granularity, method- or statement-level. However, prior techniques are mainly considering Java object-oriented projects but not modularized Java projects. Given the explicit support of architectural constructs introduced by the Java Platform Module System (JPMS) in the ninth edition of Java, these research efforts are not customized for component-based Java projects. To that end, we propose two static component-based RTS approaches called CORTS and its variant C2RTS tailored for component-based Java software systems. CORTS leverages the architectural information such as components and ports, specified in the module descriptor files, to construct module-level dependency graph and identify relevant tests. The variant, C2RTS, is a hybrid approach in which it integrates analysis at both the module and class levels, employing module descriptor files and compile-time information to construct the dependency graph and identify relevant tests. We evaluated CORTS and C2RTS on 1200 revisions of 12 real-world open source software systems, and compared the results with those of class-level dynamic (Ekstazi) and static (STARTS) RTS approaches. The results showed that CORTS and C2RTS outperformed the static class-level RTS in terms of safety violation that measures to what extent an RTS technique misses test cases that should be selected. Using Ekstazi as the baseline, the average safety violation with respect to Ekstazi was 1.14% for CORTS, 2.21% for C2RTS, and 3.19% for STARTS. On the other hand, the results showed that CORTS and C2RTS selected more test cases than Ekstazi and STARTS. The average reduction in test suite size was 22.78% for CORTS and 43.47% for C2RTS comparing to the 68.48% for STARTS and 84.21% for Ekstazi. For all the studied subjects, CORTS and C2RTS reduced the size of the static dependency graphs compared to those generated by static class-level RTS, leading to faster graph construction and analysis for test case selection. Additionally, CORTS and C2RTS achieved reductions in overall end-to-end regression testing time compared to the retest-all strategy.}
}
@article{HETTIARACHCHI20161,
title = {Risk-based test case prioritization using a fuzzy expert system},
journal = {Information and Software Technology},
volume = {69},
pages = {1-15},
year = {2016},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2015.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0950584915001500},
author = {Charitha Hettiarachchi and Hyunsook Do and Byoungju Choi},
keywords = {Regression testing, Requirements risks-based testing, Test case prioritization, Fuzzy expert system, Empirical study},
abstract = {Context: The use of system requirements and their risks enables software testers to identify more important test cases that can reveal the faults associated with system components. Objective: The goal of this research is to make the requirements risk estimation process more systematic and precise by reducing subjectivity using a fuzzy expert system. Further, we provide empirical results that show that our proposed approach can improve the effectiveness of test case prioritization. Method: In this research, we used requirements modification status, complexity, security, and size of the software requirements as risk indicators and employed a fuzzy expert system to estimate the requirements risks. Further, we employed a semi-automated process to gather the required data for our approach and to make the risk estimation process less subjective. Results: The results of our study indicated that the prioritized tests based on our new approach can detect faults early, and also the approach can be effective at finding more faults earlier in the high-risk system components compared to the control techniques. Conclusion: We proposed an enhanced risk-based test case prioritization approach that estimates requirements risks systematically with a fuzzy expert system. With the proposed approach, testers can detect more faults earlier than with other control techniques. Further, the proposed semi-automated, systematic approach can easily be applied to industrial applications and can help improve regression testing effectiveness.}
}
@article{CHONG20131994,
title = {Efficient software clustering technique using an adaptive and preventive dendrogram cutting approach},
journal = {Information and Software Technology},
volume = {55},
number = {11},
pages = {1994-2012},
year = {2013},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2013.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0950584913001481},
author = {Chun Yong Chong and Sai Peck Lee and Teck Chaw Ling},
keywords = {Software maintenance, Design recovery, Software clustering, Remodularization},
abstract = {Context
Software clustering is a key technique that is used in reverse engineering to recover a high-level abstraction of the software in the case of limited resources. Very limited research has explicitly discussed the problem of finding the optimum set of clusters in the design and how to penalize for the formation of singleton clusters during clustering.
Objective
This paper attempts to enhance the existing agglomerative clustering algorithms by introducing a complementary mechanism. To solve the architecture recovery problem, the proposed approach focuses on minimizing redundant effort and penalizing for the formation of singleton clusters during clustering while maintaining the integrity of the results.
Method
An automated solution for cutting a dendrogram that is based on least-squares regression is presented in order to find the best cut level. A dendrogram is a tree diagram that shows the taxonomic relationships of clusters of software entities. Moreover, a factor to penalize clusters that will form singletons is introduced in this paper. Simulations were performed on two open-source projects. The proposed approach was compared against the exhaustive and highest gap dendrogram cutting methods, as well as two well-known cluster validity indices, namely, Dunn’s index and the Davies-Bouldin index.
Results
When comparing our clustering results against the original package diagram, our approach achieved an average accuracy rate of 90.07% from two simulations after the utility classes were removed. The utility classes in the source code affect the accuracy of the software clustering, owing to its omnipresent behavior. The proposed approach also successfully penalized the formation of singleton clusters during clustering.
Conclusion
The evaluation indicates that the proposed approach can enhance the quality of the clustering results by guiding software maintainers through the cutting point selection process. The proposed approach can be used as a complementary mechanism to improve the effectiveness of existing clustering algorithms.}
}
@article{SHIN2022111174,
title = {An empirical comparison of four Java-based regression test selection techniques},
journal = {Journal of Systems and Software},
volume = {186},
pages = {111174},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111174},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002582},
author = {Min Kyung Shin and Sudipto Ghosh and Leo R. Vijayasarathy},
keywords = {Regression test selection, Dynamic analysis, Static analysis, Safety, Precision, Test suite reduction},
abstract = {Regression testing is a critical but expensive activity that ensures previously tested functionality is not broken by changes made to the code. Regression test selection (RTS) techniques aim to select and run only those test cases impacted by code changes. The techniques possess different characteristics related to their selection accuracy, test suite size reduction, time to select and run the test cases, and the fault detection ability of the selected test cases. This paper presents an empirical comparison of four Java-based RTS techniques (Ekstazi, HyRTS, OpenClover and STARTS) using multiple revisions from five open source projects. The results show that STARTS selects more test cases than Ekstazi and HyRTS. OpenClover selects the most test cases. Safety and precision violations measure to what extent a technique misses test cases that should be selected and selects only the test cases that are impacted. Using HyRTS as the baseline, OpenClover had significantly worse safety violations compared to STARTS and Ekstazi, and significantly worse precision violations compared to Ekstazi. While STARTS and Ekstazi did not differ on safety violations, Ekstazi had significantly fewer precision violations than STARTS. The average fault detection ability of the RTS techniques was 8.75% lower than the original test suite.}
}
@article{AGARWAL2023200175,
title = {A novel DCNN-ELM hybrid framework for face mask detection},
journal = {Intelligent Systems with Applications},
volume = {17},
pages = {200175},
year = {2023},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2022.200175},
url = {https://www.sciencedirect.com/science/article/pii/S2667305322001120},
author = {Charu Agarwal and Pranjul Itondia and Anurag Mishra},
keywords = {COVID-19, Face mask detector, Masked face, Transfer learning, Convolution neural network},
abstract = {The Coronavirus disease (2019) has caused massive destruction of human lives and capital around the world. The latest variant Omicron is proved to be the most infectious of all its previous counterparts – Alpha, Beta and Delta. Various measures are identified, tested and implemented to minimize the attack on humans. Face masks are one of those measures that are shown to be very effective in containing the infection. However, it requires continuous monitoring for law enforcement. In the present manuscript, a detailed research investigation using different ablation studies is carried out to develop the framework for face mask recognition using pre-trained deep convolution neural networks (DCNN) models used in conjunction with a fast single layer feed-forward neural network (SLFNN) commonly known as Extreme Learning Machine (ELM) as classification technique. The ELM is well known for its real time data processing capabilities and has been successfully applied both for regression and classification problems of image processing and biomedical domain. It is for the first time that in this paper we have proposed the use of ELM as classifier for face mask detection. As a precursor to this, for feature selection, six pre-trained DCNNs such as Xception, Vgg16, Vgg19, ResNet50, ResNet 101 and ResNet152 are tested for this purpose. The best testing accuracy is obtained in case of ResNet152 transfer learning model used with ELM as the classifier. The performance evaluation through different ablation studies on testing accuracy explicitly proves that ResNet152 - ELM hybrid architecture is not only the best among the selected transfer learning models but also proves so when it is compared with several other classifiers used for the face mask detection operation. Through this investigation, novelty of the use of ResNet152 + ELM for face mask detection framework in real time domain is established.}
}
@article{SANTOS2023108088,
title = {A data-driven optimization model for the workover rig scheduling problem: Case study in an oil company},
journal = {Computers & Chemical Engineering},
volume = {170},
pages = {108088},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2022.108088},
url = {https://www.sciencedirect.com/science/article/pii/S0098135422004215},
author = {Iuri Martins Santos and Silvio Hamacher and Fabricio Oliveira},
keywords = {Oil and gas, Workover rig scheduling problem, Data-driven optimization, Simulation},
abstract = {After completion, oil wells often require intervention services to increase productivity, correct oil flow losses, and solve mechanical failures. These interventions, known as workovers, are made using oil rigs, an expensive and scarce resource. The workover rig scheduling problem (WRSP) comprises deciding which wells demanding workovers will be attended to, which rigs will serve them, and when the operations must be performed, minimizing the rig fleet costs and the oil production loss associated with the workover delay. This study presents a data-driven optimization methodology for the WRSP using text mining and regression models to predict the duration of the workover activities and a mixed-integer linear programming model to obtain the solutions for the model. A sensitivity analysis is performed using simulation to measure the impact of the regression error in the solution.}
}
@incollection{QU2013141,
title = {Chapter 4 - Testing of Configurable Systems},
editor = {Atif Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {89},
pages = {141-162},
year = {2013},
issn = {0065-2458},
doi = {https://doi.org/10.1016/B978-0-12-408094-2.00004-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780124080942000047},
author = {Xiao Qu},
keywords = {Software testing, Configurable software testing, Regression testing, Configuration prioritization, Test case prioritization, Test case selection, Change impact analysis, Combinatorial interaction testing},
abstract = {Configurable software system allows users to customize its applications in various ways, and is becoming increasingly prevalent. Testing configurable software requires extra effort over testing traditional software because there is evidence that running the same test case under different configurations may detect different faults. Differentiating test cases and configurations as two independent factors for testing, we must consider not just which test case to utilize, but also which configurations to test. Ideally, an exhaustive testing approach would combine every test case with every possible configuration. But since the full configuration space of most software systems is huge, it is infeasible to test all possible configurations with all test cases. Instead, selection techniques are necessary to select configurations for testing a software system, and to select test cases for the different configurations under test. Despite successful selection techniques, sometimes it is still costly to run only selected configurations and test cases. In particular, the cost is magnified when new features and functionality are added as a system evolves, and the new version is regression tested. Regression testing is an important but expensive way to build confidence that software changes do not introduce new faults as the software evolves, and many efforts have been made to improve its performance given limited resources. Test case prioritization has been extensively researched to determine which test cases should be run first, but has rarely been considered for configurations. In this chapter we introduce issues relevant to testing configurable software systems, we then present techniques for both selection and prioritization of these systems.}
}
@article{FAIZ20241217,
title = {A Novel Fractional Dengue Transmission Model in the Presence of Wolbachia Using Stochastic Based Artificial Neural Network},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {139},
number = {2},
pages = {1217-1238},
year = {2024},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.029879},
url = {https://www.sciencedirect.com/science/article/pii/S152614922400211X},
author = {Zeshan Faiz and Iftikhar Ahmed and Dumitru Baleanu and Shumaila Javeed},
keywords = {Wolbachia, dengue, neural network, vertical transmission, mean square error, Levenberg-Marquardt},
abstract = {The purpose of this research work is to investigate the numerical solutions of the fractional dengue transmission model (FDTM) in the presence of Wolbachia using the stochastic-based Levenberg-Marquardt neural network (LM-NN) technique. The fractional dengue transmission model (FDTM) consists of 12 compartments. The human population is divided into four compartments; susceptible humans (Sh), exposed humans (Eh), infectious humans (Ih), and recovered humans (Rh). Wolbachia-infected and Wolbachia-uninfected mosquito population is also divided into four compartments: aquatic (eggs, larvae, pupae), susceptible, exposed, and infectious. We investigated three different cases of vertical transmission probability (η), namely when Wolbachia-free mosquitoes persist only (η=0.6), when both types of mosquitoes persist (η = 0.8), and when Wolbachia-carrying mosquitoes persist only (η = 1). The objective of this study is to investigate the effectiveness of Wolbachia in reducing dengue and presenting the numerical results by using the stochastic structure LM-NN approach with 10 hidden layers of neurons for three different cases of the fractional order derivatives (α = 0.4, 0.6, 0.8). LM-NN approach includes a training, validation, and testing procedure to minimize the mean square error (MSE) values using the reference dataset (obtained by solving the model using the Adams-Bashforth-Moulton method (ABM). The distribution of data is 80% data for training, 10% for validation, and, 10% for testing purpose) results. A comprehensive investigation is accessible to observe the competence, precision, capacity, and efficiency of the suggested LM-NN approach by executing the MSE, state transitions findings, and regression analysis. The effectiveness of the LM-NN approach for solving the FDTM is demonstrated by the overlap of the findings with trustworthy measures, which achieves a precision of up to 10−4.}
}
@article{ISMAEEL2023110604,
title = {A structural equation modelling paradigm for eco-rehabilitation and adaptive reuse of cultural heritage buildings},
journal = {Building and Environment},
volume = {242},
pages = {110604},
year = {2023},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2023.110604},
url = {https://www.sciencedirect.com/science/article/pii/S0360132323006315},
author = {Walaa S.E. Ismaeel and Ahmed Gouda Mohamed},
keywords = {Adaptive reuse, Eco-rehabilitation, Energy efficiency, Indoor environmental quality, Materials and resources, Structural equation modelling},
abstract = {The study developed an integrated hierarchical structural equation modelling (SEM) for the eco-rehabilitation and adaptive reuse of cultural heritage buildings (CHBs). The research method constituted 1) keyword-based mapping analysis, 2) questionnaire survey, and 3) model formulation using SEM. The model constituted three environmental parameters, corresponding criteria, and their relative importance weights (RIWs). This portrayed the efficient use of materials and resources (MR), indoor environmental quality (IEQ), and energy efficiency (EE), and ranked them to prioritize action. The results showed that MR, IEQ, and EE acquired RIWs of 33.03%, 32.28%, and 34.7%, respectively. For MR criteria level, heritage elements' integrity, material durability and resilience, and designing for adaptability attained RIWs of 8.67%, 8.12%, and 7.95%, respectively. For IEQ criteria level, heritage building age and condition, the efficiency of the ventilation system, as well as space function and activity, depicted RIWs of 15.34%, 13.33%, and 11.41%, mutually. For EE criteria level, interventions to attain an energy-efficient heritage building envelope, the efficiency of the electromechanical system, and installing smart systems for monitoring and control rendered RIWs of 15.59%, 15.01%, and 13.61%, consecutively. The study applied the proposed model to two distinct case study projects. The differences between them were evident at both the parameter and criteria levels due to either the inherent potentials or limitations of the project. Thus, the proposed model provided flexibility for application and promoted novel approaches for heritage conservationists, environmental engineers, and decision-makers to think, act, and respond to CHB eco-rehabilitation and adaptive reuse principles and practices.}
}
@article{HAIDER2024108472,
title = {Subnetwork prediction approach for aircraft schedule recovery},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108472},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108472},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624006304},
author = {Imran Haider and Goutam Sen and Mohd Arsalan and Amit Kumar Das},
keywords = {Aircraft schedule recovery, Subnetwork selection, Machine learning, Recursive feature elimination, Optimization decision},
abstract = {The combinatorial optimization techniques for the aircraft schedule recovery problem are too expensive to compute. However, we require a reasonable solution within 1–2 min for real-time application. The computational time of traditional optimization algorithms will drastically reduce if we can accurately predict the subnetwork affected by the disruption. In this study, we advocate the use of machine learning (ML) as a promising tool to predict the subnetwork. The optimal recovery schedules for a large number of disruptions are used for offline training, and subsequently, the trained ML model is employed to reduce the search space for new disruption cases substantially. To achieve this, we employ a unique feature space specifically designed to capture the essential characteristics of the problem. A notable contribution is constructing a novel feature space based on revised aircraft schedules designed to capture the essential characteristics of the problem. The recursive feature elimination technique is employed for optimal feature selection. Five machine learning classifiers: Logistic Regression, Random Forest, Extreme gradient boosting, Light gradient boosting, and Categorical Boosting are compared. The performance is evaluated on real data obtained from an airline company. Our study demonstrates that, with the subnetwork of aircraft predicted by the classifier, the computational time of the column generation approach is remarkably reduced without deteriorating the solution quality in all the disruption instances tested, with more than 98% of the instances being solved within 60 s. The results highlight the remarkable advantage of integrating ML in the pre-optimization phase.}
}
@article{GARCIA2021913,
title = {Test Case Generation From Web Usage Information},
journal = {Procedia Computer Science},
volume = {181},
pages = {913-920},
year = {2021},
note = {CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.247},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921002908},
author = {Jorge Esparteiro Garcia and Ana C.R. Paiva and Anca-Maria Bizoi},
keywords = {Requirements engineering, test cases, web usage, recommender systems},
abstract = {In the context of SaaS (Software as a Service) where software has to be up and running 7 days a week and 24 hours a day, keeping the requirements specification and related test cases up to date can be difficult. Managing requirements in this context has additional challenges that need to be taken into account, for instance, re-prioritize requirements continuously and identify/update new dependencies among them. When requirements change, related test cases need to be updated accordingly. We claim that extracting and analyzing the usage of the SaaS can help to maintain requirements and test cases updated and contribute to improve the overall quality of the services provided. This paper presents an extension to REQAnalytics. REQAnalytics is a recommendation system that collects information about the usage of a SaaS and generates recommendations to improve the SaaS provided. The evolution involves extending the analysis performed over the sequences of functionalities (requirements) and refining the data provided for Software Requirements Specification, with the purpose of helping the requirements engineers in the requirement maintenance activities, and to improve the overall quality of the services. Furthermore, the extension presented in this paper is able to generate test cases in a regression testing context.}
}
@article{SUDHAMATHI2024101277,
title = {Ensemble regression based Extra Tree Regressor for hybrid crop yield prediction system},
journal = {Measurement: Sensors},
volume = {35},
pages = {101277},
year = {2024},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2024.101277},
url = {https://www.sciencedirect.com/science/article/pii/S2665917424002538},
author = {T. Sudhamathi and K. Perumal},
keywords = {Crop yield prediction, LESSO regression, Kernel, Principal component analysis, Ensemble regression, Extra tree regressor},
abstract = {Objective
The worldwide economies are built on agriculture, and plans for food security, resource allocation, and agricultural practices are all heavily influenced by accurate crop production predictions. Predictive models are becoming indispensable tools for predicting crop prospects due to the development of technology based on data.
Limitation
A significant disadvantage of the ER-ETR for Hybrid Crop Yield Prediction System can involve overfitting, particularly in cases when the dataset is small or the model complexity is not well managed. Inaccurate forecasts based on unreported data and decreased generalization can result from approach.
Method
Initially, the dataset is collected from the GitHub and preprocessed using the Standardscaler method. 70 % of the preprocessed data is used as the training set, and the remaining 30 % is used as the testing set. Kernel Principal Component Analysis (KPCA) is employed to extract the feature. The Least Absolute Shrinkage and Selection Operator (LESSO) Regression is used to feature selection.A reliable method for predicting hybrid crop productivity is provided by the suggested ensemble regression that makes use of feature ensemble regression using Extra Tree Regressor (ER-ETR).
Result
A simple internet-based programme for immediate forecasting is created using the Python web framework, and the model that has been trained may be used to predict the resulting profitability. Mean absolute error (MAE), mean square error (MSE), root mean square error (RMSE) and R2 were the testing metrics utilized to assess the classification model. With a 95 % accuracy rate, the suggested model is superior to existing models in terms of accuracy in crop production forecasting while still preserving the data's original distribution.Because of the intuitive online interface, stakeholders can forecast immediately and make well-informed decisions on the best use of resources from agriculture.
Conclusion
The study creates a hybrid crop yield prediction system using the ER-ETR approach. Agricultural forecasting benefits greatly from its capacity to integrate several models and take advantage of each one's advantages, which improves prediction accuracy and dependability.}
}
@article{DECARVALHOSERVIA2024954,
title = {The automated discovery of kinetic rate models – methodological frameworks††Electronic supplementary information (ESI) available: (1) A detailed evaluation of various model selection criteria, leading to the adoption of AIC for both ADoK-S and ADoK-W; (2) an analytical discussion leading to the utilization of the two top-performing models from ADoK-S or ADoK-W in MBDoE, as opposed to using Gaussian process state space models and other naive parametric models; (3) a benchmarking study comparing state-of-the-art derivative approximation methods against our GP-based approach; (4) the performance of ADoK-S on an additional multi-reaction case study. See DOI: https://doi.org/10.1039/d3dd00212h},
journal = {Digital Discovery},
volume = {3},
number = {5},
pages = {954-968},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00212h},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000676},
author = {Miguel Ángel {de Carvalho Servia} and Ilya Orson Sandoval and King Kuok (Mimi) Hii and Klaus Hellgardt and Dongda Zhang and Ehecatl {Antonio del Rio Chanona}},
abstract = {The industrialization of catalytic processes requires reliable kinetic models for their design, optimization and control. Mechanistic models require significant domain knowledge, while data-driven and hybrid models lack interpretability. Automated knowledge discovery methods, such as ALAMO (Automated Learning of Algebraic Models for Optimization), SINDy (Sparse Identification of Nonlinear Dynamics), and genetic programming, have gained popularity but suffer from limitations such as needing model structure assumptions, exhibiting poor scalability, and displaying sensitivity to noise. To overcome these challenges, we propose two methodological frameworks, ADoK-S and ADoK-W (Automated Discovery of Kinetic rate models using a Strong/Weak formulation of symbolic regression), for the automated generation of catalytic kinetic models using a robust criterion for model selection. We leverage genetic programming for model generation and a sequential optimization routine for model refinement. The frameworks are tested against three case studies of increasing complexity, demonstrating their ability to retrieve the underlying kinetic rate model with limited noisy data from the catalytic systems, showcasing their potential for chemical reaction engineering applications.}
}
@article{ANSARI2016152,
title = {Optimized Regression Test Using Test Case Prioritization},
journal = {Procedia Computer Science},
volume = {79},
pages = {152-160},
year = {2016},
note = {Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.03.020},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916001514},
author = {Ahlam Ansari and Anam Khan and Alisha Khan and Konain Mukadam},
keywords = {Regression testing, Test case prioritization, Ant colony optimization},
abstract = {Regression testing ensures that changes made in the fixes or any enhancement changes do not impact the previously working functionality. Whenever software is modified, a set of test cases are run to assure that changes don’t affect the other parts of the software. Hence all existing test cases need to be tested as well as new test cases need to be created. It is nonviable to re-execute every test case for a given software, because if there are more number of test cases to be tested, the more effort and time is required. This problem can be solved by prioritizing test cases. Test case prioritization techniques reorder the priority of a test case in an attempt to ensure that maximum faults are uncovered by the high prioritized test cases. In this paper we propose an optimized test case prioritization technique using Ant Colony Optimization (ACO) to reduce the cost, effort and time taken to perform regression testing and also uncover maximum faults.}
}
@article{MENDONCA2024112157,
title = {Feature-oriented test case selection and prioritization during the evolution of highly-configurable systems},
journal = {Journal of Systems and Software},
volume = {217},
pages = {112157},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112157},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224002024},
author = {Willian D.F. Mendonça and Wesley K.G. Assunção and Silvia R. Vergilio},
keywords = {Software evolution, Software product line, Regression testing, Test case prioritization},
abstract = {Testing Highly Configurable Systems (HCSs) is a challenging task, especially in an evolution scenario where features are added, changed, or removed, which hampers test case selection and prioritization. Existing work is usually based on the variability model, which is not always available or updated. Yet, the few existing approaches rely on links between test cases and changed files (or lines of code), not considering how features are implemented, usually spread over several and unchanged files. To overcome these limitations, we introduce FeaTestSelPrio, a feature-oriented test case selection and prioritization approach for HCSs. The approach links test cases to feature implementations, using HCS pre-processor directives, to select test cases based on features affected by changes in each commit. After, the test cases are prioritized according to the number of features they cover. Our approach selects a greater number of tests and takes longer to execute than a changed-file-oriented approach, used as baseline, but FeaTestSelPrio performs better regarding detected failures. By adding the approach execution time to the execution time of the selected test cases, we reached a reduction of ≈50%, in comparison with retest-all. The prioritization step allows reducing the average test budget in 86% of the failed commits.}
}
@article{HUANG2020110712,
title = {Regression test case prioritization by code combinations coverage},
journal = {Journal of Systems and Software},
volume = {169},
pages = {110712},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110712},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301540},
author = {Rubing Huang and Quanjun Zhang and Dave Towey and Weifeng Sun and Jinfu Chen},
keywords = {Software testing, Regression testing, Test case prioritization, Code combinations coverage},
abstract = {Regression test case prioritization (RTCP) aims to improve the rate of fault detection by executing more important test cases as early as possible. Various RTCP techniques have been proposed based on different coverage criteria. Among them, a majority of techniques leverage code coverage information to guide the prioritization process, with code units being considered individually, and in isolation. In this paper, we propose a new coverage criterion, code combinations coverage, that combines the concepts of code coverage and combination coverage. We apply this coverage criterion to RTCP, as a new prioritization technique, code combinations coverage based prioritization (CCCP). We report on empirical studies conducted to compare the testing effectiveness and efficiency of CCCP with four popular RTCP techniques: total, additional, adaptive random, and search-based test prioritization. The experimental results show that even when the lowest combination strength is assigned, overall, the CCCP fault detection rates are greater than those of the other four prioritization techniques. The CCCP prioritization costs are also found to be comparable to the additional test prioritization technique. Moreover, our results also show that when the combination strength is increased, CCCP provides higher fault detection rates than the state-of-the-art, regardless of the levels of code coverage.}
}
@article{SANTOS2021107649,
title = {Multi-objective adaptive differential evolution for SVM/SVR hyperparameters selection},
journal = {Pattern Recognition},
volume = {110},
pages = {107649},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107649},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320304520},
author = {Carlos Eduardo da Silva Santos and Renato Coral Sampaio and Leandro dos Santos Coelho and Guillermo Alvarez Bestard and Carlos Humberto Llanos},
keywords = {Support vector machines, Parameters selection problem, Multi-objective optimization, Differential evolution, Adaptive parameters strategy},
abstract = {Parameters Selection Problem (PSP) is a relevant and complex optimization issue in Support Vector Machine (SVM) and Support Vector Regression (SVR), looking for obtaining an optimal set of hyperparameters. In our case, the optimization problem is addressed to obtain models that minimize the number of support vectors and maximize generalization capacity. However, to obtain accurate and low complexity solutions, defining an adequate kernel function and the SVM/SVR’s hyperparameters are necessary, which currently represents a relevant research topic. To tackle this problem, this work proposes a multi-objective metaheuristic named Adaptive Parameter control with Mutant Tournament Multi-Objective Differential Evolution (APMT-MODE). Its performance is first tested in a series of benchmarks for classification and regression problems using simple kernels such as Gaussian and polynomial kernels. In both cases, the APMT-MODE is able to yield more precise and more straightforward solutions using simple kernels. Then, the approach is used on a real case study to create a welding bead depth and width SVR models for a Gas Metal Arc Welding (GMAW) process. Additionally, a study on kernel functions was developed in terms of computational effort, aiming to assess its performance for embedded systems applications.}
}
@incollection{LOU20191,
title = {Chapter One - A Survey on Regression Test-Case Prioritization},
editor = {Atif M. Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {113},
pages = {1-46},
year = {2019},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2018.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065245818300615},
author = {Yiling Lou and Junjie Chen and Lingming Zhang and Dan Hao},
keywords = {Regression testing, Test-case prioritization},
abstract = {Regression testing is crucial for ensuring the quality of modern software systems, but can be extremely costly in practice. Test-case prioritization has been proposed to improve the effectiveness of regression testing by scheduling the execution order of test cases to detect regression bugs faster. Since its first proposal, test-case prioritization has been intensively studied in the literature. In this chapter, we perform an extensive survey and analysis on existing test-case prioritization techniques, as well as pointing out future directions for test-case prioritization. More specifically, we collect 191 papers on test-case prioritization from 1997 to 2016 and conduct a detailed survey to systematically investigate these work from six aspects, i.e., algorithms, criteria, measurements, constraints, empirical studies, and scenarios. For each of the six aspects, we discuss the existing work and the trend during the evolution of test-case prioritization. Furthermore, we discuss the current limitations/issues in test-case prioritization research, as well as potential future directions on test-case prioritization. Our analyses provide the evidence that test-case prioritization topic is attracting increasing interests, while the need for practical test-case prioritization tools remains.}
}
@article{MONDAL2021110850,
title = {Hansie: Hybrid and consensus regression test prioritization},
journal = {Journal of Systems and Software},
volume = {172},
pages = {110850},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110850},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302405},
author = {Shouvick Mondal and Rupesh Nasre},
keywords = {Regression test prioritization, Priority awareness, Hybridization, Consensus, Permutation distances},
abstract = {Traditionally, given a test-suite and the underlying system-under-test, existing test-case prioritization heuristics report a permutation of the original test-suite that is seemingly best according to their criteria. However, we observe that a single heuristic does not perform optimally in all possible scenarios, given the diverse nature of software and its changes. Hence, multiple individual heuristics exhibit effectiveness differently. Interestingly, together, the heuristics bear the potential of improving the overall regression test selection across scenarios. In this paper, we pose the test-case prioritization as a rank aggregation problem from social choice theory. Our solution approach, named Hansie, is two-flavored: one involving priority-aware hybridization, and the other involving priority-blind computation of a consensus ordering from individual prioritizations. To speed-up test-execution, Hansie executes the aggregated test-case orderings in a parallel multi-processed manner leveraging regular windows in the absence of ties, and irregular windows in the presence of ties. We show the benefit of test-execution after prioritization and introduce a cost-cognizant metric (EPL) for quantifying overall timeline latency due to load-imbalance arising from uniform or non-uniform parallelization windows. We evaluate Hansie on 20 open-source subjects totaling 287,530 lines of source code, 69,305 test-cases, and with parallelization support of up to 40 logical CPUs.}
}
@article{BARBOSA2022106902,
title = {A Systematic Literature Review on prioritizing software test cases using Markov chains},
journal = {Information and Software Technology},
volume = {147},
pages = {106902},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106902},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922000623},
author = {Gerson Barbosa and Érica Ferreira {de Souza} and Luciana Brasil Rebelo {dos Santos} and Marlon {da Silva} and Juliana Marino Balera and Nandamudi Lankalapalli Vijaykumar},
keywords = {Systematic Literature Review, Markov Chains, Test case prioritization},
abstract = {Context:
Software Testing is a costly activity since the size of the test case set tends to increase as the construction of the software evolves. Test Case Prioritization (TCP) can reduce the effort and cost of software testing. TCP is an activity where a subset of the existing test cases is selected in order to maximize the possibility of finding defects. On the other hand, Markov Chains representing a reactive system, when solved, can present the occupation time of each of their states. The idea is to use such information and associate priority to those test cases that consist of states with the highest probabilities.
Objective:
The objective of this paper is to conduct a survey to identify and understand key initiatives for using Markov Chains in TCP. Aspects such as approaches, developed techniques, programming languages, analytical and simulation results, and validation tests are investigated.
Methods:
A Systematic Literature Review (SLR) was conducted considering studies published up to July 2021 from five different databases to answer the three research questions.
Results:
From SLR, we identified 480 studies addressing Markov Chains in TCP that have been reviewed in order to extract relevant information on a set of research questions.
Conclusion:
The final 12 studies analyzed use Markov Chains at some stage of test case prioritization in a distinct way, that is, we found that there is no strong relationship between any of the studies, not only on how the technique was used but also in the context of the application. Concerning the fields of application of this subject, 6 forms of approach were found: Controlled Markov Chain, Usage Model, Model-Based Test, Regression Test, Statistical Test, and Random Test. This demonstrates the versatility and robustness of the tool. A large part of the studies developed some prioritization tool, being its validation done in some cases analytically and in others numerically, such as: Measure of the software specification, Optimal Test Transition Probabilities, Adaptive Software Testing, Automatic Prioritization, Ant Colony Optimization, Model Driven approach, and Monte Carlo Random Testing.}
}
@article{BERECIARTUAPEREZ2022106933,
title = {Insect counting through deep learning-based density maps estimation},
journal = {Computers and Electronics in Agriculture},
volume = {197},
pages = {106933},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.106933},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922002502},
author = {Arantza Bereciartua-Pérez and Laura Gómez and Artzai Picón and Ramón Navarra-Mestre and Christian Klukas and Till Eggers},
keywords = {Convolutional neural network, Deep learning, Density map estimation, Insect counting, Image processing, Precision agriculture},
abstract = {Digitalization and automation of assessments in field trials are established practice for farming product development. The use of image-based methods has provided good results in different applications. Although these models can leverage some problems, they still perform poorly under real field conditions using mobile devices on complex applications. Among these applications, insect counting and detection is necessary for integrated pest management strategies in order to apply specific treatments at early infection stages to reduce economic losses and minimize chemical usage. Currently the counting task for the assessment of the degree of infestation is done manually by the farmer. Current state of the art object counting methods do not provide accurate counting in crowded images with overlapped or touching objects which is the case for insect counting images. This makes necessary to define novel approaches for insect counting. In this work, we propose a novel solution based on deep learning density map estimation to tackle insects counting in wild conditions. To this end, a fully convolutional regression network has been designed to accurately estimate a probabilistic density map for the counting regression problem. The estimated density map is then used for counting whiteflies in eggplant leaves. The proposed method was compared with a baseline based on candidate object selection and classification approach. The results for alive adult whitefly counting by means of density map estimation provided R2 = 0.97 for the counted insects in the main leaf of the image, that outperforms by far the baseline algorithm (R2 = 0.85) based on image processing methods for feature extraction and candidate selection and deep learning-based classifier. This solution was embedded to be used in mobile devices, and it has been gone for exhaustive validation tests, with diverse illumination conditions and background variability, over leaves taken at different heights, with different perspectives and even unfocused images, for the analyzed pest under real conditions.}
}
@article{TANG2025100406,
title = {Uneven internal SOC distribution estimation of lithium-ion batteries using ultrasonic transmission signals: A new data screening technique and an improved deep residual network},
journal = {eTransportation},
volume = {24},
pages = {100406},
year = {2025},
issn = {2590-1168},
doi = {https://doi.org/10.1016/j.etran.2025.100406},
url = {https://www.sciencedirect.com/science/article/pii/S259011682500013X},
author = {Ting Tang and Quan Xia and Mingkang Xu and Zhe Deng and Fusheng Jiang and Zeyu Wu and Yi Ren and Dezhen Yang and Cheng Qian},
keywords = {Ultrasonic scanning, Lithium-ion battery, Uneven state of charge distribution, Active learning, Pooling extreme learning machine},
abstract = {Ultrasonic for state of charge (SOC) estimation of lithium-ion batteries has the advantages of non-destructive and real-time. The existing methods mainly depend on single-site detection, which is based on the assumption of uniform SOC distribution. However, the uneven SOC distribution existing inside the cell will cause rapid degradation of local performance, thereby bringing safety risks. Therefore, a novel method combining multi-site detection signals for the uneven internal SOC distribution estimation has been proposed, including Gaussian process regression-active learning (GPR-AL) and deep residual-pooling extreme learning machine (DR-PELM). Firstly, a focused ultrasonic beam is adopted to scan the cell. The preferred sites with lower uncertainty and their signal amplitude of ultrasonic waveform are extracted by GPR-AL. Then, DR-PELM has been established to learn the relationship between ultrasound signal features and SOC, which can reduce the impact of redundant information and noise. Finally, the accuracy of method has been verified through several case studies and destructive tests of lithium-ion detection. The results show that the mean error of general SOC estimation is 2.88 %, and the uneven SOC distribution estimation error is 0.37 %. Thus, the proposed method present good accuracy by integrating multiple selection sites with lower uncertainty and optimizing the network structure.}
}
@article{SRIKANTH2016122,
title = {Test case prioritization of build acceptance tests for an enterprise cloud application: An industrial case study},
journal = {Journal of Systems and Software},
volume = {119},
pages = {122-135},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.06.017},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300851},
author = {Hema Srikanth and Mikaela Cashman and Myra B. Cohen},
keywords = {Regression testing, Prioritization, Software as a service, Cloud computing},
abstract = {The use of cloud computing brings many new opportunities for companies to deliver software in a highly-customizable and dynamic way. One such paradigm, Software as a Service (SaaS), allows users to subscribe and unsubscribe to services as needed. While beneficial to both subscribers and SaaS service providers, failures escaping to the field in these systems can potentially impact an entire customer base. Build Acceptance Testing (BAT) is a black box technique performed to validate the quality of a SaaS system every time a build is generated. In BAT, the same set of test cases is executed simultaneously across many different servers, making this a time consuming test process. Since BAT contains the most critical use cases, it may not be obvious which tests to perform first, given that the time to complete all test cases across different servers in any given day may be insufficient. While all tests must be eventually run, it is critical to run those tests first which are likely to find failures. In this work, we ask if it is possible to prioritize BAT tests for improved time to fault detection and present several different approaches, each based on the services executed when running each BAT. In an empirical study on a production enterprise system, we first analyze the historical data from several months in the field, and then use that data to derive the prioritization order for the current development BATs. We then examine if the orders change significantly when we consider fault severity using a cost-based prioritization metric. We find that the prioritization order in which we run the tests does matter, and that the use of historical information is a good heuristic for this order. Prioritized tests have an increase in the rate of fault detection, with the average percent of faults detected (APFD) increasing from less than 0.30 to as high as 0.77 on a scale of zero to one. Although severity slightly changes which order performs best, we see that there are clusters of orderings, ones which improve time to early fault detection ones which don’t.}
}
@article{TIAN2014320,
title = {Bootstrap techniques for sensitivity analysis and model selection in building thermal performance analysis},
journal = {Applied Energy},
volume = {135},
pages = {320-328},
year = {2014},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2014.08.110},
url = {https://www.sciencedirect.com/science/article/pii/S0306261914009337},
author = {Wei Tian and Jitian Song and Zhanyong Li and Pieter {de Wilde}},
keywords = {Building thermal performance, Bootstrap method, Sensitivity analysis, Model selection},
abstract = {In regression analysis, there are two main aims: interpretation and prediction, which can be also applied in building performance analysis. Interpretation is used to understand the relationship between input parameters and building energy performance (also called sensitivity analysis), whereas prediction is used to create a reliable energy model to estimate building energy consumption. This article explores the implementation of a distribution-free bootstrap method for these two purposes. The bootstrap is a resampling method that enables assessment of the accuracy of an estimator by random sampling with replacement from an original dataset. An office building is used as a case study to demonstrate the application of this method in assessing building thermal performance. The results indicate that the probabilistic sensitivity analysis incorporating the bootstrap approach provides valuable insights into the variations in sensitivity indicators, which are not available from typical deterministic sensitivity analysis. The single point values from deterministic methods may lead to misleading prioritization of energy saving measures because they do not provide the distributions of sensitivity indicators. Information on prediction errors obtained from the bootstrap method can facilitate the selection of an appropriate building energy metamodel to more accurately predict the energy consumption of buildings, compared with the traditional one-time data splitting method (also called holdout cross-validation method), which partitions the data into a training set and a test set.}
}
@article{ZHANG2022183,
title = {Integrated optimization of test case selection and sequencing for reliability testing of the mainboard of Internet backbone routers},
journal = {European Journal of Operational Research},
volume = {299},
number = {1},
pages = {183-194},
year = {2022},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2021.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S0377221721005440},
author = {Hanxiao Zhang and Yan-Fu Li},
keywords = {Reliability, Reliability testing plan, Test case selection, Test case sequencing, Branch-and-price},
abstract = {Internet backbone refers to the principal data routes between large, strategically interconnected networks and core routers on the Internet. Internet backbone router is essentially the core router of Internet backbone and its performance is mainly relevant to the reliability of its mainboard. The mainboard is an embedded system consisting of hardware and software. Its reliability testing involves executing a number of test cases, which are designed to expose potential defects, under harsh environmental conditions. The testing process is largely prolonged due to the dramatic increase of the number of test cases, mainly due to the continuous increase and upgrade of its functional modules. Thus, there is a big demand from industry to improve the reliability testing efficiency and effectiveness. In this work, we exploit the principles of regression testing in software maintenance: test case selection and prioritization, and construct two testing planning models to largely reduce the testing time as well as to improve the effectiveness of failure detections. The former is a two-step model we introduced in previous work that optimizes test case selection and test case sequencing sequentially. The latter, an integrated model is newly developed, optimizing the test case selection and sequencing simultaneously with the precedence constraints among the test cases. Moreover, we propose exact algorithms based on branch-and-price for solving these two models. Finally, we present a case study demonstrating that the integrated model outperforms the two-step method and the advantage is more significant if the sequencing objective has greater weight in the integrated objective function.}
}
@article{WANG202368,
title = {Online fault diagnosis of PV array considering label errors based on distributionally robust logistic regression},
journal = {Renewable Energy},
volume = {203},
pages = {68-80},
year = {2023},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2022.11.126},
url = {https://www.sciencedirect.com/science/article/pii/S0960148122017840},
author = {Mengyuan Wang and Xiaoyuan Xu and Zheng Yan},
keywords = {Photovoltaic array, Fault diagnosis, Label error, Distributionally robust logistic regression},
abstract = {This paper proposes a robust diagnosis method of photovoltaic (PV) array faults considering label errors in training data. First, the online data of PV systems, including the sequences of voltages, currents, and output power at maximum power points, are used to establish the input data of fault diagnosis. Second, a data processing method is used to extract fault features from electrical signals under fluctuating ambient conditions. Third, the parameter estimation of the regression-based fault diagnosis model is formulated as a stochastic optimization problem. To hedge against label errors, an ambiguity set of probability distributions is established from training data, and a distributionally robust logistic regression method is proposed to minimize the expected log-loss function under the worst-case probability distribution for obtaining model parameters of fault diagnosis. Finally, the proposed method is tested on real-world PV arrays under diverse conditions and scenarios. Data processing increases diagnosis accuracy by 18.4% when training data is error-free. The diagnosis accuracy is higher than 98% when the label error rate is smaller than 4%.}
}
@article{ZHU2025109002,
title = {Ensemble transfer learning assisted soft sensor for distributed output inference in chemical processes},
journal = {Computers & Chemical Engineering},
volume = {194},
pages = {109002},
year = {2025},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2025.109002},
url = {https://www.sciencedirect.com/science/article/pii/S0098135425000067},
author = {Jialiang Zhu and Wangwang Zhu and Yi Liu},
keywords = {Chemical process, Distributed outputs, Local model, Ensemble learning, Transfer learning},
abstract = {Chemical processes with distributed outputs are characterized by various operating conditions, and the scarcity of labeled data poses challenges to the prediction of product quality. An ensemble transfer Gaussian process regression (ETGPR) model is developed for prediction of different quantities of distributed outputs. First, for each test instances from target domain, just-in-time learning is adopted to select distance-based similar instances from source domain in related operating conditions. Mutual information helps create various local models by building diverse input variable sets. Subsequently, Bayesian inference is used to produce the posterior probabilities relative to the test instance, then set as the weights of local prediction. The instance transfer is thus completed via distance-based similar instance selection from source domain for local model construction, and the model performance is improved by the ensemble weighting strategy, concerning the target domain, under diverse operating conditions. Therefore, by utilizing and transferring information from source domain, unsupervised transfer can be implemented with available unlabeled target data. The superiority of ETGPR model is confirmed in the case of modeling the polymerization process with distributed outputs.}
}
@article{WANG2024107339,
title = {Cluster-based adaptive test case prioritization},
journal = {Information and Software Technology},
volume = {165},
pages = {107339},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107339},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923001945},
author = {Xiaolin Wang and Sulan Zhang},
keywords = {Test case prioritization, Clustering analysis, Requirement, Regression testing},
abstract = {In order to enhance the efficiency of regression testing, test case prioritization (TCP) has been widely implemented, wherein a higher priority test case is executed earlier. Traditional TCP methods focus on improving the prioritization algorithm's efficacy. However, the majority of TCP approaches are characterized by a predetermined sequence of test cases prior to execution. Once established, this sequence remains consistent throughout the entire test execution process. As a result, any execution information generated during current test execution (such as fault-detected information) is unavailable for use in current round of test case prioritization and can only be utilized in subsequent regression testing. To address the issue of lagging utilization of fault-detected information, a cluster-based adaptive test case prioritization approach is proposed, which adds the new adaptive adjustment content in pre-prioritization. First, a new clustering criterion is defined and designed, by which produces test-case clusters in advance. Second, an adaptive TCP algorithm is proposed, which utilizes fault-detected information to adaptively adjust the order of test cases during the execution process based on the test-case clusters. Finally, one open-source Java program and three industrial-grade Java programs were selected for empirical evaluation. The experimental results demonstrate that the proposed technique not only serves as an enhanced version of pre-prioritization to improve the performance of the corresponding pre-prioritization technique, but also functions as an independent approach that outperforms other TCP techniques, including cluster-based TCPs, and another adaptive TCP. Specifically, when step=2 is applied using our cluster-based adaptive TCP approach, the results are significantly better than those obtained with step=1. For instance, in CT-14, the median APFD improvement rate for step=2 reaches 17.08 %, which is substantially higher than that achieved with step=1 (5.48 %).}
}
@article{NI2024110033,
title = {Feature incremental learning with causality},
journal = {Pattern Recognition},
volume = {146},
pages = {110033},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2023.110033},
url = {https://www.sciencedirect.com/science/article/pii/S0031320323007306},
author = {Haotian Ni and Shilin Gu and Ruidong Fan and Chenping Hou},
keywords = {Feature incremental, Causal inference, Balancing regularizer},
abstract = {With the emerging of new data collection ways, the features are incremental and accumulated gradually. Due to the expansion of feature spaces, it is more common that there are unknown biases between the distribution of training and testing datasets. It is known as the unknown data selection bias, which belongs to the learning scenario with non-i.i.d samples. The performance of traditional approaches, which need the i.i.d. assumption, will be aggravated seriously. How to design an algorithm to address the problem of data selection bias in this feature incremental scenario is crucial but rarely studied. In this paper, we propose a feature incremental classification algorithm with causality. Firstly, we embed the confounding variable balance algorithm in causal learning into the prediction modeling and utilize the logical regression algorithm with balancing regular terms as a baseline. Then, to satisfy the special requirement of feature increment, we design a new regularizer, which maintains the consistency of the regression coefficients between the data in the current and previous stages. It retains the correlation between the old features and labels. Finally, we propose the Multiple Balancing Logistic Regression model (MBRLR) to jointly optimize the balancing regularizer and weighted logistic regression model with multiple feature sets. We also present theoretical results to show that our proposed algorithm can make precise and stable predictions. Besides, the numerical results also demonstrate that our MBRLR algorithm is superior to other methods.}
}
@incollection{DO201653,
title = {Chapter Three - Recent Advances in Regression Testing Techniques},
editor = {Atif M. Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {103},
pages = {53-77},
year = {2016},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2016.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0065245816300286},
author = {H. Do},
keywords = {Regression testing, Regression test selection, Test case prioritization, Test suite minimization},
abstract = {Software systems and their environment change are continuous. They are enhanced, corrected, and ported to new platforms. These changes can affect a system adversely, thus software engineers perform regression testing to ensure the quality of the modified systems. Regression testing is an integral part of most major software projects, but as projects grow larger and the number of tests increases, performing regression testing becomes more costly. To address this problem, many researchers and practitioners have proposed and empirically evaluated various regression testing techniques, such as regression test selection, test case prioritization, and test suite minimization. Recent surveys on these techniques indicate that this research area continues to grow, heuristics and the types of data utilized become diverse, and wider application domains have been considered. This chapter presents the current status and the trends of three regression testing techniques and discusses recent advances of each technique.}
}
@article{UCAR2024,
title = {Estimating rock strength parameters across varied failure criteria: Application of spreadsheet and R-based orthogonal regression to triaxial test data},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
year = {2024},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2024.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S167477552400550X},
author = {Roberto Úcar and Luis Arlegui and Norly Belandria and Francisco Torrijo},
keywords = {Rock failure criteria, Nonlinear regression, Orthogonal regression, Triaxial testing, Dot product},
abstract = {Triaxial tests, a staple in rock engineering, are labor-intensive, sample-demanding, and costly, making their optimization highly advantageous. These tests are essential for characterizing rock strength, and by adopting a failure criterion, they allow for the derivation of criterion parameters through regression, facilitating their integration into modeling programs. In this study, we introduce the application of an underutilized statistical technique—orthogonal regression— well-suited for analyzing triaxial test data. Additionally, we present an innovation in this technique by minimizing the Euclidean distance while incorporating orthogonality between vectors as a constraint, for the case of orthogonal linear regression. Also, we consider the Modified Least Squares method. We exemplify this approach by developing the necessary equations to apply the Mohr-Coulomb, Murrell, Hoek-Brown, and Úcar criteria, and implement these equations in both spreadsheet calculations and R scripts. Finally, we demonstrate the technique's application using five datasets of varied lithologies from specialized literature, showcasing its versatility and effectiveness.}
}
@article{THIEU2025103977,
title = {MetaPerceptron: A standardized framework for metaheuristic-driven multi-layer perceptron optimization},
journal = {Computer Standards & Interfaces},
volume = {93},
pages = {103977},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.103977},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925000066},
author = {Nguyen Van Thieu and Seyedali Mirjalili and Harish Garg and Nguyen Thanh Hoang},
keywords = {Metaheuristic algorithms, Multilayer perceptron, Metaheuristic-based MLP, Python library, Neural network, Open-source software},
abstract = {The multi-layer perceptron (MLP) remains a foundational architecture within neural networks, widely recognized for its ability to model complex, non-linear relationships between inputs and outputs. Despite its success, MLP training processes often face challenges like susceptibility to local optima and overfitting when relying on traditional gradient descent optimization. Metaheuristic algorithms (MHAs) have recently emerged as robust alternatives for optimizing MLP training, yet no current package offers a comprehensive, standardized framework for MHA-MLP hybrid models. This paper introduces MetaPerceptron, an standardized open-source Python framework designed to integrate MHAs with MLPs seamlessly, supporting both regression and classification tasks. MetaPerceptron is built on top of PyTorch, Scikit-Learn, and Mealpy. Through this design, MetaPerceptron promotes standardization in MLP optimization, incorporating essential machine learning utilities such as model forecasting, feature selection, hyperparameter tuning, and pipeline creation. By offering over 200 MHAs, MetaPerceptron empowers users to experiment across a broad array of metaheuristic optimization techniques without reimplementation. This framework significantly enhances accessibility, adaptability, and consistency in metaheuristic-trained neural network research and applications, positioning it as a valuable resource for machine learning, data science, and computational optimization. The entire source code is freely available on Github: https://github.com/thieu1995/MetaPerceptron}
}
@article{ZHAO2016886,
title = {One day ahead wind speed forecasting: A resampling-based approach},
journal = {Applied Energy},
volume = {178},
pages = {886-901},
year = {2016},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2016.06.098},
url = {https://www.sciencedirect.com/science/article/pii/S030626191630873X},
author = {Weigang Zhao and Yi-Ming Wei and Zhongyue Su},
keywords = {Wind speed forecasting, General regression neural network, Cross-validation, Fibonacci search method, Leave-one-day-out resampling, Forecast correction},
abstract = {Wind speed forecasting plays a vital role in dispatch planning and operational security for wind farms, however, its difficulty is commonly accepted. This paper develops a nonlinear autoregressive (exogenous) model for one-day-ahead mean hourly wind speed forecasting, where general regression neural network is employed to model nonlinearities of the system. Specifically, this model is a two-stage method consisting of the model selection and training stage along with the iterative forecasting and correcting stage. In the former stage, the model is in the series-parallel configuration, and its test error is estimated by the cross-validation (CV) method. With the help of ARIMA identification results, CV errors are minimized by the Fibonacci search method to select the best lag structure and the only adjustable parameter. In the latter stage, the model is in the parallel configuration, and the so-called leave-one-day-out resampling method is proposed to iteratively estimate correction parameters for horizons up to 24h ahead, which holds out each full-day data segment from the sample of observations in turn to faithfully reproduce the entire process of training, iterative forecasting and correcting in the in-sample period. Finally, the out-of-sample corrected forecasts can be successively obtained by using the model selected and trained in the former stage and the correction parameters estimated in the latter stage. Furthermore, effectiveness of this model is verified with four real-world case studies of two wind farms in China.}
}
@article{LIU2024108673,
title = {Machine learning-based models for estimating liquefaction-induced building settlements},
journal = {Soil Dynamics and Earthquake Engineering},
volume = {182},
pages = {108673},
year = {2024},
issn = {0267-7261},
doi = {https://doi.org/10.1016/j.soildyn.2024.108673},
url = {https://www.sciencedirect.com/science/article/pii/S0267726124002252},
author = {Chenying Liu and Jorge Macedo},
keywords = {Liquefaction-induced building settlements, Machine learning, Feature selection, Case histories, Performance-based earthquake engineering},
abstract = {Engineers often estimate the amount of liquefaction-induced building settlements (LIBS) as a performance proxy to assess the potential of earthquake-induced damage to buildings. The first robust LIBS models were initially developed in 2017 and 2018 using traditional statistical approaches. More recently, machine learning techniques have started to be used in developing LIBS models. These recent efforts are a step forward in realizing the potential of machine learning in liquefaction engineering; however, they have often considered only one ML technique for a given dataset and typically used only held-out test sets for model assessment. In this study, five ML-based LIBS models with varying flexibility (i.e., ridge regression, partial least square regression — PLSR, random forest, gradient boosting decision tree — GBDT, and support vector regression) are developed using a LIBS database generated by soil–structure numerical simulations of different buildings and soil profiles shaken by ground motions with varying intensity measures. The motivation for considering models with different flexibility is to include different bias–variance trade-offs. Feature selection with different ML techniques indicates that cumulative absolute velocity, spectral acceleration at one second, contact pressure, foundation width, the thickness of the liquefiable layer, and a shearing liquefaction index are important features in estimating LIBS. The developed ML-based models are assessed considering prediction accuracy in test sets, performance against centrifuge tests and case histories, and trends. The assessment indicates that the random forest, GBDT, and SVR models perform best, providing standard deviation reductions up to 40% relative to a multi-linear regression. Specifically, the random forest and GBDT models exhibit a root mean square error (RMSE) of 0.29 and a coefficient of determination (R2) of 0.93 on test sets, demonstrating a notable improvement compared to a traditional multi-linear regression model, which yields an RMSE of 0.47 and an R2 of 0.82. Moreover, random forest and GBDT, alongside SVR, show a good performance in centrifuge tests and case histories. Finally, given the scarcity of LIBS models, this study also contributes to treating epistemic uncertainties in estimating LIBS, which is ultimately beneficial for performance-based assessments.}
}
@article{BAJAJ2021107584,
title = {Discrete cuckoo search algorithms for test case prioritization},
journal = {Applied Soft Computing},
volume = {110},
pages = {107584},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107584},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621005056},
author = {Anu Bajaj and Om Prakash Sangwan},
keywords = {Search based software testing, Regression testing, Test case prioritization, Meta-heuristics, Nature-inspired algorithms, Cuckoo search algorithm, Asexual reproduction algorithm, Permutation encoding},
abstract = {Regression testing is an essential aspect of the software development lifecycle. As the software evolves, the test suite grows, hence the cost and effort to retest the software. Test case prioritization is one of the mitigation techniques for regression testing. It ranks the test cases to maximize the desired properties, e.g., detecting faults early. The efficiency and effectiveness of test case prioritization techniques can be enhanced using optimization algorithms. Nature-inspired algorithms are gaining more attention due to their easy implementation and quality of the solutions. This paper proposes the discrete cuckoo search algorithm for test case prioritization. The prioritization problem deals with ordering the test cases. Therefore, a new adaptation strategy using asexual genetic reproduction is introduced to convert real numbers into permutation sequences. Furthermore, the cuckoo search algorithm’s effectiveness is extended with the genetic algorithm’s mutation operator to balance the trade-off between exploration and exploitation. An in-depth comparative study on four case studies is conducted between the proposed algorithms, existing state-of-the-art algorithms and baseline approach. Statistical investigation confirms that the proposed hybrid cuckoo search algorithm outperforms the genetic algorithm, particle swarm optimization, ant colony optimization, tree seed algorithm and random search by 4.29%, 5.52%, 8.38%, 2.74% and 10.80%, respectively.}
}
@article{WANG2023130066,
title = {Relationship between track geometry defect occurrence and substructure condition: A case study on one passenger railroad in the United States},
journal = {Construction and Building Materials},
volume = {365},
pages = {130066},
year = {2023},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2022.130066},
url = {https://www.sciencedirect.com/science/article/pii/S0950061822037229},
author = {Xin Wang and Xiang Liu and Todd L. Euston},
keywords = {Track geometry defect, Passenger railroad, Substructure condition, Data-driven approach, Gradient boosting},
abstract = {Analyzing the relationship between track geometry defect occurrence and substructure condition can provide assistance for track inspection and spot maintenance, which contributes to better train operation quality. This paper develops a data-driven approach to estimate the occurrence of track geometry defects on concrete-tie tracks on one passenger railroad in the United States, using substructure data, rail seat abrasion data, infrastructure data, traffic data, track class information, and maintenance data. Feature extraction was implemented to generate input variables for the machine learning models. Recursive feature elimination (RFE) was applied to reduce data dimensionality by recursively considering smaller sets of features. Three data treatment methods, including no resampling, undersampling, and oversampling, were incorporated to address imbalanced data issues. The developed models included logistic regression, artificial neural network, and gradient boosting. The hyperparameters of the proposed models were optimized using Bayesian optimization. The performance of the proposed methods was finally evaluated based on the test dataset generated using random data partitioning. Based on data collected from one passenger railroad, the gradient boosting method with data oversampling shows the highest performance in estimating the occurrence of geometry defects. The F1-score of the model is 0.662, with G-Mean of 0.738. Feature importance identifies that surfacing, traffic, curvature, switch, and rail replacement are the top five factors influencing the predicted probability of track geometry defect occurrence. The proposed model can be used to prioritize maintenance activities on locations prone to track geometry defects and thus further improve infrastructure safety given budgetary constraints.}
}
@article{LOUKREZIS2025115746,
title = {Multivariate sensitivity-adaptive polynomial chaos expansion for high-dimensional surrogate modeling and uncertainty quantification},
journal = {Applied Mathematical Modelling},
volume = {137},
pages = {115746},
year = {2025},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2024.115746},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X24004992},
author = {Dimitrios Loukrezis and Eric Diehl and Herbert {De Gersem}},
keywords = {Polynomial chaos expansion, Multivariate sensitivity analysis, Machine learning regression, Surrogate modeling, Uncertainty quantification, Curse of dimensionality, Adaptive approximation, Electric machine, Power grid},
abstract = {This work develops a novel basis-adaptive method for constructing anisotropic polynomial chaos expansions of multidimensional (vector-valued, multi-output) model responses. The adaptive basis selection is based on multivariate sensitivity analysis metrics that can be estimated by post-processing the polynomial chaos expansion and results in a common anisotropic polynomial basis for the vector-valued response. This allows the application of the method to problems with up to moderately high-dimensional model inputs (in the order of tens) and up to very high-dimensional model responses (in the order of thousands). The method is applied to different engineering test cases for surrogate modeling and uncertainty quantification, including use cases related to electric machine and power grid modeling and simulation, and is found to produce highly accurate results with comparatively low data and computational demand.}
}
@article{ANDERSON2019110,
title = {On the use of usage patterns from telemetry data for test case prioritization},
journal = {Information and Software Technology},
volume = {113},
pages = {110-130},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919301223},
author = {Jeff Anderson and Maral Azizi and Saeed Salem and Hyunsook Do},
keywords = {Regression testing, Test case prioritization, Telemetry data, Usage patterns},
abstract = {Context
Modern applications contain pervasive telemetry to ensure reliability and enable monitoring and diagnosis. This presents a new opportunity in the area of regression testing techniques, as we now have the ability to consider usage profiles of the software when making decisions on test execution.
Objective
The results of our prior work on test prioritization using telemetry data showed improvement rate on test suite reduction, and test execution time. The objective of this paper is to further investigate this approach and apply prioritization based on multiple prioritization algorithms in an enterprise level cloud application as well as open source projects. We aim to provide an effective prioritization scheme that practitioners can implement with minimum effort. The other objective is to compare the results and the benefits of this technique factors with code coverage-based prioritization approaches, which is the most commonly used test prioritization technique.
Method
We introduce a method for identifying usage patterns based on telemetry, which we refer to as “telemetry fingerprinting.” Through the use of various algorithms to compute fingerprints, we conduct empirical studies on multiple software products to show that telemetry fingerprinting can be used to more effectively prioritize regression tests.
Results
Our experimental results show that the proposed techniques were able to reduce over 30% in regression test suite run times compared to the coverage-based prioritization technique in detecting discoverable faults. Further, the results indicate that fingerprints are effective in identifying usage patterns, and that the fingerprints can be applied to improve regression testing techniques.
Conclusion
In this research, we introduce the concept of fingerprinting software usage patterns through telemetry. We provide various algorithms to compute fingerprints and conduct empirical studies that show that fingerprints are effective in identifying distinct usage patterns. By applying these techniques, we believe that regression testing techniques can be improved beyond the current state-of-the-art, yielding additional cost and quality benefits.}
}
@article{MAGALHAES2020110430,
title = {HSP: A hybrid selection and prioritisation of regression test cases based on information retrieval and code coverage applied on an industrial case study},
journal = {Journal of Systems and Software},
volume = {159},
pages = {110430},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110430},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302043},
author = {Claudio Magalhães and João Andrade and Lucas Perrusi and Alexandre Mota and Flávia Barros and Eliot Maia},
keywords = {Test cases selection and prioritisation, Regression testing, Static analysis, Information retrieval, Code coverage},
abstract = {The usual way to guarantee quality of software products is via testing. This paper presents a novel strategy for selection and prioritisation of Test Cases (TC) for Regression testing. In the lack of code artifacts from where to derive Test Plans, this work uses information conveyed by textual documents maintained by Industry, such as Change Requests. The proposed process is based on Information Retrieval techniques combined with indirect code coverage measures to select and prioritise TCs. The aim is to provide a high coverage Test Plan which would maximise the number of bugs found. This process was implemented as a prototype tool which was used in a case study with our industrial partner (Motorola Mobility). Experiments results revealed that the combined strategy provides better results than the use of information retrieval and code coverage independently. Yet, it is worth mentioning that any of these automated options performed better than the previous manual process deployed by our industrial partner to create test plans.}
}
@article{OMAE2024111809,
title = {Deep learned features selection algorithm: Removal operation of anomaly feature maps (RO-AFM)},
journal = {Applied Soft Computing},
volume = {162},
pages = {111809},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111809},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624005830},
author = {Yuto Omae and Yohei Kakimoto and Yuki Saito and Daisuke Fukamachi and Koichi Nagashima and Yasuo Okumura and Jun Toyotani},
keywords = {Convolutional neural networks, Feature maps, Feature selection},
abstract = {Class/Regression Activation Maps (CAMs/RAMs; AMs) are often embedded into Convolutional Neural Networks (CNNs) for checking activated regions on input images at estimation. CNNs sometime generate unreliable AMs, such as activated regions, are inappropriate. Because AM is calculated by stacking many feature maps generated by the final convolutional layer, when there are Anomaly Feature Maps (AFMs), unreliable AMs can be generated. For example, suppose we have a CNN that evaluates the heart. In this case, the feature maps that focus on regions unrelated to the heart (e.g., shoulders and esophagus) are AFMs. Additionally, we have a hypothesis that the estimation accuracy of CNNs is increased by removing AFMs. However, methods for automatically detecting and removing AFMs have not been sufficiently studied in previous research to improve the performance of CNNs. Therefore, we propose a method named “Removal Operation of Anomaly Feature Maps (RO-AFMs)” to automatically detect and remove AFMs. When applying an RO-AFM to the Global Average Pooling (GAP) feature vectors of a CNN, dimensions of the GAP vector are reduced. Therefore, an RO-AFM is regarded as a deep-feature selection algorithm. From the results of adopting an RO-AFM to a Regression CNN (R-CNN) for estimating pulmonary artery wedge pressure, which is one of the measurement score for representing cardiac anomaly state, improved reliability of AM and estimation accuracy were verified. A comparison of RO-AFM and the existing methods, i.e., Lasso and the Feature Selection Layer (FSL), indicated that RO-AFM performed slightly better on the estimation accuracy. The computation time required for RO-AFM to evaluate all features was 1.833 s on average, confirming that RO-AFM is a lightweight process. Therefore, RO-AFM is useful for constructing a medical CNN that emphasizes explainability (e.g., CNNs for estimating the risk of a disease or a test value from chest X-ray or computed tomography images).}
}
@article{CAO2024108245,
title = {Systematic evaluation of machine learning-enhanced trifocal IOL power selection for axial myopia cataract patients},
journal = {Computers in Biology and Medicine},
volume = {173},
pages = {108245},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108245},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524003299},
author = {Danmin Cao and Min Hu and Danlin Zhi and Jianheng Liang and Qian Tan and Qiong Lei and Maoyan Li and Hao Cheng and Li Wang and Weiwei Dai},
keywords = {Cataract, Axial myopia, Trifocal IOL, IOL formula, Machine learning},
abstract = {Purpose
This study aimed to evaluate and optimize intraocular lens (IOL) power selection for cataract patients with high axial myopia receiving trifocal IOLs.
Design
A multi-center, retrospective observational case series was conducted. Patients having an axial length ≥26 mm and undergoing cataract surgery with trifocal IOL implanted were studied.
Methods
Preoperative biometric and postoperative outcome data from 139 eyes were collected to train and test various machine learning (ML) models (support vector machine, linear regression, and stacking regressor) using five-fold cross-validation. The models' performance was further validated externally using data from 48 eyes enrolled from other hospitals. Performance of seven IOL calculation formulas (BUII, Kane, EVO, K6, DGS, Holladay I, and SRK/T) were examined with and without ML models.
Results
The results of cross-validation revealed improvements across all IOL calculation formulas, especially for K6 and Holladay I. The model increased the percentage of eyes with a prediction error (PE) within ±0.50 D from 71.94% to 79.14% for K6, and from 35.25% to 51.80% for Holladay I. In external validation involving 48 patients from other centers, six out of seven formulas demonstrated a reduction in the mean absolute error (MAE). K6's PE within ±0.50 D improved from 62.50% to 77.08%, and Holladay I from 16.67% to 58.33%.
Conclusions
In this study, we conducted a comprehensive evaluation of seven IOL power calculation formulas in high axial myopia cases and explored the effectiveness of the Stacking Regressor model in augmenting their accuracy. Of these formulas, K6 and Holladay I exhibited the most significant improvements, suggesting that integrating ML may have varying levels of effectiveness across different formulas but holds substantial promise in improving the predictability of IOL power calculations in patients with long eyes.}
}
@article{KARIWALA20131,
title = {Branch and bound method for regression-based controlled variable selection},
journal = {Computers & Chemical Engineering},
volume = {54},
pages = {1-7},
year = {2013},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2013.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0098135413000719},
author = {Vinay Kariwala and Lingjian Ye and Yi Cao},
keywords = {Branch and bound, Control structure design, Controlled variables, Combinatorial optimization, Distillation, Self-optimizing control},
abstract = {Self-optimizing control is a promising method for selection of controlled variables (CVs) from available measurements. Recently, Ye, Cao, Li, and Song (2012) have proposed a globally optimal method for selection of self-optimizing CVs by converting the CV selection problem into a regression problem. In this approach, the necessary conditions of optimality (NCO) are approximated by linear combinations of available measurements over the entire operation region. In practice, it is desired that a subset of available measurements be combined as CVs to obtain a good trade-off between the economic performance and the complexity of control system. The subset selection problem, however, is combinatorial in nature, which makes the application of the globally optimal CV selection method to large-scale processes difficult. In this work, an efficient branch and bound (BAB) algorithm is developed to handle the computational complexity associated with the selection of globally optimal CVs. The proposed BAB algorithm identifies the best measurement subset such that the regression error in approximating NCO is minimized and is also applicable to the general regression problem. Numerical tests using randomly generated matrices and a binary distillation column case study demonstrate the computational efficiency of the proposed BAB algorithm.}
}
@article{JIANG201591,
title = {Input-based adaptive randomized test case prioritization: A local beam search approach},
journal = {Journal of Systems and Software},
volume = {105},
pages = {91-106},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.03.066},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215000680},
author = {Bo Jiang and W.K. Chan},
keywords = {Regression testing, Adaptive test case prioritization, Randomized algorithm},
abstract = {Test case prioritization assigns the execution priorities of the test cases in a given test suite. Many existing test case prioritization techniques assume the full-fledged availability of code coverage data, fault history, or test specification, which are seldom well-maintained in real-world software development projects. This paper proposes a novel family of input-based local-beam-search adaptive-randomized techniques. They make adaptive tree-based randomized explorations with a randomized candidate test set strategy to even out the search space explorations among the branches of the exploration trees constructed by the test inputs in the test suite. We report a validation experiment on a suite of four medium-size benchmarks. The results show that our techniques achieve either higher APFD values than or the same mean APFD values as the existing code-coverage-based greedy or search-based prioritization techniques, including Genetic, Greedy and ART, in both our controlled experiment and case study. Our techniques are also significantly more efficient than the Genetic and Greedy, but are less efficient than ART.}
}
@article{SHEIKH20226789,
title = {An Optimized Test Case Minimization Technique Using Genetic Algorithm for Regression Testing},
journal = {Computers, Materials and Continua},
volume = {74},
number = {3},
pages = {6789-6806},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.028625},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822003484},
author = {Rubab Sheikh and Muhammad Imran Babar and Rawish Butt and Abdelzahir Abdelmaboud and Taiseer Abdalla {Elfadil Eisa}},
keywords = {Test case minimization, regression testing, testreduce, genetic algorithm, 100-dollar prioritization},
abstract = {Regression testing is a widely used approach to confirm the correct functionality of the software in incremental development. The use of test cases makes it easier to test the ripple effect of changed requirements. Rigorous testing may help in meeting the quality criteria that is based on the conformance to the requirements as given by the intended stakeholders. However, a minimized and prioritized set of test cases may reduce the efforts and time required for testing while focusing on the timely delivery of the software application. In this research, a technique named TestReduce has been presented to get a minimal set of test cases based on high priority to ensure that the web application meets the required quality criteria. A new technique TestReduce is proposed with a blend of genetic algorithm to find an optimized and minimal set of test cases. The ultimate objective associated with this study is to provide a technique that may solve the minimization problem of regression test cases in the case of linked requirements. In this research, the 100-Dollar prioritization approach is used to define the priority of the new requirements.}
}
@article{TVARDOVSKII2024103053,
title = {Testing and incremental conformance testing of timed state machines},
journal = {Science of Computer Programming},
volume = {233},
pages = {103053},
year = {2024},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2023.103053},
url = {https://www.sciencedirect.com/science/article/pii/S0167642323001351},
author = {Aleksandr Tvardovskii and Khaled El-Fakih and Nina Yevtushenko},
keywords = {Conformance testing, Model-based testing, Incremental regression testing, Software evolution and maintenance, Timed finite state machines},
abstract = {We present methods for testing and incremental testing of systems modeled as finite state machines with timeouts (TFSMs). For testing, we establish an appropriate fault model and show how a complete test suite can be derived for a given TFSM specification using traditional FSM-based test derivation approaches considering an untimed FSM abstraction of the given specification. In addition, we consider reducing the cost of testing a modified or an evolving TFSM specification by the selection of appropriate incremental test suites that can verify whether the modified parts of a modified specification are correctly implemented in a corresponding implementation under test. In particular, we define the incremental testing problem for TFSMs and investigate appropriate fault models that can be used for incremental test derivation and accordingly propose related test selection algorithms. According to conducted experiments length and run time (sum of time delays) of obtained test suites are much lower than their theoretic upper bounds; in some cases, these bounds are linear. In addition, for incremental testing, when the modified part is up to 20% of the whole specification, length and run time of incremental test suites are at least twice as less than those obtained using the whole modified specification.}
}
@article{KANTARAKIAS2023112377,
title = {Sensitivity-enhanced generalized polynomial chaos for efficient uncertainty quantification},
journal = {Journal of Computational Physics},
volume = {491},
pages = {112377},
year = {2023},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2023.112377},
url = {https://www.sciencedirect.com/science/article/pii/S0021999123004722},
author = {Kyriakos D. Kantarakias and George Papadakis},
keywords = {Uncertainty quantification, Generalised polynomial chaos, Sensitivity-enhanced  minimisation, Optimal sampling of stochastic space},
abstract = {We consider the Least Squares (LSQ) regression method for Uncertainty Quantification (UQ) using generalised polynomial chaos (gPC) and augment the linear system with the gradient of the Quantity of Interest (QoI) with respect to the stochastic variables. The gradient is computed very efficiently for all variables from the adjoint system of equations. To minimise the condition number of the augmented LSQ system, an effective sampling strategy of the stochastic space is required. We compare two strategies. In the first, we apply pivoted QR decomposition to the standard LSQ matrix and evaluate both the QoI and its gradient at the sample points identified. In the second strategy, we apply QR decomposition directly to the augmented matrix. We find that the first strategy is more efficient in terms of accuracy vs number of evaluations. We call the new approach sensitivity-enhanced generalised polynomial chaos, or se-gPC, and apply it to several test cases including an aerodynamic case with 40 stochastic parameters. The method can produce accurate estimations of the statistical moments using a small number of sampling points. The computational cost scales as ∼mp−1, instead of ∼mp of the standard LSQ formulation, where m is the number of stochastic variables and p the chaos order. The solution of the adjoint system of equations is implemented in many computational mechanics packages, thus the infrastructure exists for the application of the method to a wide variety of engineering problems.}
}
@article{MINHAS2020106254,
title = {Regression testing for large-scale embedded software development – Exploring the state of practice},
journal = {Information and Software Technology},
volume = {120},
pages = {106254},
year = {2020},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.106254},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919302721},
author = {Nasir Mehmood Minhas and Kai Petersen and Jürgen Börstler and Krzysztof Wnuk},
keywords = {Regression testing, Practices, Challenges, Goals, Multi-case study},
abstract = {Context
A majority of the regression testing techniques proposed by academics have not been adopted in industry. To increase adoption rates, we need to improve our understanding of the practitioners’ perspectives on regression testing.
Objective
This study aims at exploring the regression testing state of practice in the large-scale embedded software development. The study has two objectives: 1) to highlight the potential challenges in practice, and 2) to identify the industry-relevant research areas regarding regression testing.
Method
We conducted a qualitative study in two large-scale embedded software development companies, where we carried out semi-structured interviews with representatives from five software testing teams.
Results
The practitioners run regression testing mostly with limited scope based on the size, complexity, and location of the change. Test cases are prioritized on the basis of risk and critical functionality. The practitioners rely on their knowledge and experience for the decision making regarding selection and prioritization of test cases. The companies are using both automated and manual regression testing, and mainly rely on in-house developed tools for test automation. The challenges identified in the companies are: time to test, information management, test suite maintenance, lack of communication, test selection/prioritization, lack of assessment, etc. Regression testing goals identified in this study are customer satisfaction, critical defect detection, confidence, effectiveness, efficiency, and controlled slip through of faults.
Conclusions
Considering the current state of practice and the identified challenges we conclude that there is a need to reconsider the regression test strategy in the companies. Researchers need to analyze the industry perspective when proposing new regression testing techniques.}
}
@article{POUDYAL2025101128,
title = {Exploring cement Production's role in GDP using explainable AI and sustainability analysis in Nepal},
journal = {Case Studies in Chemical and Environmental Engineering},
volume = {11},
pages = {101128},
year = {2025},
issn = {2666-0164},
doi = {https://doi.org/10.1016/j.cscee.2025.101128},
url = {https://www.sciencedirect.com/science/article/pii/S2666016425000350},
author = {Ramhari Poudyal and Biplov Paneru and Bishwash Paneru and Tilak Giri and Bibek Paneru and Tim Reynolds and Khem Narayan Poudyal and Mohan B. Dangi},
keywords = {Energy conservation, Machine learning, SHAP analysis, Guided user interface (GUI), Energy efficiency, Energy management, Sustainability, UCIL},
abstract = {Due to rising demand, the worldwide cement market is expected to increase from $340.61 billion in 2022 to $481.73 billion by 2029. Quarrying, raw material processing, and calcination are steps in cement production. The societies in India and Nepal have to deal with environmental issues such as air pollution, resource depletion, and the effects of climate change. A case study of Nepal's Udayapur Cement Industry Limited (UCIL) exposed antiquated production methods that reduce energy efficiency. Utilizing regression models like Extra Trees (Extremely Randomized Trees) Regressor, CatBoost (Categorial Boosting) Regressor, and XGBoost (eXtreme Gradient Boosting) Regressor, Random Forest and Ensemble of Sparse Embedded Trees (SET) machine learning is used to examine the demand, supply, and Gross Domestic Product (GDP) performance of cement manufacturing in India which shares a common cement related infrastructure to Nepal. Since businesses understand how important sustainability is to attract new customers and minimizing environmental effects, our study emphasizes the necessity of sustainable practices in the cement production industry. On evaluation, the Extra Trees Regressor showed strong performance, along with the SET (Stacking) model, which was further validated using a nested cross-validation technique. Random Forest, on the other hand, had trouble; it displayed the greatest RMSE (15617.85) and the lowest testing (0.8117), suggesting poorer generalization. The SET (Stacking) Ensemble model gained a testing R2 score (0.9372) and a testing RMSE (9019.76). In cross-validation, the Extra Trees model with a mean cross-validation R2 score of 0.93 and a low standard deviation of 0.04 proved to be the best-performing model, as evidenced by lower differences in R2 score across folds compared to other models, demonstrating its high predictive performance. The SHAP (SHapley Additive exPlanations) interpretability analysis indicates that population is the primary factor influencing GDP estimates. A Tkinter-based application was also developed to forecast GDP using the training model. To attain sustainability and lessen the effects of climate change on the cement sector, these findings highlight the adoption of cutting-edge technologies and energy-efficient procedures.}
}
@article{BANIAS2019119,
title = {Test case selection-prioritization approach based on memoization dynamic programming algorithm},
journal = {Information and Software Technology},
volume = {115},
pages = {119-130},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S095058491930134X},
author = {Ovidiu Banias},
keywords = {Software testing, Test case selection, Test case prioritization, Dynamic programming, Algorithms},
abstract = {Context
In the software industry, selection and prioritization techniques become a necessity in the regression and validation testing phases because a lot of test cases are available for reuse, yet time and project specific constraints must be respected.
Objective
In this paper we propose a dynamic programming approach in solving test case selection-prioritization problems. We focus on low memory consumption in pseudo-polynomial time complexity applicable in both selection and selection-prioritization problems over sets of test cases or test suites. In dynamic programming optimization solutions, huge amounts of memory are required and unfortunately the memory is limited. Therefore, lower memory consumption leads to a higher number of test cases to be involved in the selection process.
Method
Our approach is suited for medium to large projects where the required memory space is not higher than the order of tens of GBytes. We employed both objective methods as the dynamic programming algorithm and subjective and empiric human decision as defining the prioritization criteria. Furthermore, we propose a method of employing multiple project specific criteria in evaluating the importance of a test case in the project context.
Results
To evaluate the proposed solution relative to the classical dynamic programming knapsack solution, we developed a suite of comparative case studies based on 1000 generated scenarios as close as possible to real project scenarios. The results of the comparative study reported the proposed algorithm requires up to 400 times less memory in the best-case scenarios and about 40 times less memory in average.
Conclusion
The solution delivers optimal results in pseudo-polynomial time complexity, is effective for amounts of test cases up to the order of millions and compared with the classical dynamic programming methods leads to higher number of test cases to be involved in the selection process due to reduced memory consumption.}
}
@article{HASSAN2025104332,
title = {Ensemble learning of deep CNN models and two stage level prediction of Cobb angle on surface topography in adolescents with idiopathic scoliosis},
journal = {Medical Engineering & Physics},
volume = {140},
pages = {104332},
year = {2025},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2025.104332},
url = {https://www.sciencedirect.com/science/article/pii/S1350453325000517},
author = {Mostafa Hassan and Jose Maria {Gonzalez Ruiz} and Nada Mohamed and Thomaz Nogueira Burke and Qipei Mei and Lindsey Westover},
keywords = {Adolescent idiopathic scoliosis, Convolutional neural network, Cobb angle, Surface topography, Medical imaging, Deep learning},
abstract = {This study employs Convolutional Neural Networks (CNNs) as feature extractors with appended regression layers for the non-invasive prediction of Cobb Angle (CA) from Surface Topography (ST) scans in adolescents with Idiopathic Scoliosis (AIS). The aim is to minimize radiation exposure during critical growth periods by offering a reliable, non-invasive assessment tool. The efficacy of various CNN-based feature extractors—DenseNet121, EfficientNetB0, ResNet18, SqueezeNet, and a modified U-Net—was evaluated on a dataset of 654 ST scans using a regression analysis framework for accurate CA prediction. The dataset comprised 590 training and 64 testing scans. Performance was evaluated using Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and accuracy in classifying scoliosis severity (mild, moderate, severe) based on CA measurements. The EfficientNetB0 feature extractor outperformed other models, demonstrating strong performance on the training set (R=0.96, R=20.93) and achieving an MAE of 6.13∘ and RMSE of 7.5∘ on the test set. In terms of scoliosis severity classification, it achieved high precision (84.62%) and specificity (95.65% for mild cases and 82.98% for severe cases), highlighting its clinical applicability in AIS management. The regression-based approach using the EfficientNetB0 as a feature extractor presents a significant advancement for accurately determining CA from ST scans, offering a promising tool for improving scoliosis severity categorization and management in adolescents.}
}
@article{PIRESJUNIOR2023112628,
title = {Ensemble learning application in multiplexed optical fibser sensor system for liquid level assessment},
journal = {Measurement},
volume = {211},
pages = {112628},
year = {2023},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2023.112628},
url = {https://www.sciencedirect.com/science/article/pii/S0263224123001926},
author = {Robertson Pires-Junior and Arnaldo Leal-Junior},
keywords = {Optical fiber sensors, Polymer optical fibers, Liquid level assessment, Liquid identification, Machine learning, Ensemble learning},
abstract = {This paper presents the development and analysis of a sensor system based on multiplexed intensity variation sensors using a polymer optical fiber (POF). The sensor is based on a multiplexing technique from side-coupling of light emitting diodes (LEDs) with the sequential activation of the light sources. In this case, 20 sensors are developed from the side-coupling between the lateral section of the POF and each LED. The sensor system is embedded in a polydimethylsiloxane (PDMS) resin for encapsulation, chemical and mechanical protection of the sensors. The sensors sensitivities as a function of the refractive index and pressure are experimentally obtained. Then, the sensors are positioned inside an acrylic tank for the liquid level measurement and the water and oil identification. The tests using water and oil mixtures in the tank are performed to evaluate the possibility of measuring water and oil levels. To that extent, an ensemble learning algorithm using random forest (RF) is applied on the responses of the 20 sensors to obtain the level of each fluid. In addition, the algorithm's parameters of the RF approach are optimized using the minimization of root mean squared error (RMSE) as the objective. The dataset are divided into train and test samples with an additional dataset used as validation of the proposed RF-based regression model. Results show the feasibility of the proposed sensor system, where the mean errors for water and total levels are 0.14 cm and 0.08 cm, respectively. In the validation tests, a determination coefficient (R2) of 0.99 is obtained and a RMSE of 3.51 cm and 2.69 cm for water and total levels, respectively.}
}
@article{SONG2024105850,
title = {Probabilistic prediction of uniaxial compressive strength for rocks from sparse data using Bayesian Gaussian process regression with Synthetic Minority Oversampling Technique (SMOTE)},
journal = {Computers and Geotechnics},
volume = {165},
pages = {105850},
year = {2024},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2023.105850},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X23006079},
author = {Chao Song and Tengyuan Zhao and Ling Xu and Xiaolin Huang},
keywords = {Data-driven approach, Site investigation, Sparse data, Feature selection, Machine learning},
abstract = {Uniaxial compressive strength (UCS) of rocks is one of key rock strength parameters. Generally speaking, UCS can be measured directly through uniaxial compression tests, which is often unfeasible, especially when intact rock samples are highly fragile. Alternatively, the UCS of rocks can be estimated indirectly from other easily available rock indices. Note that adequate measurement data is the prerequisite for the accurate estimation of UCS using indirect methods. This may be difficult to achieve due to the limitation of time and budget, especially for small- to medium-sized projects. In this case, it becomes a challenging issue on how to develop a robust and reliable model for UCS estimation using the sparse measurement data. A fully Bayesian Gaussian process regression (fB-GPR) approach with Synthetic Minority Oversampling Technique (SMOTE) is proposed in this paper to address this problem. A real-life example from Malaysia was used for illustration and validation of proposed method. Results showed that when the synthetic sample size in SMOTE reaches 30 (i.e., optimal synthetic sample size), the coefficient of determination (R2) increases by about 18.92%, and the accuracy of feature selection reaches 98%, compared with the scenario with only sparse measurement data used for fB-GPR model development.}
}
@article{DOBSLAW2023111802,
title = {Generic and industrial scale many-criteria regression test selection},
journal = {Journal of Systems and Software},
volume = {205},
pages = {111802},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111802},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223001978},
author = {Felix Dobslaw and Ruiyuan Wan and Yuechan Hao},
keywords = {Software testing, Regression testing, Test case selection, Industrial-scale optimization},
abstract = {While several test case selection algorithms (heuristic and optimal) and formulations (linear and non-linear) have been proposed, no multi-criteria framework enables Pareto search — the state-of-the-art approach of doing multi-criteria optimization. Therefore, we introduce the highly parallelizable, openly available Many-Criteria Test-Optimization Algorithm (MC-TOA) framework that combines heuristic Pareto search and optimality gap knowledge per criterion. MC-TOA is largely agnostic to the criteria formulations and can incorporate many criteria where existing approaches offer limited scope (single or few objectives/constraints), lack flexibility in the expression and assurance of constraints, or run into problem complexity issues. For two large-scale systems with up to six criteria and thousands of system test cases, MC-TOA not only produces, over the board, superior Pareto fronts in terms of HVI score compared to the state-of-the-art many-objective heuristic baseline, it also does that within minutes of runtime for worst-case executions, i.e., assuming that a regression affects the entire test-suite. MC-TOA depends on convex solvers. We find that the evaluated open-source solvers are slower but suffice for smaller systems, while being less robust for larger systems. Linear formulations execute faster and obtain near-optimal results, which led to faster and better overall convergence of MC-TOA compared to integer formulations. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
@article{SALAHSHOOR2023115657,
title = {Model-free Data-Driven viscoelasticity in the frequency domain},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {403},
pages = {115657},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2022.115657},
url = {https://www.sciencedirect.com/science/article/pii/S0045782522006120},
author = {Hossein Salahshoor and Michael Ortiz},
keywords = {Viscoelasticity, Frequency domain, Data-Driven computing, Model-free computing, Machine learning},
abstract = {We develop a Data-Driven framework for the simulation of wave propagation in viscoelastic solids directly from dynamic testing material data, including data from Dynamic Mechanical Analysis (DMA), nano-indentation, Dynamic Shear Testing (DST) and Magnetic Resonance Elastography (MRE), without the need for regression or material modeling. The problem is formulated in the frequency domain and the method of solution seeks to minimize a distance between physically admissible histories of stress and strain, in the sense of compatibility and equilibrium, and the material data. We metrize the space of histories by means of the flat-norm of their Fourier transform, which allows consideration of infinite wave trains such as harmonic functions. Another significant advantage of the flat norm is that it allows the response of the system at one frequency to be inferred from data at nearby frequencies. We demonstrate and verify the approach by means of two test cases, a polymeric truss structure characterized by DMA data and a 3D soft gel sample characterized by MRE data. The examples demonstrate the ease of implementation of the Data-Driven scheme within conventional commercial codes and its robust convergence properties, both with respect to the solver and the data.}
}
@article{CHAUHAN2024109945,
title = {On active learning for Gaussian process-based global sensitivity analysis},
journal = {Reliability Engineering & System Safety},
volume = {245},
pages = {109945},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2024.109945},
url = {https://www.sciencedirect.com/science/article/pii/S0951832024000206},
author = {Mohit S. Chauhan and Mariel Ojeda-Tuz and Ryan A. Catarelli and Kurtis R. Gurley and Dimitrios Tsapetis and Michael D. Shields},
keywords = {Sobol index, Active learning, Global sensitivity analysis, Gaussian process regression, Kriging},
abstract = {This paper explores the application of active learning strategies to adaptively learn Sobol indices for global sensitivity analysis. We demonstrate that active learning for Sobol indices poses unique challenges due to the definition of the Sobol index as a ratio of variances estimated from Gaussian process surrogates. Consequently, learning strategies must either focus on convergence in the numerator or the denominator of this ratio. However, rapid convergence in either one does not guarantee convergence in the Sobol index. We propose a novel strategy for active learning that focuses on resolving the main effects of the Gaussian process (associated with the numerator of the Sobol index) and compare this with existing strategies based on convergence in the total variance (the denominator of the Sobol index). The new strategy, implemented through a new learning function termed the MUSIC (minimize uncertainty in Sobol index convergence), generally converges in Sobol index error more rapidly than the existing strategies based on the Expected Improvement for Global Fit (EIGF) and the Variance Improvement for Global Fit (VIGF). Both strategies are compared with simple sequential random sampling and the MUSIC learning function generally converges most rapidly for low-dimensional problems. However, for high-dimensional problems, the performance is comparable to random sampling. The new learning strategy is demonstrated for a practical case of adaptive experimental design for large-scale Boundary Layer Wind Tunnel experiments.}
}
@article{TAHVILI201826,
title = {ESPRET: A tool for execution time estimation of manual test cases},
journal = {Journal of Systems and Software},
volume = {146},
pages = {26-41},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301778},
author = {Sahar Tahvili and Wasif Afzal and Mehrdad Saadatmand and Markus Bohlin and Sharvathul Hasan Ameerjan},
keywords = {Software testing, Execution time, Test specification, Optimization, Manual testing, Regression analysis},
abstract = {Manual testing is still a predominant and an important approach for validation of computer systems, particularly in certain domains such as safety-critical systems. Knowing the execution time of test cases is important to perform test scheduling, prioritization and progress monitoring. In this work, we present, apply and evaluate ESPRET (EStimation and PRediction of Execution Time) as our tool for estimating and predicting the execution time of manual test cases based on their test specifications. Our approach works by extracting timing information for various steps in manual test specification. This information is then used to estimate the maximum time for test steps that have not previously been executed, but for which textual specifications exist. As part of our approach, natural language parsing of the specifications is performed to identify word combinations to check whether existing timing information on various test steps is already available or not. Since executing test cases on the several machines may take different time, we predict the actual execution time for test cases by a set of regression models. Finally, an empirical evaluation of the approach and tool has been performed on a railway use case at Bombardier Transportation (BT) in Sweden.}
}
@article{KHATIBSYARBINI201874,
title = {Test case prioritization approaches in regression testing: A systematic literature review},
journal = {Information and Software Technology},
volume = {93},
pages = {74-93},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2017.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0950584916304888},
author = {Muhammad Khatibsyarbini and Mohd Adham Isa and Dayang N.A. Jawawi and Rooster Tumeng},
keywords = {Test case prioritization, Regression testing, Software testing, Systematic literature review},
abstract = {Context
Software quality can be assured by going through software testing process. However, software testing phase is an expensive process as it consumes a longer time. By scheduling test cases execution order through a prioritization approach, software testing efficiency can be improved especially during regression testing.
Objective
It is a notable step to be taken in constructing important software testing environment so that a system's commercial value can increase. The main idea of this review is to examine and classify the current test case prioritization approaches based on the articulated research questions.
Method
Set of search keywords with appropriate repositories were utilized to extract most important studies that fulfill all the criteria defined and classified under journal, conference paper, symposiums and workshops categories. 69 primary studies were nominated from the review strategy.
Results
There were 40 journal articles, 21 conference papers, three workshop articles, and five symposium articles collected from the primary studies. As for the result, it can be said that TCP approaches are still broadly open for improvements. Each approach in TCP has specified potential values, advantages, and limitation. Additionally, we found that variations in the starting point of TCP process among the approaches provide a different timeline and benefit to project manager to choose which approaches suite with the project schedule and available resources.
Conclusion
Test case prioritization has already been considerably discussed in the software testing domain. However, it is commonly learned that there are quite a number of existing prioritization techniques that can still be improved especially in data used and execution process for each approach.}
}
@article{MIRZEHIKALATEHKAZEMI2023200061,
title = {Application of XGB-based metaheuristic techniques for prediction time-to-failure of mining machinery},
journal = {Systems and Soft Computing},
volume = {5},
pages = {200061},
year = {2023},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2023.200061},
url = {https://www.sciencedirect.com/science/article/pii/S2772941923000145},
author = {Mohammad {Mirzehi Kalateh Kazemi} and Zohreh Nabavi and Mojtaba Rezakhah and Ali Masoudi},
keywords = {XGB-based hybrid model, Failure time data, extreme gradient boosting (XGB), particle swarm optimization (PSO), gray wolf optimization (GWO), Metaheuristic optimization},
abstract = {Mining equipment is a critical component in the success of mining operations, and unplanned downtime can be costly. Efficient and intelligent maintenance planning is therefore essential to minimize downtime and maximize productivity. Consecutive time-to-failure (TTF) is an important indicator of machine reliability, and accurate TTF predictions enable effective preventive maintenance planning. Therefore, this study proposes hybrid models of extreme gradient boosting (XGB), optimized by particle swarm optimization (PSO) and gray wolf optimization (GWO), for the prediction of TTF in mining machinery. Additionally, validation of the hybrid model was conducted using support vector regression (SVR) method. Historical data on mining machine failures were collected, and a case study was conducted to investigate shovels in an open-pit mine. The PSO-XGB method was found to be the most accurate predictor of failure time with R2 values of 0.99, RMSE values of 50.66 and 51.77, MAE values of 4.52 and 10.81, and AARE values of 1.15 and 1.24 in the training and testing phases. This research highlights the importance of efficient and intelligent maintenance planning to minimize downtime and optimize productivity in mining operations.}
}
@article{RAD2025105809,
title = {Tackling the small imbalanced horizontal dataset regressions by Stability Selection and SMOGN: a case study of ventilation-free days prediction in the pediatric intensive care unit and the importance of PRISM},
journal = {International Journal of Medical Informatics},
volume = {196},
pages = {105809},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.105809},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625000267},
author = {Milad Rad and Alireza Rafiei and Jocelyn Grunwell and Rishikesan Kamaleswaran},
keywords = {Synthetic data, Machine learning, Ventilation-free days, Data imbalance, Critical care},
abstract = {Objective
The regression of small imbalanced horizontal datasets is an important problem in bioinformatics due to rare but vital data points impacting model performance. Most clinical studies suffer from imbalance in their distribution which impacts the learning ability of regression or classification models. The imbalance once combined with the small number of samples reduces the prediction performance. An improvement in the trainability of small imbalanced datasets hugely improves the potency of current prediction models that rely on a small set of valuable expensive samples.
Materials and methods
A method called Stability Selection has been used to overcome the high dimensionality problem, which arises when the sample sizes are relatively small compared to the number of features. The method was used to improve the performance of the Synthetic Minority Over-Sampling Technique for Regression with Gaussian Noise (SMOGN), an imbalance removal algorithm. To test the new pipeline, a small imbalanced cohort of pediatric ICU patients was used to predict the number of Ventilator-Free Days (VFD) a patient may experience for an admission period of 28 days due to respiratory illnesses.
Results
Our model demonstrated its effectiveness by overcoming label imbalance while predicting almost all the non-surviving patients in the test dataset using Stability Selection before applying SMOGN. Our study also highlighted the importance of Pediatrics Risk of Mortality (PRISM) as a powerful VFD predictor if combined with other clinical features.
Conclusion
This paper shows how a hybrid strategy of Stability Selection, SMOGN, and regression can improve the outcome of highly imbalanced datasets and reduce the probability of highly expensive false negative detections in severe acute respiratory disease syndrome cases. The proposed modeling pipeline can reduce the overall VFD regression error but is also expandable to other regressable features. We also showed the importance of PRISM as a strong VFD predictor.}
}
@article{HOKINOYAMAGUTI2020104198,
title = {Development of CART model for prediction of tuberculosis treatment loss to follow up in the state of São Paulo, Brazil: A case–control study},
journal = {International Journal of Medical Informatics},
volume = {141},
pages = {104198},
year = {2020},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2020.104198},
url = {https://www.sciencedirect.com/science/article/pii/S1386505619314133},
author = {Verena {Hokino Yamaguti} and Domingos Alves and Rui Pedro {Charters Lopes Rijo} and Newton Shydeo {Brandão Miyoshi} and Antônio Ruffino-Netto},
keywords = {Tuberculosis, Treatment loss to follow up, Prediction model, Feature selection},
abstract = {Background
Tuberculosis is the leading cause of infectious disease-related death, surpassing even the immunodeficiency virus. Treatment loss to follow up and irregular medication use contribute to persistent morbidity and mortality. This increases bacillus drug resistance and has a negative impact on disease control.
Objective
This study aims to develop a computational model that predicts the loss to follow up treatment in tuberculosis patients, thereby increasing treatment adherence and cure, reducing efforts regarding treatment relapses and decreasing disease spread.
Methods
This is a case-controlled study. Included in the data set were 103,846 tuberculosis cases from the state of São Paulo. They were collected using the TBWEB, an information system used as a tuberculosis treatment monitor, containing samples from 2006 to 2016. This set was later resampled into 6 segments with a 1-1 ratio. This ratio was used to avoid any bias during the model construction.
Results
The Classification and Regression Trees were used as the prediction model. Training and test sets accounted for 70% in the former and 30% in the latter of the tuberculosis cases. The model displayed an accuracy of 0.76, F-measure of 0.77, sensitivity of 0.80 and specificity of 0.71. The model emphasizes the relationship between several variables that had been identified in previous studies as related to patient cure or loss to follow up treatment in tuberculosis patients.
Conclusion
It was possible to construct a predictive model for loss to follow up treatment in tuberculosis patients using Classification and Regression Trees. Although the fact that the ideal predictive ability was not achieved, it seems reasonable to propose the use of Classification and Regression Trees models to predict likelihood of treatment follow up to support healthcare professionals in minimising the loss to follow up.}
}
@article{NGUYEN2022111299,
title = {In situ measurement of fish color based on machine vision: A case study of measuring a clownfish’s color},
journal = {Measurement},
volume = {197},
pages = {111299},
year = {2022},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2022.111299},
url = {https://www.sciencedirect.com/science/article/pii/S0263224122005401},
author = {Chanh-Nghiem Nguyen and Van-Thoai Vo and Lam-Hong-Ngoc Nguyen and Hua {Thai Nhan} and Chi-Ngon Nguyen},
keywords = {Clownfish color, Ridge regression, Brightness adjustment, In situ color measurement of ornamental fish, CIEDE2000},
abstract = {This study proposed an innovative technique to measure the fish color in situ based on machine vision to avoid potential effects on fish health that might result from conventional measurement with a colorimeter. The research goal was achieved by developing a color conversion model trained with images of a color reference target in the ambient environment and clay samples in the aquarium representing the target fish. Brightness adjustment was effectively applied to these images to minimize uneven illumination in both environments. The generalization ability of the model was ensured with regularized regression. Consequently, an optimal cubic ridge model was obtained with appreciably low training and testing mean color errors of 1.17 ± 0.64 and 1.10 ± 0.50 CIEDE2000 color difference units, respectively. Preliminary results of measuring the clownfish color showed that the proposed system had much potential for in situ and non-invasive visualizing of the color distribution of small ornamental fish with color non-uniformity.}
}
@article{MONDAL2019110403,
title = {Mahtab: Phase-wise acceleration of regression testing for C},
journal = {Journal of Systems and Software},
volume = {158},
pages = {110403},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110403},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301773},
author = {Shouvick Mondal and Rupesh Nasre},
keywords = {Regression test selection, Test-prioritization, Parallelization window, Relevance-and-confinedness},
abstract = {Software regression testing consists of offline, online, and execution phases which are executed sequentially. The offline phase involves code instrumentation and test-coverage collection. Subsequently, the online phase performs program differencing, test-suite selection and prioritization. Finally, the selected test-cases are executed against the new version of software for its re-validation. Regression testing is a time-consuming process and is often on the critical path of the project. To improve the turn-around time of software development cycle, our goal is to reduce regression testing time across all phases using multi-core parallelization. This poses several challenges that stem from I/O, dependence on third-party libraries, and inherently sequential components in the overall testing process. We propose parallelization test-windows to effectively partition test-cases across threads. To measure the benefit of prioritization coupled with multi-threaded execution, we propose a new metric, EPSilon, for rewarding failure observation frequency in the timeline of test-execution. To measure the rate of code-change coverage due to regression test prioritization, we introduce ECC, a variant of the widely used APFD metric. We illustrate the effectiveness of our approach using the popular Software-artifact Infrastructure Repository (SIR) and five real-world projects from GitHub.}
}
@article{JUNG2019110419,
title = {Automated code-based test selection for software product line regression testing},
journal = {Journal of Systems and Software},
volume = {158},
pages = {110419},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110419},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301931},
author = {Pilsu Jung and Sungwon Kang and Jihyun Lee},
keywords = {Product lines testing, Regression test selection, Software maintenance, Software evolution},
abstract = {Regression testing for software product lines (SPLs) is challenging and can be expensive because it must ensure that all the products of a product family are correct whenever changes are made. SPL regression testing can be made efficient through a test case selection method that selects only the test cases relevant to the changes. Some approaches for SPL test case selection have been proposed but either they were not efficient by requiring intervention from human experts or they cannot be used if requirements specifications, architecture and/or traceabilities for test cases are not available or partially eroded. To address these limitations, we propose an automated method of source code-based regression test selection for SPLs. Our method reduces the repetition of the selection procedure and minimizes the in-depth analysis effort for source code and test cases based on the commonality and variability of a product family. Evaluation results of our method using six product lines show that our method reduces the overall time to perform regression testing by 14.8% ∼ 49.1% on average compared to an approach of repetitively applying Ekstazi, which is the state-of-the-art regression test selection method for a single product, to each product of a product family.}
}
@article{IBRAHIM2025111481,
title = {Impacts of climate change on energy-saving sensitivity of residential building envelope design parameters in three hot-dry cities},
journal = {Journal of Building Engineering},
volume = {99},
pages = {111481},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.111481},
url = {https://www.sciencedirect.com/science/article/pii/S2352710224030493},
author = {Ahmed J. Ibrahim and Dnya D. Zangana and Sheng Liu and Holly Samuelson and Linchuan Yang},
keywords = {Sensitivity analysis, Energy consumption, Climate resilience, Climate change projections, Envelope design parameters},
abstract = {Warming climatic conditions are projected to intensify extreme heat events, especially in hot climates, affecting the energy-saving effectiveness of various building envelope design parameters. However, limited studies exist on the energy-saving sensitivity of building envelope design parameters for residential buildings in hot and dry climates under future climate change. This study aims to fill this gap by examining typical residential buildings in three cities in Iraq, classified as hot desert, hot semiarid, and Mediterranean. First, the most common type of residential building was selected as a case study, and its energy modeling was validated using measured energy bills. Second, future climatic weather files were constructed using the latest general circulation models to assess their impacts on building energy consumption. Third, the energy-saving sensitivity of applicable building envelope design parameters under different future climatic conditions was obtained through local and global sensitivity analysis methods. The results of global sensitivity analysis indicate that the solar heat gain coefficient of windows, the specific heat of exterior walls, and the projection of side fins are the most important factors, with standardized regression coefficients (SRC) ranging from −0.92 to 0.62. Notably, the SRC of windows' solar heat gain coefficient is expected to increase under future climate scenarios. In contrast, the significance of the specific heat of exterior walls depends on local climates. This study provides insights for policymakers and architects to prioritize building envelope design strategies that enhance the climate resilience of residential buildings.}
}
@article{ENGBERS2024597,
title = {Unsupervised Model Selection for Assembly Process Optimization},
journal = {Procedia CIRP},
volume = {130},
pages = {597-603},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.135},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124012927},
author = {Hendrik Engbers and Dirk Schweers and Michael Freitag},
keywords = {Model Selection, Anomaly Detection, Process Data, Assembly Assistance System},
abstract = {Manufacturing systems generate large amounts of data, but the availability of appropriate labels for training and systematically evaluating machine learning algorithms can be limited. This makes it difficult to compare different models and select the most effective one for a specific use case. Therefore, we propose a method that aims at predicting conventional model evaluation metrics to support the selection of the most appropriate algorithm and its hyperparameters. The proposed method uses a Gradient Boosting Regressor (GBR) that integrates the Calinski-Harabasz Index (CHI) of different unsupervised anomaly detection algorithms as a suitability indicator. As a result, this method does not require labeled data, benefits from fast processing, and can be fully automated. We have applied this approach to an industrial assembly assistance system and tested it on over 10,000 publicly available datasets. Our experiments show improvements in prediction performance, measured in terms of precision against the best single candidate, with an average increase of 58% and a median increase of 200%. In addition, recall shows an average increase of 62% and a median increase of 300%.}
}
@article{MOHAMAD2025104833,
title = {Machine learning predictive performance in road accident severity: A case study from Thailand},
journal = {Results in Engineering},
volume = {26},
pages = {104833},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.104833},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025009089},
author = {Ittirit Mohamad and Sajjakaj JomnonKwao and Vatanavongs Ratanavaraha},
keywords = {Machine learning, Comparative analysis, Road safety, Accident severity, Deep learning, Transportation, Risk assessment, Logistics, Big data},
abstract = {Traffic accidents remain a major cause of fatalities and economic losses worldwide, necessitating the development of accurate predictive models for enhancing road safety and minimizing risks. In Thailand, where road traffic injuries persist as a public health challenge, data-driven approaches can significantly contribute to accident prevention strategies. This study evaluates the predictive performance of multiple supervised machine learning algorithms in classifying accident severity, addressing the gap in prior research that lacks a comparative analysis of multiple models trained on large-scale crash data. Eight algorithms were assessed, including Decision Tree (DT), Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbors (kNN), Neural Network (NN), Naïve Bayes (NB), Logistic Regression (LR), and Gradient Boosting (GB).A dataset comprising 112,837 road accidents over a five-year period in Thailand was analyzed, focusing exclusively on incidents where drivers were at fault. The dataset underwent extensive preprocessing, including missing value imputation, data balancing checks, and feature selection to ensure robustness. Among the models tested, Random Forest demonstrated superior performance in the binary classification task, achieving an average class AUC of 0.768, classification accuracy of 0.777, precision of 0.752, and recall of 0.777. Key predictive features include road type (highway), speeding, time of day (daylight), absence of lighting at night, and driver gender. While the model effectively classifies non-fatal accidents, its recall for fatalities remains limited (0.198), highlighting challenges in predicting fatal crashes due to the complex interplay of contributing factors.These findings reinforce the applicability of machine learning in traffic safety research and provide valuable insights for policymakers seeking data-driven interventions. Future work should explore advanced feature engineering and ensemble techniques to enhance fatality prediction accuracy.}
}
@article{PRADOLIMA2020106268,
title = {Test Case Prioritization in Continuous Integration environments: A systematic mapping study},
journal = {Information and Software Technology},
volume = {121},
pages = {106268},
year = {2020},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106268},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920300185},
author = {Jackson A. {Prado Lima} and Silvia R. Vergilio},
keywords = {Software testing, Continuous Integration, Test Case Prioritization},
abstract = {Context: Continuous Integration (CI) environments allow frequent integration of software changes, making software evolution more rapid and cost-effective. In such environments, the regression test plays an important role, as well as the use of Test Case Prioritization (TCP) techniques. Such techniques attempt to identify the test case order that maximizes certain goals, such as early fault detection. This research subject has been raising interest because some new challenges are faced in the CI context, as TCP techniques need to consider time constraints of the CI environments. Objective: This work presents the results of a systematic mapping study on Test Case Prioritization in Continuous Integration environments (TCPCI) that reports the main characteristics of TCPCI approaches and their evaluation aspects. Method: The mapping was conducted following a plan that includes the definition of research questions, selection criteria and search string, and the selection of search engines. The search returned 35 primary studies classified based on the goal and kind of used TCP technique, addressed CI particularities and testing problems, and adopted evaluation measures. Results: The results show a growing interest in this research subject. Most studies have been published in the last four years. 80% of the approaches are history-based, that is, are based on the failure and test execution history. The great majority of studies report evaluation results by comparing prioritization techniques. The preferred measures are Time and number/percentage of Faults Detected. Few studies address CI testing problems and characteristics, such as parallel execution and test case volatility. Conclusions: We observed a growing number of studies in the field. Future work should explore other information sources such as models and requirements, as well as CI particularities and testing problems, such as test case volatility, time constraint, and flaky tests, to solve existing challenges and offer cost-effective approaches to the software industry.}
}
@article{LUO2016179,
title = {Regression and classification using extreme learning machine based on L1-norm and L2-norm},
journal = {Neurocomputing},
volume = {174},
pages = {179-186},
year = {2016},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.03.112},
url = {https://www.sciencedirect.com/science/article/pii/S092523121501139X},
author = {Xiong Luo and Xiaohui Chang and Xiaojuan Ban},
keywords = {Extreme learning machine, Ridge regression, Elastic net, Model selection, Bayesian information criterion (BIC)},
abstract = {Extreme learning machine (ELM) is a very simple machine learning algorithm and it can achieve a good generalization performance with extremely fast speed. Therefore it has practical significance for data analysis in real-world applications. However, it is implemented normally under the empirical risk minimization scheme and it may tend to generate a large-scale and over-fitting model. In this paper, an ELM model based on L1-norm and L2-norm regularizations is proposed to handle regression and multiple-class classification problems in a unified framework. The proposed model called L1–L2-ELM combines the grouping effect benefits of L2 penalty and the tendency towards sparse solution of L1 penalty, thus it can control the complexity of the network and prevent over-fitting. To solve the mixed penalty problem, the separate elastic net algorithm and Bayesian information criterion (BIC) are adopted to find the optimal model for each response variable. We test the L1–L2-ELM algorithm on one artificial case and nine benchmark data sets to evaluate its performance. Simulation results have shown that the proposed algorithms outperform the original ELM as well as other advanced ELM algorithms in terms of prediction accuracy, and it is more robust in both regression and classification applications.}
}
@incollection{HEMMATI2019185,
title = {Chapter Four - Advances in Techniques for Test Prioritization},
editor = {Atif M. Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {112},
pages = {185-221},
year = {2019},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2017.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0065245817300566},
author = {Hadi Hemmati},
keywords = {Test case prioritization, Code coverage, Diversity, Fault detection, Regression testing, Search-based testing, Multiobjective, Execution cost, Scalability},
abstract = {With the increasing size of software systems and the continuous changes that are committed to the software's codebase, regression testing has become very expensive for real-world software applications. Test case prioritization is a classic solution in this context. Test case prioritization is the process of ranking existing test cases for execution with the goal of finding defects sooner. It is useful when the testing budget is limited and one needs to limit their test execution cost, by only running top n test cases, according to the testing budget. There are many heuristics and algorithms to rank test cases. In this chapter, we will see some of the most common test case prioritization techniques from software testing literature as well as trends and advances in this domain.}
}
@article{IBRAHIM2023481,
title = {Evaluation of angled splitters as scour countermeasure at circular piers},
journal = {Alexandria Engineering Journal},
volume = {74},
pages = {481-494},
year = {2023},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2023.05.067},
url = {https://www.sciencedirect.com/science/article/pii/S1110016823004271},
author = {Mohamed M. Ibrahim and Mahmoud A. Refaey and Hadeer M. Hashem and Ahmed M. Ibraheem},
keywords = {Angled splitter, Circular pier, Local scour, Velocity distribution, Bed configurations},
abstract = {Scour around bridge piers is local phenomenon may cause complete failure for the hydraulic structure. This study explored experimentally using splitter plates at specific angles installed upstream single circular bridge pier to improve the nearby flow field and minimize the local scour. Ninety runs were carried out considering 9 splitter models. Four splitter lengths and 3 vertex angles were used. The splitter lengths were between 0 and 1.5 times of pier diameter, each was tested for 3 vertex angles ranged between 0° and 30°. The tests were done under 9 different hydraulic conditions including 3 discharges of 75, 100, and 125 l/s and 3 tailwater depths of 12.5, 15, and 17.5 cm. The turbulent flow conditions were investigated by plotting velocity profiles at different sections. The bed configurations under clear water conditions were presented. The results of pier without splitter were used as reference. The study outcome that the local scour depth was decreased by the increase of splitter length and vertex angle. The near-bed flow velocity and the corresponding Froude No. downstream of the pier was minimized for 1.5D splitter length at 30° vertex angle and the minimum scour geometry was located. The effectiveness of splitters were remarkable by the decrease of flow discharge and increase of tailwater depth provided that the discontinuity of scour hole length in case of multi-circular piers. Regression analysis was employed to develop empirical formula for the estimation of maximum scour depth around circular pier with splitter.}
}
@article{GHANI2022635,
title = {Improved Test Case Selection Algorithm to Reduce Time in Regression Testing},
journal = {Computers, Materials and Continua},
volume = {72},
number = {1},
pages = {635-650},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.025027},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822010694},
author = {Israr Ghani and Wan M. N. Wan-Kadir and Adila Firdaus Arbain and Noraini Ibrahim},
keywords = {Test case selection, regression testing, change detection, TCS algorithm, test suite minimization},
abstract = {Regression testing (RT) is an essential but an expensive activity in software development. RT confirms that new faults/errors will not have occurred in the modified program. RT efficiency can be improved through an effective technique of selected only modified test cases that appropriate to the modifications within the given time frame. Earlier, several test case selection approaches have been introduced, but either these techniques were not sufficient according to the requirements of software tester experts or they are ineffective and cannot be used for available test suite specifications and architecture. To address these limitations, we recommend an improved and efficient test case selection (TCS) algorithm for RT. Our proposed technique decreases the execution time and redundancy of the duplicate test cases (TC) and detects only modified changes that appropriate to the modifications in test cases. To reduce execution time for TCS, evaluation results of our proposed approach are established on fault detection, redundancy and already executed test case. Results indicate that proposed technique decreases the inclusive testing time of TCS to execute modified test cases by, on average related to a method of Hybrid Whale Algorithm (HWOA), which is a progressive TCS approach in regression testing for a single product.}
}
@article{ROZA2024107444,
title = {On the use of contextual information for machine learning based test case prioritization in continuous integration development},
journal = {Information and Software Technology},
volume = {171},
pages = {107444},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107444},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924000491},
author = {Enrique A. da Roza and Jackson A. do {Prado Lima} and Silvia R. Vergilio},
keywords = {Regression testing, Continuous integration, Reinforcement learning},
abstract = {Context:
In most software organizations, Continuous Integration (CI) is a common practice usually subject to some budgets. Consequently, prioritizing test cases to be executed in the CI cycle is fundamental. The idea is first to execute test cases with higher failure-proneness to provide rapid feedback and decrease costs. To perform this task approaches in the literature adopt failure history and Machine Learning (ML). However, in addition to the failure history, it is also important to consider information from the CI context of the organizations and the application domain.
Objective:
For this end, we introduce a contextual information approach for ML algorithms. Such an approach considers information from the testing activity that can be easily collected, such as test case execution time, size, and complexity. We implement the approach by introducing two contextual versions of the algorithms: Multi-Armed Bandit (MAB) and Random Forest (RF).
Method:
Six systems are used to compare both contextual algorithms and to evaluate their performance regarding their corresponding non-contextual versions, considering three different budgets.
Results:
Contextual algorithms perform better when indicators related to test time reduction are considered, as the contextual information they use is related to execution time. Regarding NAPFD and APFDc, the non-contextual algorithms have better general performance, but both contextual versions obtain competitive results.
Conclusions:
The contextual versions implemented can capture the desired context information in the prioritization without negatively impacting their performance regarding fault-detection.}
}
@article{HASNAIN20201051,
title = {An Ontology Based Test Case Prioritization Approach in Regression Testing},
journal = {Computers, Materials and Continua},
volume = {67},
number = {1},
pages = {1051-1068},
year = {2020},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2021.014686},
url = {https://www.sciencedirect.com/science/article/pii/S1546221820001897},
author = {Muhammad Hasnain and Seung Ryul Jeong and Muhammad Fermi Pasha and Imran Ghani},
keywords = {Software code metric, machine learning, faults detection, testing},
abstract = {Regression testing is a widely studied research area, with the aim of meeting the quality challenges of software systems. To achieve a software system of good quality, we face high consumption of resources during testing. To overcome this challenge, test case prioritization (TCP) as a sub-type of regression testing is continuously investigated to achieve the testing objectives. This study provides an insight into proposing the ontology-based TCP (OTCP) approach, aimed at reducing the consumption of resources for the quality improvement and maintenance of software systems. The proposed approach uses software metrics to examine the behavior of classes of software systems. It uses Binary Logistic Regression (BLR) and AdaBoostM1 classifiers to verify correct predictions of the faulty and non-faulty classes of software systems. Reference ontology is used to match the code metrics and class attributes. We investigated five Java programs for the evaluation of the proposed approach, which was used to achieve code metrics. This study has resulted in an average percentage of fault detected (APFD) value of 94.80%, which is higher when compared to other TCP approaches. In future works, large sized programs in different languages can be used to evaluate the scalability of the proposed OTCP approach.}
}
@article{XIAN2022109690,
title = {Unified whale optimization algorithm based multi-kernel SVR ensemble learning for wind speed forecasting},
journal = {Applied Soft Computing},
volume = {130},
pages = {109690},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109690},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622007396},
author = {Huafeng Xian and Jinxing Che},
keywords = {Wind speed forecasting, Support vector regression, Model selection, Unified optimization, Whale optimization algorithm},
abstract = {Support vector regression (SVR) is widely used in the field of wind speed forecasting because of its excellent nonlinear learning ability. However, the drawback of SVR is the model selection problem, which has the high complexity O(K×m3) including kernel function selection and parameter selection. To solve this problem, this paper proposes a multi-kernel SVR ensemble (MKSVRE) model based on unified optimization and whale optimization algorithm (WOA), where the MKSVRE model is used to solve the kernel function selection problem, and the unified optimization and the WOA are used to solve the parameter selection problem. The proposed model provides an alternative without the need to specifically select a kernel function and thus enhances the adaptability of SVR to diverse data. In addition, the unified optimization takes into account the interactions between models and achieves a global parameter selection. The proposed model is tested by simulations on wind speed data from Shandong Province, China. By comparing the prediction results of the proposed model, the single kernel SVR models, the models before and after optimization, and six other models, the effectiveness of the proposed model is confirmed.}
}
@article{AKIAN2022111595,
title = {Learning “best” kernels from data in Gaussian process regression. With application to aerodynamics},
journal = {Journal of Computational Physics},
volume = {470},
pages = {111595},
year = {2022},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2022.111595},
url = {https://www.sciencedirect.com/science/article/pii/S002199912200657X},
author = {J.-L. Akian and L. Bonnet and H. Owhadi and É. Savin},
keywords = {Reproducing kernel Hilbert space, Gaussian process regression, Kernel ridge regression, Kernel flow, Aerodynamics},
abstract = {This paper introduces algorithms to select/design kernels in Gaussian process regression/kriging surrogate modeling techniques. We adopt the setting of kernel method solutions in ad hoc functional spaces, namely Reproducing Kernel Hilbert Spaces (RKHS), to solve the problem of approximating a regular target function given observations of it, i.e. supervised learning. A first class of algorithms is kernel flow, which was introduced in the context of classification in machine learning. It can be seen as a cross-validation procedure whereby a “best” kernel is selected such that the loss of accuracy incurred by removing some part of the dataset (typically half of it) is minimized. A second class of algorithms is called spectral kernel ridge regression, and aims at selecting a “best” kernel such that the norm of the function to be approximated is minimal in the associated RKHS. Within Mercer's theorem framework, we obtain an explicit construction of that “best” kernel in terms of the main features of the target function. Both approaches of learning kernels from data are illustrated by numerical examples on synthetic test functions, and on a classical test case in turbulence modeling validation for transonic flows about a two-dimensional airfoil.}
}
@article{ZHANG2022111419,
title = {Test case prioritization using partial attention},
journal = {Journal of Systems and Software},
volume = {192},
pages = {111419},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111419},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001285},
author = {Quanjun Zhang and Chunrong Fang and Weisong Sun and Shengcheng Yu and Yutao Xu and Yulei Liu},
keywords = {Software testing, Regression testing, Test case prioritization, Greedy algorithm},
abstract = {Test case prioritization (TCP) aims to reorder the regression test suite with a goal of increasing the fault detection rate. Various TCP techniques have been proposed based on different prioritization strategies. Among them, the greedy-based techniques are the most widely-used TCP techniques. However, existing greedy-based techniques usually reorder all candidate test cases in prioritization iterations, resulting in both efficiency and effectiveness problems. In this paper, we propose a generic partial attention mechanism, which adopts the previous priority values (i.e., the number of additionally-covered code units) to avoid considering all candidate test cases. Incorporating the mechanism with the additional-greedy strategy, we implement a novel coverage-based TCP technique based on partition ordering (OCP). OCP first groups the candidate test cases into different partitions and updates the partitions on the descending order. We conduct a comprehensive experiment on 19 versions of Java programs and 30 versions of C programs to compare the effectiveness and efficiency of OCP with six state-of-the-art TCP techniques: total-greedy, additional-greedy, lexicographical-greedy, unify-greedy, art-based, and search-based. The experimental results show that OCP achieves a better fault detection rate than the state-of-the-arts. Moreover, the time costs of OCP are found to achieve 85%–99% improvement than most state-of-the-arts.}
}
@article{GAROUSI201840,
title = {Multi-objective regression test selection in practice: An empirical study in the defense software industry},
journal = {Information and Software Technology},
volume = {103},
pages = {40-54},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2018.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0950584918301186},
author = {Vahid Garousi and Ramazan Özkan and Aysu Betin-Can},
keywords = {Regression testing, Multi-objective optimization, Genetic algorithms, Empirical study, Defence software industry, Action-research},
abstract = {Context
Executing an entire regression test-suite after every code change is often costly in large software projects. To cope with this challenge, researchers have proposed various regression test-selection techniques.
Objective
This paper was motivated by a real industrial need to improve regression-testing practices in the context of a safety-critical industrial software in the defence domain in Turkey. To address our objective, we set up and conducted an “action-research” collaborative project between industry and academia.
Method
After a careful literature review, we selected a conceptual multi-objective regression-test selection framework (called MORTO) and adopted it to our industrial context by developing a custom-built genetic algorithm (GA) based on that conceptual framework. GA is able to provide full coverage of the affected (changed) requirements while considering multiple cost and benefit factors of regression testing. e.g., minimizing the number of test cases, and maximizing cumulative number of detected faults by each test suite.
Results
The empirical results of applying the approach on the Software Under Test (SUT) demonstrate that this approach yields a more efficient test suite (in terms of costs and benefits) compared to the old (manual) test-selection approach, used in the company, and another applicable approach chosen from the literature. With this new approach, regression selection process in the project under study is not ad-hoc anymore. Furthermore, we have been able to eliminate the subjectivity of regression testing and its dependency on expert opinions.
Conclusion
Since the proposed approach has been beneficial in saving the costs of regression testing, it is currently in active use in the company. We believe that other practitioners can apply our approach in their regression-testing contexts too, when applicable. Furthermore, this paper contributes to the body of evidence in regression testing by offering a success story of successful implementation and application of multi-objective regression testing in practice.}
}