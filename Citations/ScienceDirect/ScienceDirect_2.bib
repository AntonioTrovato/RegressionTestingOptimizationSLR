@article{MA2016182,
title = {Estimation of the building energy use intensity in the urban scale by integrating GIS and big data technology},
journal = {Applied Energy},
volume = {183},
pages = {182-192},
year = {2016},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2016.08.079},
url = {https://www.sciencedirect.com/science/article/pii/S0306261916311679},
author = {Jun Ma and Jack C.P. Cheng},
keywords = {Artificial Neural Network (ANN), Big Data, Energy use intensity (EUI), Feature selection, Geographic information system (GIS), Support Vector Regression (SVR)},
abstract = {Buildings are the major source of energy consumption in urban areas. Accurate modeling and forecasting of the building energy use intensity (EUI) in the urban scale have many important applications, such as energy benchmarking and urban energy infrastructure planning. The use of Big Data technology is expected to have the capability of integrating a large number of predictors and giving an accurate prediction of the energy use intensity of buildings in the urban scale. However, past research has often used Big Data technology in estimating energy consumption of a single building rather than the urban scale, due to several challenges such as data collection and feature engineering. This paper therefore proposes a geographic information system integrated data mining methodology framework for estimating the building EUI in the urban scale, including preprocessing, feature selection, and algorithm optimization. Based on 216 prepared features, a case study on estimating the site EUI of 3640 multi-family residential buildings in New York City, was tested and validated using the proposed methodology framework. A comparative study on the feature selection strategies and the commonly used regression algorithms was also included in the case study. The results show that the framework was able to help produce lower estimation errors than previous research, and the model built by the Support Vector Regression algorithm on the features selected by Elastic Net has the least cross-validation mean squared error.}
}
@article{ALKHATIB201482,
title = {Φ-indices approach and multivariable regression analysis for prediction of discharge in asymmetric straight compound open channel flows},
journal = {Flow Measurement and Instrumentation},
volume = {38},
pages = {82-91},
year = {2014},
issn = {0955-5986},
doi = {https://doi.org/10.1016/j.flowmeasinst.2014.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0955598614000545},
author = {Issam A. Al-Khatib and Mustafa Gogus},
keywords = {-indices, Compound channel, Division line, Flood plain, Discharge estimation, Regression analysis},
abstract = {This study is related to flow measurement structures of asymmetric compound cross section mostly suggested for sediment laden-rivers, streams and wadis. Nine different models of asymmetrical rectangular cross sections were tested for a wide range of discharges. In each model, the stages and corresponding discharges were measured. From these measurements, the average discharges utilizing the Φ-indices Approach were determined. In addition, a multivariable regression model was derived with high accuracy for the prediction of discharge in asymmetric compound channels using five dimensionless parameters. The measured discharges were compared with the predicted ones obtained from the Φ-indices methods with vertical, horizontal and diagonal interface planes; FI-V, FI-D and FI-H, respectively, with the use of three well-known methods for the computation of the apparent shear stress acting on the interface perimeter, τa, and the multivariable regression model for discharge prediction. At lower relative depth values, almost all the tested methods predict discharge with acceptable accuracy. In addition, as the relative depth increases, the results demonstrate a suitable accuracy of the FI-V with the vertical division lines and the multivariable regression model method. The multivariable regression model presented has been identified as the best-fit model in 26 cases out of 29 through minimization of the mean squared errors.}
}
@article{MOROZOVA2022112146,
title = {A CFD-based surrogate model for predicting flow parameters in a ventilated room using sensor readings},
journal = {Energy and Buildings},
volume = {266},
pages = {112146},
year = {2022},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2022.112146},
url = {https://www.sciencedirect.com/science/article/pii/S0378778822003176},
author = {Nina Morozova and Francesc Xavier Trias and Roser Capdevila and Eugenio Schillaci and Assensi Oliva},
keywords = {Computational fluid dynamics, Surrogate models, Indoor airflow prediction, Machine learning, Mixed convection},
abstract = {In this work, we develop a computational fluid dynamics (CFD)-based surrogate model, which predicts flow parameters under different geometrical configurations and boundary conditions in a benchmark case of a mechanically ventilated room with mixed convection. The model inputs are the temperature and velocity values in different locations, which act as a surrogate of the sensor readings. The model’s output is a set of comfort-related flow parameters, such as the average Nusselt number on the hot wall, jet separation point, average kinetic energy, average enstrophy, and average temperature. We tested four different machine learning methods, among which we chose the gradient boosting regression due to its accurate performance. We also adapted the developed model for indoor environment control applications by determining the optimal combinations of sensor positions which minimize the prediction error. This model does not require the repetition of CFD simulations in order to be applied since the structure of the input data imitates sensor readings. Furthermore, the low computational cost of the model execution and good accuracy makes it an effective alternative to CFD for applications where rapid predictions of complex flow configurations are required, such as model predictive control.}
}
@article{HAMMADKHALIQ2023101907,
title = {Spatiotemporal landslide susceptibility mapping using machine learning models: A case study from district Hattian Bala, NW Himalaya, Pakistan},
journal = {Ain Shams Engineering Journal},
volume = {14},
number = {3},
pages = {101907},
year = {2023},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2022.101907},
url = {https://www.sciencedirect.com/science/article/pii/S2090447922002180},
author = {Ahmad {Hammad Khaliq} and Muhammad Basharat and Malik {Talha Riaz} and Muhammad {Tayyib Riaz} and Saad Wani and Nadhir Al-Ansari and Long {Ba Le} and Nguyen {Thi Thuy Linh}},
keywords = {Hattian Bala, Landslide susceptibility, Logistic regression, Machine learning, Random forest},
abstract = {The Himalayan region, a rugged mountain zone is among the most susceptible zones to the landslide hazard due to its terrain, geography, and active tectonics. Machine learning (ML) techniques are most advanced and precise methods to develop landslide susceptibility model (LSM). The current study was designed to analyze and assess the landslide susceptibility using ML approaches for District Hattian Bala, NW Himalayas, Pakistan. The historical satellite imageries are used to generate spatiotemporal landslide inventories of year 2005, 2007 and 2012. A spatial database was created pertaining to topographic, environmental, geologic, and anthropogenic factors including slope, aspect, elevation, curvature, plane curvature, profile curvature, topographic wetness index (TWI), lithology, distance to faults, distance to streams, distance to roads, normalized difference vegetation index (NDVI) and land use/ land cover (LULC). These LCFs were selected to analyze periodic landslide susceptibility in the region. The experimental design utilized 349, 393, and 735 landslide inventory of 2005, 2007, and 2012 respectively. Two ML models, i.e., Random Forest (RF) and Logistic Regression (LR) were applied to assess landslide susceptibility determine by thirteen landslide causative factors (LCFs). The spatiotemporal landslide inventory was partitioned into training (70%) and testing (30%) landslides for respective years to check the prediction accuracies of selected ML models. Comparative analysis of different LSMs was performed by the Receiver Operator Curves – Area Under Curves (ROC-AUC). The resultant accuracy, MAE, RMSE, Kappa, Precision, Recall, F1 indicated that RF outperformed the LR model. The study aims to minimize losses to lives and potential economic damage linked with recurrent slope instabilities in the region. It is anticipated that use of ML algorithms would support concerned authorities and organizations to effectively plan and manage landslide hazard in the region.}
}
@article{BROEKMEULEN2019265,
title = {Quantifying the potential to improve on food waste, freshness and sales for perishables in supermarkets},
journal = {International Journal of Production Economics},
volume = {209},
pages = {265-273},
year = {2019},
note = {The Proceedings of the 19th International Symposium on Inventories},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2017.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0925527317303067},
author = {Rob A.C.M. Broekmeulen and Karel H. {van Donselaar}},
keywords = {Food waste, Retail operations, Empirical data, Freshness, On Shelf Availability, Perishable},
abstract = {The focus of this paper is on improving the performance of fresh departments in supermarkets by reducing food waste, increasing freshness and/or increasing sales. First, two concepts will be introduced to quantify the improvement potential. Next, these concepts will be applied on empirical data for 3 product categories in 27 stores from 3 large retailers in Europe. The two concepts to quantify the improvement potential are called the Fresh Case Cover and the Efficient Frontier. The Fresh Case Cover is defined as the case pack size divided by the average demand during the store shelf life. A regression analysis shows that this single variable explains 42% of the variation in waste. The Efficient Frontier represents a lower bound on the waste needed in a store for any given On-Shelf Availability (OSA). It is demonstrated how the Efficient Frontier can be used to quantify the benefits from supply chain improvement projects and to evaluate fresh departments within a store. To quantify product freshness, an exact expression is derived and an approximation is developed and tested. To quantify waste an existing approximation is generalized. The results show that the improvement potential is very large. For example, increasing the store shelf life with just one day results in 43.1% less waste and 17% more freshness (or in 3.4% higher OSA) and unpacking in the DC results in 34.8% less waste and 1.6% more freshness (or in 2.0% higher OSA). Improving the store replenishment and execution is especially beneficial for medium and large stores.}
}
@article{PORTA2020109723,
title = {Relevance of sex, age and gait kinematics when predicting fall-risk and mortality in older adults},
journal = {Journal of Biomechanics},
volume = {105},
pages = {109723},
year = {2020},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2020.109723},
url = {https://www.sciencedirect.com/science/article/pii/S0021929020301391},
author = {S. Porta and A. Martínez and N. Millor and M. Gómez and M. Izquierdo},
keywords = {Prediction of falls/mortality risk, Logistic regression model, Feature selection for maximum accuracy prediction, Sex stratification importance},
abstract = {Approximately one-third of elderly people fall each year with severe consequences, including death. The aim of this study was to identify the most relevant features to be considered to maximize the accuracy of a logistic regression model designed for prediction of fall/mortality risk among older people. This study included 261 adults, aged over 65 years. Men and women were analyzed separately because sex stratification was revealed as being essential for our purposes of feature ranking and selection. Participants completed a 3-m walk test at their own gait velocity. An inertial sensor attached to their lumbar spine was used to record acceleration data in the three spatial directions. Signal processing techniques allowed the extraction of 21 features representative of gait kinematics, to be used as predictors to train and test the model. Age and gait speed data were also considered as predictors. A set of 23 features was considered. These features demonstrate to be more or less relevant depending on the sex of the cohort under analysis and the classification label (risk of falls and mortality). In each case, the minimum size subset of relevant features is provided to show the maximum accuracy prediction capability. Gait speed has been largely used as the single feature for the prediction fall risk among older adults. Nevertheless, prediction accuracy can be substantially improved, reaching 70% in some cases, if the task of training and testing the model takes into account some other features, namely, sex, age and gait kinematic parameters. Therefore we recommend considering sex, age and step regularity to predict fall-risk.}
}
@article{DORNAIKA2016275,
title = {Inductive and flexible feature extraction for semi-supervised pattern categorization},
journal = {Pattern Recognition},
volume = {60},
pages = {275-285},
year = {2016},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2016.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0031320316300929},
author = {F. Dornaika and Y. El Traboulsi and A. Assoum},
keywords = {Feature extraction, Semi-supervised discriminant analysis, Graph-based embedding, Out-of-sample extension, Pattern categorization},
abstract = {This paper proposes a novel discriminant semi-supervised feature extraction method for generic classification and recognition tasks. This method, called inductive flexible semi-supervised feature extraction, is a graph-based embedding method that seeks a linear subspace close to a non-linear one. It is based on a criterion that simultaneously exploits the discrimination information provided by the labeled samples, maintains the graph-based smoothness associated with all samples, regularizes the complexity of the linear transform, and minimizes the discrepancy between the unknown linear regression and the unknown non-linear projection. We extend the proposed method to the case of non-linear feature extraction through the use of kernel trick. This latter allows to obtain a nonlinear regression function with an output subspace closer to the learned manifold than that of the linear one. Extensive experiments are conducted on ten benchmark databases in order to study the performance of the proposed methods. Obtained results demonstrate a significant improvement over state-of-the-art algorithms that are based on label propagation or semi-supervised graph-based embedding.}
}
@article{MACEDO2021106795,
title = {Machine-learning-based predictive models for estimating seismically-induced slope displacements},
journal = {Soil Dynamics and Earthquake Engineering},
volume = {148},
pages = {106795},
year = {2021},
issn = {0267-7261},
doi = {https://doi.org/10.1016/j.soildyn.2021.106795},
url = {https://www.sciencedirect.com/science/article/pii/S0267726121002177},
author = {Jorge Macedo and Chenying Liu and Farahnaz Soleimani},
keywords = {Seismically-induced slope displacements, Machine-learning, Seismic performance, Slope systems},
abstract = {Engineers often use semiempirical models, which estimate the amount of seismically-induced slope displacements (D), to evaluate the seismic performance of earth structures and natural slopes. These procedures often use as inputs slope properties, earthquake parameters, and ground motion intensity measures (IMs). In this study, we propose a new set of machine learning (ML) based models to estimate D using the NGA-West2 shallow crustal ground motion database. We consider both the classification of negligible D and its estimation. The selection of features to explain D (which is based on LASSO, Forward Selection, and Random Forest) suggests that the most efficient features are the slope's yield coefficient (ky), its fundamental period (Ts), the earthquake magnitude (Mw), the peak ground velocity (PGV), and the degraded spectral acceleration at 1.3 Ts. Moreover, the feature selection suggests that there is no significant gain in accuracy beyond five features. We formulate 19 different models, considering various ML-based algorithms such as Generalized Linear Models (GLM), Partial Least Square Regressions (PLSR), Principal Component Regressions (PCR), Bagging and Boosting, Random Forest, Polynomial-based regressions, Multi-order regressions, and Kernel-based models. We assess the performance of the proposed models by evaluating test errors, their predictive performance in case histories, and comparisons against existing models. Based on the assessments, we recommend 6 ML-based models to estimate D in engineering practice.}
}
@article{ISCRA20244600,
title = {Optimizing machine learning models for classification of stroke patients with epileptiform EEG pattern: the impact of dataset balancing techniques},
journal = {Procedia Computer Science},
volume = {246},
pages = {4600-4609},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.324},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924023494},
author = {Katerina Iscra and Alessandro Biscontin and Aleksandar Miladinovic and Andrea Bonini and Giovanni Furlanis and Gabriele Prandin and Michele Malesani and Marcello Naccarato and Paolo Manganotti and Agostino Accardo and Miloš Ajčević},
keywords = {Dataset balancing techniques, Classification Models, Stroke, Epileptiform EEG patterns},
abstract = {Epileptiform electroencephalogram (EEG) patterns are commonly observed in stroke patients and can significantly impact clinical management and patient outcomes. Therefore, the classification of the stroke patients in order to identify the subjects with high probability of epileptiform EEG patterns may improve the stroke management. In recent years, there has been a notable increase in interest and utilization of machine learning, especially in the domain of classification tasks. Nevertheless, the presence of imbalanced datasets presents hurdles for machine learning algorithms, resulting in skewed predictions toward dominant classes and diminished accuracy, especially for underrepresented ones. Hence, the study aims to evaluate the effects of dataset balancing methods on the classification efficacy of machine learning models for classification of stroke patients with epileptiform EEG patterns by conducting a comparative analysis between models trained on imbalanced and balanced datasets. Four different sampling techniques were employed: an oversampling technique, SMOTENC; an undersampling technique, NearMiss; and two techniques that combine over- and undersampling methods, SMOTEToken and SMOTEENN. The features selection was made using the ReliefF scoring method and for model construction, only features that presented a contribution value greater than 0.01 were utilized. Five different machine learning models were considered in the study: classification tree, logistic regression, naïve Bayes, artificial neural network and support vector machine. The produced models were trained on the original and resampled training set and subsequently the models’ performances were evaluated on the test set. The results showed that SMOTENC was the most effective among the considered dataset balancing techniques, showing superior classification performance compared to other methods and the original dataset. Models utilizing SMOTENC exhibited significant improvements in AUC (0.76 vs 0.67) and specificity values (0.73 vs 0.43) while maintaining comparable accuracy (0.72 vs 0.74) to those trained on the original dataset, respectively. Furthermore, it has been noted that different sampling techniques result in different selection of the most predictive features. In conclusion, our study highlights the crucial role of utilizing dataset balancing methods to improve the classification performances of predictive models in case of highly unbalanced datasets such as case of stratification of stroke patients with epileptiform EEG patterns.}
}
@article{ROMANO201862,
title = {SPIRITuS: a SimPle Information Retrieval regressIon Test Selection approach},
journal = {Information and Software Technology},
volume = {99},
pages = {62-80},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2018.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0950584918300405},
author = {Simone Romano and Giuseppe Scanniello and Giuliano Antoniol and Alessandro Marchetto},
keywords = {SPIRITuS, Regression test case selection, Regression testing},
abstract = {Context:Regression Test case Selection (RTS) approaches aim at selecting only those test cases of a test suite that exercise changed parts of the System Under Test (SUT) or parts affected by changes. Objective:We present SPIRITuS (SimPle Information Retrieval regressIon Test Selection approach). It uses method code coverage information and a Vector Space Model to select test cases to be run. In a nutshell, the extent of a lexical modification to a method is used to decide if a test case has to be selected. The main design goals of SPIRITuS are to be: (i) easy to adapt to different programming languages and (ii) tunable via an easy to understand threshold. Method:To assess SPIRITuS, we conducted a large experiment on 389 faulty versions of 14 open-source programs implemented in Java. We were mainly interested in investigating the tradeoff between the number of selected test cases from the original test suite and fault detection effectiveness. We also compared SPIRITuS against well-known RTS approaches. Results:SPIRITuS selects a number of test cases significantly smaller than the number of test cases the other approaches select at the price of a slight reduction in fault detection capability. Conclusions:SPIRITuS can be considered a viable competitor of existing test case selection approaches especially when the average number of test cases covering a modified method increases (such information can be easily derived before test case selection takes place).}
}
@article{OZENER2020110632,
title = {An effective formulation of the multi-criteria test suite minimization problem},
journal = {Journal of Systems and Software},
volume = {168},
pages = {110632},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110632},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301059},
author = {O. Örsan Özener and Hasan Sözer},
keywords = {Software testing, Regression testing, Test suite minimization, Integer programming, Multi-objective optimization},
abstract = {Test suite minimization problem has been mainly addressed by employing heuristic techniques or integer linear programming focusing on a specific criterion or bi-criteria. These approaches fall short to compute optimal solutions especially when there exists overlap among test cases in terms of various criteria such as code coverage and the set of detected faults. Nonlinear formulations have also been proposed recently to address such cases. However, these formulations require significantly more computational resources compared to linear ones. Moreover, they are also subject to shortcomings that might still lead to sub-optimal solutions. In this paper, we identify such shortcomings and we propose an alternative formulation of the problem. We have empirically evaluated the effectiveness of our approach based on a publicly available dataset and compared it with respect to the state-of-the-art based on the same objective function and the same set of criteria including statement coverage, fault-revealing capability, and test execution time. Results show that our formulation leads to either better results or the same results, when the previously obtained results were already the optimal ones. In addition, our formulation is a linear formulation, which can be solved much more efficiently compared to non-linear formulations.}
}
@article{LU2022102486,
title = {SlideGraph+: Whole slide image level graphs to predict HER2 status in breast cancer},
journal = {Medical Image Analysis},
volume = {80},
pages = {102486},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102486},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522001335},
author = {Wenqi Lu and Michael Toss and Muhammad Dawood and Emad Rakha and Nasir Rajpoot and Fayyaz Minhas},
keywords = {Computational pathology, Breast cancer, Weak supervision, Human epidermal growth factor receptor, Graph neural networks},
abstract = {Human epidermal growth factor receptor 2 (HER2) is an important prognostic and predictive factor which is overexpressed in 15–20% of breast cancer (BCa). The determination of its status is a key clinical decision making step for selection of treatment regimen and prognostication. HER2 status is evaluated using transcriptomics or immunohistochemistry (IHC) through in-situ hybridisation (ISH) which incurs additional costs and tissue burden and is prone to analytical variabilities in terms of manual observational biases in scoring. In this study, we propose a novel graph neural network (GNN) based model (SlideGraph+) to predict HER2 status directly from whole-slide images of routine Haematoxylin and Eosin (H&E) stained slides. The network was trained and tested on slides from The Cancer Genome Atlas (TCGA) in addition to two independent test datasets. We demonstrate that the proposed model outperforms the state-of-the-art methods with area under the ROC curve (AUC) values > 0.75 on TCGA and 0.80 on independent test sets. Our experiments show that the proposed approach can be utilised for case triaging as well as pre-ordering diagnostic tests in a diagnostic setting. It can also be used for other weakly supervised prediction problems in computational pathology. The SlideGraph+ code repository is available at https://github.com/wenqi006/SlideGraph along with an IPython notebook showing an end-to-end use case at https://github.com/TissueImageAnalytics/tiatoolbox/blob/develop/examples/full-pipelines/slide-graph.ipynb.}
}
@article{IBIAS2021106498,
title = {Using mutual information to test from Finite State Machines: Test suite selection},
journal = {Information and Software Technology},
volume = {132},
pages = {106498},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106498},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920302408},
author = {Alfredo Ibias and Manuel Núñez and Robert M. Hierons},
keywords = {Formal approaches to testing, Information Theory, Mutual information, Finite State Machines},
abstract = {Context:
Mutual Information is an information theoretic measure designed to quantify the amount of similarity between two random variables ranging over two sets. In this paper, we adapt this concept and show how it can be used to select a good test suite to test from a Finite State Machine (FSM) based on a maximise diversity approach.
Objective:
The main goal of this paper is to use Mutual Information in order to select test suites to test from FSMs and evaluate whether we obtain better results, concerning the quality of the selected test suite, than current state-of-the-art measures.
Method:
First, we defined our scenario. We considered the case where we receive two (or more) test suites and we have to choose between them. We were interested in this scenario because it is a recurrent case in regression testing. Second, we defined our notion based on Mutual Information: Biased Mutual Information. Finally, we carried out experiments in order to evaluate the measure.
Results:
We obtained experimental evidence that demonstrates the potential value of the measure. We also showed that the time needed to compute the measure is negligible when compare to the time needed to apply extra testing. We compared our measure with a state-of-the-art test selection measure and showed that our proposal outperforms it. Finally, we have compared our measure with a notion of transition coverage. Our experiments showed that our measure is slightly worse than transition coverage, as expected, but its computation is 10 times faster.
Conclusion:
Our experiments showed that Biased Mutual Information is a good measure for selecting test suites, outperforming the current state-of-the-art measure, and having a (negative) correlation to fault coverage. Therefore, we can conclude that our new measure can be used to select the test suite that is likely to find more faults. As a result, it has the potential to be used to automate test generation.}
}
@article{ABOLGHASEMI2020107892,
title = {Demand forecasting in the presence of systematic events: Cases in capturing sales promotions},
journal = {International Journal of Production Economics},
volume = {230},
pages = {107892},
year = {2020},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2020.107892},
url = {https://www.sciencedirect.com/science/article/pii/S0925527320302553},
author = {Mahdi Abolghasemi and Jason Hurley and Ali Eshragh and Behnam Fahimnia},
keywords = {Demand forecasting, Systematic events, Time series regression models, Sales promotions, Judgmental forecasting, Supply chain},
abstract = {Reliable demand forecasts are critical for effective supply chain management. Several endogenous and exogenous variables can influence the dynamics of demand, and hence a single statistical model that only consists of historical sales data is often insufficient to produce accurate forecasts. In practice, the forecasts generated by baseline statistical models are often judgmentally adjusted by forecasters to incorporate factors and information that are not incorporated in the baseline models. There are however systematic events whose effect can be quantified and modeled to help minimize human intervention in adjusting the baseline forecasts. In this paper, we develop and test a novel regime-switching approach to quantify systematic information/events and objectively incorporate them into the baseline statistical model. Our simple yet practical and effective model can help limit forecast adjustments to only focus on the impact of less systematic events such as sudden climate change or dynamic market activities. The model is validated empirically using sales and promotional data from two Australian companies. The model is also benchmarked against commonly employed statistical and machine learning forecasting models. Discussions focus on thorough analysis of promotions impact and benchmarking results. We show that the proposed model can successfully improve forecast accuracy and avoid poor forecasts when compared to the current industry practice which heavily relies on human judgment to factor in all types of information/events. The proposed model also outperforms sophisticated machine learning methods by mitigating the generation of extremely poor forecasts that drastically differ from actual sales due to changes in demand states.}
}
@article{CHIOU2024,
title = {Recruitment for Voluntary Video and Mobile HIV Testing on Social Media Platforms During the COVID-19 Pandemic: Cross-Sectional Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/54420},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124008768},
author = {Piao-Yi Chiou and Wei-Wen Tsao and Chia-Lin Li and Jheng-Min Yu and Wen-Han Su and Zhi-Hua Liu and Cheng-Ru He and Yu-Chun Chang and Yi-Hsuan Tsai},
keywords = {COVID-19, HIV testing, mobile health, risk-taking behavior, social media, video, mobile phone},
abstract = {Background
The COVID-19 pandemic prompted social distancing policies and caused misinformation that hindered in-person HIV screening for high-risk groups. Social media platforms provide additional options for voluntary counseling and testing (VCT) for HIV, overcoming these limitations. However, there is a lack of data on HIV testing recruitment through social media platforms and its outcomes during the pandemic.
Objective
This study aimed to measure the rate of face-to-face mobile and video VCT conducted after recruitment through social media platforms and friend referrals during the pandemic and compare the geographic distribution, risk feature targeting, testing outcome, and cost between the 2 models.
Methods
Data were collected from March 3 to December 31, 2021, during the COVID-19 outbreak in Taiwan. Participants engaging in unprotected sex were recruited. After one-on-one message discussions through the platforms, the well-trained research assistants provided mobile or video VCT based on the participants’ availability. Primary outcomes were completion rate, testing results, and CD4 count. Secondary outcomes included demographic and HIV risk-taking and protective features from a questionnaire. Selection bias was controlled by adjusting for the testing site (Taipei vs non-Taipei) using univariable multinomial logistic regression.
Results
This study gathered 5142 responses on the social media platforms, recruiting 1187 participants. Video VCT had a completion rate of 31.8% (207/651), higher than mobile VCT’s 21.8% (980/4491). Both rates were higher than those before the COVID-19 pandemic. Recruitment through friend referrals, instant messaging apps (eg, Line [LY Corporation]), and geosocial dating apps (eg, Hornet [Queer Networks Inc], Grindr [Grindr LLC], and Gsland [Tien-Hao Tsai]) resulted in higher acceptance and completion rates than social networks (eg, Facebook [Meta], X [formerly Twitter], and Instagram [Meta]). Mobile VCT had higher recruitment among urban residents and screening density, while video VCT reached a broader geographic area. The mobile group was more likely to have had more than 10 sexual partners (odds ratio [OR] 1.92, 95% CI 1.05-3.50; P=.03), history of sex work (OR 4.19, 95% CI 1.68-10.43; P=.002), and sexually transmitted diseases (OR 2.23, 95% CI 1.18-4.23; P=.01) within the past 3 months. The video group was more likely to meet sexual partners through social media. The HIV-positive rate in the mobile group was 0.7% (7/973) with an average CD4 count of 460/μL, while in the video group, it was 1% (2/205) with an average CD4 count of 347/μL, indicating a later diagnosis. Both positivity rates were higher than those before the COVID-19 pandemic, with no significant difference between the groups. The video group cost US $54.68 per participant, slightly higher than the US $50.36 for the mobile group.
Conclusions
Recruiting through social media platforms that facilitate one-on-one message discussions can effectively target high-risk groups for mobile and video VCT. This approach should be integrated into the current screening model to enhance HIV case finding.}
}
@article{LIU2022107323,
title = {Machine learning-based models for estimating seismically-induced slope displacements in subduction earthquake zones},
journal = {Soil Dynamics and Earthquake Engineering},
volume = {160},
pages = {107323},
year = {2022},
issn = {0267-7261},
doi = {https://doi.org/10.1016/j.soildyn.2022.107323},
url = {https://www.sciencedirect.com/science/article/pii/S0267726122001725},
author = {Chenying Liu and Jorge Macedo},
abstract = {The assessment of the seismic performance of slope systems often relies on estimating the amount of seismically-induced slope displacements (D) using semi-empirical D models. These models take as inputs the slope properties and ground motion intensity measures (IMs) to provide D estimates that are used in engineering design. However, most of the available D models have been developed for regions affected by shallow crustal seismicity. Comparatively, the available D models for subduction tectonic settings are scarce. Moreover, most existing models have been developed using traditional statistical methods that do not take advantage of modern data-driven approaches. In this study, we develop new machine learning (ML) based D models applicable to subduction earthquake zones (considering both interface and intraslab mechanisms) using the NGA-Sub ground motion database. A systematic feature selection is performed using three ML procedures, finding that the yield coefficient (ky), the initial fundamental period of the slope system (Ts), the earthquake magnitude (M), the peak ground velocity (PGV), and the pseudo-spectral acceleration at 1.3Ts(Sa(1.3Ts)) are efficient features for estimating D in subduction earthquake zones. Based on the selected features, we develop five ML-based D models by using modern ML procedures (i.e., ridge regression, random forest, gradient boosting decision tree (GBDT), support vector regression (SVR), and residual neural network (ResNet)). The developed ML-based D models do not need to be restricted to predefined fixed functional forms, as has often been the case for previously developed D models. The ridge regression model is used to represent generic traditional D models as it has a polynomial-based functional form. Compared to the ridge regression model, the other developed ML-based models are able to better capture the complex relationship between D and the slope properties and IMs, showing a better predictive performance on test tests; hence, they outperform traditional models. In addition, we compare the performance of the developed ML-based models in terms of predictive performance, model trends, and computational cost for training. Lastly, the developed ML-based models also enhance the treatment of epistemic uncertainty in the estimation of D, given the scarcity of available robust D models for subduction zone tectonic settings.}
}
@article{FORYS20213449,
title = {Lasso Penalty method for variable selection in database construction process and developing house value models in RUA},
journal = {Procedia Computer Science},
volume = {192},
pages = {3449-3456},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.09.118},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921018573},
author = {Iwona Foryś},
keywords = {variable selection, lasso penatly method, house value, regression models},
abstract = {The aim of this paper is to confirm that in the case of the analysis of large data sets, the Lasso Penalty Method (LASSO) gives better results in the process of eliminating variables for the purpose of real estate value models than classical methods such as Ridge Regression. The selection of variables for an econometric model is closely related to its quality and suitability for intelligent decision support systems applied in the processes of real estate value management in the vicinity of airports. Airports face huge compensation payments as a result of the negative noise externalities they generate for neighbouring properties. Both the scale and complexity of this phenomenon require the development of intelligent systems to support airport decisions on compensation management and to monitor the environmental effects of these decisions. The selection of variables describing property characteristics is the first step in building a cost-effective system, as many of these characteristics are qualitative in nature. While systems can feed spatial information and data available in official registers, qualitative data often requires individual assessments and field visits. Hence, assessing the suitability of a given piece of information for a model is crucial at the data collection stage, especially when long time series are being constructed. For this purpose, it is proposed to use LASSO and then to model the value of developments consisting of detached houses on sets of variables selected with this method. The results obtained for LASSO are promising. They give the best set of qualitative and quantitative explanatory variables. The method has less variability than other subset selection methods tested. LASSO reduces some coefficients and zeros others, while retaining the positive attributes of subset selection and ridge regression. Furthermore, LASSO performs variable selection and coefficient estimation simultaneously. In the perspective of large set formation, this method of variable selection can also be used in Data Mining methods for estimating the value of large sets of properties. The obtained results can successfully support the process of property value management in the vicinity of airports}
}
@article{BOUASSALE2024104336,
title = {Development of a methodology for prediction and calibration of parameters of DEM simulations based on machine learning},
journal = {Mechanics Research Communications},
volume = {141},
pages = {104336},
year = {2024},
issn = {0093-6413},
doi = {https://doi.org/10.1016/j.mechrescom.2024.104336},
url = {https://www.sciencedirect.com/science/article/pii/S009364132400096X},
author = {Nasr-Eddine Bouassale and Mohamed Sallaou and Abdelmajid Aittaleb},
keywords = {Discrete element method (DEM), Calibration, Machine learning (ML), Support vector regression (SVR), Angle of repose},
abstract = {This research work aims to develop a robust methodology for the global estimation of interaction parameters based on machine learning, applicable to the discrete element method (DEM) in the study of granular materials. The specific objectives include establishing a theoretical framework that relates the interaction micro-parameters with the macro-parameters and the physical behaviour of the material; performing DEM simulations for different material parameters; developing a machine learning-based model for global parameter estimation; and consolidating the methodology for obtaining micro-parameters for a given material and behaviour. The methodology will be applied specifically to the case of dry copper ore, evaluating its limitations and the possibility of extension to materials with other characteristics. This approach does not consider direct experimental tests, but focuses on the characterisation of the relationship between the input parameters of the material and its response through simulations, validating the response and sensitivity of the model in its different stages. The methodology is expected to allow the systematic estimation of interaction properties for a DEM model, considering micro-parameter duplicities and their global selection, aspects little addressed in the literature. The final verification includes mechanisms and key questions that facilitate future modifications and improvements, allowing its application to materials of different characteristics beyond the specific case study.}
}
@article{TAVARES2015164,
title = {Extreme learning machine with parallel layer perceptrons},
journal = {Neurocomputing},
volume = {166},
pages = {164-171},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215004622},
author = {L.D. Tavares and R.R. Saldanha and D.A.G. Vieira},
keywords = {Parallel layer perceptrons, Extreme learning machine, Structural risk minimization, Least square estimate},
abstract = {This paper proposes using the Parallel Layer Perceptron (PLP) network, instead of the Single Layer Feedforward neural network (SLFN) in the Extreme Learning Machine (ELM) framework. Differently from the SLFNs which consider cascade layers, the PLP is designed to accomplish also parallel layers, being the SLFN its particular case. This paper explores a particular PLP configuration which considers a nonlinear layer in parallel with a linear layer. For n inputs and m nonlinear neurons, it provides (n+1)m linear parameters, while the SLFN would have only m linear parameters (one for each hidden neuron). Since the ELM is based on adjusting only the linear parameters using the least squares estimate (LSE), the PLP network provides more freedom for the proper adjustment. Results from 12 regression and 6 classification problems are presented considering the training and test errors, the linear vector norm and the system condition number. They point out that the PLP-ELM framework is more efficient than the SLFN-ELM approach.}
}
@article{DEOLIVEIRANETO2016124,
title = {Full modification coverage through automatic similarity-based test case selection},
journal = {Information and Software Technology},
volume = {80},
pages = {124-137},
year = {2016},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2016.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0950584916301392},
author = {Francisco G. {de Oliveira Neto} and Richard Torkar and Patrícia D.L. Machado},
keywords = {Regression testing, Test case selection, Model-based testing, Experimental study},
abstract = {Context: This paper presents the similarity approach for regression testing (SART), where a similarity-based test case selection technique (STCS) is used in a model-based testing process to provide selection of test cases exercising modified parts of a specification model. Unlike other model-based regression testing techniques, SART relies on similarity analysis among test cases to identify modifications, instead of comparing models, hence reducing the dependency on specific types of model. Objective: To present convincing evidence of the usage of similarity measures for modification-traversing test case selection. Method: We investigate SART in a case study and an experiment. The case study uses artefacts from industry and should be seen as a sanity check of SART, while the experiment focuses on gaining statistical power through the generation of synthetical models in order to provide convincing evidence of SART’s effectiveness. Through posthoc analysis we obtain p-values and effect sizes to observe statistically significant differences between treatments with respect to transition and modification coverage. Results: The case study with industrial artefacts revealed that SART is able to uncover the same number of defects as known similarity-based test case selection techniques. In turn, the experiment shows that SART, unlike the other investigated techniques, presents 100% modification coverage. In addition, all techniques covered a similar percentage of model transitions. Conclusions: In summary, not only does SART provide transition and defect coverage equal to known STCS techniques, but it exceeds greatly in covering modified parts of the specification model, being a suitable candidate for model-based regression testing.}
}
@article{AJWAD2024112055,
title = {A component method approach for single-sided beam-to-column joints with CHS column and welded double-tee beam},
journal = {Thin-Walled Structures},
volume = {202},
pages = {112055},
year = {2024},
issn = {0263-8231},
doi = {https://doi.org/10.1016/j.tws.2024.112055},
url = {https://www.sciencedirect.com/science/article/pii/S0263823124004981},
author = {Ali Ajwad and Sabatino {Di Benedetto} and Massimo Latour and Gianvittorio Rizzano},
keywords = {Tubular joints, Experimental tests, Finite element modelling, Parametric analysis, Regression analysis, Component method approach},
abstract = {This paper focuses on predicting the flexural stiffness and strength of beam-to-column joints with Circular-Hollow-Section (CHS) columns and externally welded double-tee beams using the Component Method approach. Currently, Eurocode 3 Part 1.8 lacks guidelines for assessing the stiffness of these joints, resulting in their practical modelling using extreme assumptions like pin or full restraint. Nevertheless, the literature demonstrates that these joints can exhibit semi-rigid behaviour due to the relatively high local deformability of the tube in the joint area. Another concern relates to the strength of these joints. In fact, recent studies have shown that Eurocode 3 Part 1.8 formula for predicting the yield resistance of these joints is over-conservative. Within this framework, the purpose of this study is to fill the current knowledge gaps (over-conservative strength prediction and lack of rules for determining the stiffness) by undertaking a thorough investigation involving numerical and analytical activities. Specifically, the research presents a component-based modelling approach for predicting stiffness and strength of CHS to double-tee beam connections. In this regard, the work presented in this paper has involved the selection of experimental tests from literature to validate a Finite Element (FE) model, specifically focusing on X- and T-joints and internal and external beam-to-column joints. The validated numerical models have been then employed to simulate the response under monotonic loading conditions of additional sets comprising forty T-joints and thirty external beam-to-column joints, respectively. The currently available formulations for predicting the resistance of T-joints were applied to the forty cases simulated, evaluating their accuracy. This allowed the individuation of the most accurate literature formula for the strength prediction of T-joints, showing that the recent proposal of Voth and Packer (2012) yields sufficiently accurate results. Instead, analytical formulations for predicting the stiffness of T-joints were properly derived in a closed-form solution and were validated against the results of the parametric study. Finally, drawing upon knowledge regarding the stiffness and strength of T-joints, the flexural response of external beam-to-columns connections was evaluated proposing a component model, whose accuracy was verified against the cases simulated in the parametric analysis.}
}
@article{LEALNETO2020104263,
title = {Prioritizing COVID-19 tests based on participatory surveillance and spatial scanning},
journal = {International Journal of Medical Informatics},
volume = {143},
pages = {104263},
year = {2020},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2020.104263},
url = {https://www.sciencedirect.com/science/article/pii/S1386505620308534},
author = {O.B Leal-Neto and F.A.S Santos and J.Y Lee and J.O Albuquerque and W.V Souza},
keywords = {Participatory surveillance, Epidemiology, Spatial scanning, COVID-19},
abstract = {Objectives
This study aimed to identify, describe and analyze priority areas for COVID-19 testing combining participatory surveillance and traditional surveillance.
Design
It was carried out a descriptive transversal study in the city of Caruaru, Pernambuco state, Brazil, within the period of 20/02/2020 to 05/05/2020. Data included all official reports for influenza-like illness notified by the municipality health department and the self-reports collected through the participatory surveillance platform Brasil Sem Corona.
Methods
We used linear regression and loess regression to verify a correlation between Participatory Surveillance (PS) and Traditional Surveillance (TS). Also a spatial scanning approach was deployed in order to identify risk clusters for COVID-19.
Results
In Caruaru, the PS had 861 active users, presenting an average of 1.2 reports per user per week. The platform Brasil Sem Corona started on March 20th and since then, has been officially used by the Caruaru health authority to improve the quality of information from the traditional surveillance system. Regarding the respiratory syndrome cases from TS, 1588 individuals were positive for this clinical outcome. The spatial scanning analysis detected 18 clusters and 6 of them presented statistical significance (p-value < 0.1). Clusters 3 and 4 presented an overlapping area that was chosen by the local authority to deploy the COVID-19 serology, where 50 individuals were tested. From there, 32 % (n = 16) presented reagent results for antibodies related to COVID-19.
Conclusion
Participatory surveillance is an effective epidemiological method to complement the traditional surveillance system in response to the COVID-19 pandemic by adding real-time spatial data to detect priority areas for COVID-19 testing.}
}
@article{BELHOUCHET2021136,
title = {A new empirical model for enhancing well log permeability prediction, using nonlinear regression method: Case study from Hassi-Berkine oil field reservoir – Algeria},
journal = {Journal of King Saud University - Engineering Sciences},
volume = {33},
number = {2},
pages = {136-145},
year = {2021},
issn = {1018-3639},
doi = {https://doi.org/10.1016/j.jksues.2020.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S1018363920302270},
author = {H.E. Belhouchet and M.S. Benzagouta and A. Dobbi and A. Alquraishi and J. Duplay},
keywords = {Permeability, Reservoir characterization, Rock typing, Hydraulic unite, Flow zone indicator},
abstract = {The reservoir permeability (K) factor is the key parameter for reservoir characterization. This parameter is considered as a determinant reservoir quality index. Depending on the data required and procedure availability, permeability can be defined from several methods such as; well test interpretation, wireline formation tester, and core data. These approaches can also be in assumption with permeability prediction targeting the non-cored sections. According to a similar status, well logs records can be an interesting support tool in use to reach the planned objectives. Thus, this investigation consists of finding out a model able to estimate the well log permeability and adjusting the outcome to the core permeability results. In this led research, the applied approach to the core data, to start with, was aimed to determine the reservoir rock types (RRT) using the flow zone indicator (FZI) method. The obtained classification allows stating a permeability model for each rock type. In order to calculate permeability from well logs, FZI has been founded out. A multi-regression technique was used to analyze the relationship of FZI with respect to specific logs such as Gamma-ray (GR), Density Log (RHOB), and Sonic log (DT). An objective function has been designated to minimize the quadratic error between the observed normalized FZI coming from core data, and the normalized FZI calculated from well logs. This process is carried out to identify a mathematical correlation allowing the estimation of FZI from porosity logs, leading to permeability determination. As results, permeability from logs was supporting relatively permeability defined from cores. The final results can be an accurate and real test for associating the exactitude performance of logging data records in boreholes with respect to the overall reservoir characterization sections. Thus, the applied investigation can be a genuine and quick method for essentially a specific deduction regarding the non-cored reservoir sections, with reference to rock typing, permeability and probably further reservoir factors.}
}
@article{BOBROWSKI2015105,
title = {Estimation of the lifetime distribution of mechatronic systems in the presence of a covariate: A comparison among parametric, semiparametric and nonparametric models},
journal = {Reliability Engineering & System Safety},
volume = {139},
pages = {105-112},
year = {2015},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2015.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0951832015000575},
author = {Sebastian Bobrowski and Hong Chen and Maik Döring and Uwe Jensen and Wolfgang Schinköthe},
keywords = {Failure time models, Lifetime distribution prediction, Regression with covariates, Model selection},
abstract = {In practice manufacturers may have lots of failure data of similar products using the same technology basis under different operating conditions. Thus, one can try to derive predictions for the distribution of the lifetime of newly developed components or new application environments through the existing data using regression models based on covariates. Three categories of such regression models are considered: a parametric, a semiparametric and a nonparametric approach. First, we assume that the lifetime is Weibull distributed, where its parameters are modelled as linear functions of the covariate. Second, the Cox proportional hazards model, well-known in Survival Analysis, is applied. Finally, a kernel estimator is used to interpolate between empirical distribution functions. In particular the last case is new in the context of reliability analysis. We propose a goodness of fit measure (GoF), which can be applied to all three types of regression models. Using this GoF measure we discuss a new model selection procedure. To illustrate this method of reliability prediction, the three classes of regression models are applied to real test data of motor experiments. Further the performance of the approaches is investigated by Monte Carlo simulations.}
}
@article{EBRAHIMI2021102193,
title = {A reinforcement learning approach for finding optimal policy of adaptive radiation therapy considering uncertain tumor biological response},
journal = {Artificial Intelligence in Medicine},
volume = {121},
pages = {102193},
year = {2021},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2021.102193},
url = {https://www.sciencedirect.com/science/article/pii/S093336572100186X},
author = {Saba Ebrahimi and Gino J. Lim},
keywords = {Reinforcement learning, Radiotherapy, Biological tumor response, Adaptive radiation therapy.},
abstract = {Recent studies have shown that a tumor's biological response to radiation varies over time and has a dynamic nature. Dynamic biological features of tumor cells underscore the importance of using fractionation and adapting the treatment plan to tumor volume changes in radiation therapy treatment. Adaptive radiation therapy (ART) is an iterative process to adjust the dose of radiation in response to potential changes during the treatment. One of the key challenges in ART is how to determine the optimal timing of adaptations corresponding to tumor response to radiation. This paper aims to develop an automated treatment planning framework incorporating the biological uncertainties to find the optimal adaptation points to achieve a more effective treatment plan. First, a dynamic tumor-response model is proposed to predict weekly tumor volume regression during the period of radiation therapy treatment based on biological factors. Second, a Reinforcement Learning (RL) framework is developed to find the optimal adaptation points for ART considering the uncertainty in biological factors with the goal of achieving maximum final tumor control while minimizing or maintaining the toxicity level of the organs at risk (OARs) per the decision-maker's preference. Third, a beamlet intensity optimization model is solved using the predicted tumor volume at each adaptation point. The performance of the proposed RT treatment planning framework is tested using a clinical non-small cell lung cancer (NSCLC) case. The results are compared with the conventional fractionation schedule (i.e., equal dose fractionation) as a reference plan. The results show that the proposed approach performed well in achieving a robust optimal ART treatment plan under high uncertainty in the biological parameters. The ART plan outperformed the reference plan by increasing the mean biological effective dose (BED) value of the tumor by 2.01%, while maintaining the OAR BED within +0.5% and reducing the variability, in terms of the interquartile range (IQR) of tumor BED, by 25%.}
}
@article{LOYOLAFUENTES2024123043,
title = {A framework for data regression of heat transfer data using machine learning},
journal = {Applied Thermal Engineering},
volume = {248},
pages = {123043},
year = {2024},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2024.123043},
url = {https://www.sciencedirect.com/science/article/pii/S1359431124007117},
author = {Jose Loyola-Fuentes and Nima Nazemzadeh and Emilio Diaz-Bejarano and Simone Mancin and Francesco Coletti},
keywords = {Heat transfer, Machine learning, Two-phase flow, Heat transfer coefficient, Condensation, Microfin tubes, Data regression},
abstract = {Machine Learning (ML) algorithms are emerging in various industries as a powerful complement/alternative to traditional data regression methods. A major reason is that, unlike deterministic models, they can be used even in the absence of detailed phenomenological knowledge. Not surprisingly, the use of ML algorithms is being explored also in heat transfer applications. It is of particular interest in systems dealing with complex geometries and underlying phenomena (e.g. fluid phase change, multi-phase flow, heavy fouling build-up). However, heat transfer systems present specific challenges that need addressing, such as the scarcity of high-quality data, the inconsistencies across published data sources, the complex (and often correlated) influence of inputs, the split of data between training and testing sets, and the limited extrapolation capabilities to unseen conditions. In an attempt to help overcome some of these challenges and, more importantly, to provide a systematic approach, this article reviews and analyses past efforts in the application of ML algorithms to heat transfer applications, and proposes a regression framework for their deployment to estimate key quantities (e.g. heat transfer coefficient), to be used for improved design and operation of heat exchangers. The framework consists of six steps: i) data pre-treatment, ii) feature selection, iii) data splitting philosophy, iv) training and testing, v) tuning of hyperparameters, and vi) performance assessment with specific indicators, to support the choice of accurate and robust models. A relevant case study involving the estimation of the condensation heat transfer coefficient in microfin tubes is used to illustrate the proposed framework. Two data-driven algorithms, Deep Neural Networks and Random Forest, are tested and compared in terms of their estimation and extrapolation capabilities. The results show that ML algorithms are generally more accurate in predicting the heat transfer coefficient than a well-known semi-empirical correlation proposed in past studies, where the mean absolute error of the most suitable ML model is 535 [Wm2K-1], compared to the error using the correlation of 1061 [Wm2K-1]. In terms of extrapolation, the selected ML model has a mean absolute error of 1819 [Wm2K-1], while for the correlation is 1111 [Wm2K-1], indicating a disadvantage of the use of semi-empirical models, although the comparison was not entirely suitable, given that the correlation was used as is and no training was done. In addition, feature selection enables simpler models that depend only on features that are potentially most related to the target variable. Special attention is needed however, as overfitting and limited extrapolation capabilities are common difficulties that are encountered when deploying these models.}
}
@article{SHEN2022,
title = {Foundations for Meaningful Consent in Canada’s Digital Health Ecosystem: Retrospective Study},
journal = {JMIR Medical Informatics},
volume = {10},
number = {3},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/30986},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422001168},
author = {Nelson Shen and Iman Kassam and Haoyu Zhao and Sheng Chen and Wei Wang and Sarah Wickham and Gillian Strudwick and Abigail Carter-Langford},
keywords = {consent, eConsent, privacy, trust, digital health, health information exchange, patient perspective, health informatics, Canada},
abstract = {Background
Canadians are increasingly gaining web-based access to digital health services, and they expect to access their data from these services through a central patient access channel. Implementing data sharing between these services will require patient trust that is fostered through meaningful consent and consent management. Understanding user consent requirements and information needs is necessary for developing a trustworthy and transparent consent management system.
Objective
The objective of this study is to explore consent management preferences and information needs to support meaningful consent.
Methods
A secondary analysis of a national survey was conducted using a retrospective descriptive study design. The 2019 cross-sectional survey used a series of vignettes and consent scenarios to explore Canadians’ privacy perspectives and preferences regarding consent management. Nonparametric tests and logistic regression analyses were conducted to identify the differences and associations between various factors.
Results
Of the 1017 total responses, 716 (70.4%) participants self-identified as potential users. Of the potential users, almost all (672/716, 93.8%) felt that the ability to control their data was important, whereas some (385/716, 53.8%) believed that an all or none control at the data source level was adequate. Most potential users preferred new data sources to be accessible by health care providers (546/716, 76.3%) and delegated parties (389/716, 54.3%) by default. Prior digital health use was associated with greater odds of granting default access when compared with no prior use, with the greatest odds of granting default access to digital health service providers (odds ratio 2.17, 95% CI 1.36-3.46). From a list of 9 information elements found in consent forms, potential users selected an average of 5.64 (SD 2.68) and 5.54 (SD 2.85) items to feel informed in consenting to data access by care partners and commercial digital health service providers, respectively. There was no significant difference in the number of items selected between the 2 scenarios (P>.05); however, there were significant differences (P<.05) in information types that were selected between the scenarios.
Conclusions
A majority of survey participants reported that they would register and use a patient access channel and believed that the ability to control data access was important, especially as it pertains to access by those outside their care. These findings suggest that a broad all or none approach based on data source may be accepted; however, approximately one-fifth of potential users were unable to decide. Although vignettes were used to introduce the questions, this study showed that more context is required for potential users to make informed consent decisions. Understanding their information needs will be critical, as these needs vary with the use case, highlighting the importance of prioritizing and tailoring information to enable meaningful consent.}
}
@article{PEDEMONTE20161145,
title = {A Systolic Genetic Search for reducing the execution cost of regression testing},
journal = {Applied Soft Computing},
volume = {49},
pages = {1145-1161},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616303441},
author = {Martín Pedemonte and Francisco Luna and Enrique Alba},
keywords = {Regression testing, Evolutionary algorithms, Parallel metaheuristics, GPU, CUDA},
abstract = {The Test Suite Minimization Problem (TSMP) is a NP-hard real-world problem that arises in the field of software engineering. It consists in selecting a minimal set of test cases from a large test suite, ensuring that the test cases selected cover a given set of requirements of a piece of software at the same time as it minimizes the amount of resources required for its execution. In this paper, we propose a Systolic Genetic Search (SGS) algorithm for solving the TSMP. SGS is a recently proposed optimization algorithm capable of taking advantage of the high degree of parallelism available in modern GPU architectures. The experimental evaluation conducted on a large number of test suites generated for seven real-world programs and seven large test suites generated for a case study from a real-world program shows that SGS is highly effective for the TSMP. SGS not only outperforms two competitive genetic algorithms, but also outperforms four heuristics specially conceived for this problem. The results also show that the GPU implementation of SGS has achieved a high performance, obtaining a large runtime reduction with respect to the CPU implementation for solutions with similar quality. The GPU implementation of SGS also shows an excellent scalability behavior when solving instances with a large number of test cases. As a consequence, the GPU-based SGS stands as a state of the art alternative for solving the TSMP in real-world software testing environments.}
}
@article{LIU2022126085,
title = {Studies on the validity of strain sensors for pavement monitoring: A case study for a fiber Bragg grating sensor and resistive sensor},
journal = {Construction and Building Materials},
volume = {321},
pages = {126085},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2021.126085},
url = {https://www.sciencedirect.com/science/article/pii/S0950061821038174},
author = {Zhen Liu and Xingyu Gu and Chunying Wu and Hua Ren and Zhou Zhou and Shi Tang},
keywords = {Asphalt pavement monitoring, Finite element simulation, FBG sensor, Resistive sensor, Validity, Sensitivity},
abstract = {To address the problems associated with the validity of pavement sensor measurement, a method of combining indoor experiments with finite element (FE) simulations for strain measurement in asphalt pavement is developed in this paper to analyze the validity of strain sensors for practical measurements. First, correlation analysis and one-way analysis of variance (ANOVA) between the simulated strain and the measured strain of the resistive (R) sensor and the fiber Bragg grating (FBG) sensor are developed, and the results show that the strain simulation of asphalt mixtures with sensors by means of FE simulation is feasible for short-term loading tests; therefore, the simulated strain without sensors is considered the true strain. The FBG sensor is more appropriate than the R sensor for use in the measurement of horizontal strain based on the stability of the regression model. Furthermore, creep experiments and FE simulations with a modified Burgers model are developed, and the results demonstrate that the FE simulation is also effective for long-term dynamic loading tests. Finally, the effect of the ratio of the modulus of the FBG sensor to that of the asphalt mixture on the stability of the regression model is analyzed, and the results suggest that the stability worsens as the modulus ratio increases at the same temperature, which could guide the selection of encapsulating materials. Moreover, the research method could also provide resources for studying the validity of sensors under more complex loading modes.}
}
@article{CHEN2023761,
title = {A fractional study based on the economic and environmental mathematical model},
journal = {Alexandria Engineering Journal},
volume = {65},
pages = {761-770},
year = {2023},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2022.09.033},
url = {https://www.sciencedirect.com/science/article/pii/S1110016822006275},
author = {Qiliang Chen and Zulqurnain Sabir and Muhammad {Asif Zahoor Raja} and Wei Gao and Haci {Mehmet Baskonus}},
keywords = {Fractional order, Economic and environmental, Scaled conjugate gradient, Reference solutions, Neural networks},
abstract = {The purpose of this investigation is to provide the numerical study based on the fractional order (FO) economic and environmental mathematical model (EEMM) called as FO-EEMM. The motive of this work is to find more realistic results of the EEMM of the non-integer and FO derivatives. The structure of the FO-EEMM is categorized into three dynamics, control accomplishment cost, capability of the manufacturing elements and the diagnostics cost of the technical exclusion. The solution of the FO-EEMM is numerically presented by using the scaled conjugate gradient neural networks (SCGNNs). Three cases based on the FO-EEMM have been scrutinized to indicate the numerical performances along with the selection of the statics as 76% for training, 13% for testing and 11% for certification. The correctness of the designed SCGNNs is authenticated by using the matching of the achieved and the reference solutions (Adams-Bashforth-Moulton). The validity, exactness, dependability, and competence of the SCGNNs is observed through the performances of the mean square error, regression, state transitions, error histograms and correlation.}
}
@article{VAGLIANO2022104688,
title = {Can we reliably automate clinical prognostic modelling? A retrospective cohort study for ICU triage prediction of in-hospital mortality of COVID-19 patients in the Netherlands},
journal = {International Journal of Medical Informatics},
volume = {160},
pages = {104688},
year = {2022},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2022.104688},
url = {https://www.sciencedirect.com/science/article/pii/S1386505622000028},
author = {I. Vagliano and S. Brinkman and A. Abu-Hanna and M.S Arbous and D.A. Dongelmans and P.W.G. Elbers and D.W. {de Lange} and M. {van der Schaar} and N.F. {de Keizer} and M.C. Schut},
abstract = {Background
Building Machine Learning (ML) models in healthcare may suffer from time-consuming and potentially biased pre-selection of predictors by hand that can result in limited or trivial selection of suitable models. We aimed to assess the predictive performance of automating the process of building ML models (AutoML) in-hospital mortality prediction modelling of triage COVID-19 patients at ICU admission versus expert-based predictor pre-selection followed by logistic regression.
Methods
We conducted an observational study of all COVID-19 patients admitted to Dutch ICUs between February and July 2020. We included 2,690 COVID-19 patients from 70 ICUs participating in the Dutch National Intensive Care Evaluation (NICE) registry. The main outcome measure was in-hospital mortality. We asessed model performance (at admission and after 24h, respectively) of AutoML compared to the more traditional approach of predictor pre-selection and logistic regression.
Findings
Predictive performance of the autoML models with variables available at admission shows fair discrimination (average AUROC = 0·75-0·76 (sdev = 0·03), PPV = 0·70-0·76 (sdev = 0·1) at cut-off = 0·3 (the observed mortality rate), and good calibration. This performance is on par with a logistic regression model with selection of patient variables by three experts (average AUROC = 0·78 (sdev = 0·03) and PPV = 0·79 (sdev = 0·2)). Extending the models with variables that are available at 24h after admission resulted in models with higher predictive performance (average AUROC = 0·77-0·79 (sdev = 0·03) and PPV = 0·79-0·80 (sdev = 0·10-0·17)).
Conclusions
AutoML delivers prediction models with fair discriminatory performance, and good calibration and accuracy, which is as good as regression models with expert-based predictor pre-selection. In the context of the restricted availability of data in an ICU quality registry, extending the models with variables that are available at 24h after admission showed small (but significantly) performance increase.}
}
@article{OPARA2022108286,
title = {Regularization and concave loss functions for estimation of chemical kinetic models},
journal = {Applied Soft Computing},
volume = {116},
pages = {108286},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.108286},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621010930},
author = {Karol R. Opara and Pin Pin Oh},
keywords = {Regularization, Loss function, Global optimization, Curve fitting, Reaction rate, Non-linear regression, Transesterification, Biodiesel},
abstract = {Non-linear regression is the primary tool for estimating kinetic models of chemical reactions. The default approach of minimizing the sum of squared residuals tends to underperform in the presence of systematic errors, non-normal distribution of residuals or identifiability issues such as a high correlation between parameters. Therefore, we argue for a careful choice of the fit criteria and propose new, concave loss functions. Together with regularization, they form a robust objective for the regression procedure. Discussion of the rationale behind the proposed approach and its effects is illustrated by laboratory data on the transesterification of palm oil. A dedicated simulation study complements qualitative examples. All of the top-performing methods use regularization. Concave loss functions were among the best in 6–7 out of 8 test cases, compared to 2–3 for the classical square loss confirming both statistical and practical usefulness of the novel fit criteria. This result holds for a variety of modern optimizers. In 76% of our simulations, we obtained results not significantly worse than the best, whereas methods currently used in the literature provide 38% for the relative and 0% for the square loss.}
}
@article{SEBASTIANI2023419,
title = {Numerical evaluation of multivariate power curves for wind turbines in wakes using nacelle lidars},
journal = {Renewable Energy},
volume = {202},
pages = {419-431},
year = {2023},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2022.11.081},
url = {https://www.sciencedirect.com/science/article/pii/S0960148122017219},
author = {Alessandro Sebastiani and Alfredo Peña and Niels Troldborg},
keywords = {Nacelle lidars, Power curves, Turbulence, Wakes, Multivariable regression},
abstract = {The IEC standards describe how to measure the power performance of an isolated wake-free wind turbine. However, most wind turbines operate under waked conditions for a substantial amount of time, calling for the need of a new methodology for power performance evaluation. We define multivariate power curves in the form of multivariate polynomial regressions, whose input variables are several wind speed and turbulence measurements retrieved with nacelle lidars. We use a dataset of synthetic power performance tests including both waked and wake-free conditions. The dataset is generated through aeroelastic simulations combined with both virtual nacelle lidars and the dynamic wake meandering model. A feature-selection algorithm is used to select the input variables among the available measurements, showing that the optimal model includes four input variables: three correspondent to wind speed and one to turbulence measures. Additionally, we give insights on the optimal nacelle-lidar scanning geometry needed to implement the multivariate power curve. Results show that the multivariate power curves predict the power output with accuracy of the same order under both waked and wake-free operation. For the in-wake cases, the accuracy is much higher than that of the IEC standard power curve, with an error reduction of up to 88%.}
}
@incollection{ESCOBAR2024189,
title = {Chapter 9 - Case studies},
editor = {Carlos A. Escobar and Ruben Morales-Menendez},
booktitle = {Machine Learning in Manufacturing},
publisher = {Elsevier},
pages = {189-205},
year = {2024},
isbn = {978-0-323-99029-5},
doi = {https://doi.org/10.1016/B978-0-323-99029-5.00010-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323990295000108},
author = {Carlos A. Escobar and Ruben Morales-Menendez},
keywords = {Case studies, Jupyter notebook, Structured data, Unstructured data},
abstract = {This chapter illustrates the machine learning and coding aspects of learning quality control. Two case studies are developed using structured and unstructured data. The main objective is to illustrate the main concepts presented in this book and for the readers to access to a basic code that can be used in the solution process of another problem. The first case study uses a publicly available dataset, it focuses on training a classifier to predict low quality wine. The random forest, XGBoost, and logistic regression algorithms are trained for this task. We illustrate the application of data preprocessing techniques, grid search for hyperparameter optimization, and feature selection methods. In the second case study, we generated a dataset of images from a toy car replica. Then, a convolutional neural network classifier is developed to automatically identify misalignments in the body of the cars. The classifier correctly detects all misalignments in the test set. This example illustrates how human-based monitoring systems are replaced by learning quality control systems.}
}
@article{MOHAMMADI2021187,
title = {Efficient uncertainty quantification of CFD problems by combination of proper orthogonal decomposition and compressed sensing},
journal = {Applied Mathematical Modelling},
volume = {94},
pages = {187-225},
year = {2021},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2021.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X21000214},
author = {Arash Mohammadi and Koji Shimoyama and Mohamad Sadeq Karimi and Mehrdad Raisee},
keywords = {Uncertainty quantification, Proper orthogonal decomposition, Multifidelity, Compressed sensing, Polynomial chaos expansion},
abstract = {In the current paper, an efficient surrogate model based on combination of Proper Orthogonal Decomposition (POD) and compressed sensing is developed for affordable representation of high dimensional stochastic fields. In the developed method, instead of the full (or classical) Polynomial Chaos Expansion (PCE), the ℓ1-minimization approach is utilized to reduce the computational work-load of the low-fidelity calculations. To assess the model capability in the real engineering problems, two challenging high-dimensional CFD test cases namely; i) turbulent transonic flow around RAE2822 airfoil with 18 geometrical uncertainties and ii) turbulent transonic flow around NASA Rotor 37 with 3 operational and 21 geometrical uncertainties are considered. Results of Uncertainty Quantification (UQ) analysis in both test cases showed that the proposed multi-fidelity approach is able to reproduce the statistics of quantities of interest with much lower computational cost than the classical regression-based PCE method. It is shown that the combination of the POD with the compressed sensing in RAE2822 and Rotor 37 test cases gives respectively computational gains between 1.26–7.72 and 1.79–9.05 times greater than the combination of the POD with the full PCE.}
}
@article{GE20141454,
title = {Active learning strategy for smart soft sensor development under a small number of labeled data samples},
journal = {Journal of Process Control},
volume = {24},
number = {9},
pages = {1454-1461},
year = {2014},
issn = {0959-1524},
doi = {https://doi.org/10.1016/j.jprocont.2014.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959152414001784},
author = {Zhiqiang Ge},
keywords = {Soft sensor, Smart, Active learning, Unlabeled data samples, Data-based modeling},
abstract = {This contribution proposes a new active learning strategy for smart soft sensor development. The main objective of the smart soft sensor is to opportunely collect labeled data samples in such a way as to minimize the error of the regression process while minimizing the number of labeled samples used, and thus to reduce the costs related to labeling training samples. Instead of randomly labeling data samples, the smart soft sensor only labels those data samples which can provide the most significant information for construction of the soft sensor. In this paper, without loss of generality, the smart soft sensor is built based on the widely used principal component regression model. For performance evaluation, an industrial case study is provided. Compared to the random sample labeling strategy, both accuracy and stability have been improved by the active learning strategy based smart soft sensor.}
}
@article{BREWICK201746,
title = {Enabling reduced-order data-driven nonlinear identification and modeling through naïve elastic net regularization},
journal = {International Journal of Non-Linear Mechanics},
volume = {94},
pages = {46-58},
year = {2017},
note = {A Conspectus of Nonlinear Mechanics: A Tribute to the Oeuvres of Professors G. Rega and F. Vestroni},
issn = {0020-7462},
doi = {https://doi.org/10.1016/j.ijnonlinmec.2017.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0020746217300732},
author = {Patrick T. Brewick and Sami F. Masri and Biagio Carboni and Walter Lacarbonara},
keywords = {Elastic net, Lasso regression, Nonlinear identification, Data-driven},
abstract = {This work discusses an improved method of reduced-order modeling for existing data-driven nonlinear identification techniques through the incorporation of naïve elastic net regularization. The data-driven methods considered for this study operate using basis functions to represent the observed nonlinearity. Elastic net regularization is used to minimize the number of non-zero coefficients, thus modifying the basis functions and providing a compact representation. The ability of the naïve elastic net to provide reduced-order nonlinear models that can both accurately fit various data sets and computationally simulate new responses is illustrated through studies considering both synthetic data and experimental data. In both cases, the results obtained with the naïve elastic net are shown to match or outperform those from other traditional methods.}
}
@article{LITY201946,
title = {Retest test selection for product-line regression testing of variants and versions of variants},
journal = {Journal of Systems and Software},
volume = {147},
pages = {46-63},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.09.090},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218302176},
author = {Sascha Lity and Manuel Nieke and Thomas Thüm and Ina Schaefer},
keywords = {Regression testing, Software evolution, Software product lines},
abstract = {Testing is a crucial activity of product-line engineering. Due to shared commonality, testing each variant individually results in redundant testing processes. By adopting regression testing strategies, variants are tested incrementally by focusing on the variability between variants to reduce the overall testing effort. However, product lines evolve during their life-cycle to adapt, e.g., to changing requirements. Hence, quality assurance has also to be ensured after product-line evolution by efficiently testing respective versions of variants. In this paper, we propose retest test selection for product-line regression testing of variants and versions of variants. Based on delta-oriented test modeling, we capture the commonality and variability of an evolving product line by means of differences between variants and versions of variants. We exploit those differences to apply change impact analyses, where we reason about changed dependencies to be retested when stepping from a variant or a version of a variant to its subsequent one by selecting test cases for reexecution. We prototypically implemented our approach and evaluated its effectiveness and efficiency by means of two evolving product lines showing positive results.}
}
@article{IBRAR2021107706,
title = {PrePass-Flow: A Machine Learning based technique to minimize ACL policy violation due to links failure in hybrid SDN},
journal = {Computer Networks},
volume = {184},
pages = {107706},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107706},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620313025},
author = {Muhammad Ibrar and Lei Wang and Gabriel-Miro Muntean and Aamir Akbar and Nadir Shah and Kaleem Razzaq Malik},
keywords = {Hybrid SDN, Machine Learning, ACL, Link Failure Prediction, Network reachability},
abstract = {The centralized architecture of Software-Defined Networking (SDN) reduces networking complexity and improves network manageability by omitting the need for box-by-box troubleshooting and management. However, due to both budget constraints and maturity level of the SDN-capable devices, organizations often are reluctant to adopt SDN in practice. Therefore, instead of migrating to a pure SDN architecture, an incremental SDN deployment strategy is preferred in practice. In this paper, we consider an incremental SDN deployment strategy known as hybrid SDN - involving simultaneous use of both SDN switches and legacy switches. The links connected to an SDN switch are called SDN links, and the rest are called legacy links. An SDN controller can directly poll the status of the SDN links via the connected SDN switches. At the same time, the status of the legacy links passes through SDN switches and reaches the controller, causing delay. As a result, the controller does not have the current status of legacy links in real-time. This delay may lead to undesired outcomes. For example, it causes network reachability problems due to Access Control List (ACL) policies. Therefore, to minimize the impact of network-layer failure in hybrid SDN, we propose a Machine Learning (ML) based technique called PrePass-Flow. PrePass-Flow predicts link failures before their occurrence, recomputes the locations of ACL policies, and installs the ACL policies in the recomputed locations in a proactive manner. The main objective of PrePass-Flow is to minimize the ACL policy violations and network reachability problems due to ACL policies in case of link failures. For the link status prediction, PrePass-Flow uses two supervised ML-based models: 1) a Logistic Regression (LR) model, and 2) a Support Vector Machine (SVM) model. Testing results show that the LR model performs better than both the SVM model and an existing approach in terms of Packet Delivery Ratio (PDR) and ACL policy violations. For instance, the LR model’s accuracy is 4% better, precision is 5% higher, sensitivity is 10% better, and Area Under the Curve (AUC) is 6% greater than the SVM model’s corresponding results.}
}
@article{FLASCHEL2023115867,
title = {Automated discovery of generalized standard material models with EUCLID},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {405},
pages = {115867},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2022.115867},
url = {https://www.sciencedirect.com/science/article/pii/S0045782522008234},
author = {Moritz Flaschel and Siddhant Kumar and Laura {De Lorenzis}},
keywords = {Unsupervised learning, Constitutive models, Generalized standard materials, Interpretable models, Sparse regression, Inverse problems},
abstract = {We extend the scope of our recently developed approach for unsupervised automated discovery of material laws (denoted as EUCLID) to the general case of a material belonging to an unknown class of constitutive behavior. To this end, we leverage the theory of generalized standard materials, which encompasses a plethora of important constitutive classes including elasticity, viscosity, plasticity and arbitrary combinations thereof. We show that, based only on full-field kinematic measurements and net reaction forces, EUCLID is able to automatically discover the two scalar thermodynamic potentials, namely, the Helmholtz free energy and the dissipation potential, which completely define the behavior of generalized standard materials. The a priori enforced constraint of convexity on these potentials guarantees by construction stability and thermodynamic consistency of the discovered model; balance of linear momentum acts as a fundamental constraint to replace the availability of stress–strain labeled pairs; sparsity promoting regularization enables the automatic selection of a small subset from a possibly large number of candidate model features and thus leads to a parsimonious, i.e., simple and interpretable, model. Importantly, since model features go hand in hand with the correspondingly active internal variables, sparse regression automatically induces a parsimonious selection of the few internal variables needed for an accurate but simple description of the material behavior. A fully automatic procedure leads to the selection of the hyperparameter controlling the weight of the sparsity promoting regularization term, in order to strike a user-defined balance between model accuracy and simplicity. By testing the method on synthetic data including artificial noise, we demonstrate that EUCLID is able to automatically discover the true hidden material model from a large catalogue of constitutive classes, including elasticity, viscoelasticity, elastoplasticity, viscoplasticity, isotropic and kinematic hardening.}
}
@article{FOUAD2023105266,
title = {Identification of Alzheimer’s disease from central lobe EEG signals utilizing machine learning and residual neural network},
journal = {Biomedical Signal Processing and Control},
volume = {86},
pages = {105266},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.105266},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423006997},
author = {Islam A. Fouad and Fatma {El-Zahraa M. Labib}},
keywords = {Alzheimer's disease, EEG signals, Pre-processing, Feature extraction, Classification, Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (LR), Resnet-50 CNN},
abstract = {Cognitive and behavioral deficits are some of the symptoms of Alzheimer's disease, a neurological disease caused by brain deterioration. Early diagnosis of the disease minimizes the disease's progression. In this way, patients' living standards can be maintained. An experienced specialist will assess the results of grueling diagnostic tests and a costly diagnosis process. This motivation led to the creation of a fully automated computer system, which uses the proposed methods to detect Alzheimer's disease from EEG signals acquired from a minimum number of electrodes: three central lobe electrodes. This work presents the advantages of implementing the proposed system. Two different datasets were presented to evaluate the system’s performance. After preprocessing the raw EEG data, wavelet transforms were applied to calculate statistical properties. First, the paper discusses the performance of different traditional machine learning classifiers: Diagonal Discriminant Analysis, Support Vector Machine (LSVM, RBF), K-Nearest Neighbors, Random Forest, Logistic Regression, and Naïve Bayes. By comparing the classifiers’ performance, it is found that Naïve Bayes and LSVM classifiers yield the highest performance of 96.55% and 95.69% when applied to the first dataset and 96.55% and 94.52% for the second dataset, respectively. “ResNet-50” Convolutional Neural Network classifier was implemented to demonstrate the capability of constructing an effective AD diagnosing system. It yields an accuracy of 97.8261% when applied to the first dataset. This work shows how Deep Learning improves the performance of classification in early medical diagnosis, which will enhance different diseases’ treatment, as “Resnet – 50” convolutional neural network classifier outperformed Naïve Bayes Classifier.}
}
@article{ALEDDA2015698,
title = {Improvements in disruption prediction at ASDEX Upgrade},
journal = {Fusion Engineering and Design},
volume = {96-97},
pages = {698-702},
year = {2015},
note = {Proceedings of the 28th Symposium On Fusion Technology (SOFT-28)},
issn = {0920-3796},
doi = {https://doi.org/10.1016/j.fusengdes.2015.03.045},
url = {https://www.sciencedirect.com/science/article/pii/S0920379615002148},
author = {R. Aledda and B. Cannas and A. Fanni and A. Pau and G. Sias},
keywords = {Disruption prediction, Nuclear fusion, Logistic regressor, Mahalanobis distance},
abstract = {In large-scale tokamaks disruptions have the potential to create serious damage to the facility. Hence disruptions must be avoided, but, when a disruption is unavoidable, minimizing its severity is mandatory. A reliable detection of a disruptive event is required to trigger proper mitigation actions. To this purpose machine learning methods have been widely studied to design disruption prediction systems at ASDEX Upgrade. The training phase of the proposed approaches is based on the availability of disrupted and non-disrupted discharges. In literature disruptive configurations were assumed appearing into the last 45ms of each disruption. Even if the achieved results in terms of correct predictions were good, it has to be highlighted that the choice of such a fixed temporal window might have limited the prediction performance. In fact, it generates confusing information in cases of disruptions with disruptive phase different from 45ms. The assessment of a specific disruptive phase for each disruptive discharge represents a relevant issue in understanding the disruptive events. In this paper, the Mahalanobis distance is applied to define a specific disruptive phase for each disruption, and a logistic regressor has been trained as disruption predictor. The results show that enhancements on the achieved performance on disruption prediction are possible by defining a specific disruptive phase for each disruption.}
}
@article{JUNSWANG20225015,
title = {Intelligent Networks for Chaotic Fractional-Order Nonlinear Financial Model},
journal = {Computers, Materials and Continua},
volume = {72},
number = {3},
pages = {5015-5030},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.027523},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822009043},
author = {Prem Junswang and Zulqurnain Sabir and Muhammad Asif Zahoor Raja and Waleed Adel and Thongchai Botmart and Wajaree Weera},
keywords = {Financial model, chaotic, fractional-order, reference dataset, artificial neural networks, levenberg-marquardt backpropagation},
abstract = {The purpose of this paper is to present a numerical approach based on the artificial neural networks (ANNs) for solving a novel fractional chaotic financial model that represents the effect of memory and chaos in the presented system. The method is constructed with the combination of the ANNs along with the Levenberg-Marquardt backpropagation (LMB), named the ANNs-LMB. This technique is tested for solving the novel problem for three cases of the fractional-order values and the obtained results are compared with the reference solution. Fifteen numbers neurons have been used to solve the fractional-order chaotic financial model. The selection of the data to solve the fractional-order chaotic financial model are selected as 75% for training, 10% for testing, and 15% for certification. The results indicate that the presented approximate solutions fit exactly with the reference solution and the method is effective and precise. The obtained results are testified to reduce the mean square error (MSE) for solving the fractional model and verified through the various measures including correlation, MSE, regression histogram of the errors, and state transition (ST).}
}
@article{BIRCHLER2023102926,
title = {Cost-effective simulation-based test selection in self-driving cars softwareImage 1},
journal = {Science of Computer Programming},
volume = {226},
pages = {102926},
year = {2023},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2023.102926},
url = {https://www.sciencedirect.com/science/article/pii/S0167642323000084},
author = {Christian Birchler and Nicolas Ganz and Sajad Khatiri and Alessio Gambi and Sebastiano Panichella},
keywords = {Self-driving cars, Software simulation, Regression testing, Test case selection, Continuous integration},
abstract = {Simulation environments are essential for the continuous development of complex cyber-physical systems such as self-driving cars (SDCs). Previous results on simulation-based testing for SDCs have shown that many automatically generated tests do not strongly contribute to the identification of SDC faults, hence do not contribute towards increasing the quality of SDCs. Because running such “uninformative” tests generally leads to a waste of computational resources and a drastic increase in the testing cost of SDCs, testers should avoid them. However, identifying “uninformative” tests before running them remains an open challenge. Hence, this paper proposes SDC-Scissor, a framework that leverages Machine Learning (ML) to identify SDC tests that are unlikely to detect faults in the SDC software under test, thus enabling testers to skip their execution and drastically increase the cost-effectiveness of simulation-based testing of SDCs software. Our evaluation concerning the usage of six ML models on two large datasets characterized by 22'652 tests showed that SDC-Scissor achieved a classification F1-score up to 96%. Moreover, our results show that SDC-Scissor outperformed a randomized baseline in identifying more failing tests per time unit. Webpage & Video: https://github.com/ChristianBirchler/sdc-scissor}
}
@article{QUIROZ2021,
title = {Development and Validation of a Machine Learning Approach for Automated Severity Assessment of COVID-19 Based on Clinical and Imaging Data: Retrospective Study},
journal = {JMIR Medical Informatics},
volume = {9},
number = {2},
year = {2021},
issn = {2291-9694},
doi = {https://doi.org/10.2196/24572},
url = {https://www.sciencedirect.com/science/article/pii/S2291969421000946},
author = {Juan Carlos Quiroz and You-Zhen Feng and Zhong-Yuan Cheng and Dana Rezazadegan and Ping-Kang Chen and Qi-Ting Lin and Long Qian and Xiao-Fang Liu and Shlomo Berkovsky and Enrico Coiera and Lei Song and Xiaoming Qiu and Sidong Liu and Xiang-Ran Cai},
keywords = {algorithm, clinical data, clinical features, COVID-19, CT scans, development, imaging, imbalanced data, machine learning, oversampling, severity assessment, validation},
abstract = {Background
COVID-19 has overwhelmed health systems worldwide. It is important to identify severe cases as early as possible, such that resources can be mobilized and treatment can be escalated.
Objective
This study aims to develop a machine learning approach for automated severity assessment of COVID-19 based on clinical and imaging data.
Methods
Clinical data—including demographics, signs, symptoms, comorbidities, and blood test results—and chest computed tomography scans of 346 patients from 2 hospitals in the Hubei Province, China, were used to develop machine learning models for automated severity assessment in diagnosed COVID-19 cases. We compared the predictive power of the clinical and imaging data from multiple machine learning models and further explored the use of four oversampling methods to address the imbalanced classification issue. Features with the highest predictive power were identified using the Shapley Additive Explanations framework.
Results
Imaging features had the strongest impact on the model output, while a combination of clinical and imaging features yielded the best performance overall. The identified predictive features were consistent with those reported previously. Although oversampling yielded mixed results, it achieved the best model performance in our study. Logistic regression models differentiating between mild and severe cases achieved the best performance for clinical features (area under the curve [AUC] 0.848; sensitivity 0.455; specificity 0.906), imaging features (AUC 0.926; sensitivity 0.818; specificity 0.901), and a combination of clinical and imaging features (AUC 0.950; sensitivity 0.764; specificity 0.919). The synthetic minority oversampling method further improved the performance of the model using combined features (AUC 0.960; sensitivity 0.845; specificity 0.929).
Conclusions
Clinical and imaging features can be used for automated severity assessment of COVID-19 and can potentially help triage patients with COVID-19 and prioritize care delivery to those at a higher risk of severe disease.}
}
@article{QI2023,
title = {Influence of E-consultation on the Intention of First-Visit Patients to Select Medical Services: Results of a Scenario Survey},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/40993},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123002972},
author = {Miaojie Qi and Jiyu Cui and Xing Li and Youli Han},
keywords = {e-consultation, medical selection, influence mechanism, scenario survey},
abstract = {Background
E-consultation is expected to improve the information level of patients, affect patients’ subsequent judgments of medical services, and guide patients to make a reasonable medical selection in the future. Thus, it is important to understand the influence mechanism of e-consultation on patients’ medical selection.
Objective
This study aims to explore the changes in first-visit patients’ understanding of disease and medical resources after e-consultation as well as the choice of follow-up medical services.
Methods
Patients’ medical selection before and after e-consultation was compared using a scenario survey. Based on the service characteristics of the e-consultation platform, representative simulation scenarios were determined, and parallel control groups were set up considering the order effect in comparison. Finally, a total of 4 scenario simulation questionnaires were designed. A total of 4164 valid questionnaires were collected through the online questionnaire collection platform. Patients’ perception of disease severity, evaluation of treatment capacity of medical institutions, selection of hospitals and doctors, and other outcome indicators were tested to analyze the differences in patients’ evaluation and choice of medical services before and after e-consultation. Additionally, the results’ stability was tested by regression analysis.
Results
In scenario 1 (mild case), before e-consultation, 14.1% (104/740) of participants considered their conditions as not serious. After e-consultation, 69.5% (539/775) of them considered their diseases as not serious. Furthermore, participants’ evaluation of the disease treatment capacity of medical institutions at all levels had improved after using e-consultation. In scenario 3 (severe case), before e-consultation, 54.1% (494/913) of the participants believed their diseases were very serious. After e-consultation, 16.6% (157/945) considered their diseases were very serious. The evaluation of disease treatment capacity of medical institutions in nontertiary hospitals decreased, whereas that of tertiary hospitals improved. In both mild and severe cases, before e-consultation, all of the participants were inclined to directly visit the hospital. After e-consultation, more than 71.4% (553/775) of the patients with mild diseases chose self-treatment, whereas those with severe diseases still opted for a face-to-face consultation. After e-consultation, patients who were set on being treated in a hospital, regardless of the disease severity, preferred to select the tertiary hospitals. Of the patients with mild diseases who chose to go to a hospital, 25.7% (57/222) wanted to consult online doctors face-to-face. By contrast, 56.4% (506/897) of the severe cases wanted to consult online doctors face-to-face.
Conclusions
E-consultation can help patients accurately enhance their awareness of the disease and guide them to make a more reasonable medical selection. However, it is likely that e-consultation makes online medical services centralized. Additionally, the guiding effect of e-consultation is limited, and e-consultation needs to be combined with other supporting systems conducive to medical selection to play an improved role.}
}
@article{MARQUESSOUDRE2024111261,
title = {A novel GPU-based approach for embedded NARMAX/FROLS system identification},
journal = {Mechanical Systems and Signal Processing},
volume = {211},
pages = {111261},
year = {2024},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2024.111261},
url = {https://www.sciencedirect.com/science/article/pii/S0888327024001596},
author = {Marlon {Marques Soudré} and Helon Vicente {Hultmann Ayala} and Alba Cristina Melo and Carlos H. Llanos},
keywords = {Embedded system software design, Nonlinear system identification parallelism, GPU, FROLS, Performance gain, Power consumption measurement},
abstract = {Identifying system dynamics is an essential task for several research areas that deal with real systems intended for purposes such as control, monitoring, or fault detection. However, the nonlinear characteristics of most real systems have led to the development of techniques with high computational complexity, which can make their use unfeasible in systems with restrictions, such as embedded systems. In this case, few studies have been done on how best to map nonlinear system identification techniques to embedded system platforms that may have parallelism capabilities, such as those incorporating GPUs. This work proposes a novel software architecture for parallel model term selection and estimation for Nonlinear AutoRegressive Moving Average with eXogenous inputs (NARMAX) models, addressed to GPU-based embedded platforms. Namely, we devise a new parallel strategy to perform Forward Regression Orthogonal Least Squares (FROLS) in nonlinear black-box system identification. The architecture presented was tested in the new NVIDIA Jetson Developer Kit, which contains a 128-core Maxwell-GPU, and compared to serial versions of the algorithm run in standard Intel Core i7 CPU and ARM A57. Using a theoretical example, we defined a parallelization strategy and validated it with an electro-mechanical positioning system representing time-invariant nonlinear systems. As a result, the time spent in the proposed parallel GPU algorithm is more than 24.5x faster, and the energy-efficiency is 22x better if compared to its serial version. This represents a significant improvement in speedup and energetic demand, allowing NARMAX/FROLS models to be constructed online using low-cost and low-power embedded platforms.}
}
@article{ZHANG2018105,
title = {A new solar power output prediction based on hybrid forecast engine and decomposition model},
journal = {ISA Transactions},
volume = {81},
pages = {105-120},
year = {2018},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2018.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0019057818302246},
author = {Weijiang Zhang and Hongshe Dang and Rolando Simoes},
keywords = {Empirical mode decomposition, IMF, Support vector regression, Feature selection, Solar energy},
abstract = {Regarding to the growing trend of photovoltaic (PV) energy as a clean energy source in electrical networks and its uncertain nature, PV energy prediction has been proposed by researchers in recent decades. This problem is directly effects on operation in power network while, due to high volatility of this signal, an accurate prediction model is demanded. A new prediction model based on Hilbert Huang transform (HHT) and integration of improved empirical mode decomposition (IEMD) with feature selection and forecast engine is presented in this paper. The proposed approach is divided into three main sections. In the first section, the signal is decomposed by the proposed IEMD as an accurate decomposition tool. To increase the accuracy of the proposed method, a new interpolation method has been used instead of cubic spline curve (CSC) fitting in EMD. Then the obtained output is entered into the new feature selection procedure to choose the best candidate inputs. Finally, the signal is predicted by a hybrid forecast engine composed of support vector regression (SVR) based on an intelligent algorithm. The effectiveness of the proposed approach has been verified over a number of real-world engineering test cases in comparison with other well-known models. The obtained results prove the validity of the proposed method.}
}
@article{TANEJA20202221,
title = {A Novel technique for test case minimization in object oriented testing},
journal = {Procedia Computer Science},
volume = {167},
pages = {2221-2228},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.274},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920307407},
author = {Divya Taneja and Rajvir Singh and Ajmer Singh and Himanshu Malik},
keywords = {Object oriented metrics, Test Case Minimization, machine learning, object oriented testing},
abstract = {Software maintenance is the costliest phase of software life cycle and it consumes almost 70 percent of resources of development process. Software testing involves the examining the built software with the intension to find the defects in it. Exhaustive testing of the software for all possible test cases is not feasible as may take infinitely large amount of time and may consume large number of other resources. Researchers in the field of the software testing are exploring the different possibilities to reduce the required number of test cases to test given software. In case of an object oriented (OO) software, the complexities like inheritance, coupling and cohesion, make the software modules more prone to the faults. This problem gets augmented in case of very large software systems. Many researchers have solved the problem of test case minimization from the different perspectives like requirements coverage; statement coverage and risk coverage. But negligible research has been done of the basis of security metrics coverage. In this paper, a technique has been presented for minimization of test cases for the OO systems. The research reported in the paper has considered security as a perspective for test cases evaluation and minimization. Publically available data sets pertaining to open source software Camel 1.6.1 have been used for the evaluation of proposed methodology. Linear Regression (LR) model for the bugs present in the data and various object oriented metrics for security have been developed. The proposed model dissects the given metrics sets into effective and non-effective metrics. Effective metrics are then utilized for giving weights to the test cases, further with the help of weights obtained the test suite is minimized. The performance results of proposed approach are encouraging.}
}
@article{GJAROY2024101530,
title = {A recall-optimised machine learning framework for small data improves risk stratification for Hirschsprung's disease},
journal = {Informatics in Medicine Unlocked},
volume = {48},
pages = {101530},
year = {2024},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2024.101530},
url = {https://www.sciencedirect.com/science/article/pii/S2352914824000868},
author = {Emilie {G. Jaroy} and Gabriel T. Risa and Inger Nina Farstad and Ragnhild Emblem and Rune Ougland},
keywords = {Machine learning, Imbalanced data, Rare diseases, Paediatric surgery, Hirschsprung's disease, Diagnostics},
abstract = {Objective
To improve the selection of patients with suspected Hirschsprung's disease for rectal biopsy with a recall-optimised machine learning framework that strongly penalises missed diagnoses, identify the most important clinical features, and investigate if this methodology is superior to the current practice of conventional logistic regression analysis.
Study design
The study data comprised the medical records of 178 children older than one month who underwent a rectal biopsy for the evaluation of Hirschsprung's disease. Each medical record contained the clinical features recorded before the rectal biopsy and the biopsy result. However, only 20 of the 178 children were diagnosed with Hirschsprung's disease. Thus, as is frequently the case for rare diseases, the dataset was small and imbalanced. We present a machine learning framework that, based on these data, produces a champion machine learning model for predicting the presence of Hirschsprung's disease in patients. Notably, the machine learning framework is recall-optimised, i.e., it strongly penalises missed diagnoses. This is achieved using a combination of synthetic minority over-sampling techniques, Bayesian hyper-parameter optimisation, and bootstrapping-based prediction thresholding for a competing set of models comprised of a logistic regression model, a random forest classifier, and a gradient-boosted classifier. Finally, the machine learning framework evaluates the performance of these three competing models and conventional logistic regression with 5-fold stratified cross-validation using an 80:20 train-test split. Model performance is ranked by the average recall across the cross-validation folds. The model with the highest recall is selected as the champion. The model with the highest accuracy is chosen in case of a tie.
Results
This study revealed that about 35% of our cohort's children without Hirschsprung's disease could have been spared a rectal biopsy while incurring no missed diagnoses using our machine learning framework. Given our aim of avoiding missed diagnosis, the champion model was vastly superior to conventional logistic regression, i.e., the status quo, which missed 40% of HD-positive cases. Moreover, the champion model pointed to a new hierarchy for the importance of clinical features associated with Hirschsprung's disease. Among all features, “gross abdominal distention” was the most important.
Conclusion
There is considerable scope for a stricter selection when referring constipated children for a rectal biopsy to diagnose or exclude Hirschsprung's disease. This study demonstrates that a recall-optimised pipeline based on classical supervised machine learning is superior to the conventional statistical and heuristic approaches used today, also for small and imbalanced datasets. This finding opens a path to better care for patients with rare diseases while alleviating pressures on healthcare systems.}
}
@article{SHAHPOURI2021826,
title = {Soot Emission Modeling of a Compression Ignition Engine Using Machine Learning},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {20},
pages = {826-833},
year = {2021},
note = {Modeling, Estimation and Control Conference MECC 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.11.274},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321023181},
author = {Saeid Shahpouri and Armin Norouzi and Christopher Hayduk and Reza Rezaei and Mahdi Shahbakhti and Charles Robert Koch},
keywords = {Diesel engines, Soot emissions, Machine learning, grey-box modeling, Physical model, data-driven modeling},
abstract = {Control of real driving soot emissions in diesel vehicles requires accurate predictive models for engine-out soot emissions. This paper presents an innovative modeling approach that combines a physics-based model and a black-box model to predict soot from a 4.5-liter compression ignition engine under varying load and speed conditions. The physical model is based on an experimentally validated 1D engine model in GT-power. In contrast, the black-box model is designed by investigating different machine learning approaches, including a Bayesian neural network (BNN), support vector machine (SVM), regression tree, and an ensemble of regression tree. The experimental data from running the engine at 219 load and speed conditions are collected and used for training and testing the soot model. The least absolute shrinkage and selection operator (LASSO) feature selection method is used on the GT model outputs to find the most critical parameters in soot prediction. The grey-box modeling results are compared with those from the black-box as well as the physical model. The results show that the grey-box SVM and black-box single hidden layer BNN method provide the best performance with a coefficient of determination (R2) of 0.95. For most cases, grey-box models outperform the black-box models with the same Machine Learning (ML) algorithm by comparing R2 of the test data, but this difference becomes negligible when a single hidden layer neural network is used.}
}
@article{SALEH2022127447,
title = {A comprehensive evaluation of existing and new model-identification approaches for non-destructive concrete strength assessment},
journal = {Construction and Building Materials},
volume = {334},
pages = {127447},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2022.127447},
url = {https://www.sciencedirect.com/science/article/pii/S0950061822011242},
author = {Eman F. Saleh and Ahmad N. Tarawneh and Hasan N. Katkhuda},
keywords = {Concrete strength assessment, NDT techniques, Conversion model, Cores, Concrete variability, Mean concrete strength, Characteristic strength},
abstract = {The common practice of concrete strength assessment is to combine non-destructive techniques (NDT) with core test measurements to develop a conversion model that is used to estimate the strengths at NDT test locations. In this work, different model identification approaches to develop this conversion model are investigated, namely regularized regression, quantile regression, Deming regression, bi-objective approach, geometric mean regression, orthogonal regression, and support vector machine (SVM) regression intending to improve the conversion model prediction capability so that accurate estimates of concrete strength can be obtained with a small number of cores. These approaches: in addition to other existing approaches, are first assessed using synthetic datasets and then tested on a real data case study by developing a set of cumulative distribution functions that provides information regarding the risk of a wrong prediction of concrete strength, outside a tolerable level. The results showed that concrete variability was best estimated using Deming regression, orthogonal regression, and bi-objective approach while local strengths were best estimated using quantile and regularized regression. Further, mean concrete strength estimation was observed to be not significantly affected by the choice of a model identification approach. Based on these results, a hybrid conversion model identification system that uses the bi-objective approach for mean and variability estimation and quantile regression for local strengths estimation is proposed. This study also proposes new tabular displays for the selection of the minimum number of cores required for reliable estimation of strength using information related to the NDT measurements and a choice of an accepted risk in the estimation. These tabular displays were produced using extensive analysis of synthetic data to determine the minimum number of cores required to limit the probability of the wrong estimation of strength within an admissible margin of error. Lastly, a web app was developed to easily provide the conversion models and the minimum number of cores for reliable concrete assessment.}
}
@article{FEDORKO201430,
title = {Failure analysis of belt conveyor damage caused by the falling material. Part I: Experimental measurements and regression models},
journal = {Engineering Failure Analysis},
volume = {36},
pages = {30-38},
year = {2014},
issn = {1350-6307},
doi = {https://doi.org/10.1016/j.engfailanal.2013.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S1350630713003075},
author = {Gabriel Fedorko and Vieroslav Molnar and Daniela Marasova and Anna Grincova and Miroslav Dovica and Jozef Zivcak and Teodor Toth and Nikoleta Husakova},
keywords = {Conveyor belt, Test device, Experimental measurement, Regression model},
abstract = {The most common case of conveyor belts damage is their puncture by falling sharp material. One of the ways, how to minimize this type of damage, is using of suitable type of conveyor belt. Therefore, the analysis of conveyor belts on the part of their puncture resistance is an important factor for their use in operation conditions. The aim of the paper is to determine the dependence among the weight of sharp material falling on the conveyor belt, shatter height and force conditions in the conveyor belt on the base of experimental measurements by the help of regression mathematical model and to determine conditions under which the conveyor belt is damaged. The experimental results enable the operator of a conveyor belt to set the shatter height and maximum weight of falling weight below the threshold values in order to prevent conveyor belt damage.}
}
@article{OMER2023200261,
title = {An adjustable machine learning gradient boosting-based controller for PV applications},
journal = {Intelligent Systems with Applications},
volume = {19},
pages = {200261},
year = {2023},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2023.200261},
url = {https://www.sciencedirect.com/science/article/pii/S2667305323000868},
author = {Zahi M. Omer and Hussain Shareef},
keywords = {Feature engineering, Gradient boosting, Machine learning, SHAP values, Photovoltaics, PI controller},
abstract = {Traditional Proportional, Integral, and Derivative (PID) controllers are employed in most industrial control applications because they are simple and easy to implement. However, they are fallible and exhibit poor performance in complicated, non-linear, time-delayed systems, and noisy feedback loops. In photovoltaic systems applications such as maximum power point (MPP) tracking, PI controller performance in low irradiance levels, varying load conditions, and partial shading scenarios is considerably inefficient in tracking the corresponding reference current, which generates MPP and causes considerable steady-state error. Machine learning can be used with selective input/output data from the PI controller to build a model that has the ability to adjust in case of steady-state error. Thus, an adjustable Machine Learning Gradient Boosting-based (MLGB) controller with a PV module and a DC-DC boost converter is proposed in this work. To create the raw dataset, a PI controller was simulated, and the input/output signals were recorded. Data preprocessing, utilizing feature engineering and Shapley Additive Explanations (SHAP) values, was used to explain the dynamic behavior of each feature, the inter-feature dependability, and their significance with reference to the model output. Hyperparameters were tuned with cross-validation while the model was being created using the CatBoost method. To assess the adjustment of each feature to minimize the error, particularly for lower irradiance values, varying load conditions, and partial shading, a regression model was built. Using the MATLAB Simulink Environment, a complete system controlled by both the PI and the MLGB controller was developed and tested. A random irradiance level fluctuation profile, along with varying load and partial shading scenarios, was used to compare three controllers, namely the PI, conventional MLGB, and adjusted MLGB controllers, to see how they respond to rapidly changing environmental conditions. It has been proven through a thorough simulation analysis that the novel adjustable MLGB controller exhibits good tracking performance to follow the DC-DC boost converter's inductor current. When compared to the traditional PI controller, the new controller exhibits better results in terms of steady-state behavior and transient responsiveness in general, with a much lower mean (3.059E-03), median (1.908E-03), and RMS value (2.168E-02) of the signal error under various conditions.}
}
@article{SHARIFZADEH2014211,
title = {Supervised feature selection for linear and non-linear regression of L⁎a⁎b⁎ color from multispectral images of meat},
journal = {Engineering Applications of Artificial Intelligence},
volume = {27},
pages = {211-227},
year = {2014},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2013.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0952197613001784},
author = {Sara Sharifzadeh and Line H. Clemmensen and Claus Borggaard and Susanne Støier and Bjarne K. Ersbøll},
keywords = {L a b color space, Multispectral imaging, Sparse regression, Artificial neural networks, Support vector machine, Supervised feature selection},
abstract = {In food quality monitoring, color is an important indicator factor of quality. The CIELab (L⁎a⁎b⁎) color space as a device independent color space is an appropriate means in this case. The commonly used colorimeter instruments can neither measure the L⁎a⁎b color in a wide area over the target surface nor in a contact-less mode. However, developing algorithms for conversion of food items images into L⁎a⁎b color space can solve both of these issues. This paper addresses the problem of L⁎a⁎b color prediction from multispectral images of different types of raw meat. The efficiency of using multispectral images instead of the standard RGB is investigated. In addition, it is demonstrated that due to the fiber structure and transparency of raw meat, the prediction models built on the standard color patches do not work for raw meat test samples. As a result, multispectral images of different types of meat samples (430–970nm) were used for training and testing of the L⁎a⁎b prediction models. Finding a sparse solution or the use of a minimum number of bands is of particular interest to make an industrial vision set-up simpler and cost effective. In this paper, a wide range of linear, non-linear, kernel-based regression and sparse regression methods are compared. In order to improve the prediction results of these models, we propose a supervised feature selection strategy which is compared with the Principal component analysis (PCA) as a pre-processing step. The results showed that the proposed feature selection method outperforms the PCA for both linear and non-linear methods. The highest performance was obtained by linear ridge regression applied on the selected features from the proposed Elastic net (EN) -based feature selection strategy. All the best models use a reduced number of wavelengths for each of the L⁎a⁎b components.}
}
@article{WANG2017274,
title = {Optimal control based regression test selection for service-oriented workflow applications},
journal = {Journal of Systems and Software},
volume = {124},
pages = {274-288},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.06.065},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300942},
author = {Hongda Wang and Jianchun Xing and Qiliang Yang and Ping Wang and Xuewei Zhang and Deshuai Han},
keywords = {Software cybernetics, Optimal control, Service-oriented workflow applications, Regression test selection, Behavioral difference, BPEL program dependence graph, Safe},
abstract = {Regression test selection, which is well known as an effective technology to ensure the quality of modified BPEL applications, is regarded as an optimal control issue. The BPEL applications under test serves as a controlled object and the regression test selection strategy functions as the corresponding controller. The performance index is to select fewest test cases to test modified BPEL applications. In addition, a promising controller (regression test selection approach) should be safe, which means that it can select all test cases in which faults might be exposed in modified versions under controlled regression testing from the original test suite. However, existing safe controllers may rerun some test cases without exposing fault. In addition, the unique features (e.g., dead path elimination semantics, communication mechanism, multi-assignment etc.) of BPEL applications also raise enormous problems in regression test selection. To address these issues, we present in this paper a safe optimal controller for BPEL applications. Firstly, to handle the unique features mentioned above, we transform BPEL applications and their modified versions into universal BPEL forms. Secondly, For our optimal controller, BPEL program dependence graphs corresponding to the two universal BPEL forms are established. Finally, guided by behavioral differences between the two versions, we construct an optimal controller and select test cases to be rerun. By contrast with the previous approaches, our approach can eliminate some unnecessary test cases to be selected. We conducted experiments with 8 BPEL applications to compare our approach with other typical approaches. Experimental results show that the test cases selected using our approach are fewer than other approaches.}
}
@article{KAKAR201556,
title = {Investigating the penalty reward calculus of software users and its impact on requirements prioritization},
journal = {Information and Software Technology},
volume = {65},
pages = {56-68},
year = {2015},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2015.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0950584915000798},
author = {Adarsh Kumar Kakar},
keywords = {User satisfaction, Requirements prioritization, Multiplicative effect, Asymmetric effect, Penalty reward contrast analysis},
abstract = {Context
The current requirements engineering techniques for prioritization of software requirements implicitly assume that each user requirement will have an independent and symmetric impact on user satisfaction. For example, it is assumed that implementing a high priority user requirement will positively impact his satisfaction and not implementing a high priority user requirement will negatively impact his satisfaction. Further, the impacts of implementing multiple user requirements on his satisfaction are expected to be additive. But is this always the case?
Objective
This paper empirically examines whether the assumptions of symmetric and multiplicative impacts of user requirements on his satisfaction are valid. Further, the study assesses the relative efficacy of 5 methods of requirements prioritization in managing these effects as reflected by the user satisfaction with the prioritized requirement sets.
Method
To test for existence and mitigation of asymmetric effects an adaptation of the widely accepted PRCA (Penalty Reward Contrast Analysis) method was used for 5 requirements prioritization techniques. To test for existence and mitigation of multiplicative effects MHMR (Moderated Hierarchical Multiple Regression) a well-accepted technique for testing interaction effects was used.
Results
Both asymmetric and multiplicative effects of software requirements on user satisfaction were observed for requirements prioritized using all 5 requirements prioritization methods raising questions about the efficacy of present day requirements prioritization techniques. Further, the results of the experiment led to proposing a new method for requirements prioritization for managing these effects.
Conclusion
The study empirically demonstrates the complexities of prioritizing software requirements and calls for a new generation of methods to address them. Understanding and resolving these complexities will enable software providers to conserve resources by enabling them to parsimoniously selecting only those requirements for implementation in the software product that have maximum incremental impact on user satisfaction.}
}
@article{ZHOU2021111228,
title = {BP neural network based reconstruction method for radiation field applications},
journal = {Nuclear Engineering and Design},
volume = {380},
pages = {111228},
year = {2021},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2021.111228},
url = {https://www.sciencedirect.com/science/article/pii/S0029549321001801},
author = {Wen Zhou and Guomin Sun and Zihui Yang and Hui Wang and Li Fang and Jianye Wang},
keywords = {Radiation field, Shielding calculation, Regression analysis, BP neural network, SuperMC},
abstract = {In order to achieve optimal radiation protection, rapid and accurate reconstruction of radiation field has vital significance in the selection of working paths during the overhaul of nuclear power plants and the decommissioning of nuclear facilities. The radiation field is usually reconstructed by various interpolation methods, but the reconstruction accuracy of such methods is insufficient, With the improvement of AI technology, neural networks have great potential in radiation field reconstruction, but conventional neural networks is prone to local minima and vanishing grandient problem. This paper aims to develop a radiation field reconstruction method based on an adaptive Back-propagation (BP) neural network neural network method with learning rate decay and a corresponding sampling method for multisampling in places where flux gradient changes drastically, and verify its accuracy and feasibility. The proposed method achieves global optimality and avoids vanishing grandient problem by virtue of adaptive algorithm and learning rate decay, ensuring that the radiation field is reconstructed with the smallest relative average error when the sampling point is determined, moreover, the proposed sampling method can greatly improve the accuracy of radiation field reconstruction. The accuracy of the proposed method was tested with three MC simulated radiation fields with simpler cases, and the feasibility of the proposed method was further validated with two MC simulated, more complex and realistic scenes. The results of the proposed method show that the errors of the three test cases are 1.7%, 6.8%, and 7.8%, and the errors of the two validated cases are 8.8% and 7.7%, respectively. The merit of this method was preliminarily verified, further validation is underway to validate its application in real world scenarios.}
}
@article{FATHI2022100421,
title = {High-quality fracture network mapping using high frequency logging while drilling (LWD) data: MSEEL case study},
journal = {Machine Learning with Applications},
volume = {10},
pages = {100421},
year = {2022},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2022.100421},
url = {https://www.sciencedirect.com/science/article/pii/S2666827022000962},
author = {Ebrahim Fathi and Timothy R. Carr and Mohammad Faiq Adenan and Brian Panetta and Abhash Kumar and B.J. Carney},
keywords = {Logging while drilling, Acceleration data, Natural fracture mapping, Marcellus Shale, Machine learning},
abstract = {The Marcellus Shale and Energy Environmental Laboratory (MSEEL) provides a comprehensive dataset and field tests that can be used to study the significance of preexisting natural fractures in different subsurface engineering problems such as the effectiveness of the stimulation of an unconventional reservoir, optimized geothermal fluids movement and integrity of the CO2 storage site. Conventionally natural fracture intensity is obtained using sonic and micro-resistivity imaging logs. However, these techniques significantly suffer from two major deficiencies: Human bias in log interpretation and extremely long interpretation time. These two deficiencies are well-recognized in the industry; however, no standard procedures exist to address them. In this study, a new automated machine learning workflow (AMLW) is introduced that uses the LWD high-resolution acceleration data along the horizontal laterals to predict the natural fracture intensities originally obtained using sonic and micro-resistivity imaging. The accuracy and robustness of the new workflow to predict the near wellbore fracture intensities are tested using both regression and classification approaches. Both the regression and classification approaches were able to predict the fracture intensities with high accuracy (average Mean Squared Error of 0.0085 for regression and average accuracy of 0.94 in the confusion matrix for classification). We have shown that only 10%–15% of the labeled resistivity image log is required for training and validation of the machine-learning model. The Automated workflow resulted in K-Neighbors Regressor and classifier algorithms as the best algorithms with a 52.74% and 139.3% improvement in comparison to the Gradient Boosting Regression algorithm (i.e. the fifth best algorithm).}
}
@article{HUSNAYAIN2020,
title = {Understanding the Community Risk Perceptions of the COVID-19 Outbreak in South Korea: Infodemiology Study},
journal = {Journal of Medical Internet Research},
volume = {22},
number = {9},
year = {2020},
issn = {1438-8871},
doi = {https://doi.org/10.2196/19788},
url = {https://www.sciencedirect.com/science/article/pii/S1438887120009279},
author = {Atina Husnayain and Eunha Shim and Anis Fuad and Emily Chia-Yu Su},
keywords = {Google Trends, risk, perception, communication, COVID-19, South Korea, outbreak, infodemiology},
abstract = {Background
South Korea is among the best-performing countries in tackling the coronavirus pandemic by using mass drive-through testing, face mask use, and extensive social distancing. However, understanding the patterns of risk perception could also facilitate effective risk communication to minimize the impacts of disease spread during this crisis.
Objective
We attempt to explore patterns of community health risk perceptions of COVID-19 in South Korea using internet search data.
Methods
Google Trends (GT) and NAVER relative search volumes (RSVs) data were collected using COVID-19–related terms in the Korean language and were retrieved according to time, gender, age groups, types of device, and location. Online queries were compared to the number of daily new COVID-19 cases and tests reported in the Kaggle open-access data set for the time period of December 5, 2019, to May 31, 2020. Time-lag correlations calculated by Spearman rank correlation coefficients were employed to assess whether correlations between new COVID-19 cases and internet searches were affected by time. We also constructed a prediction model of new COVID-19 cases using the number of COVID-19 cases, tests, and GT and NAVER RSVs in lag periods (of 1-3 days). Single and multiple regressions were employed using backward elimination and a variance inflation factor of <5.
Results
The numbers of COVID-19–related queries in South Korea increased during local events including local transmission, approval of coronavirus test kits, implementation of coronavirus drive-through tests, a face mask shortage, and a widespread campaign for social distancing as well as during international events such as the announcement of a Public Health Emergency of International Concern by the World Health Organization. Online queries were also stronger in women (r=0.763-0.823; P<.001) and age groups ≤29 years (r=0.726-0.821; P<.001), 30-44 years (r=0.701-0.826; P<.001), and ≥50 years (r=0.706-0.725; P<.001). In terms of spatial distribution, internet search data were higher in affected areas. Moreover, greater correlations were found in mobile searches (r=0.704-0.804; P<.001) compared to those of desktop searches (r=0.705-0.717; P<.001), indicating changing behaviors in searching for online health information during the outbreak. These varied internet searches related to COVID-19 represented community health risk perceptions. In addition, as a country with a high number of coronavirus tests, results showed that adults perceived coronavirus test–related information as being more important than disease-related knowledge. Meanwhile, younger, and older age groups had different perceptions. Moreover, NAVER RSVs can potentially be used for health risk perception assessments and disease predictions. Adding COVID-19–related searches provided by NAVER could increase the performance of the model compared to that of the COVID-19 case–based model and potentially be used to predict epidemic curves.
Conclusions
The use of both GT and NAVER RSVs to explore patterns of community health risk perceptions could be beneficial for targeting risk communication from several perspectives, including time, population characteristics, and location.}
}
@article{LI2022128303,
title = {Surface layer modulus prediction of asphalt pavement based on LTPP database and machine learning for Mechanical-Empirical rehabilitation design applications},
journal = {Construction and Building Materials},
volume = {344},
pages = {128303},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2022.128303},
url = {https://www.sciencedirect.com/science/article/pii/S0950061822019638},
author = {Miaomiao Li and Qingli Dai and Peifeng Su and Zhanping You and Yunxiang Ma},
keywords = {Asphalt pavement, Layer modulus, LTPP, Machine learning, ME rehabilitation design, Prediction},
abstract = {Evaluating the modulus of the existing asphalt concrete (AC) layer is a critical procedure in Mechanical-Empirical (ME) rehabilitation analysis. Generally, the modulus could be back-calculated by the Falling Weight Deflectometer (FWD) test. However, the raw FWD data of each pavement section is not always readily prepared for local highway agencies. To address this issue, the main objective of this study is to establish a reliable model by machine learning (ML) methods to predict AC layer modulus for the existing flexible pavement with data readily available from the local pavement management system, which could be an auxiliary tool for network-level sections with no FWD tests. The long-term pavement performance (LTPP) database was used to collect the original data for model training and testing, including pavement structures, service age, climate records, and pavement distresses. After preliminary data processing, matrix correlation analysis, and feature selection, the prepared dataset (total data points = 6477) with 14 predictors was fed into three regression models, including Ordinary Least-Squares regression (OLS), Random Forest regression (RF), and Gradient Boosting regression Method (GBM). The related key hyperparameters were optimized by grid search and 5-folds cross-validation. By comparison, the GBM model was finally selected due to its considerably higher prediction accuracy (R2 = 0.7921) than RF model (R2 = 0.7525) and OLS model (R2 = 0.4371) in the test set. According to the variable importance given by GBM model, surface temperature and AC layer thickness are more dominant variables in modulus estimation. In addition, a case study with predicted AC layer moduli in ME rehabilitation design was provided to verify the model application. In summary, the trained GBM model can be utilized to predict AC layer modulus for pavement evaluation and then ME rehabilitation when FWD data is not available.}
}
@article{RENDALL201999,
title = {Wide spectrum feature selection (WiSe) for regression model building},
journal = {Computers & Chemical Engineering},
volume = {121},
pages = {99-110},
year = {2019},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2018.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0098135418306999},
author = {Ricardo Rendall and Ivan Castillo and Alix Schmidt and Swee-Teng Chin and Leo H. Chiang and Marco Reis},
keywords = {Feature selection, Filtering methods, Predictive analytics, Effect sparsity, Symmetrical uncertainty},
abstract = {Developing predictive models from industrial datasets implies the consideration of many possible predictor variables (features). Using all available features for data-driven modelling is not recommended, as most of them are expected to be irrelevant and their inclusion in the model may compromise robustness and accuracy. In this work, we present, test and compare a new two-stage feature selection method called wide spectrum feature selection for regression (WiSe). In the first stage, a combination of efficient bivariate filters analyzes linear and non-linear association patterns between predictors and responses, screening out clearly noisy features. In the second stage, the reduced set of retained features is subject to further selection in the scope of the predictive methods considered, optimizing their predictive performance. Three simulated datasets and an industrial case illustrate the effectiveness and benefits of applying WiSe to support model development in a wide range of high-dimensional regression problems.}
}
@article{SHEN2023110157,
title = {Machine learning–assisted prediction of heat fluxes through thermally anisotropic building envelopes},
journal = {Building and Environment},
volume = {234},
pages = {110157},
year = {2023},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2023.110157},
url = {https://www.sciencedirect.com/science/article/pii/S0360132323001841},
author = {Zhenglai Shen and Som Shrestha and Daniel Howard and Tianli Feng and Diana Hun and Buxin She},
keywords = {Thermally anisotropic building envelope (TABE), Machine learning, Heat flux prediction, Building energy management},
abstract = {Thermally anisotropic building envelope (TABE) is a novel active building envelope that can save energy use to maintain thermal comfort in buildings by redirecting heat and coolness from building envelopes to thermal loops. Finite element models (FEMs) can be used to compute the heat fluxes through TABEs, but the high computational cost of finite element simulations has prevented parametric studies and design optimizations. This paper proposes a domain knowledge–informed, finite element–based machine learning framework to reduce the computation cost for the energy management of buildings installed with TABE that uses a ground thermal loop. First, the training heat flux data set was generated by FEM simulations with different thermal loop schedules. Then, both shallow learning models (i.e., multivariate linear regression and eXtreme Gradient Boost, or XGBoost) and a deep learning model (i.e., deep neural network, or DNN) were trained to predict the heat fluxes. Domain knowledge was used for data preprocessing and feature selection. Finally, the suitability of the selected machine learning model was tested under different thermal loop schedules. The case study results showed that: (1) XGBoost can be as accurate as DNN (coefficient of determination equal to 0.81) with much less training time; (2) the annual energy cost savings for different thermal loop schedules obtained by the XGBoost-predicted and FEM-calculated heat fluxes are consistent, having a difference of only 4%; and (3) XGBoost can reduce the computation time for the annual energy analysis of the case study building with a given thermal loop schedule from around 12 h by using FEM to less than 1 min.}
}
@article{MENDONCA2020105314,
title = {Matrix of Lags: A tool for analysis of multiple dependent time series applied for CAP scoring},
journal = {Computer Methods and Programs in Biomedicine},
volume = {189},
pages = {105314},
year = {2020},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2020.105314},
url = {https://www.sciencedirect.com/science/article/pii/S0169260719315871},
author = {Fábio Mendonça and Sheikh Shanawaz Mostafa and Fernando Morgado-Dias and Antonio G. Ravelo-García},
keywords = {Time series analysis, Matrix of Lags, CAP, Sleep quality, ECG},
abstract = {Background
Multiple methods have been developed to assess what happens between and within time series. In a particular type of these series, the previous values of the currently observed series are contingent on the lagged values of another series. These cases can commonly be addressed by regression. However, a model selection criteria should be employed to evaluate the compromise between the amount of information provided and the model complexity. This is the basis for the development of the Matrix of Lags (MoL), a tool to study dependent time series.
Methods
For each input, multiple regressions were applied to produce a model for each lag and a model selection criterion identifies the lags that will populate an auxiliary matrix. Afterwards, the energy of the lags (that are in the auxiliary matrix) was used to define a row of the MoL. Therefore, each input corresponds to a row of the MoL. To test the proposed tool, the heart rate variability and the electrocardiogram derived respiration were employed to perform the indirect estimation of the electroencephalography cyclic alternating pattern (CAP) cycles. Therefore, a support vector machine was fed with the MoL to perform the CAP cycle classification for each input signal. Multiple tests were carried out to further examine the proposed tool, including the effect of balancing the datasets, application of other regression methods and employment of two feature section models. The first was based on sequential backward selection while the second examined characteristics of a return map.
Results
The best performance of the subject independent model was attained by feeding the lags, selected by sequential backward selection, to a support vector machine, achieving an average accuracy, sensitivity, specificity and area under the receiver operating characteristic curve of, respectively, 77%, 71%, 82% and 0.77.
Conclusions
The developed model allows to perform a measurement of a characteristic marker of sleep instability (the CAP cycle) and the results are in the upper bound of the specialist agreement range with visual analysis. Thus, the developed method could possibly be used for clinical diagnosis.}
}
@article{GUILLEN2022111737,
title = {Topology optimization of an airfoil fin microchannel heat exchanger using artificial intelligence},
journal = {Nuclear Engineering and Design},
volume = {391},
pages = {111737},
year = {2022},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2022.111737},
url = {https://www.sciencedirect.com/science/article/pii/S0029549322000917},
author = {Donna Post Guillen and Alexander W. Abboud and James Bennink},
keywords = {Computational fluid dynamics, Airfoil fin, Microchannel heat exchanger, Latin hypercube sampling, Topology optimization, Genetic algorithm},
abstract = {High-performance microchannel heat exchangers are needed to supply heat for power conversion for nuclear microreactors. An airfoil fin microchannel design, constructed of Alloy 617 with helium as the working fluid, is analyzed and optimized using a design of experiments with artificial intelligence techniques. The use of airfoil fins offers the potential to reduce pressure drop across the heat exchanger, as compared to other types of channel configurations. A framework for topology optimization of airfoil fin printed circuit heat exchangers (PCHEs) has been developed that can be readily extended to different fin sizes and shapes, as well as different inlet and operating conditions, materials of construction, and working fluids. An optimization procedure is developed that employs computational fluid dynamics for a set of design points identified using Latin hypercube sampling. Computational fluid dynamics is used to analyze a simplified two-channel configuration where five design parameters are varied – inlet angle, fin scale, extent of staggering, transverse and longitudinal pitches. Two methods (a 5D polynomial and a regression neural network) are compared for generating surrogate models and the resulting response surface approximation is input to a genetic algorithm that is used to identify a set of optimal parameters. The optimal geometries are found across six channel Reynolds numbers ranging from 1000 to 5000, since inlet conditions affect flow through the heat exchanger. A set of optimal designs that maximizes heat transfer and minimizes pressure drop is identified, and a thermal stress analysis is performed on the optimal design. Correlations for the Nusselt number and Darcy friction factor are developed that can be useful for thermal hydraulic analyses using system codes. Thermal stresses are analyzed and a brief discussion of the status of code cases of PCHEs for nuclear applications is given. Testing and thermomechanical modeling is needed to facilitate future code compliance of PCHEs for high pressure and high temperature applications.}
}
@article{XIAO201915,
title = {A domain decomposition non-intrusive reduced order model for turbulent flows},
journal = {Computers & Fluids},
volume = {182},
pages = {15-27},
year = {2019},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2019.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0045793019300350},
author = {D. Xiao and C.E. Heaney and F. Fang and L. Mottet and R. Hu and D.A. Bistrian and E. Aristodemou and I.M. Navon and C.C. Pain},
keywords = {Non-intrusive reduced order modelling, Domain decomposition, Machine learning, Gaussian process regression, Urban flows, Turbulent flows, Finite element method},
abstract = {In this paper, a new Domain Decomposition Non-Intrusive Reduced Order Model (DDNIROM) is developed for turbulent flows. The method works by partitioning the computational domain into a number of subdomains in such a way that the summation of weights associated with the finite element nodes within each subdomain is approximately equal, and the communication between subdomains is minimised. With suitably chosen weights, it is expected that there will be approximately equal accuracy associated with each subdomain. This accuracy is maximised by allowing the partitioning to occur through areas of the domain that have relatively little flow activity, which, in this case, is characterised by the pointwise maximum Reynolds stresses. A Gaussian Process Regression (GPR) machine learning method is used to construct a set of local approximation functions (hypersurfaces) for each subdomain. Each local hypersurface represents not only the fluid dynamics over the subdomain it belongs to, but also the interactions of the flow dynamics with the surrounding subdomains. Thus, in this way, the surrounding subdomains may be viewed as providing boundary conditions for the current subdomain. We consider a specific example of turbulent air flow within an urban neighbourhood at a test site in London and demonstrate the effectiveness of the proposed DDNIROM.}
}
@article{BHANDARI2023107140,
title = {Integrative gene expression analysis for the diagnosis of Parkinson’s disease using machine learning and explainable AI},
journal = {Computers in Biology and Medicine},
volume = {163},
pages = {107140},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107140},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523006054},
author = {Nikita Bhandari and Rahee Walambe and Ketan Kotecha and Mehul Kaliya},
keywords = {Parkinson's disease diagnosis, Machine learning, Peripheral blood, Gene expression, Explainable artificial intelligence},
abstract = {Parkinson's disease (PD) is a progressive neurodegenerative disorder. Various symptoms and diagnostic tests are used in combination for the diagnosis of PD; however, accurate diagnosis at early stages is difficult. Blood-based markers can support physicians in the early diagnosis and treatment of PD. In this study, we used Machine Learning (ML) based methods for the diagnosis of PD by integrating gene expression data from different sources and applying explainable artificial intelligence (XAI) techniques to find the significant set of gene features contributing to diagnosis. We utilized the Least Absolute Shrinkage and Selection Operator (LASSO), and Ridge regression for the feature selection process. We utilized state-of-the-art ML techniques for the classification of PD cases and healthy controls. Logistic regression and Support Vector Machine showed the highest diagnostic accuracy. SHapley Additive exPlanations (SHAP) based global interpretable model-agnostic XAI method was utilized for the interpretation of the Support Vector Machine model. A set of significant biomarkers that contributed to the diagnosis of PD were identified. Some of these genes are associated with other neurodegenerative diseases. Our results suggest that the utilization of XAI can be useful in making early therapeutic decisions for the treatment of PD. The integration of datasets from different sources made this model robust. We believe that this research article will be of interest to clinicians as well as computational biologists in translational research.}
}
@article{KRISHNAMOORTHY202444,
title = {A novel and secured email classification and emotion detection using hybrid deep neural network},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {5},
pages = {44-57},
year = {2024},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666307424000019},
author = {Parthiban Krishnamoorthy and Mithileysh Sathiyanarayanan and Hugo Pedro Proença},
keywords = {Email classification, DNN-BiLSTM, AES algorithm, Rabit algorithm, Random forests (RF)},
abstract = {Compared to other social media data, email data differs from it in various topic-specific ways, including extensive replies, formal language, significant length disparities, high levels of anomalies, and indirect linkages. In this paper, the creation of a potent and computationally effective classifier to categorize spam and ham email documents is proposed. To assess and validate spam texts, this paper employs a variety of data mining-based classification approaches. On the benchmark Enron dataset, which is open to the public, tests were run. The final 7 Enron datasets were created by combining the six different types of Enron datasets that we had acquired. We preprocess the dataset at an early stage to exclude any useless phrases. This method falls under several categories, including Logistic Regression (LR), Convolutional Neural Networks (CNN), Random Forests (RF), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and suggested Deep Neural Networks (DNN). Using Bidirectional Long Short-Term Memory (BiLSTM), email documents may be screened for spam and labeled as such. In performance comparisons, DNN-BiLSTM outperforms other classifiers in terms of accuracy on all seven Enron datasets. In comparison to other machine learning classifiers, the findings demonstrate that DNN-BiLSTM and Convolutional Neural Networks can categorize spam with 96.39 % and 98.69 % accuracy, respectively. The report also covers the dangers of managing cloud data and the security problems that might occur. To safeguard data in the cloud while maintaining privacy, hybrid encryption is examined in this white paper. In the AES-Rabit hybrid encryption system, the symmetric session key exchange-based Rabit technique is combined with the benefits of the AES algorithm for faster data encryption.}
}
@article{LIANG2022125431,
title = {Selection of backfill grouting materials and ratios for shield tunnel considering stratum suitability},
journal = {Construction and Building Materials},
volume = {314},
pages = {125431},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2021.125431},
url = {https://www.sciencedirect.com/science/article/pii/S0950061821031706},
author = {Xiaoming Liang and Kaichen Ying and Fei Ye and Enjie Su and Tianhan Xia and Xingbo Han},
keywords = {Shield tunnel, Backfill grouting, Grout ratio, Modified material, Stratum suitability},
abstract = {In shield tunnel engineering, there is no uniform standard for the selection of backfill grouting materials and ratios. In this study, to facilitate the selection of a grout, the applications of grout types, materials, and ratios were summarized based on a statistical analysis of engineering cases. Through laboratory tests and range analysis, the relationships among the basic grout performance and ratios were examined. The reference values of the grout ratios and performance requirements in different strata were obtained using statistical methods and by regression analysis. The results showed that the grout type used in engineering is mainly a single-component grout; in strata with groundwater, the usage rate of modified grouts is significantly high. The single-component grout ratio for clay is the most affected by groundwater; for all strata, the change in the B/S ratio is the most significant. The W/B ratio is the most important factor affecting the basic grout performance, and the demand for compressive strength varies the most in all strata.}
}
@article{SAHIN2020104592,
title = {Developing comprehensive geocomputation tools for landslide susceptibility mapping: LSM tool pack},
journal = {Computers & Geosciences},
volume = {144},
pages = {104592},
year = {2020},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2020.104592},
url = {https://www.sciencedirect.com/science/article/pii/S009830042030577X},
author = {Emrehan Kutlug Sahin and Ismail Colkesen and Suheda Semih Acmali and Aykut Akgun and Arif Cagdas Aydinoglu},
keywords = {Landslide susceptibility, Feature selection, Statistically significance, ArcGIS and R integration, Random forest},
abstract = {The primary aim of this research paper is to develop an easy-to-use tool package called Landslide Susceptibility Mapping Tool Pack (LSM Tool Pack) for producing landslide susceptibility maps based on integrating R with ArcMap Software. The proposed tool contains 5 main modules namely: (1) Data Preparation (DP), (2) Feature (Factor) Selection (FS), (3) Logistic Regression (LR), (4) Random Forest (RF) and (5) Performance Evaluation (PE). The FS module brings a novel approach to determine the best factor subset in the production of landslide susceptibility maps. The feature ranking values of factors were calculated by several feature ranging methods (i.e. chi-square, information gain, rank correlation, and random forest feature importance). The logistic regression method was used at the model prediction stage for each feature ranking and different models were produced for each ranking result. And, in the last step of the FS analysis, tests of statistical significance (i.e. Wilcoxon signed-rank test, F- Test, Kolmogorov Smirnov test, and One-Sample t-test) were used to determine the significance of the difference between models. As a result, the best factor sets determined by the FS module were used as input factors in the LR Module and the RF Module to produce LSMs. Also, users can calculate the performance metric of landslide susceptibility maps by several performance metrics (overall accuracy, Area under the ROC Curve (AUC) value, kappa, F1 score, and more) with additional integrated the PE Module in ArcMap Software. The LSM Tool Pack is applied to the Sinop province of the Black Sea region of Turkey. Considered the FS module, Case 1 was selected as the experimental dataset for this present study. In the selected Case 1, feature ranking method and statistically significant analysis were determined by Chi-square and F-Test, respectively. As a result, Model-12, which is contained 12 landslide causative factors, was determined as the optimum subset. According to the results obtained by the accuracy assessment process, the RF model showed the best prediction performance with an AUC value of 0.8898. On the other hand, the calculated AUC value was 0.8119 for the LR model. The experimental results (using with dataset in actual study area) confirm the ability of the proposed feature selection approach in the landslide susceptibility mapping process.}
}
@article{ANJAIAH2022533,
title = {Detection of faults and DG islanding in PV-Wind DC ring bus microgrid by using optimized VMD based improved broad learning system},
journal = {ISA Transactions},
volume = {131},
pages = {533-551},
year = {2022},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2022.05.037},
url = {https://www.sciencedirect.com/science/article/pii/S0019057822002713},
author = {Kanche Anjaiah and P.K. Dash and Mrutyunjaya Sahani},
keywords = {Adaptive variational mode decomposition, DC-ring microgrid, DG islanding, Fault detection, Faults classification, Improved broad learning system, Improved whale optimization algorithm, dSPACE interface},
abstract = {This paper presents a novel approach for the detection and classification of photovoltaic with wind based DC ring bus microgrid DC faults and DG (distributed generation) islanding events. This novel approach consists of adaptive variational mode decomposition (AVMD) and an improved broad learning system (IBLS). Initially, DC fault current signals are captured from the DC bus under different operating conditions and processed through the AVMD to decompose the signals into intrinsic mode functions (IMFs). The VMD is made adaptive by minimizing the objective function of the L-kurtosis index for optimal modal number (K) and penalty factor (σ) through the improved whale optimization (IWO) algorithm. From the optimal IMFs, the most significant IMFs are chosen based on the threshold of the L-kurtosis index, and they are passed through statistical features to extract efficient data. Further, the training and testing of this data set is carried out through IBLS for obtaining the accurate detection and discrimination of DC faults. The conventional BLS method is improved through elastic net ridge regression for calculating the weights. The effectiveness of the proposed AVMD based IBLS algorithm is verified by its superiority in terms of relative computation time (RCT), classification accuracy (CA) with the confusion matrix, and their performance indices by comparing with other existing methods under different case studies. Finally, the simplicity and practicability of the proposed work are tested and implemented in the dSPACE 1104 embedded processor.}
}
@incollection{DECARVALHOSERVIA202333,
title = {Automated Kinetic Model Discovery – A Methodological Framework},
editor = {Antonios C. Kokossis and Michael C. Georgiadis and Efstratios Pistikopoulos},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {52},
pages = {33-38},
year = {2023},
booktitle = {33rd European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-15274-0.50006-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443152740500068},
author = {Miguel Ángel {de Carvalho Servia} and Ilya Orson Sandoval and Dongda Zhang and Klaus Hellgardt and King {Kuok Mimi Hii} and Ehecatl Antonio {del Rio Chanona}},
keywords = {catalysis, kinetic model generation, automated knowledge discovery, information criteria, machine learning},
abstract = {The industrialization of catalytic processes benefits strongly from kinetic models for optimization and control purposes. Nevertheless, mechanistic models are difficult to construct; data-driven and hybrid models lack interpretability and the flexibility to leverage physical knowledge. Thus, a different approach called automated knowledge discovery has been recently popularized. Existing methods in literature suffer from important drawbacks: necessitating assumptions about model structures, a lack of model selection automation, and sensitivity to noise. To overcome these challenges, the present work constructs a methodological framework for the automated generation of catalytic kinetic models. We leverage symbolic regression for model generation, a hybrid optimization algorithm for parameter estimation, and a robust criterion for model selection. The framework is tested with an illustrative isomerization case study, where it showcases the ability to retrieve the underlying kinetic model with a limited amount of noisy data from the catalytic system.}
}
@article{CHAPALOGLOU2022118906,
title = {Data-driven energy management of isolated power systems under rapidly varying operating conditions},
journal = {Applied Energy},
volume = {314},
pages = {118906},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.118906},
url = {https://www.sciencedirect.com/science/article/pii/S0306261922003294},
author = {Spyridon Chapaloglou and Damiano Varagnolo and Francesco Marra and Elisabetta Tedeschi},
keywords = {Stochastic model predictive control, Quantile regression, Random forests, Isolated power systems, Offshore wind power, Energy storage, Mixed-integer linear programming, Economic MPC},
abstract = {We propose an energy management algorithm for isolated industrial power systems that integrate uncertain renewable generation and energy storage. The proposed strategy is designed to ensure sustainable and cost-effective operations by managing the energy flows in the grid, and is structured so to cope with: (1) high levels of renewable power penetration, and (2) load profiles characterized by non-smooth patterns and irregular events (i.e., events such as those occurring from connections/disconnections of large scale equipment, or from large wind speed ramps). The proposed algorithm leverages a stochastic economic model predictive control (MPC) scheme capable of dealing simultaneously with the dispatch and scheduling of the local generation units. More precisely, the scheme embeds a mixed-integer linear programming (MILP) optimal control policy formulation together with a stochastic programming approach. Moreover, the optimization problem accounts for multiple techno-economical objectives, such as minimization of operational costs, battery degradation, and non-utilized energy. We test the algorithm on a case study of an isolated offshore Oil & Gas platform producing energy onsite with conventional gas turbines and a local wind farm, while integrating a battery energy storage system. The results show that the proposed approach can issue ensemble predictions that successfully capture the potential irregular variations just by using recent past information of the associated random variable, even when no particular sudden events are anticipated in the near-future (i.e., step changes/trend reversals). In this way, the approach provides useful future information for the optimal management of the grid. This effect is numerically quantified via simulations that compare the performance of the proposed stochastic optimization approach against its deterministic MPC version in several realistic operating conditions. The empirical results suggest that the stochastic version leads to better scheduling of the conventional generators, with up to 12.86% reductions of the operating cost, 2.56% reduction in fuel consumption and emissions, and 35.29% reduction in status transitions (on/off) of the gas turbines, while keeping dumped energy and battery degradation as low as possible.}
}
@article{LOPEZMARTIN2020110592,
title = {Transformed k-nearest neighborhood output distance minimization for predicting the defect density of software projects},
journal = {Journal of Systems and Software},
volume = {167},
pages = {110592},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110592},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300728},
author = {Cuauhtémoc López-Martín and Yenny Villuendas-Rey and Mohammad Azzeh and Ali {Bou Nassif} and Shadi Banitaan},
keywords = {Software defect density prediction, Case-based reasoning, Transformed k-nearest neighborhood output distance minimization, Support vector regression, Neural networks, ISBSG},
abstract = {Background
Software defect prediction is one of the most important research topics in software engineering. An important product measure to determine the effectiveness of software processes is the defect density (DD). Cased-based reasoning (CBR) has been the prediction technique most widely applied in the software prediction field. The CBR involves k-nearest neighborhood for finding the number (k) of similar software projects selected to be involved in the prediction process.
Objective
To propose the application of a transformed k-nearest neighborhood output distance minimization (TkDM) algorithm to predict the DD of software projects to compare its prediction accuracy with those obtained from statistical regression, support vector regression, and neural networks.
Method
Data sets were obtained from the ISBSG release 2018. A leave-one-out cross validation method was performed. Absolute residual was used as the prediction accuracy criterion for models.
Results
Statistical significance tests among models showed that the TkDM had the best prediction accuracy than those ones from statistical regression, support vector regression, and neural networks.
Conclusions
A TkDM can be used for predicting the DD of new and enhanced software projects developed and coded in specific platforms and programming languages types.}
}
@article{HUANG2023109046,
title = {Online monitoring of the voltage stability margin using local minimax concave penalty regression and adaptive database},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {149},
pages = {109046},
year = {2023},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2023.109046},
url = {https://www.sciencedirect.com/science/article/pii/S0142061523001035},
author = {Zongwu Huang and Xun Xu and Youping Fan and Zijiang Wang and Ben Shang and Maolin Shang and Wenxiang Yu and Yiming Wu and Dongjie Li and Mingqi Lin},
keywords = {Voltage stability margin, Local regression, Minimax concave penalty, Adaptive database, Online monitoring},
abstract = {A novel online monitoring method for the voltage stability margin (VSM) based on local minimax concave penalties (LocMCP) regression and adaptive database is proposed to ameliorate the weak model interpretability and insufficient generalization ability of the existing online monitoring methods. In this paper, the minimax concave penalty (MCP) is applied for VSM online monitoring for the first time. Compared with the multiple linear regression model (MLRM) and the local least absolute shrinkage and selection operator (LocLASSO), better prediction accuracy can be obtained through LocMCP. The MCP and local regression are combined to find the mapping relationship between VSM and reactive power reserves (RPRs) and to obtain the VSM online monitoring model composed of various local models. To further enhance the generalization ability of the model, an adaptive database is proposed. The data updating of the database is triggered when the local root mean square error (LocRMSE) exceeds the limit or is triggered in the case that the planned operation is performed. Furthermore, the local model can be updated according to the data updating results of the database. The 3-bus system, IEEE 30-bus system, and 1951-bus system are selected for verification, and the test results show that the proposed method is effective and has better generalization ability compared with other parameter regression methods.}
}
@article{SHANG2018269,
title = {Enhanced support vector regression based forecast engine to predict solar power output},
journal = {Renewable Energy},
volume = {127},
pages = {269-283},
year = {2018},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2018.04.067},
url = {https://www.sciencedirect.com/science/article/pii/S0960148118304750},
author = {Chuanfu Shang and Pengcheng Wei},
keywords = {Improved support vector regression, Feature selection, Enhanced empirical mode decomposition, PV},
abstract = {The critical role of photovoltaic (PV) energy as renewable sources in network can make some problems in power grids operation. Due to high volatility of PV signal, the prediction and its evaluation in planning and operation is very difficult. For this purpose, an accurate prediction approach is developed in this paper to tackle the mentioned problem. The proposed approach is based on enhanced empirical model decomposition (EEMD), a new feature selection method and hybrid forecast engine. The proposed feature selection is formulated by different criteria to select the best candidate inputs of forecast engine. And finally the hybrid forecast engine composed of improved support vector regression (ISVR) plus optimization algorithm to fine tune the related free parameters. Effectiveness of proposed method is applied over real-world engineering test cases through comparison with various prediction models.}
}
@article{YU202465,
title = {A performance-based hybrid deep learning model for predicting TBM advance rate using Attention-ResNet-LSTM},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
volume = {16},
number = {1},
pages = {65-80},
year = {2024},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2023.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1674775523001968},
author = {Sihao Yu and Zixin Zhang and Shuaifeng Wang and Xin Huang and Qinghua Lei},
keywords = {Tunnel boring machine (TBM), Advance rate, Deep learning, Attention-ResNet-LSTM, Evolutionary polynomial regression},
abstract = {The technology of tunnel boring machine (TBM) has been widely applied for underground construction worldwide; however, how to ensure the TBM tunneling process safe and efficient remains a major concern. Advance rate is a key parameter of TBM operation and reflects the TBM-ground interaction, for which a reliable prediction helps optimize the TBM performance. Here, we develop a hybrid neural network model, called Attention-ResNet-LSTM, for accurate prediction of the TBM advance rate. A database including geological properties and TBM operational parameters from the Yangtze River Natural Gas Pipeline Project is used to train and test this deep learning model. The evolutionary polynomial regression method is adopted to aid the selection of input parameters. The results of numerical experiments show that our Attention-ResNet-LSTM model outperforms other commonly-used intelligent models with a lower root mean square error and a lower mean absolute percentage error. Further, parametric analyses are conducted to explore the effects of the sequence length of historical data and the model architecture on the prediction accuracy. A correlation analysis between the input and output parameters is also implemented to provide guidance for adjusting relevant TBM operational parameters. The performance of our hybrid intelligent model is demonstrated in a case study of TBM tunneling through a complex ground with variable strata. Finally, data collected from the Baimang River Tunnel Project in Shenzhen of China are used to further test the generalization of our model. The results indicate that, compared to the conventional ResNet-LSTM model, our model has a better predictive capability for scenarios with unknown datasets due to its self-adaptive characteristic.}
}
@article{WANG2021114172,
title = {Efficient structural reliability analysis based on adaptive Bayesian support vector regression},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {387},
pages = {114172},
year = {2021},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2021.114172},
url = {https://www.sciencedirect.com/science/article/pii/S004578252100503X},
author = {Jinsheng Wang and Chenfeng Li and Guoji Xu and Yongle Li and Ahsan Kareem},
keywords = {Structural reliability analysis, Adaptive surrogate models, Support vector regression, Bayesian inference, Learning function},
abstract = {To reduce the computational burden for structural reliability analysis involving complex numerical models, many adaptive algorithms based on surrogate models have been developed. Among the various surrogate models, the support vector machine for regression (SVR) which is derived from statistical learning theory has demonstrated superior performance to handle nonlinear problems and to avoid overfitting with excellent generalization. Therefore, to take the advantage of the desirable features of SVR, an Adaptive algorithm based on the Bayesian SVR model (ABSVR) is proposed in this study. In ABSVR, a new learning function is devised for the effective selection of informative sample points following the concept of the penalty function method in optimization. To improve the uniformity of sample points in the design of experiments (DoE), a distance constraint term is added to the learning function. Besides, an adaptive sampling region scheme is employed to filter out samples with weak probability density to further enhance the efficiency of the proposed algorithm. Moreover, a hybrid stopping criterion based on the error-based stopping criterion using the bootstrap confidence estimation is developed to terminate the active learning process to ensure that the learning algorithm stops at an appropriate stage. The proposed ABSVR is easy to implement since no embedded optimization algorithm nor iso-probabilistic transformation is required. The performance of ABSVR is evaluated using six numerical examples featuring different complexity, and the results demonstrate the superior performance of ABSVR for structural reliability analysis in terms of accuracy and efficiency.}
}
@article{LEGUENNEC2018186,
title = {A parametric and non-intrusive reduced order model of car crash simulation},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {338},
pages = {186-207},
year = {2018},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2018.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0045782518301221},
author = {Y. Le Guennec and J.-P. Brunet and F.-Z. Daim and M. Chau and Y. Tourbier},
keywords = {Reduced order model, Crash simulation, Regression analysis, Linear programming},
abstract = {Industrials have an intensive use of numerical simulations in order to avoid physical testing and to speed up the design stages of their products. The numerical testing is indeed quicker to set-up, less expensive, and supplies a lot of information about the system under study. Moreover, it can be much closer to the physical tests as the computation power increases. Despite the rise of this power, time consuming simulations remain challenging to be used in design process, especially in an optimization study. Crash simulations belong to this category. These rapid dynamic computations are used by RENAULT during the sizing of the vehicle structure in order to ensure that it meets specifications set up to reach safety criteria in case of accidents. They are completed using finite element software such as VPS (Virtual Performance Solver) developed by ESI group that will be used in this study. For car manufacturers, the goal of the optimization study is to minimize the mass of the vehicle (and thus its consumption) by modifying the thicknesses of some parts (from 20 to 100 variables). Industrials such as RENAULT currently perform optimization studies based on numerical design of experiments. The number of computations required by this technique is from 3 to 10 times the number of variables. This is too much in order to be intensively used in a design process. In order to decrease the time-to-market and to explore alternative technical solutions, we explore the potential of using a parametrized reduced order model in the optimization studies. The parametrized reduced order model gives an estimation of the high-fidelity result for a new set of parameters without using the solver, by analysing the existing results of previous computations with various sets of parameters. The developed reduced order model is called ReCUR. It is partly based on a CUR approach embedded in a regression analysis. The regression statistical model uses the data of a few calculations made with the solver. Other tools such as clustering and linear programming are used to get the regression analysis more efficient. It is hoped to drastically reduce the number of required simulations of a standard optimization study. In this paper, the construction of the reduced order model will be presented. Then, the relevancy of using the reduced order model into a design process will be exhibited through the treatment of two industrial test-cases. Some improvements of the method as well as several potential uses will then be outlined. The applications will highlight the promising power of the method to shorten design process using optimization and long-run simulations.}
}
@article{VISSER2022118280,
title = {An operational bidding framework for aggregated electric vehicles on the electricity spot market},
journal = {Applied Energy},
volume = {308},
pages = {118280},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.118280},
url = {https://www.sciencedirect.com/science/article/pii/S0306261921015403},
author = {L.R. Visser and M.E. Kootte and A.C. Ferreira and O. Sicurani and E.J. Pauwels and C. Vuik and W.G.J.H.M. {Van Sark} and T.A. AlSkaif},
keywords = {Smart charging, Forecast, Electric Vehicles, Day ahead electricity market, Operational bidding framework, Market trading, Machine learning},
abstract = {Fluctuating electricity prices offer potential economic savings for the consumption of electricity by flexible assets such as Electric Vehicles (EVs). This study proposes an operational bidding framework that minimizes the charging costs of an EV fleet by submitting an optimized bid to the day-ahead electricity market. The framework consists of a bidding module that determines the most cost-effective bid by considering an electricity price and an EV charging demand forecast module. In this study we develop and evaluate several regression and machine learning models that forecast the electricity price and EV charging demand. Furthermore, we examine the composition of a most optimal operational bidding framework by comparing the outcome of the bidding module when fed with each of the forecast models. This is determined by considering the day-ahead electricity price and imbalance costs due to forecast errors. The study demonstrates that the best performing self-contained forecast models with the objective of electricity price and EV charging demand forecasting, do not deliver the best overall results when included in the bidding framework. Additionally, the results show that the best performing framework obtains a 26% cost savings compared to a reference case where EVs are charged inflexibly. This corresponds to an achieved savings potential of 92%. Consequently, along with the developed bidding framework, these results provide a fundamental basis for effective electricity trading on the day-ahead market.}
}
@article{ALBAIJAN2024109776,
title = {Estimating the initial fracture energy of concrete using various machine learning techniques},
journal = {Engineering Fracture Mechanics},
volume = {295},
pages = {109776},
year = {2024},
issn = {0013-7944},
doi = {https://doi.org/10.1016/j.engfracmech.2023.109776},
url = {https://www.sciencedirect.com/science/article/pii/S0013794423007348},
author = {Ibrahim Albaijan and Arsalan Mahmoodzadeh and Adil {Hussein Mohammed} and Mokhtar Mohammadi and Sohaib Gutub and Omar {Mutab Alsalami} and Hawkar {Hashim Ibrahim} and Yasser Alashker},
keywords = {Simple three-point load on single-edge notched beams, Machine learning, Initial fracture energy of concrete, User-friendly software},
abstract = {The assessment of the energy required for crack propagation in concrete structures has been fascinating since fracture mechanics was applied to concrete. In the case of concrete, considered a quasi-brittle material, the fracture energy has proven to be a crucial factor in the reliable design of structures and modeling failure behavior. However, due to the complex, time-consuming, and expensive laboratory tests, there has been ongoing and intense debate regarding the methods to estimate the fracture energy of concrete. The advent of machine learning (ML) methods in this domain can hold great promise for resolving such issues once and for all. This study used a comprehensive analysis of twelve ML algorithms for estimating the initial fracture energy of concrete (IFEC), utilizing a more extensive and diverse database (500 data points) than previous studies. The performance of the ML models was evaluated using several metrics, such as coefficient of determination (R2) and variance accounted for (VAF). The findings revealed that all the ML models employed in this study demonstrate remarkable accuracy in estimating the IFEC value, with R2 and VAF values of more than 0.86 and 93.10 %, respectively. A ranking of the models based on their estimation accuracy was provided, facilitating the selection of the support vector regression (R2 = 0.9897; VAF = 99.50 %) and long-short-term memory (R2 = 0.9804; VAF = 99.00 %) methods as the most reliable models for IFEC estimation. Both the laboratory test and ML models presented the highest IFEC value for a water-to-cement ratio of 0.35. Additionally, by increasing the values of each of the parameter's maximum size of aggregates (from 7 mm to 35 mm) and the specimen’s age (from 3 days to 180 days), the IFEC value was increased by about 100 %. Notably, a user-friendly software based on the ML models was developed, enabling fast and highly accurate estimation of IFEC, thereby eliminating the need for time-consuming and expensive laboratory tests.}
}
@article{RAUF2023107577,
title = {A novel smart feature selection strategy of lithium-ion battery degradation modelling for electric vehicles based on modern machine learning algorithms},
journal = {Journal of Energy Storage},
volume = {68},
pages = {107577},
year = {2023},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2023.107577},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X2300974X},
author = {Huzaifa Rauf and Muhammad Khalid and Naveed Arshad},
keywords = {Battery degradation, Li-ion batteries, Electric vehicles, Machine learning, Capacity loss, Prediction},
abstract = {Lithium-ion batteries are a key storage technology for electric vehicles and renewable energy applications. However, the complex degrading behaviour of batteries impacts their capacity and lifetime. Thus, battery capacity loss prediction is crucial for ensuring the longevity, safety, and reliable operation of the battery. This research proposes a smart feature selection (SFS) strategy-based machine learning framework for battery calendar and cyclic loss prediction. The presented methodology selects input parameters from the battery data of the current time step as well as the previous time step which are then utilized for model training and testing. Results demonstrate that the proposed SFS method in combination with the ML algorithms enhances the prediction accuracy and reduces the mean absolute error for all the machine learning algorithms applied in this study. The proposed SFS method is capable of excavating the useful features, therefore offering good generalization ability and accurate prediction results for capacity loss of the lithium-ion battery under real EV usage conditions. Furthermore, the results also depict that the performance accuracy of ML methods for battery calendar and cyclic loss prediction improves when combined with the SFS method. Greater improvement in prediction accuracy of battery capacity loss is observed for Gaussian Process Regression (GPR), random forest (RF), and XGBoost methods when applied in combination with the proposed SFS. This is the first-known feature selection-based ML application that is utilized to independently perform battery calendar and cyclic loss prognosis.}
}
@article{CARRILLOGALVEZ2022119070,
title = {Effect of models uncertainties on the emission constrained economic dispatch. A prediction interval-based approach},
journal = {Applied Energy},
volume = {317},
pages = {119070},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.119070},
url = {https://www.sciencedirect.com/science/article/pii/S0306261922004615},
author = {Adrian Carrillo-Galvez and Fabián Flores-Bazán and Enrique López Parra},
keywords = {Environmental constrained economic dispatch, Multiple linear regression, Prediction interval},
abstract = {Although electricity is a clean and relatively safe form of energy when it is used, the generation and transmission of electricity have severe effects on the environment. An alternative to diminish the polluting emissions released by the generating units is the Emission Constrained Economic Dispatch (ECED). This is an optimization problem where the total fuel cost is minimized while treating emissions as a constraint with a pre-specified limit. Usually, the fuel cost and emission functions of the generating units must be experimentally derived, introducing then uncertainties in the obtained models. However, these uncertainties are often neglected and the ECED problem is solved considering the coefficients of the functions involved as exact (totally known) values. In this investigation we analyzed the effect of the uncertainties associated to the experimental derivation of the input–output curves of thermal power plants. Particularly, when polynomial models are fitted through multiple linear regression, we proposed an approach that, based on the respectively prediction intervals, can provide solutions immunized, in some sense, against variability in the coefficients estimates. We tested the proposed approach in a real system from the Chilean electrical power network. For the analyzed system we noted that, when uncertainties are not considered, the deterministic optimal solutions can be environmentally infeasible in some scenarios; whereas solutions obtained through the proposed approach, can significantly diminish the risk of environmental violations. The robustness of the prediction interval-based solutions was obtained with a negligible increase of the total fuel cost in all the cases studied.}
}
@article{CHEN2021114339,
title = {Framework of airfoil max lift-to-drag ratio prediction using hybrid feature mining and Gaussian process regression},
journal = {Energy Conversion and Management},
volume = {243},
pages = {114339},
year = {2021},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.114339},
url = {https://www.sciencedirect.com/science/article/pii/S019689042100515X},
author = {Yaoran Chen and Zhikun Dong and Jie Su and Yan Wang and Zhaolong Han and Dai Zhou and Yongsheng Zhao and Yan Bao},
keywords = {Airfoil, Max lift-to-drag ratio, Gaussian process regression, Feature pool, Feature selection},
abstract = {The maximum lift-to-drag coefficient of an airfoil directly affects the aerodynamic performance of wind turbine. Machine learning methods are known for being really effective in helping to predict this parameter in a faster and more accurate way. So far, the majority of related studies have focused on the use of artificial neural networks to make this prediction, but this model has issues with its poor interpretation and the confidence level of its results was unclear. In this paper, a novel framework is proposed, involving the Gaussian process regression and a hybrid feature mining process. The aim is to use the new framework to evaluate the maximum lift-to-drag ratio of given airfoils under a turbulent flow condition, where the Reynolds number is around 100,000. The feature mining process here designed contains a hybrid feature pool that comprises various geometric characters, and a hybrid feature selector that can assist the prediction performance and make it better. Based on the airfoil dataset of the University of Illinois at Urbana-Champaign that contains a total of 1432 profiles, a comparative analysis was conducted. The results showed that the current framework can provide a more accurate estimate than parallel models in both single-point and interval aspects of view. Noticeably, the model reached an overall precision of 95.2% and 94.1% on training and testing sets, respectively. Moreover, the simplicity and the confidence reference from the model output were further illustrated with a case study, which also verified that how it can serve real engineering application.}
}
@article{SILHAVY20181,
title = {Evaluating subset selection methods for use case points estimation},
journal = {Information and Software Technology},
volume = {97},
pages = {1-9},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2017.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0950584917305153},
author = {Radek Silhavy and Petr Silhavy and Zdenka Prokopova},
keywords = {Software Development Effort Estimation, Software size estimation, Clustering techniques, Spectral Clustering, K-means, Moving Window, Use Case Points},
abstract = {When the Use Case Points method is used for software effort estimation, users are faced with low model accuracy which impacts on its practical application. This study investigates the significance of using subset selection methods for the prediction accuracy of Multiple Linear Regression models, obtained by the stepwise approach. K-means, Spectral Clustering, the Gaussian Mixture Model and Moving Window are evaluated as appropriate subset selection techniques. The methods were evaluated according to several evaluation criteria and then statistically tested. Evaluation was performing on two independent datasets - which differ in project types and size. Both were cut by the hold-out method. If clustering were used, the training sets were clustered into 3 classes; and, for each of class, an independent regression model was created. These were later used for the prediction of testing sets. If Moving Window was used, then window of sizes 5, 10 and 15 were tested. The results show that clustering techniques decrease prediction errors significantly when compared to Use Case Points or moving windows methods. Spectral Clustering was selected as the best-performing solution, because it achieves a Sum of Squared Errors reduction of 32% for the first dataset, and 98% for the second dataset. The Mean Absolute Percentage Error is less than 1% for the second dataset for Spectral Clustering; 9% for moving window; and 27% for Use Case Points. When the first dataset is used, then prediction errors are significantly higher – 53% for Spectral Clustering, but Use Case Points produces a 165% result. It can be concluded that this study proves subset selection techniques as a significant method for improving the prediction ability of linear regression models - which are used for software development effort prediction. It can also be concluded that the clustering method performs better than the moving window method.}
}
@article{ROGSTAD20131781,
title = {Test case selection for black-box regression testing of database applications},
journal = {Information and Software Technology},
volume = {55},
number = {10},
pages = {1781-1795},
year = {2013},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2013.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0950584913000980},
author = {Erik Rogstad and Lionel Briand and Richard Torkar},
keywords = {Test case selection, Regression testing, Database applications, Similarity measures},
abstract = {Context
This paper presents an approach for selecting regression test cases in the context of large-scale database applications. We focus on a black-box (specification-based) approach, relying on classification tree models to model the input domain of the system under test (SUT), in order to obtain a more practical and scalable solution. We perform an experiment in an industrial setting where the SUT is a large database application in Norway’s tax department.
Objective
We investigate the use of similarity-based test case selection for supporting black box regression testing of database applications. We have developed a practical approach and tool (DART) for functional black-box regression testing of database applications. In order to make the regression test approach scalable for large database applications, we needed a test case selection strategy that reduces the test execution costs and analysis effort. We used classification tree models to partition the input domain of the SUT in order to then select test cases. Rather than selecting test cases at random from each partition, we incorporated a similarity-based test case selection, hypothesizing that it would yield a higher fault detection rate.
Method
An experiment was conducted to determine which similarity-based selection algorithm was the most suitable in selecting test cases in large regression test suites, and whether similarity-based selection was a worthwhile and practical alternative to simpler solutions.
Results
The results show that combining similarity measurement with partition-based test case selection, by using similarity-based test case selection within each partition, can provide improved fault detection rates over simpler solutions when specific conditions are met regarding the partitions.
Conclusions
Under the conditions present in the experiment the improvements were marginal. However, a detailed analysis concludes that the similarity-based selection strategy should be applied when a large number of test cases are contained in each partition and there is significant variability within partitions. If these conditions are not present, incorporating similarity measures is not worthwhile, since the gain is negligible over a random selection within each partition.}
}
@article{IMTIAZ20191,
title = {A systematic literature review of test breakage prevention and repair techniques},
journal = {Information and Software Technology},
volume = {113},
pages = {1-19},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919300990},
author = {Javaria Imtiaz and Salman Sherin and Muhammad Uzair Khan and Muhammad Zohaib Iqbal},
keywords = {Test case repair, Regression testing, Automated testing, Systematic literature review},
abstract = {Context
When an application evolves, some of the developed test cases break. Discarding broken test cases causes a significant waste of effort and leads to test suites that are less effective and have lower coverage. Test repair approaches evolve test suites along with applications by repairing the broken test cases.
Objective
Numerous studies are published on test repair approaches every year. It is important to summarise and consolidate the existing knowledge in the area to provide directions to researchers and practitioners. This research work provides a systematic literature review in the area of test case repair and breakage prevention, aiming to guide researchers and practitioners in the field of software testing.
Method
We followed the standard protocol for conducting a systematic literature review. First, research goals were defined using the Goal Question Metric (GQM). Then we formulate research questions corresponding to each goal. Finally, metrics are extracted from the included papers. Based on the defined selection criteria a final set of 41 primary studies are included for analysis.
Results
The selection process resulted in 5 journal papers, and 36 conference papers. We present a taxonomy that lists the causes of test case breakages extracted from the literature. We found that only four proposed test repair tools are publicly available. Most studies evaluated their approaches on open-source case studies.
Conclusion
There is significant room for future research on test repair techniques. Despite the positive trend of evaluating approaches on large scale open source studies, there is a clear lack of results from studies done in a real industrial context. Few tools are publicly available which lowers the potential of adaption by industry practitioners.}
}
@article{FENTON2024111523,
title = {Embodied greenhouse gas emissions of buildings—Machine learning approach for early stage prediction},
journal = {Building and Environment},
volume = {257},
pages = {111523},
year = {2024},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.111523},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324003652},
author = {Sandie Kate Fenton and Adrian Munteanu and Klaas {De Rycke} and Lars {De Laet}},
keywords = {Embodied GHG emissions, Building, Machine learning, Design tool, Climate change mitigation},
abstract = {Observations made in architecture and engineering practices have highlighted the need to access buildings embodied greenhouse gas (GHG) emissions at early stages as well as a general understanding of the impacts of design decisions. This research addresses this need, and lack of readily available methods by leveraging knowledge from existing building’s databases, and using contextual and descriptive data, such as structure typology and location, to quantify the total embodied GHG emissions. It uses machine learning to develop a methodology for early and hands-on approximation of embodied GHG emissions, allowing to compare buildings, explain feature impacts, and verify computed results. The methodology, tested on the Embodied Carbon of European Buildings database, is generic and can be trained on other building databases and provide predictions tailored to their content. Alongside direct applications for design and decision-making, it provides a systematic analysis of features and emission standards, which, applied to a national database, could help inform policy models and mitigation strategies and transition towards a low emission and sustainable built environment.}
}
@article{DONG2024107869,
title = {Kernel functions embed into the autoencoder to identify the sparse models of nonlinear dynamics},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {131},
pages = {107869},
year = {2024},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2024.107869},
url = {https://www.sciencedirect.com/science/article/pii/S1007570424000558},
author = {Xin Dong and Yu-Long Bai and Wen-Di Wan},
keywords = {Model identification, SINDy, Kernel functions, Autoencoder},
abstract = {Numerous researches have shown that there are three main challenges in data-driven model identification methods: high-dimensional measurements, system complexity and unknown underlying dynamical properties. For most nonlinear dynamics, the feature space defined by the coefficients of their control equations is sparse. Therefore, sparse regression methods are used to learn the sparse coefficients of the control equations of nonlinear dynamics. However, this method strongly depends on the appropriate selection of the sparse basis vectors. In this essay, the autoencoder is combined with the sparse regression method to simultaneously identify the sparse coordinate and a parsimonious, interpretable and generalizable model of the specified system. It also integrates kernel functions to map the intractable measurements in the hidden space of the autoencoder into a linearly distinguishable kernel space, which kernelizes the candidate function library of the sparse identification of nonlinear dynamics (SINDy) model as the sparse dictionaries. Therefore, the flexible representation of neural networks, the simplicity of sparse regression methods and the implicit non-linear representation of kernel functions are consolidated in this article. To inspect the reliability of the proposed model in this paper, a set of nonlinear dynamics formulated by ordinary differential equations (ODEs), second-order trigonometric functions and partial differential equations (PDEs) are utilized as test cases. And the comparisons between the proposed model and other model identification methods illustrate that the performance of the former is the best.}
}
@article{TSAI2024,
title = {Building Dual AI Models and Nomograms Using Noninvasive Parameters for Aiding Male Bladder Outlet Obstruction Diagnosis and Minimizing the Need for Invasive Video-Urodynamic Studies: Development and Validation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/58599},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124004023},
author = {Chung-You Tsai and Jing-Hui Tian and Chien-Cheng Lee and Hann-Chorng Kuo},
keywords = {bladder outlet obstruction, lower urinary tract symptoms, machine learning, nomogram, artificial intelligence, video urodynamic study},
abstract = {Background
Diagnosing underlying causes of nonneurogenic male lower urinary tract symptoms associated with bladder outlet obstruction (BOO) is challenging. Video-urodynamic studies (VUDS) and pressure-flow studies (PFS) are both invasive diagnostic methods for BOO. VUDS can more precisely differentiate etiologies of male BOO, such as benign prostatic obstruction, primary bladder neck obstruction, and dysfunctional voiding, potentially outperforming PFS.
Objective
These examinations’ invasive nature highlights the need for developing noninvasive predictive models to facilitate BOO diagnosis and reduce the necessity for invasive procedures.
Methods
We conducted a retrospective study with a cohort of men with medication-refractory, nonneurogenic lower urinary tract symptoms suspected of BOO who underwent VUDS from 2001 to 2022. In total, 2 BOO predictive models were developed—1 based on the International Continence Society’s definition (International Continence Society–defined bladder outlet obstruction; ICS-BOO) and the other on video-urodynamic studies–diagnosed bladder outlet obstruction (VBOO). The patient cohort was randomly split into training and test sets for analysis. A total of 6 machine learning algorithms, including logistic regression, were used for model development. During model development, we first performed development validation using repeated 5-fold cross-validation on the training set and then test validation to assess the model’s performance on an independent test set. Both models were implemented as paper-based nomograms and integrated into a web-based artificial intelligence prediction tool to aid clinical decision-making.
Results
Among 307 patients, 26.7% (n=82) met the ICS-BOO criteria, while 82.1% (n=252) were diagnosed with VBOO. The ICS-BOO prediction model had a mean area under the receiver operating characteristic curve (AUC) of 0.74 (SD 0.09) and mean accuracy of 0.76 (SD 0.04) in development validation and AUC and accuracy of 0.86 and 0.77, respectively, in test validation. The VBOO prediction model yielded a mean AUC of 0.71 (SD 0.06) and mean accuracy of 0.77 (SD 0.06) internally, with AUC and accuracy of 0.72 and 0.76, respectively, externally. When both models’ predictions are applied to the same patient, their combined insights can significantly enhance clinical decision-making and simplify the diagnostic pathway. By the dual-model prediction approach, if both models positively predict BOO, suggesting all cases actually resulted from medication-refractory primary bladder neck obstruction or benign prostatic obstruction, surgical intervention may be considered. Thus, VUDS might be unnecessary for 100 (32.6%) patients. Conversely, when ICS-BOO predictions are negative but VBOO predictions are positive, indicating varied etiology, VUDS rather than PFS is advised for precise diagnosis and guiding subsequent therapy, accurately identifying 51.1% (47/92) of patients for VUDS.
Conclusions
The 2 machine learning models predicting ICS-BOO and VBOO, based on 6 noninvasive clinical parameters, demonstrate commendable discrimination performance. Using the dual-model prediction approach, when both models predict positively, VUDS may be avoided, assisting in male BOO diagnosis and reducing the need for such invasive procedures.}
}
@article{ALAMANIOTIS2018138,
title = {Probabilistic kernel machines for predictive monitoring of weld residual stress in energy systems},
journal = {Engineering Applications of Artificial Intelligence},
volume = {71},
pages = {138-154},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618300307},
author = {Miltiadis Alamaniotis and Jino Mathew and Alexander Chroneos and Michael E. Fitzpatrick and Lefteri H. Tsoukalas},
keywords = {Probabilistic kernel machines, Gaussian process regression, Machine learning, Welding, Residual stresses, Support vector regression},
abstract = {Predictive monitoring supports the a priori scheduling of critical component maintenance and contributes significantly in attaining a safe yet economic operation and management of complex energy systems by mitigating the risk of accidents and minimizing the number of operational pauses. The current work studies the learning ability of probabilistic kernel machines, and more particularly of Gaussian Processes (GP) equipped with various kernels for the estimation of weld residual stress profiles of stainless steel pipe welds. The GP models are tested on experimentally-obtained data of axial and hoop residual stresses in two different stainless-steel pipes. The results exhibit the ability of GP to accurately predict the weld residual stress profile in the axial and hoop direction by providing a predictive distribution, i.e., mean and variance values. Furthermore, performance of GP is compared to a non-probabilistic kernel machine, such as support vector regression (SVR) equipped with the same kernels, and to multivariate linear regression (MLR). Comparison results exhibit the robustness of GP over SVR and MLR with respect to prediction accuracy of weld residual stress in terms of root mean square error. With respect to a second metric, namely, correlation coefficient between measured and predicted values, GP is superior to SVR and MLR in the majority of the cases.}
}
@article{LI2022444,
title = {A novel remaining useful life prediction method based on multi-support vector regression fusion and adaptive weight updating},
journal = {ISA Transactions},
volume = {131},
pages = {444-459},
year = {2022},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2022.04.042},
url = {https://www.sciencedirect.com/science/article/pii/S001905782200204X},
author = {Yuxiong Li and Xianzhen Huang and Chengying Zhao and Pengfei Ding},
keywords = {Remaining useful life, Small sample cases, Support vector machine, Parameters optimization, Bayesian optimization algorithm, Adaptive updated weight},
abstract = {Remaining useful life prediction is of huge significance in preventing equipment malfunctions and reducing maintenance costs. Currently, machine learning algorithms have become hotspots in remaining useful life prediction due to their high flexibility and convenience. However, machine learnings require large amounts of data, and their prediction performance depends heavily on the selection of hyper-parameters. To overcome these shortcomings, a novel remaining useful life prediction method for small sample cases is proposed based on multi-support vector regression fusion. In the offline training phase, the fusion model is established, consisting of multiple support vector regression sub-models To obtain the optimal sub-model parameters, the Bayesian optimization algorithm is applied and an improved optimization target is formulated with various metrics describing regression and prediction performance. In the online prediction phase, an adaptive weight updating algorithm based on dynamic time warping is developed to measure the fitness of each sub-model and determine the corresponding weight value. The C-MAPSS engine dataset is used to test the performance of the proposed method, along with some existing machine learning methods as comparison. The proposed method only requires 30% of the training data sample to achieve high accuracy, with a root mean square error of 14.98, which is superior to other state-of-the-art methods. The results demonstrate the superiority of the proposed method.}
}
@article{LI2023114480,
title = {Construction and application of numerical diagram for high-skew propeller based on machine learning},
journal = {Ocean Engineering},
volume = {278},
pages = {114480},
year = {2023},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2023.114480},
url = {https://www.sciencedirect.com/science/article/pii/S0029801823008648},
author = {Liang Li and Yihong Chen and Yiming Qiang and Bin Zhou and Weizheng Chen},
keywords = {High-skew propeller, Numerical diagram, Machine learning, CFD method, Propeller design},
abstract = {The field of machine learning has experienced rapid growth, and it has introduced a new methodology for constructing propeller diagrams. To meet the high demand for designing high-skew propellers, a series of high-skew propeller schemes are generated, utilizing the INSEAN E1619 as the parent propeller. The Computational Fluid Dynamics (CFD) method was validated using the E1619 test results and was subsequently employed to perform virtual open water tests for all the series schemes. This effort produced 819 open water performance data of 42 propellers. The study trained and validated the traditional multivariate polynomial regression model and five conventional machine learning regression models based on the CFD calculation data. The analysis of the model prediction accuracy indicated that the Support Vector Machine (SVM) model had the least error among them for the digital expression of diagram hydrodynamic data. The prediction error of KT, KQ, and η decreased by over 20% compared to the LM model. The study subsequently developed a high-skew propeller diagram design program using the SVM regression model and applied it to a specific underwater vehicle's propeller design. The design results demonstrated that, compared to the B-series propeller, the design scheme provided by this numerical diagram had a comparable efficiency and a 6% smaller optimum diameter under unlimited diameter and a 7% higher efficiency under limited diameter for this case. Consequently, the developed numerical diagram in this paper provides a new tool for the propulsion performance evaluation and parameter selection of the propulsion system in the preliminary design stage for the high-skew propeller.}
}
@article{AHN2014195,
title = {The attribute impact concept: Applications in case-based reasoning and parametric cost estimation},
journal = {Automation in Construction},
volume = {43},
pages = {195-203},
year = {2014},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2014.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0926580514000636},
author = {Joseph Ahn and Sae-Hyun Ji and Moonseo Park and Hyun-Soo Lee and Sooyoung Kim and Sang-Wook Suh},
keywords = {Cost, Estimation, Attribute, Weight, Case-based reasoning, Regression analysis},
abstract = {The success of every construction project depends on the satisfactory achievement of a client's needs relating to cost, duration, and quality. Among them, costs must be managed with special awareness. In an effort to improve the estimate accuracy of cost during the initial stages of a building project, this research introduces the concept of ‘attribute impact’ (AI), which can measure the weights of attributes quantitatively and prioritize them. This study will also explain AI development, which adopts the impulse–momentum theorem of physics. For a case study, the project analyzes 163 public apartment buildings from 15 housing complex projects in Korea. To examine the validity of the proposed AI, the case study carries out two types of validation in terms of estimate accuracy using the parametric method and the case-based reasoning (CBR) applicability test. The validation results support the acceptable use of the suggested AI in measuring the weights of attributes and its estimate accuracy when combined with parametric or CBR estimation.}
}
@article{WU2022114699,
title = {Modelling of masonry infills in existing steel moment-resisting frames: Nonlinear force-displacement relationship},
journal = {Engineering Structures},
volume = {267},
pages = {114699},
year = {2022},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2022.114699},
url = {https://www.sciencedirect.com/science/article/pii/S014102962200791X},
author = {Jing-Ren Wu and Luigi {Di Sarno} and Fabio Freddi and Mario D'Aniello},
keywords = {Moment Resisting Frames, Steel Structures, Masonry Infills, Equivalent strut models, Genetic Algorithm},
abstract = {The study described and summarised in this paper was aimed at developing a framework for the definition of force-displacement relationships for single-strut models for masonry infill walls within steel moment-resisting frames. The methodology is based on a genetic algorithm optimisation and can be used for the calibration of force–displacement curves based on databases from either experiments or numerical simulation. A case study is also tested to demonstrate the framework in detail. Due to limited available experimental data on the seismic response of existing steel frames with masonry infills, a set of comprehensive finite element micro-models developed in Abaqus are used to generate a database. The optimal values of the parameters to feed a force–displacement relationship of the single-strut model of the masonry infills are obtained for each micro-model by solving optimisation problems with a genetic algorithm. The optimisation problem involves the minimisation of the discrepancies between the global responses from the database and their corresponding single-strut models through least square minimisation. With the optimal values as the input variables, a generalised quadrilinear model of the masonry strut is obtained through regression analysis and is validated against additional micro-models of infilled steel frames.}
}
@article{TSIRIKOGLOU2017139,
title = {A hyperparameters selection technique for support vector regression models},
journal = {Applied Soft Computing},
volume = {61},
pages = {139-148},
year = {2017},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2017.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S1568494617304283},
author = {P. Tsirikoglou and S. Abraham and F. Contino and C. Lacor and G. Ghorbaniasl},
keywords = {Hyperparameters optimization, Support vector regression, Evolutionary algorithms},
abstract = {Support vector regression models are powerful surrogates used in various fields of engineering. Due to the quality of their predictions and their efficiency, those models are considered as a suitable tool for surrogate evaluation. Despite their advantages, support vector regression models require an accurate selection of the configuration parameters in order to achieve good generalization performance. To overcome this limitation, a new hyperparameter selection method is developed. This method takes into account the training error to identify the optimal parameters set using evolutionary optimization schemes. Moreover, building on state-of-the-art techniques, an alternative analytically-assisted genetic algorithm is proposed in order to enhance the accuracy and robustness of the optimization scheme. The configuration is elaborated from a new search strategy in the design space. The results verify that the proposed technique improve the prediction accuracy and its robustness. Several test cases are used to demonstrate the capabilities of the method and its application potential to real engineering problems. The results prove that a surrogate model coupled with this adaptive configuration technique provides a useful prediction model suitable for various types of numerical experiments.}
}
@incollection{DONG2024107,
title = {Chapter 4 - Regression},
editor = {Qiao Dong and Xueqin Chen and Baoshan Huang},
booktitle = {Data Analysis in Pavement Engineering},
publisher = {Elsevier},
pages = {107-140},
year = {2024},
series = {Woodhead Publishing Series in Civil and Structural Engineering},
isbn = {978-0-443-15928-2},
doi = {https://doi.org/10.1016/B978-0-443-15928-2.00018-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443159282000185},
author = {Qiao Dong and Xueqin Chen and Baoshan Huang},
keywords = {Simple linear regression, Multiple linear regressions, Ordinary least squares, Maximum likelihood estimation, -test, -test, Residual diagnostic, Stepwise regression, Polynomial regression, Nonlinear regression},
abstract = {This chapter introduces regression, which is a widely used data analysis method in pavement engineering. It starts with a literature review on the applications of different regression methods in pavement data analysis. Then it introduces the definitions, parameter estimates, and significance tests of simple and multiple linear regression. Two significance tests are introduced. The F-test is used to test the significance of the model, while the t-test is used to test the significance of a variable. The model assumptions, residual diagnostic, multicollinearity, and Box-Cox transformations are discussed. The procedures and variable selections for stepwise regression, polynomial regression, and nonlinear regression are introduced. Finally, three cases on pavement maintenance effectiveness evaluation and performance prediction using multiple linear regression and nonlinear regression are presented.}
}
@article{LIU2023106486,
title = {Feature selection combined with top-down and bottom-up strategies for survival analysis: A case of prognostic prediction in glioblastoma},
journal = {Computers in Biology and Medicine},
volume = {153},
pages = {106486},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106486},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522011945},
author = {Yanan Liu and Xudong Zhao and Jilong Bian and Guohua Wang},
keywords = {Feature selection, Expression profiles, Survival analysis, Glioblastoma},
abstract = {Over the last decades, molecular signatures have attracted extensive attention in cancer research. However, most of the reported biomarkers show a weak distinguishing ability in predicting the survival risks of patients. Actually, univariate analysis is generally considered in regression analysis, which makes the existing statistical methods ineffective. Furthermore, there is too much human involvement in the ways of classifying patients with high and low risk. Last but not least, the participation of therapy after conservative surgery also makes the survival analysis more complex. In order to solve these problems, we propose a solid method of feature selection which combines top-down and bottom-up strategies. The top-down strategy is to randomly extract some genes each time and select candidate genes through cumulative voting. The bottom-up strategy is to fully enumerate the selected genes and to use a clustering algorithm to classify samples. We analyzed glioblastoma data from the Cancer Genome Atlas (TCGA) and got candidate signatures. The results of simulation data, as well as an independent test set the Chinese Glioma Genome Atlas (CGGA), verified the reliability of the method and validity of the selected features.}
}
@article{TABAIE2024,
title = {Evaluation of a Natural Language Processing Approach to Identify Diagnostic Errors and Analysis of Safety Learning System Case Review Data: Retrospective Cohort Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/50935},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005193},
author = {Azade Tabaie and Alberta Tran and Tony Calabria and Sonita S Bennett and Arianna Milicia and William Weintraub and William James Gallagher and John Yosaitis and Laura C Schubel and Mary A Hill and Kelly Michelle Smith and Kristen Miller},
keywords = {diagnostic error, electronic health records, machine learning, natural language processing, NLP, mortality, hospital, risk, length of stay, patient harm, diagnostic, EHR},
abstract = {Background
Diagnostic errors are an underappreciated cause of preventable mortality in hospitals and pose a risk for severe patient harm and increase hospital length of stay.
Objective
This study aims to explore the potential of machine learning and natural language processing techniques in improving diagnostic safety surveillance. We conducted a rigorous evaluation of the feasibility and potential to use electronic health records clinical notes and existing case review data.
Methods
Safety Learning System case review data from 1 large health system composed of 10 hospitals in the mid-Atlantic region of the United States from February 2016 to September 2021 were analyzed. The case review outcome included opportunities for improvement including diagnostic opportunities for improvement. To supplement case review data, electronic health record clinical notes were extracted and analyzed. A simple logistic regression model along with 3 forms of logistic regression models (ie, Least Absolute Shrinkage and Selection Operator, Ridge, and Elastic Net) with regularization functions was trained on this data to compare classification performances in classifying patients who experienced diagnostic errors during hospitalization. Further, statistical tests were conducted to find significant differences between female and male patients who experienced diagnostic errors.
Results
In total, 126 (7.4%) patients (of 1704) had been identified by case reviewers as having experienced at least 1 diagnostic error. Patients who had experienced diagnostic error were grouped by sex: 59 (7.1%) of the 830 women and 67 (7.7%) of the 874 men. Among the patients who experienced a diagnostic error, female patients were older (median 72, IQR 66-80 vs median 67, IQR 57-76; P=.02), had higher rates of being admitted through general or internal medicine (69.5% vs 47.8%; P=.01), lower rates of cardiovascular-related admitted diagnosis (11.9% vs 28.4%; P=.02), and lower rates of being admitted through neurology department (2.3% vs 13.4%; P=.04). The Ridge model achieved the highest area under the receiver operating characteristic curve (0.885), specificity (0.797), positive predictive value (PPV; 0.24), and F1-score (0.369) in classifying patients who were at higher risk of diagnostic errors among hospitalized patients.
Conclusions
Our findings demonstrate that natural language processing can be a potential solution to more effectively identifying and selecting potential diagnostic error cases for review and therefore reducing the case review burden.}
}
@article{ARAUJO2018515,
title = {Polynomial regression with reduced over-fitting—The PALS technique},
journal = {Measurement},
volume = {124},
pages = {515-521},
year = {2018},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2018.04.045},
url = {https://www.sciencedirect.com/science/article/pii/S0263224118303208},
author = {António Araújo},
keywords = {Data fitting, Over-fitting, Polynomial, Least-squares, Linear regression},
abstract = {In order to reduce over-fitting, a new polynomial least-squares technique, named polynomial area least-squares (PALS), was developed. The technique is based on the minimization of the sum of the squared areas defined between the polynomial fitting function and the line segments connecting every two consecutive data points. A relatively simple system of linear equations was developed to compute the free parameters of the polynomial using the available training data. The ability of the PALS technique to generalize was evaluated through the generation of test data and statistical simulations. The PALS technique produces polynomials with reduced over-fitting, with little dependency on the order of the polynomial, especially when the polynomial order is high, so that, in some cases, increasing the order of the polynomial may even contribute to further over-fitting reduction. The major advantage of PALS is that it does not depend on any case-dependent parameter necessary for the data fitting procedure; the major limitation is that it can only be applied to polynomial regression with a single independent variable.}
}