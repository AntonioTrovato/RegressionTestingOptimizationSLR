@INPROCEEDINGS{10148705,
  author={Corò, Federico and Verdecchia, Roberto and Cruciani, Emilio and Miranda, Breno and Bertolino, Antonia},
  booktitle={2020 IEEE/ACM 17th International Conference on Mining Software Repositories (MSR)}, 
  title={JTeC: A Large Collection of Java Test Classes for Test Code Analysis and Processing}, 
  year={2020},
  volume={},
  number={},
  pages={578-582},
  abstract={The recent push towards test automation and test-driven development continues to scale up the dimensions of test code that needs to be maintained, analysed, and processed side-by-side with pro-duction code. As a consequence, on the one side regression testing techniques, e.g., for test suite prioritization or test case selection, capable to handle such large-scale test suites become indispensable; on the other side, as test code exposes own characteristics, specific techniques for its analysis and refactoring are actively sought. We present JTeC, a large-scale dataset of test cases that researchers can use for benchmarking the above techniques or any other type of tool expressly targeting test code. JTeC collects more than 2.5M test classes belonging to 31K + GitHub projects and summing up to more than 430 Million SLOCs of ready-to-use real-world test code.},
  keywords={Java;Codes;Automation;Benchmark testing;Software;Data mining;Software development management;GitHub;Java;Large Scale;Software Testing;Test Suite},
  doi={10.1145/3379597.3387484},
  ISSN={2574-3864},
  month={May},}@INPROCEEDINGS{8754416,
  author={Torres, Wesley N. M. and Alves, Everton L. G. and Machado, Patrícia D. L.},
  booktitle={2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={An Empirical Study on the Spreading of Fault Revealing Test Cases in Prioritized Suites}, 
  year={2019},
  volume={1},
  number={},
  pages={129-138},
  abstract={Code edits are very common during software development. Specially for agile development, these edits need constant validation to avoid functionality regression. In this context, regression test suites are often used. However, regression testing can be very costly. Test case prioritization (TCP) techniques try to reduce this burden by reordering the tests of a given suite aiming at fastening the achievement of a certain testing goal. The literature presents a great number of TCP techniques. Most of the work related to prioritization evaluate the performance of TCP techniques by calculating the rate of test cases that fail per fault (the APFD metric). However, other aspects should be considered when evaluating prioritization results. For instance, the ability to reduce the spreading of failing test cases, since a better grouping often provides more information regarding faults. This paper presents an empirical investigation for evaluating the performance of a set of prioritization techniques comparing APFD and spreading results. Our results show that prioritization techniques generate different APFD and spreading results, being total-statement prioritization the one with the lowest spreading.},
  keywords={Measurement;Fault detection;Software;Testing;Mathematical model;Guidelines;Conferences;prioritization;test case;metric;evaluation},
  doi={10.1109/COMPSAC.2019.00027},
  ISSN={0730-3157},
  month={Jul},}@INPROCEEDINGS{7582788,
  author={Guo, Shengjian and Kusano, Markus and Wang, Chao},
  booktitle={2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Conc-iSE: Incremental symbolic execution of concurrent software}, 
  year={2016},
  volume={},
  number={},
  pages={531-542},
  abstract={Software updates often introduce new bugs to existing code bases. Prior regression testing tools focus mainly on test case selection and prioritization whereas symbolic execution tools only handle code changes in sequential software. In this paper, we propose the first incremental symbolic execution method for concurrent software to generate new tests by exploring only the executions affected by code changes between two program versions. Specifically, we develop an inter-thread and inter-procedural change-impact analysis to check if a statement is affected by the changes and then leverage the information to choose executions that need to be re-explored. We also check if execution summaries computed in the previous program can be used to avoid redundant explorations in the new program. We have implemented our method in an incremental symbolic execution tool called Conc-iSE and evaluated it on a large set of multithreaded C programs. Our experiments show that the new method can significantly reduce the overall symbolic execution time when compared with state-of-the-art symbolic execution tools such as KLEE.},
  keywords={Software;Testing;Concurrent computing;Algorithm design and analysis;Software algorithms;Computer bugs;Programming;Symbolic execution;Concurrency;Partial order reduction;Weakest precondition},
  doi={},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{6571593,
  author={},
  booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation Workshops}, 
  title={[Front-cover]}, 
  year={2013},
  volume={},
  number={},
  pages={C4-C4},
  abstract={The following topics are dealt with: software testing; software verification; software validation; engineering safety system; security system; mutation analysis; test case selection; software refactorings; software defect localization; software reachability; software maintainability; data processing; service-oriented architecture; Web services; combinatorial testing; UML; regression testing; and security testing.},
  keywords={},
  doi={10.1109/ICSTW.2013.1},
  ISSN={},
  month={March},}
