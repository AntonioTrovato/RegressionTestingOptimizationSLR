@article{CHEN2024,
title = {Trial Factors Associated With Completion of Clinical Trials Evaluating AI: Retrospective Case-Control Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/58578},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005880},
author = {David Chen and Christian Cao and Robert Kloosterman and Rod Parsa and Srinivas Raman},
keywords = {artificial intelligence, clinical trial, completion, AI, cross-sectional study, application, intervention, trial design, logistic regression, Europe, clinical, trials testing, health care, informatics, health information},
abstract = {Background
Evaluation of artificial intelligence (AI) tools in clinical trials remains the gold standard for translation into clinical settings. However, design factors associated with successful trial completion and the common reasons for trial failure are unknown.
Objective
This study aims to compare trial design factors of complete and incomplete clinical trials testing AI tools. We conducted a case-control study of complete (n=485) and incomplete (n=51) clinical trials that evaluated AI as an intervention of ClinicalTrials.gov.
Methods
Trial design factors, including area of clinical application, intended use population, and intended role of AI, were extracted. Trials that did not evaluate AI as an intervention and active trials were excluded. The assessed trial design factors related to AI interventions included the domain of clinical application related to organ systems; intended use population for patients or health care providers; and the role of AI for different applications in patient-facing clinical workflows, such as diagnosis, screening, and treatment. In addition, we also assessed general trial design factors including study type, allocation, intervention model, masking, age, sex, funder, continent, length of time, sample size, number of enrollment sites, and study start year. The main outcome was the completion of the clinical trial. Odds ratio (OR) and 95% CI values were calculated for all trial design factors using propensity-matched, multivariable logistic regression.
Results
We queried ClinicalTrials.gov on December 23, 2023, using AI keywords to identify complete and incomplete trials testing AI technologies as a primary intervention, yielding 485 complete and 51 incomplete trials for inclusion in this study. Our nested propensity-matched, case-control results suggest that trials conducted in Europe were significantly associated with trial completion when compared with North American trials (OR 2.85, 95% CI 1.14-7.10; P=.03), and the trial sample size was positively associated with trial completion (OR 1.00, 95% CI 1.00-1.00; P=.02).
Conclusions
Our case-control study is one of the first to identify trial design factors associated with completion of AI trials and catalog study-reported reasons for AI trial failure. We observed that trial design factors positively associated with trial completion include trials conducted in Europe and sample size. Given the promising clinical use of AI tools in health care, our results suggest that future translational research should prioritize addressing the design factors of AI clinical trials associated with trial incompletion and common reasons for study failure.}
}
@article{MUKHERJEE20211041,
title = {A survey on different approaches for software test case prioritization},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {33},
number = {9},
pages = {1041-1054},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1319157818303616},
author = {Rajendrani Mukherjee and K. Sridhar Patnaik},
keywords = {Regression, Prioritization, Techniques, Program, Fault, Coverage},
abstract = {Testing is the process of evaluating a system by manual or automated means. While Regression Test Selection (RTS) discards test cases and Test Suite Minimization (TSM) shows diminution in fault detection rate, Test Case Prioritization (TCP) does not discard test cases. Test Case Prioritization techniques can be coverage or historical information based or model based. It can also be cost-time aware or requirement-risk aware. GUI/Web applications need special prioritization mechanism. In this paper, 90 scholarly articles ranging from 2001 to 2018 have been reviewed. We have explored IEEE, Wiley, ACM Library, Springer, Taylor & Francis and Elsevier database. We have also described each prioritization method with their findings and subject programs. This paper includes a chronological catalogue listing of the reviewed papers. We have framed three research questions which sum up the frequently used prioritization metrics, regularly used subject programs and the distribution of different prioritization techniques. To the best of our knowledge, this is the first review with a detail report of the last 18 years of TCP techniques. We hope this article will be beneficial for both beginners and seasoned professionals.}
}
@article{SCHWARTZ201661,
title = {Cost-effective regression testing through Adaptive Test Prioritization strategies},
journal = {Journal of Systems and Software},
volume = {115},
pages = {61-81},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216000169},
author = {Amanda Schwartz and Hyunsook Do},
keywords = {Regression testing, Adaptive regression testing strategy, Test case prioritization},
abstract = {Regression testing is an important part of the software development life cycle. It is also very expensive. Many different techniques have been proposed for reducing the cost of regression testing. However, research has shown that the effectiveness of different techniques varies under different testing environments and software change characteristics. In prior work, we developed strategies to investigate ways of choosing the most cost-effective regression testing technique for a particular regression testing session. In this work, we empirically study the existing strategies presented in prior work as well as develop two additional Adaptive Test Prioritization (ATP) strategies using fuzzy analytical hierarchy process (AHP) and the weighted sum model (WSM). We also provide a comparative study examining each of the ATP strategies presented to date. This research will provide researchers and practitioners with strategies to utilize in regression testing plans as well as provide data to use when deciding which of the strategies would best fit their testing needs. The empirical studies provided in this research show that utilizing these strategies can improve the cost-effectiveness of regression testing.}
}
@article{CAMPI2025108574,
title = {Machine learning-based forecast of Helmet-CPAP therapy failure in Acute Respiratory Distress Syndrome patients},
journal = {Computer Methods and Programs in Biomedicine},
volume = {260},
pages = {108574},
year = {2025},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108574},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724005674},
author = {Riccardo Campi and Antonio {De Santis} and Paolo Colombo and Paolo Scarpazza and Marco Masseroli},
keywords = {Acute Respiratory Distress Syndrome, Helmet-Continuous Positive Airway Pressure, Predicting H-CPAP failure in ARDS patients, Machine Learning, COVID-19},
abstract = {Background and Objective:
Helmet-Continuous Positive Airway Pressure (H-CPAP) is a non-invasive respiratory support that is used for the treatment of Acute Respiratory Distress Syndrome (ARDS), a severe medical condition diagnosed when symptoms like profound hypoxemia, pulmonary opacities on radiography, or unexplained respiratory failure are present. It can be classified as mild, moderate or severe. H-CPAP therapy is recommended as the initial treatment approach for mild ARDS. Even though the efficacy of H-CPAP in managing patients with moderate-to-severe hypoxemia remains unclear, its use has increased for these cases in response to the emergence of the COVID-19 Pandemic. Using the electronic medical records (EMR) from the Pulmonology Department of Vimercate Hospital, in this study we develop and evaluate a Machine Learning (ML) system able to predict the failure of H-CPAP therapy on ARDS patients.
Methods:
The Vimercate Hospital EMR provides demographic information, blood tests, and vital parameters of all hospitalizations of patients who are treated with H-CPAP and diagnosed with ARDS. This data is used to create a dataset of 622 records and 38 features, with 70%–30% split between training and test sets. Different ML models such as SVM, XGBoost, Neural Network, Random Forest, and Logistic Regression are iteratively trained in a cross-validation fashion. We also apply a feature selection algorithm to improve predictions quality and reduce the number of features.
Results and Conclusions:
The SVM and Neural Network models proved to be the most effective, achieving final accuracies of 95.19% and 94.65%, respectively. In terms of F1-score, the models scored 88.61% and 87.18%, respectively. Additionally, the SVM and XGBoost models performed well with a reduced number of features (23 and 13, respectively). The PaO2/FiO2 Ratio, C-Reactive Protein, and O2 Saturation resulted as the most important features, followed by Heartbeats, White Blood Cells, and D-Dimer, in accordance with the clinical scientific literature.}
}
@article{PRADHAN201986,
title = {Employing rule mining and multi-objective search for dynamic test case prioritization},
journal = {Journal of Systems and Software},
volume = {153},
pages = {86-104},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.03.064},
url = {https://www.sciencedirect.com/science/article/pii/S016412121930072X},
author = {Dipesh Pradhan and Shuai Wang and Shaukat Ali and Tao Yue and Marius Liaaen},
keywords = {Multi-objective optimization, Rule mining, Dynamic test case prioritization, Search, Black-box regression testing},
abstract = {Test case prioritization (TP) is widely used in regression testing for optimal reordering of test cases to achieve specific criteria (e.g., higher fault detection capability) as early as possible. In our earlier work, we proposed an approach for black-box dynamic TP using rule mining and multi-objective search (named as REMAP) by defining two objectives (fault detection capability and test case reliance score) and considering test case execution results at runtime. In this paper, we conduct an extensive empirical evaluation of REMAP by employing three different rule mining algorithms and three different multi-objective search algorithms, and we also evaluate REMAP with one additional objective (estimated execution time) for a total of 18 different configurations (i.e., 3 rule mining algorithms ×  3 search algorithms ×  2 different set of objectives) of REMAP. Specifically, we empirically evaluated the 18 variants of REMAP with 1) two variants of random search while using two objectives and three objectives, 2) three variants of greedy algorithm based on one objective, two objectives, and three objectives, 3) 18 variants of static search-based prioritization approaches, and 4) six variants of rule-based prioritization approaches using two industrial and three open source case studies. Results showed that the two best variants of REMAP with two objectives and three objectives significantly outperformed the best variants of competing approaches by 84.4% and 88.9%, and managed to achieve on average 14.2% and 18.8% higher Average Percentage of Faults Detected per Cost (APFDc) scores.}
}
@article{CHEN2018107,
title = {Test case prioritization for object-oriented software: An adaptive random sequence approach based on clustering},
journal = {Journal of Systems and Software},
volume = {135},
pages = {107-125},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2017.09.031},
url = {https://www.sciencedirect.com/science/article/pii/S0164121217302170},
author = {Jinfu Chen and Lili Zhu and Tsong Yueh Chen and Dave Towey and Fei-Ching Kuo and Rubing Huang and Yuchi Guo},
keywords = {Object-oriented software, Adaptive random sequence, Test cases prioritization, Cluster analysis, Test cases selection},
abstract = {Test case prioritization (TCP) attempts to improve fault detection effectiveness by scheduling the important test cases to be executed earlier, where the importance is determined by some criteria or strategies. Adaptive random sequences (ARSs) can be used to improve the effectiveness of TCP based on white-box information (such as code coverage information) or black-box information (such as test input information). To improve the testing effectiveness for object-oriented software in regression testing, in this paper, we present an ARS approach based on clustering techniques using black-box information. We use two clustering methods: (1) clustering test cases according to the number of objects and methods, using the K-means and K-medoids clustering algorithms; and (2) clustered based on an object and method invocation sequence similarity metric using the K-medoids clustering algorithm. Our approach can construct ARSs that attempt to make their neighboring test cases as diverse as possible. Experimental studies were also conducted to verify the proposed approach, with the results showing both enhanced probability of earlier fault detection, and higher effectiveness than random prioritization and method coverage TCP technique.}
}
@article{KIM201888,
title = {Association networks in a matched case-control design – Co-occurrence patterns of preexisting chronic medical conditions in patients with major depression versus their matched controls},
journal = {Journal of Biomedical Informatics},
volume = {87},
pages = {88-95},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2018.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S1532046418301941},
author = {Min-hyung Kim and Samprit Banerjee and Yize Zhao and Fei Wang and Yiye Zhang and Yongjun Zhu and Joseph DeFerio and Lauren Evans and Sang Min Park and Jyotishman Pathak},
keywords = {Matched pair analysis, Network analysis, Interaction analysis, Chronic medical conditions, Major depressive disorder},
abstract = {Objective
We present a method for comparing association networks in a matched case-control design, which provides a high-level comparison of co-occurrence patterns of features after adjusting for confounding factors. We demonstrate this approach by examining the differential distribution of chronic medical conditions in patients with major depressive disorder (MDD) compared to the distribution of these conditions in their matched controls.
Materials and methods
Newly diagnosed MDD patients were matched to controls based on their demographic characteristics, socioeconomic status, place of residence, and healthcare service utilization in the Korean National Health Insurance Service’s National Sample Cohort. Differences in the networks of chronic medical conditions in newly diagnosed MDD cases treated with antidepressants, and their matched controls, were prioritized with a permutation test accounting for the false discovery rate. Sensitivity analyses for the associations between prioritized pairs of chronic medical conditions and new MDD diagnosis were performed with regression modeling.
Results
By comparing the association networks of chronic medical conditions in newly diagnosed depression patients and their matched controls, five pairs of such conditions were prioritized among 105 possible pairs after controlling the false discovery rate at 5%. In sensitivity analyses using regression modeling, four out of the five prioritized pairs were statistically significant for the interaction terms.
Conclusion
Association networks in a matched case-control design can provide a high-level comparison of comorbid features after adjusting for confounding factors, thereby supplementing traditional clinical study approaches. We demonstrate the differential co-occurrence pattern of chronic medical conditions in patients with MDD and prioritize the chronic conditions that have statistically significant interactions in regression models for depression.}
}
@article{URRACA20189,
title = {Evaluation of a novel GA-based methodology for model structure selection: The GA-PARSIMONY},
journal = {Neurocomputing},
volume = {271},
pages = {9-17},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.08.154},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217312171},
author = {R. Urraca and E. Sodupe-Ortega and J. Antonanzas and F. Antonanzas-Torres and F.J. Martinez-de-Pison},
keywords = {Genetic algorithms, Parameter tuning, Feature selection, Parsimony criterion, Model comparative},
abstract = {Most proposed metaheuristics for feature selection and model parameter optimization are based on a two-termed Loss+Penalty function. Their main drawback is the need of a manual set of the parameter that balances between the loss and the penalty term. In this paper, a novel methodology referred as the GA-PARSIMONY and specifically designed to overcome this issue is evaluated in detail in thirteen public databases with five regression techniques. It is a GA-based meta-heuristic that splits the classic two-termed minimization functions by making two consecutive ranks of individuals. The first rank is based solely on the generalization error, while the second (named ReRank) is based on the complexity of the models, giving a special weight to the complexity entailed by large number of inputs. For each database, models with lowest testing RMSE and without statistical difference among them were referred as winner models. Within this group, the number of features selected was below 50%, which proves an optimal balance between error minimization and parsimony. Particularly, the most complex algorithms (MLP and SVR) were mostly selected in the group of winner models, while using around40–45% of the available attributes. The most basic IBk, ridge regression (LIN) and M5P were only classified as winner models in the simpler databases, but using less number of features in those cases (up to a 20–25% of the initial inputs).}
}
@article{CUI2024102083,
title = {A label learning approach using competitive population optimization algorithm feature selection to improve multi-label classification algorithms},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {5},
pages = {102083},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102083},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824001721},
author = {Lianhe Cui},
keywords = {Competitive swarm optimizer, Feature selection, Multi-label data, Reconstruction error, Sparse representation},
abstract = {One of the crucial pre-processing stages in data mining and machine learning is feature selection, which is used to choose a subset of representative characteristics and decrease dimensions. By eliminating unnecessary and redundant features, feature selection can improve machine learning tasks’ accuracy. This work presents a novel multi-label classification (MLC) model utilizing a combination of stack regression (RR) and original label space transformation (IPLST) called RR-IPLST (original label space transformation-ridge regression). A novel embedded technique is implemented, utilizing competitive crowding optimizer (CSO) for multi-label feature selection. Particles are first created using this procedure, after which they are split into two equal groups and compete in pairs. The winners advance to the next iteration, while the losers pick up tips from the victors. At the conclusion of each iteration, the objective function for every particle is determined. A local search technique inspired by the gradient descent algorithm is used to find the local structure of the data, and half of the initial population is produced by the similarity between features and labels in order to boost the convergence rate. Ultimately, feature selection is carried out depending on the best particle. Six popular and sophisticated multi-label feature selection techniques are evaluated to see how well the suggested approach performs. According to the simulation results, the application of the suggested solution performs better than comparable techniques in terms of stability, accuracy, precision, convergence, error measurement, and other criteria that have been examined on various data sets. In 93.35% of cases, the test results demonstrate superiority over traditional algorithms.}
}
@article{SANDOVALALCOCER2020102415,
title = {Prioritizing versions for performance regression testing: The Pharo case},
journal = {Science of Computer Programming},
volume = {191},
pages = {102415},
year = {2020},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2020.102415},
url = {https://www.sciencedirect.com/science/article/pii/S0167642320300265},
author = {Juan Pablo {Sandoval Alcocer} and Alexandre Bergel and Marco Tulio Valente},
keywords = {Performance regression, Software performance, Software evolution, Performance regression prediction, Regression benchmarking},
abstract = {Context
Software performance may suffer regressions caused by source code changes. Measuring performance at each new software version is useful for early detection of performance regressions. However, systematically running benchmarks is often impractical (e.g., long running execution, prioritizing functional correctness over non-functional).
Objective
In this article, we propose Horizontal Profiling, a sampling technique to predict when a new revision may cause a regression by analyzing the source code and using run-time information of a previous version. The goal of Horizontal Profiling is to reduce the performance testing overhead by benchmarking just software versions that contain costly source code changes.
Method
We present an evaluation in which we apply Horizontal Profiling to identify performance regressions of 17 software projects written in the Pharo programming language, totaling 1,288 software versions.
Results
Horizontal Profiling detects more than 80% of the regressions by benchmarking less than 20% of the versions. In addition, our experiments show that Horizontal Profiling has better precision and executes the benchmarks in less versions that the state of the art tools, under our benchmarks.
Conclusions
We conclude that by adequately characterizing the run-time information of a previous version, it is possible to determine if a new version is likely to introduce a performance regression or not. As a consequence, a significant fraction of the performance regressions are identified by benchmarking only a small fraction of the software versions.}
}
@article{CAO2024105087,
title = {Transient temperature analysis and engineering application of steel shell immersed tunnel protected by fireproof board},
journal = {Case Studies in Thermal Engineering},
volume = {61},
pages = {105087},
year = {2024},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2024.105087},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X24011183},
author = {Peng Cao and Qingliang Wu and Enlong Liu and Huixian Wang},
keywords = {Fire, Steel-concrete-steel structure, Analytical solution, Thermal resistance, Fireproof board, Regression analysis},
abstract = {Based on the Shenzhen-Zhongshan Link, the transient analytical solution of the steel shell immersed tunnel under the protection of fireproof board was deduced and verified through fire test. Then, the variation of the maximum temperature of the bottom steel shell with the thickness and thermal conductivity of the fireproof board was analyzed and suggestions on the selection of fireproof boards were given. Finally, a fitting formula for the maximum temperature of bottom steel shell was proposed. The results show that: (1) When the thermal contact resistance of the steel-concrete interface and the thermal resistance of cavity are 0.01 m2 °C/W and 0.02 m2 °C/W respectively under the case of 25 mm thick fireproof board, the variation of the analytical solution is consistent with test results, and the peak value is similar. (2) Based on the three-dimensional diagram of d -λ-T, with 300 °C as the fire resistance limit of structure, the range of the fireproof board parameters is obtained: when λ reaches 0.14 and 0.4 respectively, d shall not be less than 10 mm and 28.38 mm (3) The scatter points obtained from analysis were fitted using quadratic polynomials and linear functions respectively. Considering the accuracy and simplicity, the linear fitting formula is given as T = 275.66–7.41*d+644.6*λ.}
}
@article{HU2025102919,
title = {A learning-guided hybrid genetic algorithm and multi-neighborhood search for the integrated process planning and scheduling problem with reconfigurable manufacturing cells},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {93},
pages = {102919},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102919},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524002060},
author = {Yiwen Hu and Hongliang Dong and Jianhua Liu and Cunbo Zhuang and Feng Zhang},
keywords = {Integrated process planning and scheduling, Reconfigurable manufacturing cells, Hybrid algorithm, Neighborhood structure, Learning-guided mechanism},
abstract = {Integrated process planning and scheduling (IPPS) is a crucial component of an intelligent manufacturing system. While most existing studies have focused on the manufacturing workshop, less attention has been given to the assembly and test workshops, which typically include reconfigurable manufacturing cells (RMCs). Therefore, this paper focuses on IPPS with reconfigurable manufacturing cells (IPPS_RMCs) in the context of assembly and test workshops. The objective of IPPS_RMCs is to minimize the makespan and total weighted tardiness, taking into account priority constraints and capability conversion limits of RMCs. To address and optimize this problem, a learning-guided hybrid genetic algorithm (LG_HGA) is proposed, which utilizes chromosome encoding to solve the process planning and scheduling problem synchronously. The LG_HGA incorporates NSGA-II as the global search and employs a learning-guided multi-neighborhood search (LG_MNS) to achieve a better balance between exploration and exploitation. In the global search phase, a problem-based methodology for gene operation is introduced. The LG_MNS consists of four neighborhood structures, based on critical paths and heuristic rules. Additionally, the learning-guided mechanism involves using a decision tree regression model to learn data from the knowledge base and determine how to perform local search. Through case tests of various sizes, the experimental results demonstrate that LG_HGA outperforms several advanced multi-objective evolutionary algorithms due to the proposed improved genetic operations, neighborhood structure, and learning mechanism.}
}
@article{AHMED20222211,
title = {Value-Based Test Case Prioritization for Regression Testing Using Genetic Algorithms},
journal = {Computers, Materials and Continua},
volume = {74},
number = {1},
pages = {2211-2238},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.032664},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822002466},
author = {Farrukh Shahzad Ahmed and Awais Majeed and Tamim Ahmed Khan},
keywords = {Average percentage of fault detection, test case prioritization, regression testing, and value-based testing, value-based test case prioritization, genetic algorithms},
abstract = {Test Case Prioritization (TCP) techniques perform better than other regression test optimization techniques including Test Suite Reduction (TSR) and Test Case Selection (TCS). Many TCP techniques are available, and their performance is usually measured through a metric Average Percentage of Fault Detection (APFD). This metric is value-neutral because it only works well when all test cases have the same cost, and all faults have the same severity. Using APFD for performance evaluation of test case orders where test cases cost or faults severity varies is prone to produce false results. Therefore, using the right metric for performance evaluation of TCP techniques is very important to get reliable and correct results. In this paper, two value-based TCP techniques have been introduced using Genetic Algorithm (GA) including Value-Cognizant Fault Detection-Based TCP (VCFDB-TCP) and Value-Cognizant Requirements Coverage-Based TCP (VCRCB-TCP). Two novel value-based performance evaluation metrics are also introduced for value-based TCP including Average Percentage of Fault Detection per value (APFDv) and Average Percentage of Requirements Coverage per value (APRCv). Two case studies are performed to validate proposed techniques and performance evaluation metrics. The proposed GA-based techniques outperformed the existing state-of-the-art TCP techniques including Original Order (OO), Reverse Order (REV-O), Random Order (RO), and Greedy algorithm.}
}
@article{SINGHAL20226755,
title = {Fault Coverage-Based Test Case Prioritization and Selection Using African Buffalo Optimization},
journal = {Computers, Materials and Continua},
volume = {74},
number = {3},
pages = {6755-6774},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.032308},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822002740},
author = {Shweta Singhal and Nishtha Jatana and Ahmad F Subahi and Charu Gupta and Osamah Ibrahim Khalaf and Youseef Alotaibi},
keywords = {Test case prioritization, regression testing, test case selection, African buffalo optimization, nature-inspired, meta-heuristic},
abstract = {Software needs modifications and requires revisions regularly. Owing to these revisions, retesting software becomes essential to ensure that the enhancements made, have not affected its bug-free functioning. The time and cost incurred in this process, need to be reduced by the method of test case selection and prioritization. It is observed that many nature-inspired techniques are applied in this area. African Buffalo Optimization is one such approach, applied to regression test selection and prioritization. In this paper, the proposed work explains and proves the applicability of the African Buffalo Optimization approach to test case selection and prioritization. The proposed algorithm converges in polynomial time (O(n2)). In this paper, the empirical evaluation of applying African Buffalo Optimization for test case prioritization is done on sample data set with multiple iterations. An astounding 62.5% drop in size and a 48.57% drop in the runtime of the original test suite were recorded. The obtained results are compared with Ant Colony Optimization. The comparative analysis indicates that African Buffalo Optimization and Ant Colony Optimization exhibit similar fault detection capabilities (80%), and a reduction in the overall execution time and size of the resultant test suite. The results and analysis, hence, advocate and encourages the use of African Buffalo Optimization in the area of test case selection and prioritization.}
}
@article{MAHDIEH2020106269,
title = {Incorporating fault-proneness estimations into coverage-based test case prioritization methods},
journal = {Information and Software Technology},
volume = {121},
pages = {106269},
year = {2020},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106269},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920300197},
author = {Mostafa Mahdieh and Seyed-Hassan Mirian-Hosseinabadi and Khashayar Etemadi and Ali Nosrati and Sajad Jalali},
keywords = {Regression testing, Test case prioritization, Defect prediction, Machine learning, Bug history},
abstract = {Context: During the development process of a software program, regression testing is used to ensure that the correct behavior of the software is retained after updates to the source code. This regression testing becomes costly over time as the number of test cases increases and it makes sense to prioritize test cases in order to execute fault-detecting test cases as soon as possible. There are many coverage-based test case prioritization (TCP) methods that only use the code coverage data to prioritize test cases. By incorporating the fault-proneness estimations of code units into the coverage-based TCP methods, we can improve such techniques. Objective: In this paper, we aim to propose an approach which improves coverage-based TCP methods by considering the fault-proneness distribution over code units. Further, we present the results of an empirical study that shows using our proposed approach significantly improves the additional strategy, which is a widely used coverage-based TCP method. Method: The approach presented in this study uses the bug history of the software in order to introduce a defect prediction method to learn a neural network model. This model is then used to estimate fault-proneness of each area of the source code and then the estimations are incorporated into coverage-based TCP methods. Our proposed approach is a general idea that can be applied to many coverage-based methods, such as the additional and total TCP methods. Results: The proposed methods are evaluated on datasets collected from the development history of five real-world projects including 357 versions in total. The experiments show that using an appropriate bug history can improve coverage-based TCP methods. Conclusion: The proposed approach can be applied to various coverage-based TCP methods and the experiments show that it can improve these methods by incorporating estimations of code units fault-proneness.}
}
@article{HAGHIGHATKHAH201880,
title = {Test prioritization in continuous integration environments},
journal = {Journal of Systems and Software},
volume = {146},
pages = {80-98},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.08.061},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301730},
author = {Alireza Haghighatkhah and Mika Mäntylä and Markku Oivo and Pasi Kuvaja},
keywords = {Test case prioritization, Regression testing, Continuous integration, Build history, Test diversity},
abstract = {Two heuristics namely diversity-based (DBTP) and history-based test prioritization (HBTP) have been separately proposed in the literature. Yet, their combination has not been widely studied in continuous integration (CI) environments. The objective of this study is to catch regression faults earlier, allowing developers to integrate and verify their changes more frequently and continuously. To achieve this, we investigated six open-source projects, each of which included several builds over a large time period. Findings indicate that previous failure knowledge seems to have strong predictive power in CI environments and can be used to effectively prioritize tests. HBTP does not necessarily need to have large data, and its effectiveness improves to a certain degree with larger history interval. DBTP can be used effectively during the early stages, when no historical data is available, and also combined with HBTP to improve its effectiveness. Among the investigated techniques, we found that history-based diversity using NCD Multiset is superior in terms of effectiveness but comes with relatively higher overhead in terms of method execution time. Test prioritization in CI environments can be effectively performed with negligible investment using previous failure knowledge, and its effectiveness can be further improved by considering dissimilarities among the tests.}
}
@article{PAN2024102472,
title = {A method for filling missing values in multivariate sequence bidirectional recurrent neural networks based on feature correlations},
journal = {Journal of Computational Science},
volume = {83},
pages = {102472},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102472},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324002655},
author = {Xiaoying Pan and Hao Wang and Mingzhu Lei and Tong Ju and Lin Bai},
keywords = {Multivariate time series, Missing data, Ensemble filling model, Two-way correlation, Variable correlation},
abstract = {Multivariate real-life time series data often contain missing values. These missing values often affect subsequent prediction tasks. Traditional imputation methods generally consider only some of the characteristics of multivariate time series data. This can easily lead to inaccurate filling results. In this paper, a feature correlation-based bidirectional recurrent network (BRNN-FR) is proposed to solve the problem of missing values in multivariate sequence data. First, this method involves the design of a bidirectional prediction network based on time intervals and the use of forward and reverse time series information between data points to obtain the characteristics of data changes with time to the greatest extent. Second, considering the correlation between features, a combined feature selection strategy based on the Pearson correlation coefficient and mutual information was proposed. A multiple regression model was established to predict between features. Finally, a bidirectional network ensemble filling algorithm based on the relationships between features is established to predict missing values. Comprehensive experiments on four public datasets show that the mean absolute error (MAE), root mean square error (RMSE) and maximum R2 value (R2_score) of the BRNN-FR algorithm in the direct imputation test are better than those of the other comparison methods in most cases. BRNN-FR also achieved a better area under the curve (AUC) in the indirect comparison experiment of two classifications of in-hospital death after filling the medical dataset. Using the AIR air quality dataset and the power transformer temperature dataset from the ETTH1 interpolation regression to predict the next 3 hours and 6 hours of average numerical results, most of the optimal regression results are obtained.}
}
@article{GAO2024113119,
title = {Dynamics optimization of small branch pipes in nuclear power plants based on machine learning algorithms},
journal = {Nuclear Engineering and Design},
volume = {422},
pages = {113119},
year = {2024},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2024.113119},
url = {https://www.sciencedirect.com/science/article/pii/S002954932400219X},
author = {Hongbo Gao and Shuai Zhou and Lei Lin and Zhilin Chen and Decheng Xu and Changning Li and XiaoFeng Zhu},
abstract = {Vibration fatigue failure of small branch pipes poses a great threat to the safe operation of nuclear power plants. However, the transient and wide-band vibration problems are not adequately considered in ASME and RCC-M code, resulting in repeated fatigue failures. In addition, the current research mainly focuses on vibration test methods and fatigue analysis methods, neglecting the study of pipeline vibration characteristics. Therefore, innovative approaches were essential for effectively managing complex dynamic loads. In this study, an innovative approach combining backpropagation artificial neural networks (BP-ANN) and non-dominated sorting Genetic Algorithm II (NSGA-II) was proposed to optimize the vibration of these pipes. The goal was mitigating vibration-induced failures by enhancing operational stability. The methodology progressed through several key stages. Firstly, BP-ANN was utilized for regression analysis, correlating pipe characteristics to vibration effects. Through regression analysis, the complex interrelationships governing the pipes' dynamic behavior was revealed. Subsequently, based on the regression model, NSGA-II was used to derive an optimal combination of design parameters to minimize the vibration response. The proposed technique was validated on an L-shaped cantilevered pipe via finite element simulations and physical experiments. The analysis case shows that the BP-ANN model demonstrated excellent accuracy in predicting vibration responses. Meanwhile, NSGA-II successfully revealed the trade-offs between conflicting objectives, generating a Pareto-optimal set balancing stability under different excitation directions. This study highlights the potential of machine learning methods for dynamic optimization of small branch pipes in nuclear power plants, and verifies the accuracy and effectiveness of the method through experiments. The research results provide a new idea for small branch pipe design and vibration control of nuclear power plant, which contributes to enhancing the safety and reliability of small branch pipes.}
}
@article{IQBAL20226324,
title = {Test case prioritization for model transformations},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {8, Part B},
pages = {6324-6338},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002147},
author = {Saqib Iqbal and Issam Al-Azzoni},
keywords = {Model transformations, Model-driven engineering, Regression testing, Test case prioritization},
abstract = {The application of model transformations is a critical component in Model-Driven Engineering (MDE). To ensure the correctness of the generated models, these model transformations need to be extensively tested. However, during the regression testing of these model transformations, it becomes too costly to frequently run a large number of test cases. Test case prioritization techniques are needed to rank the test cases and help the tester during the regression testing to be more efficient. The objective is to rank the fault revealing test cases higher so that a tester can only execute the top ranked test cases and still be able to detect as many faults as possible in the case of limited budget and resources. The aim of this paper is to present a test prioritization approach for the regression testing of model transformations. The approach is based on exploiting the rule coverage information of the test cases. The paper presents an empirical study which compares several techniques introduced by our approach for prioritizing test cases. The approach is complemented with a tool that implements the proposed techniques and can automatically generate test case orderings.}
}
@article{WANG201814,
title = {Using reliability risk analysis to prioritize test cases},
journal = {Journal of Systems and Software},
volume = {139},
pages = {14-31},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.01.033},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218300128},
author = {Ying Wang and Zhiliang Zhu and Bo Yang and Fangda Guo and Hai Yu},
keywords = {Regression testing, Test case prioritization, Probabilistic risk analysis, Information flow, Complex network},
abstract = {In this paper, we present a risk-based test case prioritization (Ri-TCP) algorithm based on the transmission of information flows among software components. Most of the existing approaches rely on the historical code changes or test case execution data, few of them effectively use the system topology information covered by test cases when scheduling the execution of test cases. From the perspective of code structure, the proposed algorithm firstly maps software into an information flow-based directed network model. Then, functional paths covered by each test case are represented by a set of barbell motifs. Finally, combining with probabilistic risk analysis (PRA) and fault tree model, we assign a priority to each test case by calculating the sum of risk indexes of all the barbells covered by it. Experimental results demonstrate that Ri-TCP technique has a higher detection rate of faults with serious risk indicators and performs stably in different systems, compared with the other state-of-the-art algorithms.}
}
@article{HABIB2024200164,
title = {A similarity-based multi-objective test optimization technique using search algorithm},
journal = {Systems and Soft Computing},
volume = {6},
pages = {200164},
year = {2024},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2024.200164},
url = {https://www.sciencedirect.com/science/article/pii/S2772941924000930},
author = {Amir Sohail Habib and Saif Ur Rehman Khan and Shahid Hussain and Naseem Ibrahim and Habib un Nisa and Abdullah Yousafzai},
keywords = {Regression testing, test suite reduction, Multi-objective optimization, Meta-heuristic search algorithms, Grey Wolf Optimizer},
abstract = {Context:
Software undergoes a constant evolution driven by ongoing changes in customer requirements, which enhances the competitive advantage. Regression testing plays a pivotal role by ensuring that modifications have not introduced detrimental effects on the system under test.
Problem:
However, regression testing becomes prohibitively expensive as the software grows in complexity and the size of the test suite also expands. Moreover, keeping the test cases up-to-date and managing the relevant test data can become a laborious and challenging task. Hence, it is required to optimize the test suite by finding a diverse subset of test cases having high code coverage, fault-detection rate, and minimal execution time.
Objective:
To solve the regression test optimization problem, the researchers have proposed various approaches including greedy algorithms, search-based algorithms, and clustering algorithms. However, existing approaches lack in finding the global optimal solution and are mostly focused on the single-objective test optimization problem. Inspired by this, we propose a Similarity-based Multi-Objective Optimization Technique (SMOOT) for test suite reduction using a Grey Wolf Optimizer (GWO) algorithm. The proposed technique employs different similarity metrics, including Cosine Similarity, Euclidean Distance, Jaccard Similarity, Manhattan Distance, and Minkowski Distance, to evaluate the similarity score of the tests. This ensures a comprehensive assessment of test diversity to achieve high code coverage and fault-detection rate while minimizing the test execution cost.
Method:
We evaluated the performance of GWO with state-of-the-art search-based algorithms using three varying types of case studies. Similarly, to evaluate the similarity score of the considered search algorithms, we employed state-of-the-art similarity measures.
Results:
The experimental results revealed that GWO significantly outperformed the considered search algorithms by attaining high code coverage and fault-detection rate while minimizing the test execution time. Moreover, we found that GWO attained a higher similarity score than the other considered search algorithms using the employed similarity measures.
Conclusion:
Based on the attained results, we believe that the proposed technique could be useful for the researchers and practitioners by effectively handling multi-objective regression test optimization problem.}
}
@article{DAS2024100170,
title = {An advantageous charging/discharging scheduling of electric vehicles in a PV energy enhanced power distribution grid},
journal = {Green Energy and Intelligent Transportation},
volume = {3},
number = {2},
pages = {100170},
year = {2024},
issn = {2773-1537},
doi = {https://doi.org/10.1016/j.geits.2024.100170},
url = {https://www.sciencedirect.com/science/article/pii/S2773153724000227},
author = {Pritam Das and Partha Kayal},
keywords = {Charging-discharging scheduling, Electric vehicles, Solar irradiance forecasting, Optimization, Distribution network},
abstract = {Electric vehicles (EVs) are going to overrule the transportation sector due to their pollution-free technology and low running costs. However, charging the EVs causes significant power demand and stress on the power delivery network. The challenge can be tackled well when charging and discharging scheduling are coordinated with intelligent EV routing. In this work, two-stage charging and discharging scheduling are proposed. In the first stage, a time scheduling algorithm is structured to identify EV charging/discharging slots at different hours, and at a later stage, the slots are optimally distributed among different charging stations. Routing of the EVs towards the EVCSs has been designed to enhance the useful participation of the EVs in the charging and discharging program. In this regard, a possible number of EVs in the test region has been forecasted with a regression model. The adequacy of the combined charging-discharging and location scheduling model is tested on a typical PV-enhanced 28-bus Indian distribution network. Three case studies containing three sub-cases in each have been performed incorporating the choice of the EV owners towards charging and discharging in different time slots in a day. The case studies have resulted in a peak-to-average ratio (PAR) of 1.151,0, 1.165,0, 1.196,8, 1.165,0, 1.180,9, 1.196,8, 1.196,8, 1.196,8 and 1.196,8 for the 24-h demand pattern in Case-1a, Case-1b, Case-1c, Case-2a, Case-2b, Case-2c, Case-3a, Case-3b and Case-1c respectively in comparison to a PAR of 1.2 for the 24-h demand in base case.}
}
@article{CHI2020110539,
title = {Relation-based test case prioritization for regression testing},
journal = {Journal of Systems and Software},
volume = {163},
pages = {110539},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110539},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300212},
author = {Jianlei Chi and Yu Qu and Qinghua Zheng and Zijiang Yang and Wuxia Jin and Di Cui and Ting Liu},
keywords = {Software testing, Test case prioritization, Dynamic call sequence},
abstract = {Test case prioritization (TCP), which aims at detecting faults as early as possible is broadly used in program regression testing. Most existing TCP techniques exploit coverage information with the hypothesis that higher coverage has more chance to catch bugs. Static structure information such as function and statement are frequently employed as coverage granularity. However, the former consumes less costs but presents lower capability to detect faults, the latter typically incurs more overhead. In this paper, dynamic function call sequences are argued that can guide TCP effectively. Same set of functions/statements can exhibit very different execution behaviors. Therefore, mapping program behaviors to unit-based (function/statement) coverage may not be enough to predict fault detection capability. We propose a new approach AGC (Additional Greedy method Call sequence). Our approach leverages dynamic relation-based coverage as measurement to extend the original additional greedy coverage algorithm in TCP techniques. We conduct our experiments on eight real-world java open source projects and systematically compare AGC against 22 state-of-the-art TCP techniques with different granularities. Results show that AGC outperforms existing techniques on large programs in terms of bug detection capability, and also achieves the highest mean APFD value. The performance demonstrates a growth trend as the size of the program increases.}
}
@article{ALREFAI2025103343,
title = {Component-based architectural regression test selection for modularized software systems},
journal = {Journal of Systems Architecture},
volume = {160},
pages = {103343},
year = {2025},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2025.103343},
url = {https://www.sciencedirect.com/science/article/pii/S1383762125000153},
author = {Mohammed Al-Refai and Mahmoud M. Hammad},
keywords = {Regression test selection, Static analysis, Component-based architecture, Java platform module system, Software architecture},
abstract = {Regression testing is an essential part of software development, but it can be costly and require significant computational resources. Regression Test Selection (RTS) improves regression testing efficiency by only re-executing the tests that have been affected by code changes. Recently, dynamic and static RTS techniques for Java projects showed that selecting tests at a coarser granularity, class-level, is more effective than selecting tests at a finer granularity, method- or statement-level. However, prior techniques are mainly considering Java object-oriented projects but not modularized Java projects. Given the explicit support of architectural constructs introduced by the Java Platform Module System (JPMS) in the ninth edition of Java, these research efforts are not customized for component-based Java projects. To that end, we propose two static component-based RTS approaches called CORTS and its variant C2RTS tailored for component-based Java software systems. CORTS leverages the architectural information such as components and ports, specified in the module descriptor files, to construct module-level dependency graph and identify relevant tests. The variant, C2RTS, is a hybrid approach in which it integrates analysis at both the module and class levels, employing module descriptor files and compile-time information to construct the dependency graph and identify relevant tests. We evaluated CORTS and C2RTS on 1200 revisions of 12 real-world open source software systems, and compared the results with those of class-level dynamic (Ekstazi) and static (STARTS) RTS approaches. The results showed that CORTS and C2RTS outperformed the static class-level RTS in terms of safety violation that measures to what extent an RTS technique misses test cases that should be selected. Using Ekstazi as the baseline, the average safety violation with respect to Ekstazi was 1.14% for CORTS, 2.21% for C2RTS, and 3.19% for STARTS. On the other hand, the results showed that CORTS and C2RTS selected more test cases than Ekstazi and STARTS. The average reduction in test suite size was 22.78% for CORTS and 43.47% for C2RTS comparing to the 68.48% for STARTS and 84.21% for Ekstazi. For all the studied subjects, CORTS and C2RTS reduced the size of the static dependency graphs compared to those generated by static class-level RTS, leading to faster graph construction and analysis for test case selection. Additionally, CORTS and C2RTS achieved reductions in overall end-to-end regression testing time compared to the retest-all strategy.}
}
@article{HETTIARACHCHI20161,
title = {Risk-based test case prioritization using a fuzzy expert system},
journal = {Information and Software Technology},
volume = {69},
pages = {1-15},
year = {2016},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2015.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0950584915001500},
author = {Charitha Hettiarachchi and Hyunsook Do and Byoungju Choi},
keywords = {Regression testing, Requirements risks-based testing, Test case prioritization, Fuzzy expert system, Empirical study},
abstract = {Context: The use of system requirements and their risks enables software testers to identify more important test cases that can reveal the faults associated with system components. Objective: The goal of this research is to make the requirements risk estimation process more systematic and precise by reducing subjectivity using a fuzzy expert system. Further, we provide empirical results that show that our proposed approach can improve the effectiveness of test case prioritization. Method: In this research, we used requirements modification status, complexity, security, and size of the software requirements as risk indicators and employed a fuzzy expert system to estimate the requirements risks. Further, we employed a semi-automated process to gather the required data for our approach and to make the risk estimation process less subjective. Results: The results of our study indicated that the prioritized tests based on our new approach can detect faults early, and also the approach can be effective at finding more faults earlier in the high-risk system components compared to the control techniques. Conclusion: We proposed an enhanced risk-based test case prioritization approach that estimates requirements risks systematically with a fuzzy expert system. With the proposed approach, testers can detect more faults earlier than with other control techniques. Further, the proposed semi-automated, systematic approach can easily be applied to industrial applications and can help improve regression testing effectiveness.}
}
@article{CHONG20131994,
title = {Efficient software clustering technique using an adaptive and preventive dendrogram cutting approach},
journal = {Information and Software Technology},
volume = {55},
number = {11},
pages = {1994-2012},
year = {2013},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2013.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0950584913001481},
author = {Chun Yong Chong and Sai Peck Lee and Teck Chaw Ling},
keywords = {Software maintenance, Design recovery, Software clustering, Remodularization},
abstract = {Context
Software clustering is a key technique that is used in reverse engineering to recover a high-level abstraction of the software in the case of limited resources. Very limited research has explicitly discussed the problem of finding the optimum set of clusters in the design and how to penalize for the formation of singleton clusters during clustering.
Objective
This paper attempts to enhance the existing agglomerative clustering algorithms by introducing a complementary mechanism. To solve the architecture recovery problem, the proposed approach focuses on minimizing redundant effort and penalizing for the formation of singleton clusters during clustering while maintaining the integrity of the results.
Method
An automated solution for cutting a dendrogram that is based on least-squares regression is presented in order to find the best cut level. A dendrogram is a tree diagram that shows the taxonomic relationships of clusters of software entities. Moreover, a factor to penalize clusters that will form singletons is introduced in this paper. Simulations were performed on two open-source projects. The proposed approach was compared against the exhaustive and highest gap dendrogram cutting methods, as well as two well-known cluster validity indices, namely, Dunn’s index and the Davies-Bouldin index.
Results
When comparing our clustering results against the original package diagram, our approach achieved an average accuracy rate of 90.07% from two simulations after the utility classes were removed. The utility classes in the source code affect the accuracy of the software clustering, owing to its omnipresent behavior. The proposed approach also successfully penalized the formation of singleton clusters during clustering.
Conclusion
The evaluation indicates that the proposed approach can enhance the quality of the clustering results by guiding software maintainers through the cutting point selection process. The proposed approach can be used as a complementary mechanism to improve the effectiveness of existing clustering algorithms.}
}
@article{SHIN2022111174,
title = {An empirical comparison of four Java-based regression test selection techniques},
journal = {Journal of Systems and Software},
volume = {186},
pages = {111174},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111174},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002582},
author = {Min Kyung Shin and Sudipto Ghosh and Leo R. Vijayasarathy},
keywords = {Regression test selection, Dynamic analysis, Static analysis, Safety, Precision, Test suite reduction},
abstract = {Regression testing is a critical but expensive activity that ensures previously tested functionality is not broken by changes made to the code. Regression test selection (RTS) techniques aim to select and run only those test cases impacted by code changes. The techniques possess different characteristics related to their selection accuracy, test suite size reduction, time to select and run the test cases, and the fault detection ability of the selected test cases. This paper presents an empirical comparison of four Java-based RTS techniques (Ekstazi, HyRTS, OpenClover and STARTS) using multiple revisions from five open source projects. The results show that STARTS selects more test cases than Ekstazi and HyRTS. OpenClover selects the most test cases. Safety and precision violations measure to what extent a technique misses test cases that should be selected and selects only the test cases that are impacted. Using HyRTS as the baseline, OpenClover had significantly worse safety violations compared to STARTS and Ekstazi, and significantly worse precision violations compared to Ekstazi. While STARTS and Ekstazi did not differ on safety violations, Ekstazi had significantly fewer precision violations than STARTS. The average fault detection ability of the RTS techniques was 8.75% lower than the original test suite.}
}
@article{AGARWAL2023200175,
title = {A novel DCNN-ELM hybrid framework for face mask detection},
journal = {Intelligent Systems with Applications},
volume = {17},
pages = {200175},
year = {2023},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2022.200175},
url = {https://www.sciencedirect.com/science/article/pii/S2667305322001120},
author = {Charu Agarwal and Pranjul Itondia and Anurag Mishra},
keywords = {COVID-19, Face mask detector, Masked face, Transfer learning, Convolution neural network},
abstract = {The Coronavirus disease (2019) has caused massive destruction of human lives and capital around the world. The latest variant Omicron is proved to be the most infectious of all its previous counterparts – Alpha, Beta and Delta. Various measures are identified, tested and implemented to minimize the attack on humans. Face masks are one of those measures that are shown to be very effective in containing the infection. However, it requires continuous monitoring for law enforcement. In the present manuscript, a detailed research investigation using different ablation studies is carried out to develop the framework for face mask recognition using pre-trained deep convolution neural networks (DCNN) models used in conjunction with a fast single layer feed-forward neural network (SLFNN) commonly known as Extreme Learning Machine (ELM) as classification technique. The ELM is well known for its real time data processing capabilities and has been successfully applied both for regression and classification problems of image processing and biomedical domain. It is for the first time that in this paper we have proposed the use of ELM as classifier for face mask detection. As a precursor to this, for feature selection, six pre-trained DCNNs such as Xception, Vgg16, Vgg19, ResNet50, ResNet 101 and ResNet152 are tested for this purpose. The best testing accuracy is obtained in case of ResNet152 transfer learning model used with ELM as the classifier. The performance evaluation through different ablation studies on testing accuracy explicitly proves that ResNet152 - ELM hybrid architecture is not only the best among the selected transfer learning models but also proves so when it is compared with several other classifiers used for the face mask detection operation. Through this investigation, novelty of the use of ResNet152 + ELM for face mask detection framework in real time domain is established.}
}
@article{SANTOS2023108088,
title = {A data-driven optimization model for the workover rig scheduling problem: Case study in an oil company},
journal = {Computers & Chemical Engineering},
volume = {170},
pages = {108088},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2022.108088},
url = {https://www.sciencedirect.com/science/article/pii/S0098135422004215},
author = {Iuri Martins Santos and Silvio Hamacher and Fabricio Oliveira},
keywords = {Oil and gas, Workover rig scheduling problem, Data-driven optimization, Simulation},
abstract = {After completion, oil wells often require intervention services to increase productivity, correct oil flow losses, and solve mechanical failures. These interventions, known as workovers, are made using oil rigs, an expensive and scarce resource. The workover rig scheduling problem (WRSP) comprises deciding which wells demanding workovers will be attended to, which rigs will serve them, and when the operations must be performed, minimizing the rig fleet costs and the oil production loss associated with the workover delay. This study presents a data-driven optimization methodology for the WRSP using text mining and regression models to predict the duration of the workover activities and a mixed-integer linear programming model to obtain the solutions for the model. A sensitivity analysis is performed using simulation to measure the impact of the regression error in the solution.}
}
@incollection{QU2013141,
title = {Chapter 4 - Testing of Configurable Systems},
editor = {Atif Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {89},
pages = {141-162},
year = {2013},
issn = {0065-2458},
doi = {https://doi.org/10.1016/B978-0-12-408094-2.00004-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780124080942000047},
author = {Xiao Qu},
keywords = {Software testing, Configurable software testing, Regression testing, Configuration prioritization, Test case prioritization, Test case selection, Change impact analysis, Combinatorial interaction testing},
abstract = {Configurable software system allows users to customize its applications in various ways, and is becoming increasingly prevalent. Testing configurable software requires extra effort over testing traditional software because there is evidence that running the same test case under different configurations may detect different faults. Differentiating test cases and configurations as two independent factors for testing, we must consider not just which test case to utilize, but also which configurations to test. Ideally, an exhaustive testing approach would combine every test case with every possible configuration. But since the full configuration space of most software systems is huge, it is infeasible to test all possible configurations with all test cases. Instead, selection techniques are necessary to select configurations for testing a software system, and to select test cases for the different configurations under test. Despite successful selection techniques, sometimes it is still costly to run only selected configurations and test cases. In particular, the cost is magnified when new features and functionality are added as a system evolves, and the new version is regression tested. Regression testing is an important but expensive way to build confidence that software changes do not introduce new faults as the software evolves, and many efforts have been made to improve its performance given limited resources. Test case prioritization has been extensively researched to determine which test cases should be run first, but has rarely been considered for configurations. In this chapter we introduce issues relevant to testing configurable software systems, we then present techniques for both selection and prioritization of these systems.}
}
@article{FAIZ20241217,
title = {A Novel Fractional Dengue Transmission Model in the Presence of Wolbachia Using Stochastic Based Artificial Neural Network},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {139},
number = {2},
pages = {1217-1238},
year = {2024},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.029879},
url = {https://www.sciencedirect.com/science/article/pii/S152614922400211X},
author = {Zeshan Faiz and Iftikhar Ahmed and Dumitru Baleanu and Shumaila Javeed},
keywords = {Wolbachia, dengue, neural network, vertical transmission, mean square error, Levenberg-Marquardt},
abstract = {The purpose of this research work is to investigate the numerical solutions of the fractional dengue transmission model (FDTM) in the presence of Wolbachia using the stochastic-based Levenberg-Marquardt neural network (LM-NN) technique. The fractional dengue transmission model (FDTM) consists of 12 compartments. The human population is divided into four compartments; susceptible humans (Sh), exposed humans (Eh), infectious humans (Ih), and recovered humans (Rh). Wolbachia-infected and Wolbachia-uninfected mosquito population is also divided into four compartments: aquatic (eggs, larvae, pupae), susceptible, exposed, and infectious. We investigated three different cases of vertical transmission probability (η), namely when Wolbachia-free mosquitoes persist only (η=0.6), when both types of mosquitoes persist (η = 0.8), and when Wolbachia-carrying mosquitoes persist only (η = 1). The objective of this study is to investigate the effectiveness of Wolbachia in reducing dengue and presenting the numerical results by using the stochastic structure LM-NN approach with 10 hidden layers of neurons for three different cases of the fractional order derivatives (α = 0.4, 0.6, 0.8). LM-NN approach includes a training, validation, and testing procedure to minimize the mean square error (MSE) values using the reference dataset (obtained by solving the model using the Adams-Bashforth-Moulton method (ABM). The distribution of data is 80% data for training, 10% for validation, and, 10% for testing purpose) results. A comprehensive investigation is accessible to observe the competence, precision, capacity, and efficiency of the suggested LM-NN approach by executing the MSE, state transitions findings, and regression analysis. The effectiveness of the LM-NN approach for solving the FDTM is demonstrated by the overlap of the findings with trustworthy measures, which achieves a precision of up to 10−4.}
}
@article{ISMAEEL2023110604,
title = {A structural equation modelling paradigm for eco-rehabilitation and adaptive reuse of cultural heritage buildings},
journal = {Building and Environment},
volume = {242},
pages = {110604},
year = {2023},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2023.110604},
url = {https://www.sciencedirect.com/science/article/pii/S0360132323006315},
author = {Walaa S.E. Ismaeel and Ahmed Gouda Mohamed},
keywords = {Adaptive reuse, Eco-rehabilitation, Energy efficiency, Indoor environmental quality, Materials and resources, Structural equation modelling},
abstract = {The study developed an integrated hierarchical structural equation modelling (SEM) for the eco-rehabilitation and adaptive reuse of cultural heritage buildings (CHBs). The research method constituted 1) keyword-based mapping analysis, 2) questionnaire survey, and 3) model formulation using SEM. The model constituted three environmental parameters, corresponding criteria, and their relative importance weights (RIWs). This portrayed the efficient use of materials and resources (MR), indoor environmental quality (IEQ), and energy efficiency (EE), and ranked them to prioritize action. The results showed that MR, IEQ, and EE acquired RIWs of 33.03%, 32.28%, and 34.7%, respectively. For MR criteria level, heritage elements' integrity, material durability and resilience, and designing for adaptability attained RIWs of 8.67%, 8.12%, and 7.95%, respectively. For IEQ criteria level, heritage building age and condition, the efficiency of the ventilation system, as well as space function and activity, depicted RIWs of 15.34%, 13.33%, and 11.41%, mutually. For EE criteria level, interventions to attain an energy-efficient heritage building envelope, the efficiency of the electromechanical system, and installing smart systems for monitoring and control rendered RIWs of 15.59%, 15.01%, and 13.61%, consecutively. The study applied the proposed model to two distinct case study projects. The differences between them were evident at both the parameter and criteria levels due to either the inherent potentials or limitations of the project. Thus, the proposed model provided flexibility for application and promoted novel approaches for heritage conservationists, environmental engineers, and decision-makers to think, act, and respond to CHB eco-rehabilitation and adaptive reuse principles and practices.}
}
@article{HAIDER2024108472,
title = {Subnetwork prediction approach for aircraft schedule recovery},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108472},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108472},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624006304},
author = {Imran Haider and Goutam Sen and Mohd Arsalan and Amit Kumar Das},
keywords = {Aircraft schedule recovery, Subnetwork selection, Machine learning, Recursive feature elimination, Optimization decision},
abstract = {The combinatorial optimization techniques for the aircraft schedule recovery problem are too expensive to compute. However, we require a reasonable solution within 1–2 min for real-time application. The computational time of traditional optimization algorithms will drastically reduce if we can accurately predict the subnetwork affected by the disruption. In this study, we advocate the use of machine learning (ML) as a promising tool to predict the subnetwork. The optimal recovery schedules for a large number of disruptions are used for offline training, and subsequently, the trained ML model is employed to reduce the search space for new disruption cases substantially. To achieve this, we employ a unique feature space specifically designed to capture the essential characteristics of the problem. A notable contribution is constructing a novel feature space based on revised aircraft schedules designed to capture the essential characteristics of the problem. The recursive feature elimination technique is employed for optimal feature selection. Five machine learning classifiers: Logistic Regression, Random Forest, Extreme gradient boosting, Light gradient boosting, and Categorical Boosting are compared. The performance is evaluated on real data obtained from an airline company. Our study demonstrates that, with the subnetwork of aircraft predicted by the classifier, the computational time of the column generation approach is remarkably reduced without deteriorating the solution quality in all the disruption instances tested, with more than 98% of the instances being solved within 60 s. The results highlight the remarkable advantage of integrating ML in the pre-optimization phase.}
}
@article{GARCIA2021913,
title = {Test Case Generation From Web Usage Information},
journal = {Procedia Computer Science},
volume = {181},
pages = {913-920},
year = {2021},
note = {CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.247},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921002908},
author = {Jorge Esparteiro Garcia and Ana C.R. Paiva and Anca-Maria Bizoi},
keywords = {Requirements engineering, test cases, web usage, recommender systems},
abstract = {In the context of SaaS (Software as a Service) where software has to be up and running 7 days a week and 24 hours a day, keeping the requirements specification and related test cases up to date can be difficult. Managing requirements in this context has additional challenges that need to be taken into account, for instance, re-prioritize requirements continuously and identify/update new dependencies among them. When requirements change, related test cases need to be updated accordingly. We claim that extracting and analyzing the usage of the SaaS can help to maintain requirements and test cases updated and contribute to improve the overall quality of the services provided. This paper presents an extension to REQAnalytics. REQAnalytics is a recommendation system that collects information about the usage of a SaaS and generates recommendations to improve the SaaS provided. The evolution involves extending the analysis performed over the sequences of functionalities (requirements) and refining the data provided for Software Requirements Specification, with the purpose of helping the requirements engineers in the requirement maintenance activities, and to improve the overall quality of the services. Furthermore, the extension presented in this paper is able to generate test cases in a regression testing context.}
}
@article{SUDHAMATHI2024101277,
title = {Ensemble regression based Extra Tree Regressor for hybrid crop yield prediction system},
journal = {Measurement: Sensors},
volume = {35},
pages = {101277},
year = {2024},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2024.101277},
url = {https://www.sciencedirect.com/science/article/pii/S2665917424002538},
author = {T. Sudhamathi and K. Perumal},
keywords = {Crop yield prediction, LESSO regression, Kernel, Principal component analysis, Ensemble regression, Extra tree regressor},
abstract = {Objective
The worldwide economies are built on agriculture, and plans for food security, resource allocation, and agricultural practices are all heavily influenced by accurate crop production predictions. Predictive models are becoming indispensable tools for predicting crop prospects due to the development of technology based on data.
Limitation
A significant disadvantage of the ER-ETR for Hybrid Crop Yield Prediction System can involve overfitting, particularly in cases when the dataset is small or the model complexity is not well managed. Inaccurate forecasts based on unreported data and decreased generalization can result from approach.
Method
Initially, the dataset is collected from the GitHub and preprocessed using the Standardscaler method. 70 % of the preprocessed data is used as the training set, and the remaining 30 % is used as the testing set. Kernel Principal Component Analysis (KPCA) is employed to extract the feature. The Least Absolute Shrinkage and Selection Operator (LESSO) Regression is used to feature selection.A reliable method for predicting hybrid crop productivity is provided by the suggested ensemble regression that makes use of feature ensemble regression using Extra Tree Regressor (ER-ETR).
Result
A simple internet-based programme for immediate forecasting is created using the Python web framework, and the model that has been trained may be used to predict the resulting profitability. Mean absolute error (MAE), mean square error (MSE), root mean square error (RMSE) and R2 were the testing metrics utilized to assess the classification model. With a 95 % accuracy rate, the suggested model is superior to existing models in terms of accuracy in crop production forecasting while still preserving the data's original distribution.Because of the intuitive online interface, stakeholders can forecast immediately and make well-informed decisions on the best use of resources from agriculture.
Conclusion
The study creates a hybrid crop yield prediction system using the ER-ETR approach. Agricultural forecasting benefits greatly from its capacity to integrate several models and take advantage of each one's advantages, which improves prediction accuracy and dependability.}
}
@article{DECARVALHOSERVIA2024954,
title = {The automated discovery of kinetic rate models – methodological frameworks††Electronic supplementary information (ESI) available: (1) A detailed evaluation of various model selection criteria, leading to the adoption of AIC for both ADoK-S and ADoK-W; (2) an analytical discussion leading to the utilization of the two top-performing models from ADoK-S or ADoK-W in MBDoE, as opposed to using Gaussian process state space models and other naive parametric models; (3) a benchmarking study comparing state-of-the-art derivative approximation methods against our GP-based approach; (4) the performance of ADoK-S on an additional multi-reaction case study. See DOI: https://doi.org/10.1039/d3dd00212h},
journal = {Digital Discovery},
volume = {3},
number = {5},
pages = {954-968},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00212h},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000676},
author = {Miguel Ángel {de Carvalho Servia} and Ilya Orson Sandoval and King Kuok (Mimi) Hii and Klaus Hellgardt and Dongda Zhang and Ehecatl {Antonio del Rio Chanona}},
abstract = {The industrialization of catalytic processes requires reliable kinetic models for their design, optimization and control. Mechanistic models require significant domain knowledge, while data-driven and hybrid models lack interpretability. Automated knowledge discovery methods, such as ALAMO (Automated Learning of Algebraic Models for Optimization), SINDy (Sparse Identification of Nonlinear Dynamics), and genetic programming, have gained popularity but suffer from limitations such as needing model structure assumptions, exhibiting poor scalability, and displaying sensitivity to noise. To overcome these challenges, we propose two methodological frameworks, ADoK-S and ADoK-W (Automated Discovery of Kinetic rate models using a Strong/Weak formulation of symbolic regression), for the automated generation of catalytic kinetic models using a robust criterion for model selection. We leverage genetic programming for model generation and a sequential optimization routine for model refinement. The frameworks are tested against three case studies of increasing complexity, demonstrating their ability to retrieve the underlying kinetic rate model with limited noisy data from the catalytic systems, showcasing their potential for chemical reaction engineering applications.}
}
@article{ANSARI2016152,
title = {Optimized Regression Test Using Test Case Prioritization},
journal = {Procedia Computer Science},
volume = {79},
pages = {152-160},
year = {2016},
note = {Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.03.020},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916001514},
author = {Ahlam Ansari and Anam Khan and Alisha Khan and Konain Mukadam},
keywords = {Regression testing, Test case prioritization, Ant colony optimization},
abstract = {Regression testing ensures that changes made in the fixes or any enhancement changes do not impact the previously working functionality. Whenever software is modified, a set of test cases are run to assure that changes don’t affect the other parts of the software. Hence all existing test cases need to be tested as well as new test cases need to be created. It is nonviable to re-execute every test case for a given software, because if there are more number of test cases to be tested, the more effort and time is required. This problem can be solved by prioritizing test cases. Test case prioritization techniques reorder the priority of a test case in an attempt to ensure that maximum faults are uncovered by the high prioritized test cases. In this paper we propose an optimized test case prioritization technique using Ant Colony Optimization (ACO) to reduce the cost, effort and time taken to perform regression testing and also uncover maximum faults.}
}
@article{MENDONCA2024112157,
title = {Feature-oriented test case selection and prioritization during the evolution of highly-configurable systems},
journal = {Journal of Systems and Software},
volume = {217},
pages = {112157},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112157},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224002024},
author = {Willian D.F. Mendonça and Wesley K.G. Assunção and Silvia R. Vergilio},
keywords = {Software evolution, Software product line, Regression testing, Test case prioritization},
abstract = {Testing Highly Configurable Systems (HCSs) is a challenging task, especially in an evolution scenario where features are added, changed, or removed, which hampers test case selection and prioritization. Existing work is usually based on the variability model, which is not always available or updated. Yet, the few existing approaches rely on links between test cases and changed files (or lines of code), not considering how features are implemented, usually spread over several and unchanged files. To overcome these limitations, we introduce FeaTestSelPrio, a feature-oriented test case selection and prioritization approach for HCSs. The approach links test cases to feature implementations, using HCS pre-processor directives, to select test cases based on features affected by changes in each commit. After, the test cases are prioritized according to the number of features they cover. Our approach selects a greater number of tests and takes longer to execute than a changed-file-oriented approach, used as baseline, but FeaTestSelPrio performs better regarding detected failures. By adding the approach execution time to the execution time of the selected test cases, we reached a reduction of ≈50%, in comparison with retest-all. The prioritization step allows reducing the average test budget in 86% of the failed commits.}
}
@article{HUANG2020110712,
title = {Regression test case prioritization by code combinations coverage},
journal = {Journal of Systems and Software},
volume = {169},
pages = {110712},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110712},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301540},
author = {Rubing Huang and Quanjun Zhang and Dave Towey and Weifeng Sun and Jinfu Chen},
keywords = {Software testing, Regression testing, Test case prioritization, Code combinations coverage},
abstract = {Regression test case prioritization (RTCP) aims to improve the rate of fault detection by executing more important test cases as early as possible. Various RTCP techniques have been proposed based on different coverage criteria. Among them, a majority of techniques leverage code coverage information to guide the prioritization process, with code units being considered individually, and in isolation. In this paper, we propose a new coverage criterion, code combinations coverage, that combines the concepts of code coverage and combination coverage. We apply this coverage criterion to RTCP, as a new prioritization technique, code combinations coverage based prioritization (CCCP). We report on empirical studies conducted to compare the testing effectiveness and efficiency of CCCP with four popular RTCP techniques: total, additional, adaptive random, and search-based test prioritization. The experimental results show that even when the lowest combination strength is assigned, overall, the CCCP fault detection rates are greater than those of the other four prioritization techniques. The CCCP prioritization costs are also found to be comparable to the additional test prioritization technique. Moreover, our results also show that when the combination strength is increased, CCCP provides higher fault detection rates than the state-of-the-art, regardless of the levels of code coverage.}
}
@article{SANTOS2021107649,
title = {Multi-objective adaptive differential evolution for SVM/SVR hyperparameters selection},
journal = {Pattern Recognition},
volume = {110},
pages = {107649},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107649},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320304520},
author = {Carlos Eduardo da Silva Santos and Renato Coral Sampaio and Leandro dos Santos Coelho and Guillermo Alvarez Bestard and Carlos Humberto Llanos},
keywords = {Support vector machines, Parameters selection problem, Multi-objective optimization, Differential evolution, Adaptive parameters strategy},
abstract = {Parameters Selection Problem (PSP) is a relevant and complex optimization issue in Support Vector Machine (SVM) and Support Vector Regression (SVR), looking for obtaining an optimal set of hyperparameters. In our case, the optimization problem is addressed to obtain models that minimize the number of support vectors and maximize generalization capacity. However, to obtain accurate and low complexity solutions, defining an adequate kernel function and the SVM/SVR’s hyperparameters are necessary, which currently represents a relevant research topic. To tackle this problem, this work proposes a multi-objective metaheuristic named Adaptive Parameter control with Mutant Tournament Multi-Objective Differential Evolution (APMT-MODE). Its performance is first tested in a series of benchmarks for classification and regression problems using simple kernels such as Gaussian and polynomial kernels. In both cases, the APMT-MODE is able to yield more precise and more straightforward solutions using simple kernels. Then, the approach is used on a real case study to create a welding bead depth and width SVR models for a Gas Metal Arc Welding (GMAW) process. Additionally, a study on kernel functions was developed in terms of computational effort, aiming to assess its performance for embedded systems applications.}
}
@incollection{LOU20191,
title = {Chapter One - A Survey on Regression Test-Case Prioritization},
editor = {Atif M. Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {113},
pages = {1-46},
year = {2019},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2018.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065245818300615},
author = {Yiling Lou and Junjie Chen and Lingming Zhang and Dan Hao},
keywords = {Regression testing, Test-case prioritization},
abstract = {Regression testing is crucial for ensuring the quality of modern software systems, but can be extremely costly in practice. Test-case prioritization has been proposed to improve the effectiveness of regression testing by scheduling the execution order of test cases to detect regression bugs faster. Since its first proposal, test-case prioritization has been intensively studied in the literature. In this chapter, we perform an extensive survey and analysis on existing test-case prioritization techniques, as well as pointing out future directions for test-case prioritization. More specifically, we collect 191 papers on test-case prioritization from 1997 to 2016 and conduct a detailed survey to systematically investigate these work from six aspects, i.e., algorithms, criteria, measurements, constraints, empirical studies, and scenarios. For each of the six aspects, we discuss the existing work and the trend during the evolution of test-case prioritization. Furthermore, we discuss the current limitations/issues in test-case prioritization research, as well as potential future directions on test-case prioritization. Our analyses provide the evidence that test-case prioritization topic is attracting increasing interests, while the need for practical test-case prioritization tools remains.}
}
@article{MONDAL2021110850,
title = {Hansie: Hybrid and consensus regression test prioritization},
journal = {Journal of Systems and Software},
volume = {172},
pages = {110850},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110850},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302405},
author = {Shouvick Mondal and Rupesh Nasre},
keywords = {Regression test prioritization, Priority awareness, Hybridization, Consensus, Permutation distances},
abstract = {Traditionally, given a test-suite and the underlying system-under-test, existing test-case prioritization heuristics report a permutation of the original test-suite that is seemingly best according to their criteria. However, we observe that a single heuristic does not perform optimally in all possible scenarios, given the diverse nature of software and its changes. Hence, multiple individual heuristics exhibit effectiveness differently. Interestingly, together, the heuristics bear the potential of improving the overall regression test selection across scenarios. In this paper, we pose the test-case prioritization as a rank aggregation problem from social choice theory. Our solution approach, named Hansie, is two-flavored: one involving priority-aware hybridization, and the other involving priority-blind computation of a consensus ordering from individual prioritizations. To speed-up test-execution, Hansie executes the aggregated test-case orderings in a parallel multi-processed manner leveraging regular windows in the absence of ties, and irregular windows in the presence of ties. We show the benefit of test-execution after prioritization and introduce a cost-cognizant metric (EPL) for quantifying overall timeline latency due to load-imbalance arising from uniform or non-uniform parallelization windows. We evaluate Hansie on 20 open-source subjects totaling 287,530 lines of source code, 69,305 test-cases, and with parallelization support of up to 40 logical CPUs.}
}
@article{BARBOSA2022106902,
title = {A Systematic Literature Review on prioritizing software test cases using Markov chains},
journal = {Information and Software Technology},
volume = {147},
pages = {106902},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106902},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922000623},
author = {Gerson Barbosa and Érica Ferreira {de Souza} and Luciana Brasil Rebelo {dos Santos} and Marlon {da Silva} and Juliana Marino Balera and Nandamudi Lankalapalli Vijaykumar},
keywords = {Systematic Literature Review, Markov Chains, Test case prioritization},
abstract = {Context:
Software Testing is a costly activity since the size of the test case set tends to increase as the construction of the software evolves. Test Case Prioritization (TCP) can reduce the effort and cost of software testing. TCP is an activity where a subset of the existing test cases is selected in order to maximize the possibility of finding defects. On the other hand, Markov Chains representing a reactive system, when solved, can present the occupation time of each of their states. The idea is to use such information and associate priority to those test cases that consist of states with the highest probabilities.
Objective:
The objective of this paper is to conduct a survey to identify and understand key initiatives for using Markov Chains in TCP. Aspects such as approaches, developed techniques, programming languages, analytical and simulation results, and validation tests are investigated.
Methods:
A Systematic Literature Review (SLR) was conducted considering studies published up to July 2021 from five different databases to answer the three research questions.
Results:
From SLR, we identified 480 studies addressing Markov Chains in TCP that have been reviewed in order to extract relevant information on a set of research questions.
Conclusion:
The final 12 studies analyzed use Markov Chains at some stage of test case prioritization in a distinct way, that is, we found that there is no strong relationship between any of the studies, not only on how the technique was used but also in the context of the application. Concerning the fields of application of this subject, 6 forms of approach were found: Controlled Markov Chain, Usage Model, Model-Based Test, Regression Test, Statistical Test, and Random Test. This demonstrates the versatility and robustness of the tool. A large part of the studies developed some prioritization tool, being its validation done in some cases analytically and in others numerically, such as: Measure of the software specification, Optimal Test Transition Probabilities, Adaptive Software Testing, Automatic Prioritization, Ant Colony Optimization, Model Driven approach, and Monte Carlo Random Testing.}
}
@article{BERECIARTUAPEREZ2022106933,
title = {Insect counting through deep learning-based density maps estimation},
journal = {Computers and Electronics in Agriculture},
volume = {197},
pages = {106933},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.106933},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922002502},
author = {Arantza Bereciartua-Pérez and Laura Gómez and Artzai Picón and Ramón Navarra-Mestre and Christian Klukas and Till Eggers},
keywords = {Convolutional neural network, Deep learning, Density map estimation, Insect counting, Image processing, Precision agriculture},
abstract = {Digitalization and automation of assessments in field trials are established practice for farming product development. The use of image-based methods has provided good results in different applications. Although these models can leverage some problems, they still perform poorly under real field conditions using mobile devices on complex applications. Among these applications, insect counting and detection is necessary for integrated pest management strategies in order to apply specific treatments at early infection stages to reduce economic losses and minimize chemical usage. Currently the counting task for the assessment of the degree of infestation is done manually by the farmer. Current state of the art object counting methods do not provide accurate counting in crowded images with overlapped or touching objects which is the case for insect counting images. This makes necessary to define novel approaches for insect counting. In this work, we propose a novel solution based on deep learning density map estimation to tackle insects counting in wild conditions. To this end, a fully convolutional regression network has been designed to accurately estimate a probabilistic density map for the counting regression problem. The estimated density map is then used for counting whiteflies in eggplant leaves. The proposed method was compared with a baseline based on candidate object selection and classification approach. The results for alive adult whitefly counting by means of density map estimation provided R2 = 0.97 for the counted insects in the main leaf of the image, that outperforms by far the baseline algorithm (R2 = 0.85) based on image processing methods for feature extraction and candidate selection and deep learning-based classifier. This solution was embedded to be used in mobile devices, and it has been gone for exhaustive validation tests, with diverse illumination conditions and background variability, over leaves taken at different heights, with different perspectives and even unfocused images, for the analyzed pest under real conditions.}
}
@article{TANG2025100406,
title = {Uneven internal SOC distribution estimation of lithium-ion batteries using ultrasonic transmission signals: A new data screening technique and an improved deep residual network},
journal = {eTransportation},
volume = {24},
pages = {100406},
year = {2025},
issn = {2590-1168},
doi = {https://doi.org/10.1016/j.etran.2025.100406},
url = {https://www.sciencedirect.com/science/article/pii/S259011682500013X},
author = {Ting Tang and Quan Xia and Mingkang Xu and Zhe Deng and Fusheng Jiang and Zeyu Wu and Yi Ren and Dezhen Yang and Cheng Qian},
keywords = {Ultrasonic scanning, Lithium-ion battery, Uneven state of charge distribution, Active learning, Pooling extreme learning machine},
abstract = {Ultrasonic for state of charge (SOC) estimation of lithium-ion batteries has the advantages of non-destructive and real-time. The existing methods mainly depend on single-site detection, which is based on the assumption of uniform SOC distribution. However, the uneven SOC distribution existing inside the cell will cause rapid degradation of local performance, thereby bringing safety risks. Therefore, a novel method combining multi-site detection signals for the uneven internal SOC distribution estimation has been proposed, including Gaussian process regression-active learning (GPR-AL) and deep residual-pooling extreme learning machine (DR-PELM). Firstly, a focused ultrasonic beam is adopted to scan the cell. The preferred sites with lower uncertainty and their signal amplitude of ultrasonic waveform are extracted by GPR-AL. Then, DR-PELM has been established to learn the relationship between ultrasound signal features and SOC, which can reduce the impact of redundant information and noise. Finally, the accuracy of method has been verified through several case studies and destructive tests of lithium-ion detection. The results show that the mean error of general SOC estimation is 2.88 %, and the uneven SOC distribution estimation error is 0.37 %. Thus, the proposed method present good accuracy by integrating multiple selection sites with lower uncertainty and optimizing the network structure.}
}
@article{SRIKANTH2016122,
title = {Test case prioritization of build acceptance tests for an enterprise cloud application: An industrial case study},
journal = {Journal of Systems and Software},
volume = {119},
pages = {122-135},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.06.017},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300851},
author = {Hema Srikanth and Mikaela Cashman and Myra B. Cohen},
keywords = {Regression testing, Prioritization, Software as a service, Cloud computing},
abstract = {The use of cloud computing brings many new opportunities for companies to deliver software in a highly-customizable and dynamic way. One such paradigm, Software as a Service (SaaS), allows users to subscribe and unsubscribe to services as needed. While beneficial to both subscribers and SaaS service providers, failures escaping to the field in these systems can potentially impact an entire customer base. Build Acceptance Testing (BAT) is a black box technique performed to validate the quality of a SaaS system every time a build is generated. In BAT, the same set of test cases is executed simultaneously across many different servers, making this a time consuming test process. Since BAT contains the most critical use cases, it may not be obvious which tests to perform first, given that the time to complete all test cases across different servers in any given day may be insufficient. While all tests must be eventually run, it is critical to run those tests first which are likely to find failures. In this work, we ask if it is possible to prioritize BAT tests for improved time to fault detection and present several different approaches, each based on the services executed when running each BAT. In an empirical study on a production enterprise system, we first analyze the historical data from several months in the field, and then use that data to derive the prioritization order for the current development BATs. We then examine if the orders change significantly when we consider fault severity using a cost-based prioritization metric. We find that the prioritization order in which we run the tests does matter, and that the use of historical information is a good heuristic for this order. Prioritized tests have an increase in the rate of fault detection, with the average percent of faults detected (APFD) increasing from less than 0.30 to as high as 0.77 on a scale of zero to one. Although severity slightly changes which order performs best, we see that there are clusters of orderings, ones which improve time to early fault detection ones which don’t.}
}
@article{TIAN2014320,
title = {Bootstrap techniques for sensitivity analysis and model selection in building thermal performance analysis},
journal = {Applied Energy},
volume = {135},
pages = {320-328},
year = {2014},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2014.08.110},
url = {https://www.sciencedirect.com/science/article/pii/S0306261914009337},
author = {Wei Tian and Jitian Song and Zhanyong Li and Pieter {de Wilde}},
keywords = {Building thermal performance, Bootstrap method, Sensitivity analysis, Model selection},
abstract = {In regression analysis, there are two main aims: interpretation and prediction, which can be also applied in building performance analysis. Interpretation is used to understand the relationship between input parameters and building energy performance (also called sensitivity analysis), whereas prediction is used to create a reliable energy model to estimate building energy consumption. This article explores the implementation of a distribution-free bootstrap method for these two purposes. The bootstrap is a resampling method that enables assessment of the accuracy of an estimator by random sampling with replacement from an original dataset. An office building is used as a case study to demonstrate the application of this method in assessing building thermal performance. The results indicate that the probabilistic sensitivity analysis incorporating the bootstrap approach provides valuable insights into the variations in sensitivity indicators, which are not available from typical deterministic sensitivity analysis. The single point values from deterministic methods may lead to misleading prioritization of energy saving measures because they do not provide the distributions of sensitivity indicators. Information on prediction errors obtained from the bootstrap method can facilitate the selection of an appropriate building energy metamodel to more accurately predict the energy consumption of buildings, compared with the traditional one-time data splitting method (also called holdout cross-validation method), which partitions the data into a training set and a test set.}
}
@article{ZHANG2022183,
title = {Integrated optimization of test case selection and sequencing for reliability testing of the mainboard of Internet backbone routers},
journal = {European Journal of Operational Research},
volume = {299},
number = {1},
pages = {183-194},
year = {2022},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2021.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S0377221721005440},
author = {Hanxiao Zhang and Yan-Fu Li},
keywords = {Reliability, Reliability testing plan, Test case selection, Test case sequencing, Branch-and-price},
abstract = {Internet backbone refers to the principal data routes between large, strategically interconnected networks and core routers on the Internet. Internet backbone router is essentially the core router of Internet backbone and its performance is mainly relevant to the reliability of its mainboard. The mainboard is an embedded system consisting of hardware and software. Its reliability testing involves executing a number of test cases, which are designed to expose potential defects, under harsh environmental conditions. The testing process is largely prolonged due to the dramatic increase of the number of test cases, mainly due to the continuous increase and upgrade of its functional modules. Thus, there is a big demand from industry to improve the reliability testing efficiency and effectiveness. In this work, we exploit the principles of regression testing in software maintenance: test case selection and prioritization, and construct two testing planning models to largely reduce the testing time as well as to improve the effectiveness of failure detections. The former is a two-step model we introduced in previous work that optimizes test case selection and test case sequencing sequentially. The latter, an integrated model is newly developed, optimizing the test case selection and sequencing simultaneously with the precedence constraints among the test cases. Moreover, we propose exact algorithms based on branch-and-price for solving these two models. Finally, we present a case study demonstrating that the integrated model outperforms the two-step method and the advantage is more significant if the sequencing objective has greater weight in the integrated objective function.}
}
@article{WANG202368,
title = {Online fault diagnosis of PV array considering label errors based on distributionally robust logistic regression},
journal = {Renewable Energy},
volume = {203},
pages = {68-80},
year = {2023},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2022.11.126},
url = {https://www.sciencedirect.com/science/article/pii/S0960148122017840},
author = {Mengyuan Wang and Xiaoyuan Xu and Zheng Yan},
keywords = {Photovoltaic array, Fault diagnosis, Label error, Distributionally robust logistic regression},
abstract = {This paper proposes a robust diagnosis method of photovoltaic (PV) array faults considering label errors in training data. First, the online data of PV systems, including the sequences of voltages, currents, and output power at maximum power points, are used to establish the input data of fault diagnosis. Second, a data processing method is used to extract fault features from electrical signals under fluctuating ambient conditions. Third, the parameter estimation of the regression-based fault diagnosis model is formulated as a stochastic optimization problem. To hedge against label errors, an ambiguity set of probability distributions is established from training data, and a distributionally robust logistic regression method is proposed to minimize the expected log-loss function under the worst-case probability distribution for obtaining model parameters of fault diagnosis. Finally, the proposed method is tested on real-world PV arrays under diverse conditions and scenarios. Data processing increases diagnosis accuracy by 18.4% when training data is error-free. The diagnosis accuracy is higher than 98% when the label error rate is smaller than 4%.}
}
@article{ZHU2025109002,
title = {Ensemble transfer learning assisted soft sensor for distributed output inference in chemical processes},
journal = {Computers & Chemical Engineering},
volume = {194},
pages = {109002},
year = {2025},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2025.109002},
url = {https://www.sciencedirect.com/science/article/pii/S0098135425000067},
author = {Jialiang Zhu and Wangwang Zhu and Yi Liu},
keywords = {Chemical process, Distributed outputs, Local model, Ensemble learning, Transfer learning},
abstract = {Chemical processes with distributed outputs are characterized by various operating conditions, and the scarcity of labeled data poses challenges to the prediction of product quality. An ensemble transfer Gaussian process regression (ETGPR) model is developed for prediction of different quantities of distributed outputs. First, for each test instances from target domain, just-in-time learning is adopted to select distance-based similar instances from source domain in related operating conditions. Mutual information helps create various local models by building diverse input variable sets. Subsequently, Bayesian inference is used to produce the posterior probabilities relative to the test instance, then set as the weights of local prediction. The instance transfer is thus completed via distance-based similar instance selection from source domain for local model construction, and the model performance is improved by the ensemble weighting strategy, concerning the target domain, under diverse operating conditions. Therefore, by utilizing and transferring information from source domain, unsupervised transfer can be implemented with available unlabeled target data. The superiority of ETGPR model is confirmed in the case of modeling the polymerization process with distributed outputs.}
}
@article{WANG2024107339,
title = {Cluster-based adaptive test case prioritization},
journal = {Information and Software Technology},
volume = {165},
pages = {107339},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107339},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923001945},
author = {Xiaolin Wang and Sulan Zhang},
keywords = {Test case prioritization, Clustering analysis, Requirement, Regression testing},
abstract = {In order to enhance the efficiency of regression testing, test case prioritization (TCP) has been widely implemented, wherein a higher priority test case is executed earlier. Traditional TCP methods focus on improving the prioritization algorithm's efficacy. However, the majority of TCP approaches are characterized by a predetermined sequence of test cases prior to execution. Once established, this sequence remains consistent throughout the entire test execution process. As a result, any execution information generated during current test execution (such as fault-detected information) is unavailable for use in current round of test case prioritization and can only be utilized in subsequent regression testing. To address the issue of lagging utilization of fault-detected information, a cluster-based adaptive test case prioritization approach is proposed, which adds the new adaptive adjustment content in pre-prioritization. First, a new clustering criterion is defined and designed, by which produces test-case clusters in advance. Second, an adaptive TCP algorithm is proposed, which utilizes fault-detected information to adaptively adjust the order of test cases during the execution process based on the test-case clusters. Finally, one open-source Java program and three industrial-grade Java programs were selected for empirical evaluation. The experimental results demonstrate that the proposed technique not only serves as an enhanced version of pre-prioritization to improve the performance of the corresponding pre-prioritization technique, but also functions as an independent approach that outperforms other TCP techniques, including cluster-based TCPs, and another adaptive TCP. Specifically, when step=2 is applied using our cluster-based adaptive TCP approach, the results are significantly better than those obtained with step=1. For instance, in CT-14, the median APFD improvement rate for step=2 reaches 17.08 %, which is substantially higher than that achieved with step=1 (5.48 %).}
}
@article{NI2024110033,
title = {Feature incremental learning with causality},
journal = {Pattern Recognition},
volume = {146},
pages = {110033},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2023.110033},
url = {https://www.sciencedirect.com/science/article/pii/S0031320323007306},
author = {Haotian Ni and Shilin Gu and Ruidong Fan and Chenping Hou},
keywords = {Feature incremental, Causal inference, Balancing regularizer},
abstract = {With the emerging of new data collection ways, the features are incremental and accumulated gradually. Due to the expansion of feature spaces, it is more common that there are unknown biases between the distribution of training and testing datasets. It is known as the unknown data selection bias, which belongs to the learning scenario with non-i.i.d samples. The performance of traditional approaches, which need the i.i.d. assumption, will be aggravated seriously. How to design an algorithm to address the problem of data selection bias in this feature incremental scenario is crucial but rarely studied. In this paper, we propose a feature incremental classification algorithm with causality. Firstly, we embed the confounding variable balance algorithm in causal learning into the prediction modeling and utilize the logical regression algorithm with balancing regular terms as a baseline. Then, to satisfy the special requirement of feature increment, we design a new regularizer, which maintains the consistency of the regression coefficients between the data in the current and previous stages. It retains the correlation between the old features and labels. Finally, we propose the Multiple Balancing Logistic Regression model (MBRLR) to jointly optimize the balancing regularizer and weighted logistic regression model with multiple feature sets. We also present theoretical results to show that our proposed algorithm can make precise and stable predictions. Besides, the numerical results also demonstrate that our MBRLR algorithm is superior to other methods.}
}
@incollection{DO201653,
title = {Chapter Three - Recent Advances in Regression Testing Techniques},
editor = {Atif M. Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {103},
pages = {53-77},
year = {2016},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2016.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0065245816300286},
author = {H. Do},
keywords = {Regression testing, Regression test selection, Test case prioritization, Test suite minimization},
abstract = {Software systems and their environment change are continuous. They are enhanced, corrected, and ported to new platforms. These changes can affect a system adversely, thus software engineers perform regression testing to ensure the quality of the modified systems. Regression testing is an integral part of most major software projects, but as projects grow larger and the number of tests increases, performing regression testing becomes more costly. To address this problem, many researchers and practitioners have proposed and empirically evaluated various regression testing techniques, such as regression test selection, test case prioritization, and test suite minimization. Recent surveys on these techniques indicate that this research area continues to grow, heuristics and the types of data utilized become diverse, and wider application domains have been considered. This chapter presents the current status and the trends of three regression testing techniques and discusses recent advances of each technique.}
}
@article{UCAR2024,
title = {Estimating rock strength parameters across varied failure criteria: Application of spreadsheet and R-based orthogonal regression to triaxial test data},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
year = {2024},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2024.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S167477552400550X},
author = {Roberto Úcar and Luis Arlegui and Norly Belandria and Francisco Torrijo},
keywords = {Rock failure criteria, Nonlinear regression, Orthogonal regression, Triaxial testing, Dot product},
abstract = {Triaxial tests, a staple in rock engineering, are labor-intensive, sample-demanding, and costly, making their optimization highly advantageous. These tests are essential for characterizing rock strength, and by adopting a failure criterion, they allow for the derivation of criterion parameters through regression, facilitating their integration into modeling programs. In this study, we introduce the application of an underutilized statistical technique—orthogonal regression— well-suited for analyzing triaxial test data. Additionally, we present an innovation in this technique by minimizing the Euclidean distance while incorporating orthogonality between vectors as a constraint, for the case of orthogonal linear regression. Also, we consider the Modified Least Squares method. We exemplify this approach by developing the necessary equations to apply the Mohr-Coulomb, Murrell, Hoek-Brown, and Úcar criteria, and implement these equations in both spreadsheet calculations and R scripts. Finally, we demonstrate the technique's application using five datasets of varied lithologies from specialized literature, showcasing its versatility and effectiveness.}
}
@article{THIEU2025103977,
title = {MetaPerceptron: A standardized framework for metaheuristic-driven multi-layer perceptron optimization},
journal = {Computer Standards & Interfaces},
volume = {93},
pages = {103977},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.103977},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925000066},
author = {Nguyen Van Thieu and Seyedali Mirjalili and Harish Garg and Nguyen Thanh Hoang},
keywords = {Metaheuristic algorithms, Multilayer perceptron, Metaheuristic-based MLP, Python library, Neural network, Open-source software},
abstract = {The multi-layer perceptron (MLP) remains a foundational architecture within neural networks, widely recognized for its ability to model complex, non-linear relationships between inputs and outputs. Despite its success, MLP training processes often face challenges like susceptibility to local optima and overfitting when relying on traditional gradient descent optimization. Metaheuristic algorithms (MHAs) have recently emerged as robust alternatives for optimizing MLP training, yet no current package offers a comprehensive, standardized framework for MHA-MLP hybrid models. This paper introduces MetaPerceptron, an standardized open-source Python framework designed to integrate MHAs with MLPs seamlessly, supporting both regression and classification tasks. MetaPerceptron is built on top of PyTorch, Scikit-Learn, and Mealpy. Through this design, MetaPerceptron promotes standardization in MLP optimization, incorporating essential machine learning utilities such as model forecasting, feature selection, hyperparameter tuning, and pipeline creation. By offering over 200 MHAs, MetaPerceptron empowers users to experiment across a broad array of metaheuristic optimization techniques without reimplementation. This framework significantly enhances accessibility, adaptability, and consistency in metaheuristic-trained neural network research and applications, positioning it as a valuable resource for machine learning, data science, and computational optimization. The entire source code is freely available on Github: https://github.com/thieu1995/MetaPerceptron}
}
@article{ZHAO2016886,
title = {One day ahead wind speed forecasting: A resampling-based approach},
journal = {Applied Energy},
volume = {178},
pages = {886-901},
year = {2016},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2016.06.098},
url = {https://www.sciencedirect.com/science/article/pii/S030626191630873X},
author = {Weigang Zhao and Yi-Ming Wei and Zhongyue Su},
keywords = {Wind speed forecasting, General regression neural network, Cross-validation, Fibonacci search method, Leave-one-day-out resampling, Forecast correction},
abstract = {Wind speed forecasting plays a vital role in dispatch planning and operational security for wind farms, however, its difficulty is commonly accepted. This paper develops a nonlinear autoregressive (exogenous) model for one-day-ahead mean hourly wind speed forecasting, where general regression neural network is employed to model nonlinearities of the system. Specifically, this model is a two-stage method consisting of the model selection and training stage along with the iterative forecasting and correcting stage. In the former stage, the model is in the series-parallel configuration, and its test error is estimated by the cross-validation (CV) method. With the help of ARIMA identification results, CV errors are minimized by the Fibonacci search method to select the best lag structure and the only adjustable parameter. In the latter stage, the model is in the parallel configuration, and the so-called leave-one-day-out resampling method is proposed to iteratively estimate correction parameters for horizons up to 24h ahead, which holds out each full-day data segment from the sample of observations in turn to faithfully reproduce the entire process of training, iterative forecasting and correcting in the in-sample period. Finally, the out-of-sample corrected forecasts can be successively obtained by using the model selected and trained in the former stage and the correction parameters estimated in the latter stage. Furthermore, effectiveness of this model is verified with four real-world case studies of two wind farms in China.}
}
@article{LIU2024108673,
title = {Machine learning-based models for estimating liquefaction-induced building settlements},
journal = {Soil Dynamics and Earthquake Engineering},
volume = {182},
pages = {108673},
year = {2024},
issn = {0267-7261},
doi = {https://doi.org/10.1016/j.soildyn.2024.108673},
url = {https://www.sciencedirect.com/science/article/pii/S0267726124002252},
author = {Chenying Liu and Jorge Macedo},
keywords = {Liquefaction-induced building settlements, Machine learning, Feature selection, Case histories, Performance-based earthquake engineering},
abstract = {Engineers often estimate the amount of liquefaction-induced building settlements (LIBS) as a performance proxy to assess the potential of earthquake-induced damage to buildings. The first robust LIBS models were initially developed in 2017 and 2018 using traditional statistical approaches. More recently, machine learning techniques have started to be used in developing LIBS models. These recent efforts are a step forward in realizing the potential of machine learning in liquefaction engineering; however, they have often considered only one ML technique for a given dataset and typically used only held-out test sets for model assessment. In this study, five ML-based LIBS models with varying flexibility (i.e., ridge regression, partial least square regression — PLSR, random forest, gradient boosting decision tree — GBDT, and support vector regression) are developed using a LIBS database generated by soil–structure numerical simulations of different buildings and soil profiles shaken by ground motions with varying intensity measures. The motivation for considering models with different flexibility is to include different bias–variance trade-offs. Feature selection with different ML techniques indicates that cumulative absolute velocity, spectral acceleration at one second, contact pressure, foundation width, the thickness of the liquefiable layer, and a shearing liquefaction index are important features in estimating LIBS. The developed ML-based models are assessed considering prediction accuracy in test sets, performance against centrifuge tests and case histories, and trends. The assessment indicates that the random forest, GBDT, and SVR models perform best, providing standard deviation reductions up to 40% relative to a multi-linear regression. Specifically, the random forest and GBDT models exhibit a root mean square error (RMSE) of 0.29 and a coefficient of determination (R2) of 0.93 on test sets, demonstrating a notable improvement compared to a traditional multi-linear regression model, which yields an RMSE of 0.47 and an R2 of 0.82. Moreover, random forest and GBDT, alongside SVR, show a good performance in centrifuge tests and case histories. Finally, given the scarcity of LIBS models, this study also contributes to treating epistemic uncertainties in estimating LIBS, which is ultimately beneficial for performance-based assessments.}
}
@article{BAJAJ2021107584,
title = {Discrete cuckoo search algorithms for test case prioritization},
journal = {Applied Soft Computing},
volume = {110},
pages = {107584},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107584},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621005056},
author = {Anu Bajaj and Om Prakash Sangwan},
keywords = {Search based software testing, Regression testing, Test case prioritization, Meta-heuristics, Nature-inspired algorithms, Cuckoo search algorithm, Asexual reproduction algorithm, Permutation encoding},
abstract = {Regression testing is an essential aspect of the software development lifecycle. As the software evolves, the test suite grows, hence the cost and effort to retest the software. Test case prioritization is one of the mitigation techniques for regression testing. It ranks the test cases to maximize the desired properties, e.g., detecting faults early. The efficiency and effectiveness of test case prioritization techniques can be enhanced using optimization algorithms. Nature-inspired algorithms are gaining more attention due to their easy implementation and quality of the solutions. This paper proposes the discrete cuckoo search algorithm for test case prioritization. The prioritization problem deals with ordering the test cases. Therefore, a new adaptation strategy using asexual genetic reproduction is introduced to convert real numbers into permutation sequences. Furthermore, the cuckoo search algorithm’s effectiveness is extended with the genetic algorithm’s mutation operator to balance the trade-off between exploration and exploitation. An in-depth comparative study on four case studies is conducted between the proposed algorithms, existing state-of-the-art algorithms and baseline approach. Statistical investigation confirms that the proposed hybrid cuckoo search algorithm outperforms the genetic algorithm, particle swarm optimization, ant colony optimization, tree seed algorithm and random search by 4.29%, 5.52%, 8.38%, 2.74% and 10.80%, respectively.}
}
@article{WANG2023130066,
title = {Relationship between track geometry defect occurrence and substructure condition: A case study on one passenger railroad in the United States},
journal = {Construction and Building Materials},
volume = {365},
pages = {130066},
year = {2023},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2022.130066},
url = {https://www.sciencedirect.com/science/article/pii/S0950061822037229},
author = {Xin Wang and Xiang Liu and Todd L. Euston},
keywords = {Track geometry defect, Passenger railroad, Substructure condition, Data-driven approach, Gradient boosting},
abstract = {Analyzing the relationship between track geometry defect occurrence and substructure condition can provide assistance for track inspection and spot maintenance, which contributes to better train operation quality. This paper develops a data-driven approach to estimate the occurrence of track geometry defects on concrete-tie tracks on one passenger railroad in the United States, using substructure data, rail seat abrasion data, infrastructure data, traffic data, track class information, and maintenance data. Feature extraction was implemented to generate input variables for the machine learning models. Recursive feature elimination (RFE) was applied to reduce data dimensionality by recursively considering smaller sets of features. Three data treatment methods, including no resampling, undersampling, and oversampling, were incorporated to address imbalanced data issues. The developed models included logistic regression, artificial neural network, and gradient boosting. The hyperparameters of the proposed models were optimized using Bayesian optimization. The performance of the proposed methods was finally evaluated based on the test dataset generated using random data partitioning. Based on data collected from one passenger railroad, the gradient boosting method with data oversampling shows the highest performance in estimating the occurrence of geometry defects. The F1-score of the model is 0.662, with G-Mean of 0.738. Feature importance identifies that surfacing, traffic, curvature, switch, and rail replacement are the top five factors influencing the predicted probability of track geometry defect occurrence. The proposed model can be used to prioritize maintenance activities on locations prone to track geometry defects and thus further improve infrastructure safety given budgetary constraints.}
}
@article{LOUKREZIS2025115746,
title = {Multivariate sensitivity-adaptive polynomial chaos expansion for high-dimensional surrogate modeling and uncertainty quantification},
journal = {Applied Mathematical Modelling},
volume = {137},
pages = {115746},
year = {2025},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2024.115746},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X24004992},
author = {Dimitrios Loukrezis and Eric Diehl and Herbert {De Gersem}},
keywords = {Polynomial chaos expansion, Multivariate sensitivity analysis, Machine learning regression, Surrogate modeling, Uncertainty quantification, Curse of dimensionality, Adaptive approximation, Electric machine, Power grid},
abstract = {This work develops a novel basis-adaptive method for constructing anisotropic polynomial chaos expansions of multidimensional (vector-valued, multi-output) model responses. The adaptive basis selection is based on multivariate sensitivity analysis metrics that can be estimated by post-processing the polynomial chaos expansion and results in a common anisotropic polynomial basis for the vector-valued response. This allows the application of the method to problems with up to moderately high-dimensional model inputs (in the order of tens) and up to very high-dimensional model responses (in the order of thousands). The method is applied to different engineering test cases for surrogate modeling and uncertainty quantification, including use cases related to electric machine and power grid modeling and simulation, and is found to produce highly accurate results with comparatively low data and computational demand.}
}
@article{ANDERSON2019110,
title = {On the use of usage patterns from telemetry data for test case prioritization},
journal = {Information and Software Technology},
volume = {113},
pages = {110-130},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919301223},
author = {Jeff Anderson and Maral Azizi and Saeed Salem and Hyunsook Do},
keywords = {Regression testing, Test case prioritization, Telemetry data, Usage patterns},
abstract = {Context
Modern applications contain pervasive telemetry to ensure reliability and enable monitoring and diagnosis. This presents a new opportunity in the area of regression testing techniques, as we now have the ability to consider usage profiles of the software when making decisions on test execution.
Objective
The results of our prior work on test prioritization using telemetry data showed improvement rate on test suite reduction, and test execution time. The objective of this paper is to further investigate this approach and apply prioritization based on multiple prioritization algorithms in an enterprise level cloud application as well as open source projects. We aim to provide an effective prioritization scheme that practitioners can implement with minimum effort. The other objective is to compare the results and the benefits of this technique factors with code coverage-based prioritization approaches, which is the most commonly used test prioritization technique.
Method
We introduce a method for identifying usage patterns based on telemetry, which we refer to as “telemetry fingerprinting.” Through the use of various algorithms to compute fingerprints, we conduct empirical studies on multiple software products to show that telemetry fingerprinting can be used to more effectively prioritize regression tests.
Results
Our experimental results show that the proposed techniques were able to reduce over 30% in regression test suite run times compared to the coverage-based prioritization technique in detecting discoverable faults. Further, the results indicate that fingerprints are effective in identifying usage patterns, and that the fingerprints can be applied to improve regression testing techniques.
Conclusion
In this research, we introduce the concept of fingerprinting software usage patterns through telemetry. We provide various algorithms to compute fingerprints and conduct empirical studies that show that fingerprints are effective in identifying distinct usage patterns. By applying these techniques, we believe that regression testing techniques can be improved beyond the current state-of-the-art, yielding additional cost and quality benefits.}
}
@article{MAGALHAES2020110430,
title = {HSP: A hybrid selection and prioritisation of regression test cases based on information retrieval and code coverage applied on an industrial case study},
journal = {Journal of Systems and Software},
volume = {159},
pages = {110430},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110430},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302043},
author = {Claudio Magalhães and João Andrade and Lucas Perrusi and Alexandre Mota and Flávia Barros and Eliot Maia},
keywords = {Test cases selection and prioritisation, Regression testing, Static analysis, Information retrieval, Code coverage},
abstract = {The usual way to guarantee quality of software products is via testing. This paper presents a novel strategy for selection and prioritisation of Test Cases (TC) for Regression testing. In the lack of code artifacts from where to derive Test Plans, this work uses information conveyed by textual documents maintained by Industry, such as Change Requests. The proposed process is based on Information Retrieval techniques combined with indirect code coverage measures to select and prioritise TCs. The aim is to provide a high coverage Test Plan which would maximise the number of bugs found. This process was implemented as a prototype tool which was used in a case study with our industrial partner (Motorola Mobility). Experiments results revealed that the combined strategy provides better results than the use of information retrieval and code coverage independently. Yet, it is worth mentioning that any of these automated options performed better than the previous manual process deployed by our industrial partner to create test plans.}
}
@article{OMAE2024111809,
title = {Deep learned features selection algorithm: Removal operation of anomaly feature maps (RO-AFM)},
journal = {Applied Soft Computing},
volume = {162},
pages = {111809},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111809},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624005830},
author = {Yuto Omae and Yohei Kakimoto and Yuki Saito and Daisuke Fukamachi and Koichi Nagashima and Yasuo Okumura and Jun Toyotani},
keywords = {Convolutional neural networks, Feature maps, Feature selection},
abstract = {Class/Regression Activation Maps (CAMs/RAMs; AMs) are often embedded into Convolutional Neural Networks (CNNs) for checking activated regions on input images at estimation. CNNs sometime generate unreliable AMs, such as activated regions, are inappropriate. Because AM is calculated by stacking many feature maps generated by the final convolutional layer, when there are Anomaly Feature Maps (AFMs), unreliable AMs can be generated. For example, suppose we have a CNN that evaluates the heart. In this case, the feature maps that focus on regions unrelated to the heart (e.g., shoulders and esophagus) are AFMs. Additionally, we have a hypothesis that the estimation accuracy of CNNs is increased by removing AFMs. However, methods for automatically detecting and removing AFMs have not been sufficiently studied in previous research to improve the performance of CNNs. Therefore, we propose a method named “Removal Operation of Anomaly Feature Maps (RO-AFMs)” to automatically detect and remove AFMs. When applying an RO-AFM to the Global Average Pooling (GAP) feature vectors of a CNN, dimensions of the GAP vector are reduced. Therefore, an RO-AFM is regarded as a deep-feature selection algorithm. From the results of adopting an RO-AFM to a Regression CNN (R-CNN) for estimating pulmonary artery wedge pressure, which is one of the measurement score for representing cardiac anomaly state, improved reliability of AM and estimation accuracy were verified. A comparison of RO-AFM and the existing methods, i.e., Lasso and the Feature Selection Layer (FSL), indicated that RO-AFM performed slightly better on the estimation accuracy. The computation time required for RO-AFM to evaluate all features was 1.833 s on average, confirming that RO-AFM is a lightweight process. Therefore, RO-AFM is useful for constructing a medical CNN that emphasizes explainability (e.g., CNNs for estimating the risk of a disease or a test value from chest X-ray or computed tomography images).}
}
@article{CAO2024108245,
title = {Systematic evaluation of machine learning-enhanced trifocal IOL power selection for axial myopia cataract patients},
journal = {Computers in Biology and Medicine},
volume = {173},
pages = {108245},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108245},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524003299},
author = {Danmin Cao and Min Hu and Danlin Zhi and Jianheng Liang and Qian Tan and Qiong Lei and Maoyan Li and Hao Cheng and Li Wang and Weiwei Dai},
keywords = {Cataract, Axial myopia, Trifocal IOL, IOL formula, Machine learning},
abstract = {Purpose
This study aimed to evaluate and optimize intraocular lens (IOL) power selection for cataract patients with high axial myopia receiving trifocal IOLs.
Design
A multi-center, retrospective observational case series was conducted. Patients having an axial length ≥26 mm and undergoing cataract surgery with trifocal IOL implanted were studied.
Methods
Preoperative biometric and postoperative outcome data from 139 eyes were collected to train and test various machine learning (ML) models (support vector machine, linear regression, and stacking regressor) using five-fold cross-validation. The models' performance was further validated externally using data from 48 eyes enrolled from other hospitals. Performance of seven IOL calculation formulas (BUII, Kane, EVO, K6, DGS, Holladay I, and SRK/T) were examined with and without ML models.
Results
The results of cross-validation revealed improvements across all IOL calculation formulas, especially for K6 and Holladay I. The model increased the percentage of eyes with a prediction error (PE) within ±0.50 D from 71.94% to 79.14% for K6, and from 35.25% to 51.80% for Holladay I. In external validation involving 48 patients from other centers, six out of seven formulas demonstrated a reduction in the mean absolute error (MAE). K6's PE within ±0.50 D improved from 62.50% to 77.08%, and Holladay I from 16.67% to 58.33%.
Conclusions
In this study, we conducted a comprehensive evaluation of seven IOL power calculation formulas in high axial myopia cases and explored the effectiveness of the Stacking Regressor model in augmenting their accuracy. Of these formulas, K6 and Holladay I exhibited the most significant improvements, suggesting that integrating ML may have varying levels of effectiveness across different formulas but holds substantial promise in improving the predictability of IOL power calculations in patients with long eyes.}
}
@article{KARIWALA20131,
title = {Branch and bound method for regression-based controlled variable selection},
journal = {Computers & Chemical Engineering},
volume = {54},
pages = {1-7},
year = {2013},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2013.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0098135413000719},
author = {Vinay Kariwala and Lingjian Ye and Yi Cao},
keywords = {Branch and bound, Control structure design, Controlled variables, Combinatorial optimization, Distillation, Self-optimizing control},
abstract = {Self-optimizing control is a promising method for selection of controlled variables (CVs) from available measurements. Recently, Ye, Cao, Li, and Song (2012) have proposed a globally optimal method for selection of self-optimizing CVs by converting the CV selection problem into a regression problem. In this approach, the necessary conditions of optimality (NCO) are approximated by linear combinations of available measurements over the entire operation region. In practice, it is desired that a subset of available measurements be combined as CVs to obtain a good trade-off between the economic performance and the complexity of control system. The subset selection problem, however, is combinatorial in nature, which makes the application of the globally optimal CV selection method to large-scale processes difficult. In this work, an efficient branch and bound (BAB) algorithm is developed to handle the computational complexity associated with the selection of globally optimal CVs. The proposed BAB algorithm identifies the best measurement subset such that the regression error in approximating NCO is minimized and is also applicable to the general regression problem. Numerical tests using randomly generated matrices and a binary distillation column case study demonstrate the computational efficiency of the proposed BAB algorithm.}
}
@article{JIANG201591,
title = {Input-based adaptive randomized test case prioritization: A local beam search approach},
journal = {Journal of Systems and Software},
volume = {105},
pages = {91-106},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.03.066},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215000680},
author = {Bo Jiang and W.K. Chan},
keywords = {Regression testing, Adaptive test case prioritization, Randomized algorithm},
abstract = {Test case prioritization assigns the execution priorities of the test cases in a given test suite. Many existing test case prioritization techniques assume the full-fledged availability of code coverage data, fault history, or test specification, which are seldom well-maintained in real-world software development projects. This paper proposes a novel family of input-based local-beam-search adaptive-randomized techniques. They make adaptive tree-based randomized explorations with a randomized candidate test set strategy to even out the search space explorations among the branches of the exploration trees constructed by the test inputs in the test suite. We report a validation experiment on a suite of four medium-size benchmarks. The results show that our techniques achieve either higher APFD values than or the same mean APFD values as the existing code-coverage-based greedy or search-based prioritization techniques, including Genetic, Greedy and ART, in both our controlled experiment and case study. Our techniques are also significantly more efficient than the Genetic and Greedy, but are less efficient than ART.}
}
@article{SHEIKH20226789,
title = {An Optimized Test Case Minimization Technique Using Genetic Algorithm for Regression Testing},
journal = {Computers, Materials and Continua},
volume = {74},
number = {3},
pages = {6789-6806},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.028625},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822003484},
author = {Rubab Sheikh and Muhammad Imran Babar and Rawish Butt and Abdelzahir Abdelmaboud and Taiseer Abdalla {Elfadil Eisa}},
keywords = {Test case minimization, regression testing, testreduce, genetic algorithm, 100-dollar prioritization},
abstract = {Regression testing is a widely used approach to confirm the correct functionality of the software in incremental development. The use of test cases makes it easier to test the ripple effect of changed requirements. Rigorous testing may help in meeting the quality criteria that is based on the conformance to the requirements as given by the intended stakeholders. However, a minimized and prioritized set of test cases may reduce the efforts and time required for testing while focusing on the timely delivery of the software application. In this research, a technique named TestReduce has been presented to get a minimal set of test cases based on high priority to ensure that the web application meets the required quality criteria. A new technique TestReduce is proposed with a blend of genetic algorithm to find an optimized and minimal set of test cases. The ultimate objective associated with this study is to provide a technique that may solve the minimization problem of regression test cases in the case of linked requirements. In this research, the 100-Dollar prioritization approach is used to define the priority of the new requirements.}
}
@article{TVARDOVSKII2024103053,
title = {Testing and incremental conformance testing of timed state machines},
journal = {Science of Computer Programming},
volume = {233},
pages = {103053},
year = {2024},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2023.103053},
url = {https://www.sciencedirect.com/science/article/pii/S0167642323001351},
author = {Aleksandr Tvardovskii and Khaled El-Fakih and Nina Yevtushenko},
keywords = {Conformance testing, Model-based testing, Incremental regression testing, Software evolution and maintenance, Timed finite state machines},
abstract = {We present methods for testing and incremental testing of systems modeled as finite state machines with timeouts (TFSMs). For testing, we establish an appropriate fault model and show how a complete test suite can be derived for a given TFSM specification using traditional FSM-based test derivation approaches considering an untimed FSM abstraction of the given specification. In addition, we consider reducing the cost of testing a modified or an evolving TFSM specification by the selection of appropriate incremental test suites that can verify whether the modified parts of a modified specification are correctly implemented in a corresponding implementation under test. In particular, we define the incremental testing problem for TFSMs and investigate appropriate fault models that can be used for incremental test derivation and accordingly propose related test selection algorithms. According to conducted experiments length and run time (sum of time delays) of obtained test suites are much lower than their theoretic upper bounds; in some cases, these bounds are linear. In addition, for incremental testing, when the modified part is up to 20% of the whole specification, length and run time of incremental test suites are at least twice as less than those obtained using the whole modified specification.}
}
@article{KANTARAKIAS2023112377,
title = {Sensitivity-enhanced generalized polynomial chaos for efficient uncertainty quantification},
journal = {Journal of Computational Physics},
volume = {491},
pages = {112377},
year = {2023},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2023.112377},
url = {https://www.sciencedirect.com/science/article/pii/S0021999123004722},
author = {Kyriakos D. Kantarakias and George Papadakis},
keywords = {Uncertainty quantification, Generalised polynomial chaos, Sensitivity-enhanced  minimisation, Optimal sampling of stochastic space},
abstract = {We consider the Least Squares (LSQ) regression method for Uncertainty Quantification (UQ) using generalised polynomial chaos (gPC) and augment the linear system with the gradient of the Quantity of Interest (QoI) with respect to the stochastic variables. The gradient is computed very efficiently for all variables from the adjoint system of equations. To minimise the condition number of the augmented LSQ system, an effective sampling strategy of the stochastic space is required. We compare two strategies. In the first, we apply pivoted QR decomposition to the standard LSQ matrix and evaluate both the QoI and its gradient at the sample points identified. In the second strategy, we apply QR decomposition directly to the augmented matrix. We find that the first strategy is more efficient in terms of accuracy vs number of evaluations. We call the new approach sensitivity-enhanced generalised polynomial chaos, or se-gPC, and apply it to several test cases including an aerodynamic case with 40 stochastic parameters. The method can produce accurate estimations of the statistical moments using a small number of sampling points. The computational cost scales as ∼mp−1, instead of ∼mp of the standard LSQ formulation, where m is the number of stochastic variables and p the chaos order. The solution of the adjoint system of equations is implemented in many computational mechanics packages, thus the infrastructure exists for the application of the method to a wide variety of engineering problems.}
}
@article{MINHAS2020106254,
title = {Regression testing for large-scale embedded software development – Exploring the state of practice},
journal = {Information and Software Technology},
volume = {120},
pages = {106254},
year = {2020},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.106254},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919302721},
author = {Nasir Mehmood Minhas and Kai Petersen and Jürgen Börstler and Krzysztof Wnuk},
keywords = {Regression testing, Practices, Challenges, Goals, Multi-case study},
abstract = {Context
A majority of the regression testing techniques proposed by academics have not been adopted in industry. To increase adoption rates, we need to improve our understanding of the practitioners’ perspectives on regression testing.
Objective
This study aims at exploring the regression testing state of practice in the large-scale embedded software development. The study has two objectives: 1) to highlight the potential challenges in practice, and 2) to identify the industry-relevant research areas regarding regression testing.
Method
We conducted a qualitative study in two large-scale embedded software development companies, where we carried out semi-structured interviews with representatives from five software testing teams.
Results
The practitioners run regression testing mostly with limited scope based on the size, complexity, and location of the change. Test cases are prioritized on the basis of risk and critical functionality. The practitioners rely on their knowledge and experience for the decision making regarding selection and prioritization of test cases. The companies are using both automated and manual regression testing, and mainly rely on in-house developed tools for test automation. The challenges identified in the companies are: time to test, information management, test suite maintenance, lack of communication, test selection/prioritization, lack of assessment, etc. Regression testing goals identified in this study are customer satisfaction, critical defect detection, confidence, effectiveness, efficiency, and controlled slip through of faults.
Conclusions
Considering the current state of practice and the identified challenges we conclude that there is a need to reconsider the regression test strategy in the companies. Researchers need to analyze the industry perspective when proposing new regression testing techniques.}
}
@article{POUDYAL2025101128,
title = {Exploring cement Production's role in GDP using explainable AI and sustainability analysis in Nepal},
journal = {Case Studies in Chemical and Environmental Engineering},
volume = {11},
pages = {101128},
year = {2025},
issn = {2666-0164},
doi = {https://doi.org/10.1016/j.cscee.2025.101128},
url = {https://www.sciencedirect.com/science/article/pii/S2666016425000350},
author = {Ramhari Poudyal and Biplov Paneru and Bishwash Paneru and Tilak Giri and Bibek Paneru and Tim Reynolds and Khem Narayan Poudyal and Mohan B. Dangi},
keywords = {Energy conservation, Machine learning, SHAP analysis, Guided user interface (GUI), Energy efficiency, Energy management, Sustainability, UCIL},
abstract = {Due to rising demand, the worldwide cement market is expected to increase from $340.61 billion in 2022 to $481.73 billion by 2029. Quarrying, raw material processing, and calcination are steps in cement production. The societies in India and Nepal have to deal with environmental issues such as air pollution, resource depletion, and the effects of climate change. A case study of Nepal's Udayapur Cement Industry Limited (UCIL) exposed antiquated production methods that reduce energy efficiency. Utilizing regression models like Extra Trees (Extremely Randomized Trees) Regressor, CatBoost (Categorial Boosting) Regressor, and XGBoost (eXtreme Gradient Boosting) Regressor, Random Forest and Ensemble of Sparse Embedded Trees (SET) machine learning is used to examine the demand, supply, and Gross Domestic Product (GDP) performance of cement manufacturing in India which shares a common cement related infrastructure to Nepal. Since businesses understand how important sustainability is to attract new customers and minimizing environmental effects, our study emphasizes the necessity of sustainable practices in the cement production industry. On evaluation, the Extra Trees Regressor showed strong performance, along with the SET (Stacking) model, which was further validated using a nested cross-validation technique. Random Forest, on the other hand, had trouble; it displayed the greatest RMSE (15617.85) and the lowest testing (0.8117), suggesting poorer generalization. The SET (Stacking) Ensemble model gained a testing R2 score (0.9372) and a testing RMSE (9019.76). In cross-validation, the Extra Trees model with a mean cross-validation R2 score of 0.93 and a low standard deviation of 0.04 proved to be the best-performing model, as evidenced by lower differences in R2 score across folds compared to other models, demonstrating its high predictive performance. The SHAP (SHapley Additive exPlanations) interpretability analysis indicates that population is the primary factor influencing GDP estimates. A Tkinter-based application was also developed to forecast GDP using the training model. To attain sustainability and lessen the effects of climate change on the cement sector, these findings highlight the adoption of cutting-edge technologies and energy-efficient procedures.}
}
@article{BANIAS2019119,
title = {Test case selection-prioritization approach based on memoization dynamic programming algorithm},
journal = {Information and Software Technology},
volume = {115},
pages = {119-130},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S095058491930134X},
author = {Ovidiu Banias},
keywords = {Software testing, Test case selection, Test case prioritization, Dynamic programming, Algorithms},
abstract = {Context
In the software industry, selection and prioritization techniques become a necessity in the regression and validation testing phases because a lot of test cases are available for reuse, yet time and project specific constraints must be respected.
Objective
In this paper we propose a dynamic programming approach in solving test case selection-prioritization problems. We focus on low memory consumption in pseudo-polynomial time complexity applicable in both selection and selection-prioritization problems over sets of test cases or test suites. In dynamic programming optimization solutions, huge amounts of memory are required and unfortunately the memory is limited. Therefore, lower memory consumption leads to a higher number of test cases to be involved in the selection process.
Method
Our approach is suited for medium to large projects where the required memory space is not higher than the order of tens of GBytes. We employed both objective methods as the dynamic programming algorithm and subjective and empiric human decision as defining the prioritization criteria. Furthermore, we propose a method of employing multiple project specific criteria in evaluating the importance of a test case in the project context.
Results
To evaluate the proposed solution relative to the classical dynamic programming knapsack solution, we developed a suite of comparative case studies based on 1000 generated scenarios as close as possible to real project scenarios. The results of the comparative study reported the proposed algorithm requires up to 400 times less memory in the best-case scenarios and about 40 times less memory in average.
Conclusion
The solution delivers optimal results in pseudo-polynomial time complexity, is effective for amounts of test cases up to the order of millions and compared with the classical dynamic programming methods leads to higher number of test cases to be involved in the selection process due to reduced memory consumption.}
}
@article{HASSAN2025104332,
title = {Ensemble learning of deep CNN models and two stage level prediction of Cobb angle on surface topography in adolescents with idiopathic scoliosis},
journal = {Medical Engineering & Physics},
volume = {140},
pages = {104332},
year = {2025},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2025.104332},
url = {https://www.sciencedirect.com/science/article/pii/S1350453325000517},
author = {Mostafa Hassan and Jose Maria {Gonzalez Ruiz} and Nada Mohamed and Thomaz Nogueira Burke and Qipei Mei and Lindsey Westover},
keywords = {Adolescent idiopathic scoliosis, Convolutional neural network, Cobb angle, Surface topography, Medical imaging, Deep learning},
abstract = {This study employs Convolutional Neural Networks (CNNs) as feature extractors with appended regression layers for the non-invasive prediction of Cobb Angle (CA) from Surface Topography (ST) scans in adolescents with Idiopathic Scoliosis (AIS). The aim is to minimize radiation exposure during critical growth periods by offering a reliable, non-invasive assessment tool. The efficacy of various CNN-based feature extractors—DenseNet121, EfficientNetB0, ResNet18, SqueezeNet, and a modified U-Net—was evaluated on a dataset of 654 ST scans using a regression analysis framework for accurate CA prediction. The dataset comprised 590 training and 64 testing scans. Performance was evaluated using Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and accuracy in classifying scoliosis severity (mild, moderate, severe) based on CA measurements. The EfficientNetB0 feature extractor outperformed other models, demonstrating strong performance on the training set (R=0.96, R=20.93) and achieving an MAE of 6.13∘ and RMSE of 7.5∘ on the test set. In terms of scoliosis severity classification, it achieved high precision (84.62%) and specificity (95.65% for mild cases and 82.98% for severe cases), highlighting its clinical applicability in AIS management. The regression-based approach using the EfficientNetB0 as a feature extractor presents a significant advancement for accurately determining CA from ST scans, offering a promising tool for improving scoliosis severity categorization and management in adolescents.}
}
@article{PIRESJUNIOR2023112628,
title = {Ensemble learning application in multiplexed optical fibser sensor system for liquid level assessment},
journal = {Measurement},
volume = {211},
pages = {112628},
year = {2023},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2023.112628},
url = {https://www.sciencedirect.com/science/article/pii/S0263224123001926},
author = {Robertson Pires-Junior and Arnaldo Leal-Junior},
keywords = {Optical fiber sensors, Polymer optical fibers, Liquid level assessment, Liquid identification, Machine learning, Ensemble learning},
abstract = {This paper presents the development and analysis of a sensor system based on multiplexed intensity variation sensors using a polymer optical fiber (POF). The sensor is based on a multiplexing technique from side-coupling of light emitting diodes (LEDs) with the sequential activation of the light sources. In this case, 20 sensors are developed from the side-coupling between the lateral section of the POF and each LED. The sensor system is embedded in a polydimethylsiloxane (PDMS) resin for encapsulation, chemical and mechanical protection of the sensors. The sensors sensitivities as a function of the refractive index and pressure are experimentally obtained. Then, the sensors are positioned inside an acrylic tank for the liquid level measurement and the water and oil identification. The tests using water and oil mixtures in the tank are performed to evaluate the possibility of measuring water and oil levels. To that extent, an ensemble learning algorithm using random forest (RF) is applied on the responses of the 20 sensors to obtain the level of each fluid. In addition, the algorithm's parameters of the RF approach are optimized using the minimization of root mean squared error (RMSE) as the objective. The dataset are divided into train and test samples with an additional dataset used as validation of the proposed RF-based regression model. Results show the feasibility of the proposed sensor system, where the mean errors for water and total levels are 0.14 cm and 0.08 cm, respectively. In the validation tests, a determination coefficient (R2) of 0.99 is obtained and a RMSE of 3.51 cm and 2.69 cm for water and total levels, respectively.}
}
@article{SONG2024105850,
title = {Probabilistic prediction of uniaxial compressive strength for rocks from sparse data using Bayesian Gaussian process regression with Synthetic Minority Oversampling Technique (SMOTE)},
journal = {Computers and Geotechnics},
volume = {165},
pages = {105850},
year = {2024},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2023.105850},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X23006079},
author = {Chao Song and Tengyuan Zhao and Ling Xu and Xiaolin Huang},
keywords = {Data-driven approach, Site investigation, Sparse data, Feature selection, Machine learning},
abstract = {Uniaxial compressive strength (UCS) of rocks is one of key rock strength parameters. Generally speaking, UCS can be measured directly through uniaxial compression tests, which is often unfeasible, especially when intact rock samples are highly fragile. Alternatively, the UCS of rocks can be estimated indirectly from other easily available rock indices. Note that adequate measurement data is the prerequisite for the accurate estimation of UCS using indirect methods. This may be difficult to achieve due to the limitation of time and budget, especially for small- to medium-sized projects. In this case, it becomes a challenging issue on how to develop a robust and reliable model for UCS estimation using the sparse measurement data. A fully Bayesian Gaussian process regression (fB-GPR) approach with Synthetic Minority Oversampling Technique (SMOTE) is proposed in this paper to address this problem. A real-life example from Malaysia was used for illustration and validation of proposed method. Results showed that when the synthetic sample size in SMOTE reaches 30 (i.e., optimal synthetic sample size), the coefficient of determination (R2) increases by about 18.92%, and the accuracy of feature selection reaches 98%, compared with the scenario with only sparse measurement data used for fB-GPR model development.}
}
@article{DOBSLAW2023111802,
title = {Generic and industrial scale many-criteria regression test selection},
journal = {Journal of Systems and Software},
volume = {205},
pages = {111802},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111802},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223001978},
author = {Felix Dobslaw and Ruiyuan Wan and Yuechan Hao},
keywords = {Software testing, Regression testing, Test case selection, Industrial-scale optimization},
abstract = {While several test case selection algorithms (heuristic and optimal) and formulations (linear and non-linear) have been proposed, no multi-criteria framework enables Pareto search — the state-of-the-art approach of doing multi-criteria optimization. Therefore, we introduce the highly parallelizable, openly available Many-Criteria Test-Optimization Algorithm (MC-TOA) framework that combines heuristic Pareto search and optimality gap knowledge per criterion. MC-TOA is largely agnostic to the criteria formulations and can incorporate many criteria where existing approaches offer limited scope (single or few objectives/constraints), lack flexibility in the expression and assurance of constraints, or run into problem complexity issues. For two large-scale systems with up to six criteria and thousands of system test cases, MC-TOA not only produces, over the board, superior Pareto fronts in terms of HVI score compared to the state-of-the-art many-objective heuristic baseline, it also does that within minutes of runtime for worst-case executions, i.e., assuming that a regression affects the entire test-suite. MC-TOA depends on convex solvers. We find that the evaluated open-source solvers are slower but suffice for smaller systems, while being less robust for larger systems. Linear formulations execute faster and obtain near-optimal results, which led to faster and better overall convergence of MC-TOA compared to integer formulations. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
@article{SALAHSHOOR2023115657,
title = {Model-free Data-Driven viscoelasticity in the frequency domain},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {403},
pages = {115657},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2022.115657},
url = {https://www.sciencedirect.com/science/article/pii/S0045782522006120},
author = {Hossein Salahshoor and Michael Ortiz},
keywords = {Viscoelasticity, Frequency domain, Data-Driven computing, Model-free computing, Machine learning},
abstract = {We develop a Data-Driven framework for the simulation of wave propagation in viscoelastic solids directly from dynamic testing material data, including data from Dynamic Mechanical Analysis (DMA), nano-indentation, Dynamic Shear Testing (DST) and Magnetic Resonance Elastography (MRE), without the need for regression or material modeling. The problem is formulated in the frequency domain and the method of solution seeks to minimize a distance between physically admissible histories of stress and strain, in the sense of compatibility and equilibrium, and the material data. We metrize the space of histories by means of the flat-norm of their Fourier transform, which allows consideration of infinite wave trains such as harmonic functions. Another significant advantage of the flat norm is that it allows the response of the system at one frequency to be inferred from data at nearby frequencies. We demonstrate and verify the approach by means of two test cases, a polymeric truss structure characterized by DMA data and a 3D soft gel sample characterized by MRE data. The examples demonstrate the ease of implementation of the Data-Driven scheme within conventional commercial codes and its robust convergence properties, both with respect to the solver and the data.}
}
@article{CHAUHAN2024109945,
title = {On active learning for Gaussian process-based global sensitivity analysis},
journal = {Reliability Engineering & System Safety},
volume = {245},
pages = {109945},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2024.109945},
url = {https://www.sciencedirect.com/science/article/pii/S0951832024000206},
author = {Mohit S. Chauhan and Mariel Ojeda-Tuz and Ryan A. Catarelli and Kurtis R. Gurley and Dimitrios Tsapetis and Michael D. Shields},
keywords = {Sobol index, Active learning, Global sensitivity analysis, Gaussian process regression, Kriging},
abstract = {This paper explores the application of active learning strategies to adaptively learn Sobol indices for global sensitivity analysis. We demonstrate that active learning for Sobol indices poses unique challenges due to the definition of the Sobol index as a ratio of variances estimated from Gaussian process surrogates. Consequently, learning strategies must either focus on convergence in the numerator or the denominator of this ratio. However, rapid convergence in either one does not guarantee convergence in the Sobol index. We propose a novel strategy for active learning that focuses on resolving the main effects of the Gaussian process (associated with the numerator of the Sobol index) and compare this with existing strategies based on convergence in the total variance (the denominator of the Sobol index). The new strategy, implemented through a new learning function termed the MUSIC (minimize uncertainty in Sobol index convergence), generally converges in Sobol index error more rapidly than the existing strategies based on the Expected Improvement for Global Fit (EIGF) and the Variance Improvement for Global Fit (VIGF). Both strategies are compared with simple sequential random sampling and the MUSIC learning function generally converges most rapidly for low-dimensional problems. However, for high-dimensional problems, the performance is comparable to random sampling. The new learning strategy is demonstrated for a practical case of adaptive experimental design for large-scale Boundary Layer Wind Tunnel experiments.}
}
@article{TAHVILI201826,
title = {ESPRET: A tool for execution time estimation of manual test cases},
journal = {Journal of Systems and Software},
volume = {146},
pages = {26-41},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301778},
author = {Sahar Tahvili and Wasif Afzal and Mehrdad Saadatmand and Markus Bohlin and Sharvathul Hasan Ameerjan},
keywords = {Software testing, Execution time, Test specification, Optimization, Manual testing, Regression analysis},
abstract = {Manual testing is still a predominant and an important approach for validation of computer systems, particularly in certain domains such as safety-critical systems. Knowing the execution time of test cases is important to perform test scheduling, prioritization and progress monitoring. In this work, we present, apply and evaluate ESPRET (EStimation and PRediction of Execution Time) as our tool for estimating and predicting the execution time of manual test cases based on their test specifications. Our approach works by extracting timing information for various steps in manual test specification. This information is then used to estimate the maximum time for test steps that have not previously been executed, but for which textual specifications exist. As part of our approach, natural language parsing of the specifications is performed to identify word combinations to check whether existing timing information on various test steps is already available or not. Since executing test cases on the several machines may take different time, we predict the actual execution time for test cases by a set of regression models. Finally, an empirical evaluation of the approach and tool has been performed on a railway use case at Bombardier Transportation (BT) in Sweden.}
}
@article{KHATIBSYARBINI201874,
title = {Test case prioritization approaches in regression testing: A systematic literature review},
journal = {Information and Software Technology},
volume = {93},
pages = {74-93},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2017.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0950584916304888},
author = {Muhammad Khatibsyarbini and Mohd Adham Isa and Dayang N.A. Jawawi and Rooster Tumeng},
keywords = {Test case prioritization, Regression testing, Software testing, Systematic literature review},
abstract = {Context
Software quality can be assured by going through software testing process. However, software testing phase is an expensive process as it consumes a longer time. By scheduling test cases execution order through a prioritization approach, software testing efficiency can be improved especially during regression testing.
Objective
It is a notable step to be taken in constructing important software testing environment so that a system's commercial value can increase. The main idea of this review is to examine and classify the current test case prioritization approaches based on the articulated research questions.
Method
Set of search keywords with appropriate repositories were utilized to extract most important studies that fulfill all the criteria defined and classified under journal, conference paper, symposiums and workshops categories. 69 primary studies were nominated from the review strategy.
Results
There were 40 journal articles, 21 conference papers, three workshop articles, and five symposium articles collected from the primary studies. As for the result, it can be said that TCP approaches are still broadly open for improvements. Each approach in TCP has specified potential values, advantages, and limitation. Additionally, we found that variations in the starting point of TCP process among the approaches provide a different timeline and benefit to project manager to choose which approaches suite with the project schedule and available resources.
Conclusion
Test case prioritization has already been considerably discussed in the software testing domain. However, it is commonly learned that there are quite a number of existing prioritization techniques that can still be improved especially in data used and execution process for each approach.}
}
@article{MIRZEHIKALATEHKAZEMI2023200061,
title = {Application of XGB-based metaheuristic techniques for prediction time-to-failure of mining machinery},
journal = {Systems and Soft Computing},
volume = {5},
pages = {200061},
year = {2023},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2023.200061},
url = {https://www.sciencedirect.com/science/article/pii/S2772941923000145},
author = {Mohammad {Mirzehi Kalateh Kazemi} and Zohreh Nabavi and Mojtaba Rezakhah and Ali Masoudi},
keywords = {XGB-based hybrid model, Failure time data, extreme gradient boosting (XGB), particle swarm optimization (PSO), gray wolf optimization (GWO), Metaheuristic optimization},
abstract = {Mining equipment is a critical component in the success of mining operations, and unplanned downtime can be costly. Efficient and intelligent maintenance planning is therefore essential to minimize downtime and maximize productivity. Consecutive time-to-failure (TTF) is an important indicator of machine reliability, and accurate TTF predictions enable effective preventive maintenance planning. Therefore, this study proposes hybrid models of extreme gradient boosting (XGB), optimized by particle swarm optimization (PSO) and gray wolf optimization (GWO), for the prediction of TTF in mining machinery. Additionally, validation of the hybrid model was conducted using support vector regression (SVR) method. Historical data on mining machine failures were collected, and a case study was conducted to investigate shovels in an open-pit mine. The PSO-XGB method was found to be the most accurate predictor of failure time with R2 values of 0.99, RMSE values of 50.66 and 51.77, MAE values of 4.52 and 10.81, and AARE values of 1.15 and 1.24 in the training and testing phases. This research highlights the importance of efficient and intelligent maintenance planning to minimize downtime and optimize productivity in mining operations.}
}
@article{RAD2025105809,
title = {Tackling the small imbalanced horizontal dataset regressions by Stability Selection and SMOGN: a case study of ventilation-free days prediction in the pediatric intensive care unit and the importance of PRISM},
journal = {International Journal of Medical Informatics},
volume = {196},
pages = {105809},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.105809},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625000267},
author = {Milad Rad and Alireza Rafiei and Jocelyn Grunwell and Rishikesan Kamaleswaran},
keywords = {Synthetic data, Machine learning, Ventilation-free days, Data imbalance, Critical care},
abstract = {Objective
The regression of small imbalanced horizontal datasets is an important problem in bioinformatics due to rare but vital data points impacting model performance. Most clinical studies suffer from imbalance in their distribution which impacts the learning ability of regression or classification models. The imbalance once combined with the small number of samples reduces the prediction performance. An improvement in the trainability of small imbalanced datasets hugely improves the potency of current prediction models that rely on a small set of valuable expensive samples.
Materials and methods
A method called Stability Selection has been used to overcome the high dimensionality problem, which arises when the sample sizes are relatively small compared to the number of features. The method was used to improve the performance of the Synthetic Minority Over-Sampling Technique for Regression with Gaussian Noise (SMOGN), an imbalance removal algorithm. To test the new pipeline, a small imbalanced cohort of pediatric ICU patients was used to predict the number of Ventilator-Free Days (VFD) a patient may experience for an admission period of 28 days due to respiratory illnesses.
Results
Our model demonstrated its effectiveness by overcoming label imbalance while predicting almost all the non-surviving patients in the test dataset using Stability Selection before applying SMOGN. Our study also highlighted the importance of Pediatrics Risk of Mortality (PRISM) as a powerful VFD predictor if combined with other clinical features.
Conclusion
This paper shows how a hybrid strategy of Stability Selection, SMOGN, and regression can improve the outcome of highly imbalanced datasets and reduce the probability of highly expensive false negative detections in severe acute respiratory disease syndrome cases. The proposed modeling pipeline can reduce the overall VFD regression error but is also expandable to other regressable features. We also showed the importance of PRISM as a strong VFD predictor.}
}
@article{HOKINOYAMAGUTI2020104198,
title = {Development of CART model for prediction of tuberculosis treatment loss to follow up in the state of São Paulo, Brazil: A case–control study},
journal = {International Journal of Medical Informatics},
volume = {141},
pages = {104198},
year = {2020},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2020.104198},
url = {https://www.sciencedirect.com/science/article/pii/S1386505619314133},
author = {Verena {Hokino Yamaguti} and Domingos Alves and Rui Pedro {Charters Lopes Rijo} and Newton Shydeo {Brandão Miyoshi} and Antônio Ruffino-Netto},
keywords = {Tuberculosis, Treatment loss to follow up, Prediction model, Feature selection},
abstract = {Background
Tuberculosis is the leading cause of infectious disease-related death, surpassing even the immunodeficiency virus. Treatment loss to follow up and irregular medication use contribute to persistent morbidity and mortality. This increases bacillus drug resistance and has a negative impact on disease control.
Objective
This study aims to develop a computational model that predicts the loss to follow up treatment in tuberculosis patients, thereby increasing treatment adherence and cure, reducing efforts regarding treatment relapses and decreasing disease spread.
Methods
This is a case-controlled study. Included in the data set were 103,846 tuberculosis cases from the state of São Paulo. They were collected using the TBWEB, an information system used as a tuberculosis treatment monitor, containing samples from 2006 to 2016. This set was later resampled into 6 segments with a 1-1 ratio. This ratio was used to avoid any bias during the model construction.
Results
The Classification and Regression Trees were used as the prediction model. Training and test sets accounted for 70% in the former and 30% in the latter of the tuberculosis cases. The model displayed an accuracy of 0.76, F-measure of 0.77, sensitivity of 0.80 and specificity of 0.71. The model emphasizes the relationship between several variables that had been identified in previous studies as related to patient cure or loss to follow up treatment in tuberculosis patients.
Conclusion
It was possible to construct a predictive model for loss to follow up treatment in tuberculosis patients using Classification and Regression Trees. Although the fact that the ideal predictive ability was not achieved, it seems reasonable to propose the use of Classification and Regression Trees models to predict likelihood of treatment follow up to support healthcare professionals in minimising the loss to follow up.}
}
@article{NGUYEN2022111299,
title = {In situ measurement of fish color based on machine vision: A case study of measuring a clownfish’s color},
journal = {Measurement},
volume = {197},
pages = {111299},
year = {2022},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2022.111299},
url = {https://www.sciencedirect.com/science/article/pii/S0263224122005401},
author = {Chanh-Nghiem Nguyen and Van-Thoai Vo and Lam-Hong-Ngoc Nguyen and Hua {Thai Nhan} and Chi-Ngon Nguyen},
keywords = {Clownfish color, Ridge regression, Brightness adjustment, In situ color measurement of ornamental fish, CIEDE2000},
abstract = {This study proposed an innovative technique to measure the fish color in situ based on machine vision to avoid potential effects on fish health that might result from conventional measurement with a colorimeter. The research goal was achieved by developing a color conversion model trained with images of a color reference target in the ambient environment and clay samples in the aquarium representing the target fish. Brightness adjustment was effectively applied to these images to minimize uneven illumination in both environments. The generalization ability of the model was ensured with regularized regression. Consequently, an optimal cubic ridge model was obtained with appreciably low training and testing mean color errors of 1.17 ± 0.64 and 1.10 ± 0.50 CIEDE2000 color difference units, respectively. Preliminary results of measuring the clownfish color showed that the proposed system had much potential for in situ and non-invasive visualizing of the color distribution of small ornamental fish with color non-uniformity.}
}
@article{MONDAL2019110403,
title = {Mahtab: Phase-wise acceleration of regression testing for C},
journal = {Journal of Systems and Software},
volume = {158},
pages = {110403},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110403},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301773},
author = {Shouvick Mondal and Rupesh Nasre},
keywords = {Regression test selection, Test-prioritization, Parallelization window, Relevance-and-confinedness},
abstract = {Software regression testing consists of offline, online, and execution phases which are executed sequentially. The offline phase involves code instrumentation and test-coverage collection. Subsequently, the online phase performs program differencing, test-suite selection and prioritization. Finally, the selected test-cases are executed against the new version of software for its re-validation. Regression testing is a time-consuming process and is often on the critical path of the project. To improve the turn-around time of software development cycle, our goal is to reduce regression testing time across all phases using multi-core parallelization. This poses several challenges that stem from I/O, dependence on third-party libraries, and inherently sequential components in the overall testing process. We propose parallelization test-windows to effectively partition test-cases across threads. To measure the benefit of prioritization coupled with multi-threaded execution, we propose a new metric, EPSilon, for rewarding failure observation frequency in the timeline of test-execution. To measure the rate of code-change coverage due to regression test prioritization, we introduce ECC, a variant of the widely used APFD metric. We illustrate the effectiveness of our approach using the popular Software-artifact Infrastructure Repository (SIR) and five real-world projects from GitHub.}
}
@article{JUNG2019110419,
title = {Automated code-based test selection for software product line regression testing},
journal = {Journal of Systems and Software},
volume = {158},
pages = {110419},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110419},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301931},
author = {Pilsu Jung and Sungwon Kang and Jihyun Lee},
keywords = {Product lines testing, Regression test selection, Software maintenance, Software evolution},
abstract = {Regression testing for software product lines (SPLs) is challenging and can be expensive because it must ensure that all the products of a product family are correct whenever changes are made. SPL regression testing can be made efficient through a test case selection method that selects only the test cases relevant to the changes. Some approaches for SPL test case selection have been proposed but either they were not efficient by requiring intervention from human experts or they cannot be used if requirements specifications, architecture and/or traceabilities for test cases are not available or partially eroded. To address these limitations, we propose an automated method of source code-based regression test selection for SPLs. Our method reduces the repetition of the selection procedure and minimizes the in-depth analysis effort for source code and test cases based on the commonality and variability of a product family. Evaluation results of our method using six product lines show that our method reduces the overall time to perform regression testing by 14.8% ∼ 49.1% on average compared to an approach of repetitively applying Ekstazi, which is the state-of-the-art regression test selection method for a single product, to each product of a product family.}
}
@article{IBRAHIM2025111481,
title = {Impacts of climate change on energy-saving sensitivity of residential building envelope design parameters in three hot-dry cities},
journal = {Journal of Building Engineering},
volume = {99},
pages = {111481},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.111481},
url = {https://www.sciencedirect.com/science/article/pii/S2352710224030493},
author = {Ahmed J. Ibrahim and Dnya D. Zangana and Sheng Liu and Holly Samuelson and Linchuan Yang},
keywords = {Sensitivity analysis, Energy consumption, Climate resilience, Climate change projections, Envelope design parameters},
abstract = {Warming climatic conditions are projected to intensify extreme heat events, especially in hot climates, affecting the energy-saving effectiveness of various building envelope design parameters. However, limited studies exist on the energy-saving sensitivity of building envelope design parameters for residential buildings in hot and dry climates under future climate change. This study aims to fill this gap by examining typical residential buildings in three cities in Iraq, classified as hot desert, hot semiarid, and Mediterranean. First, the most common type of residential building was selected as a case study, and its energy modeling was validated using measured energy bills. Second, future climatic weather files were constructed using the latest general circulation models to assess their impacts on building energy consumption. Third, the energy-saving sensitivity of applicable building envelope design parameters under different future climatic conditions was obtained through local and global sensitivity analysis methods. The results of global sensitivity analysis indicate that the solar heat gain coefficient of windows, the specific heat of exterior walls, and the projection of side fins are the most important factors, with standardized regression coefficients (SRC) ranging from −0.92 to 0.62. Notably, the SRC of windows' solar heat gain coefficient is expected to increase under future climate scenarios. In contrast, the significance of the specific heat of exterior walls depends on local climates. This study provides insights for policymakers and architects to prioritize building envelope design strategies that enhance the climate resilience of residential buildings.}
}
@article{ENGBERS2024597,
title = {Unsupervised Model Selection for Assembly Process Optimization},
journal = {Procedia CIRP},
volume = {130},
pages = {597-603},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.135},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124012927},
author = {Hendrik Engbers and Dirk Schweers and Michael Freitag},
keywords = {Model Selection, Anomaly Detection, Process Data, Assembly Assistance System},
abstract = {Manufacturing systems generate large amounts of data, but the availability of appropriate labels for training and systematically evaluating machine learning algorithms can be limited. This makes it difficult to compare different models and select the most effective one for a specific use case. Therefore, we propose a method that aims at predicting conventional model evaluation metrics to support the selection of the most appropriate algorithm and its hyperparameters. The proposed method uses a Gradient Boosting Regressor (GBR) that integrates the Calinski-Harabasz Index (CHI) of different unsupervised anomaly detection algorithms as a suitability indicator. As a result, this method does not require labeled data, benefits from fast processing, and can be fully automated. We have applied this approach to an industrial assembly assistance system and tested it on over 10,000 publicly available datasets. Our experiments show improvements in prediction performance, measured in terms of precision against the best single candidate, with an average increase of 58% and a median increase of 200%. In addition, recall shows an average increase of 62% and a median increase of 300%.}
}
@article{MOHAMAD2025104833,
title = {Machine learning predictive performance in road accident severity: A case study from Thailand},
journal = {Results in Engineering},
volume = {26},
pages = {104833},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.104833},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025009089},
author = {Ittirit Mohamad and Sajjakaj JomnonKwao and Vatanavongs Ratanavaraha},
keywords = {Machine learning, Comparative analysis, Road safety, Accident severity, Deep learning, Transportation, Risk assessment, Logistics, Big data},
abstract = {Traffic accidents remain a major cause of fatalities and economic losses worldwide, necessitating the development of accurate predictive models for enhancing road safety and minimizing risks. In Thailand, where road traffic injuries persist as a public health challenge, data-driven approaches can significantly contribute to accident prevention strategies. This study evaluates the predictive performance of multiple supervised machine learning algorithms in classifying accident severity, addressing the gap in prior research that lacks a comparative analysis of multiple models trained on large-scale crash data. Eight algorithms were assessed, including Decision Tree (DT), Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbors (kNN), Neural Network (NN), Naïve Bayes (NB), Logistic Regression (LR), and Gradient Boosting (GB).A dataset comprising 112,837 road accidents over a five-year period in Thailand was analyzed, focusing exclusively on incidents where drivers were at fault. The dataset underwent extensive preprocessing, including missing value imputation, data balancing checks, and feature selection to ensure robustness. Among the models tested, Random Forest demonstrated superior performance in the binary classification task, achieving an average class AUC of 0.768, classification accuracy of 0.777, precision of 0.752, and recall of 0.777. Key predictive features include road type (highway), speeding, time of day (daylight), absence of lighting at night, and driver gender. While the model effectively classifies non-fatal accidents, its recall for fatalities remains limited (0.198), highlighting challenges in predicting fatal crashes due to the complex interplay of contributing factors.These findings reinforce the applicability of machine learning in traffic safety research and provide valuable insights for policymakers seeking data-driven interventions. Future work should explore advanced feature engineering and ensemble techniques to enhance fatality prediction accuracy.}
}
@article{PRADOLIMA2020106268,
title = {Test Case Prioritization in Continuous Integration environments: A systematic mapping study},
journal = {Information and Software Technology},
volume = {121},
pages = {106268},
year = {2020},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106268},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920300185},
author = {Jackson A. {Prado Lima} and Silvia R. Vergilio},
keywords = {Software testing, Continuous Integration, Test Case Prioritization},
abstract = {Context: Continuous Integration (CI) environments allow frequent integration of software changes, making software evolution more rapid and cost-effective. In such environments, the regression test plays an important role, as well as the use of Test Case Prioritization (TCP) techniques. Such techniques attempt to identify the test case order that maximizes certain goals, such as early fault detection. This research subject has been raising interest because some new challenges are faced in the CI context, as TCP techniques need to consider time constraints of the CI environments. Objective: This work presents the results of a systematic mapping study on Test Case Prioritization in Continuous Integration environments (TCPCI) that reports the main characteristics of TCPCI approaches and their evaluation aspects. Method: The mapping was conducted following a plan that includes the definition of research questions, selection criteria and search string, and the selection of search engines. The search returned 35 primary studies classified based on the goal and kind of used TCP technique, addressed CI particularities and testing problems, and adopted evaluation measures. Results: The results show a growing interest in this research subject. Most studies have been published in the last four years. 80% of the approaches are history-based, that is, are based on the failure and test execution history. The great majority of studies report evaluation results by comparing prioritization techniques. The preferred measures are Time and number/percentage of Faults Detected. Few studies address CI testing problems and characteristics, such as parallel execution and test case volatility. Conclusions: We observed a growing number of studies in the field. Future work should explore other information sources such as models and requirements, as well as CI particularities and testing problems, such as test case volatility, time constraint, and flaky tests, to solve existing challenges and offer cost-effective approaches to the software industry.}
}
@article{LUO2016179,
title = {Regression and classification using extreme learning machine based on L1-norm and L2-norm},
journal = {Neurocomputing},
volume = {174},
pages = {179-186},
year = {2016},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.03.112},
url = {https://www.sciencedirect.com/science/article/pii/S092523121501139X},
author = {Xiong Luo and Xiaohui Chang and Xiaojuan Ban},
keywords = {Extreme learning machine, Ridge regression, Elastic net, Model selection, Bayesian information criterion (BIC)},
abstract = {Extreme learning machine (ELM) is a very simple machine learning algorithm and it can achieve a good generalization performance with extremely fast speed. Therefore it has practical significance for data analysis in real-world applications. However, it is implemented normally under the empirical risk minimization scheme and it may tend to generate a large-scale and over-fitting model. In this paper, an ELM model based on L1-norm and L2-norm regularizations is proposed to handle regression and multiple-class classification problems in a unified framework. The proposed model called L1–L2-ELM combines the grouping effect benefits of L2 penalty and the tendency towards sparse solution of L1 penalty, thus it can control the complexity of the network and prevent over-fitting. To solve the mixed penalty problem, the separate elastic net algorithm and Bayesian information criterion (BIC) are adopted to find the optimal model for each response variable. We test the L1–L2-ELM algorithm on one artificial case and nine benchmark data sets to evaluate its performance. Simulation results have shown that the proposed algorithms outperform the original ELM as well as other advanced ELM algorithms in terms of prediction accuracy, and it is more robust in both regression and classification applications.}
}
@incollection{HEMMATI2019185,
title = {Chapter Four - Advances in Techniques for Test Prioritization},
editor = {Atif M. Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {112},
pages = {185-221},
year = {2019},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2017.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0065245817300566},
author = {Hadi Hemmati},
keywords = {Test case prioritization, Code coverage, Diversity, Fault detection, Regression testing, Search-based testing, Multiobjective, Execution cost, Scalability},
abstract = {With the increasing size of software systems and the continuous changes that are committed to the software's codebase, regression testing has become very expensive for real-world software applications. Test case prioritization is a classic solution in this context. Test case prioritization is the process of ranking existing test cases for execution with the goal of finding defects sooner. It is useful when the testing budget is limited and one needs to limit their test execution cost, by only running top n test cases, according to the testing budget. There are many heuristics and algorithms to rank test cases. In this chapter, we will see some of the most common test case prioritization techniques from software testing literature as well as trends and advances in this domain.}
}
@article{IBRAHIM2023481,
title = {Evaluation of angled splitters as scour countermeasure at circular piers},
journal = {Alexandria Engineering Journal},
volume = {74},
pages = {481-494},
year = {2023},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2023.05.067},
url = {https://www.sciencedirect.com/science/article/pii/S1110016823004271},
author = {Mohamed M. Ibrahim and Mahmoud A. Refaey and Hadeer M. Hashem and Ahmed M. Ibraheem},
keywords = {Angled splitter, Circular pier, Local scour, Velocity distribution, Bed configurations},
abstract = {Scour around bridge piers is local phenomenon may cause complete failure for the hydraulic structure. This study explored experimentally using splitter plates at specific angles installed upstream single circular bridge pier to improve the nearby flow field and minimize the local scour. Ninety runs were carried out considering 9 splitter models. Four splitter lengths and 3 vertex angles were used. The splitter lengths were between 0 and 1.5 times of pier diameter, each was tested for 3 vertex angles ranged between 0° and 30°. The tests were done under 9 different hydraulic conditions including 3 discharges of 75, 100, and 125 l/s and 3 tailwater depths of 12.5, 15, and 17.5 cm. The turbulent flow conditions were investigated by plotting velocity profiles at different sections. The bed configurations under clear water conditions were presented. The results of pier without splitter were used as reference. The study outcome that the local scour depth was decreased by the increase of splitter length and vertex angle. The near-bed flow velocity and the corresponding Froude No. downstream of the pier was minimized for 1.5D splitter length at 30° vertex angle and the minimum scour geometry was located. The effectiveness of splitters were remarkable by the decrease of flow discharge and increase of tailwater depth provided that the discontinuity of scour hole length in case of multi-circular piers. Regression analysis was employed to develop empirical formula for the estimation of maximum scour depth around circular pier with splitter.}
}
@article{GHANI2022635,
title = {Improved Test Case Selection Algorithm to Reduce Time in Regression Testing},
journal = {Computers, Materials and Continua},
volume = {72},
number = {1},
pages = {635-650},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.025027},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822010694},
author = {Israr Ghani and Wan M. N. Wan-Kadir and Adila Firdaus Arbain and Noraini Ibrahim},
keywords = {Test case selection, regression testing, change detection, TCS algorithm, test suite minimization},
abstract = {Regression testing (RT) is an essential but an expensive activity in software development. RT confirms that new faults/errors will not have occurred in the modified program. RT efficiency can be improved through an effective technique of selected only modified test cases that appropriate to the modifications within the given time frame. Earlier, several test case selection approaches have been introduced, but either these techniques were not sufficient according to the requirements of software tester experts or they are ineffective and cannot be used for available test suite specifications and architecture. To address these limitations, we recommend an improved and efficient test case selection (TCS) algorithm for RT. Our proposed technique decreases the execution time and redundancy of the duplicate test cases (TC) and detects only modified changes that appropriate to the modifications in test cases. To reduce execution time for TCS, evaluation results of our proposed approach are established on fault detection, redundancy and already executed test case. Results indicate that proposed technique decreases the inclusive testing time of TCS to execute modified test cases by, on average related to a method of Hybrid Whale Algorithm (HWOA), which is a progressive TCS approach in regression testing for a single product.}
}
@article{ROZA2024107444,
title = {On the use of contextual information for machine learning based test case prioritization in continuous integration development},
journal = {Information and Software Technology},
volume = {171},
pages = {107444},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107444},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924000491},
author = {Enrique A. da Roza and Jackson A. do {Prado Lima} and Silvia R. Vergilio},
keywords = {Regression testing, Continuous integration, Reinforcement learning},
abstract = {Context:
In most software organizations, Continuous Integration (CI) is a common practice usually subject to some budgets. Consequently, prioritizing test cases to be executed in the CI cycle is fundamental. The idea is first to execute test cases with higher failure-proneness to provide rapid feedback and decrease costs. To perform this task approaches in the literature adopt failure history and Machine Learning (ML). However, in addition to the failure history, it is also important to consider information from the CI context of the organizations and the application domain.
Objective:
For this end, we introduce a contextual information approach for ML algorithms. Such an approach considers information from the testing activity that can be easily collected, such as test case execution time, size, and complexity. We implement the approach by introducing two contextual versions of the algorithms: Multi-Armed Bandit (MAB) and Random Forest (RF).
Method:
Six systems are used to compare both contextual algorithms and to evaluate their performance regarding their corresponding non-contextual versions, considering three different budgets.
Results:
Contextual algorithms perform better when indicators related to test time reduction are considered, as the contextual information they use is related to execution time. Regarding NAPFD and APFDc, the non-contextual algorithms have better general performance, but both contextual versions obtain competitive results.
Conclusions:
The contextual versions implemented can capture the desired context information in the prioritization without negatively impacting their performance regarding fault-detection.}
}
@article{HASNAIN20201051,
title = {An Ontology Based Test Case Prioritization Approach in Regression Testing},
journal = {Computers, Materials and Continua},
volume = {67},
number = {1},
pages = {1051-1068},
year = {2020},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2021.014686},
url = {https://www.sciencedirect.com/science/article/pii/S1546221820001897},
author = {Muhammad Hasnain and Seung Ryul Jeong and Muhammad Fermi Pasha and Imran Ghani},
keywords = {Software code metric, machine learning, faults detection, testing},
abstract = {Regression testing is a widely studied research area, with the aim of meeting the quality challenges of software systems. To achieve a software system of good quality, we face high consumption of resources during testing. To overcome this challenge, test case prioritization (TCP) as a sub-type of regression testing is continuously investigated to achieve the testing objectives. This study provides an insight into proposing the ontology-based TCP (OTCP) approach, aimed at reducing the consumption of resources for the quality improvement and maintenance of software systems. The proposed approach uses software metrics to examine the behavior of classes of software systems. It uses Binary Logistic Regression (BLR) and AdaBoostM1 classifiers to verify correct predictions of the faulty and non-faulty classes of software systems. Reference ontology is used to match the code metrics and class attributes. We investigated five Java programs for the evaluation of the proposed approach, which was used to achieve code metrics. This study has resulted in an average percentage of fault detected (APFD) value of 94.80%, which is higher when compared to other TCP approaches. In future works, large sized programs in different languages can be used to evaluate the scalability of the proposed OTCP approach.}
}
@article{XIAN2022109690,
title = {Unified whale optimization algorithm based multi-kernel SVR ensemble learning for wind speed forecasting},
journal = {Applied Soft Computing},
volume = {130},
pages = {109690},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109690},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622007396},
author = {Huafeng Xian and Jinxing Che},
keywords = {Wind speed forecasting, Support vector regression, Model selection, Unified optimization, Whale optimization algorithm},
abstract = {Support vector regression (SVR) is widely used in the field of wind speed forecasting because of its excellent nonlinear learning ability. However, the drawback of SVR is the model selection problem, which has the high complexity O(K×m3) including kernel function selection and parameter selection. To solve this problem, this paper proposes a multi-kernel SVR ensemble (MKSVRE) model based on unified optimization and whale optimization algorithm (WOA), where the MKSVRE model is used to solve the kernel function selection problem, and the unified optimization and the WOA are used to solve the parameter selection problem. The proposed model provides an alternative without the need to specifically select a kernel function and thus enhances the adaptability of SVR to diverse data. In addition, the unified optimization takes into account the interactions between models and achieves a global parameter selection. The proposed model is tested by simulations on wind speed data from Shandong Province, China. By comparing the prediction results of the proposed model, the single kernel SVR models, the models before and after optimization, and six other models, the effectiveness of the proposed model is confirmed.}
}
@article{AKIAN2022111595,
title = {Learning “best” kernels from data in Gaussian process regression. With application to aerodynamics},
journal = {Journal of Computational Physics},
volume = {470},
pages = {111595},
year = {2022},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2022.111595},
url = {https://www.sciencedirect.com/science/article/pii/S002199912200657X},
author = {J.-L. Akian and L. Bonnet and H. Owhadi and É. Savin},
keywords = {Reproducing kernel Hilbert space, Gaussian process regression, Kernel ridge regression, Kernel flow, Aerodynamics},
abstract = {This paper introduces algorithms to select/design kernels in Gaussian process regression/kriging surrogate modeling techniques. We adopt the setting of kernel method solutions in ad hoc functional spaces, namely Reproducing Kernel Hilbert Spaces (RKHS), to solve the problem of approximating a regular target function given observations of it, i.e. supervised learning. A first class of algorithms is kernel flow, which was introduced in the context of classification in machine learning. It can be seen as a cross-validation procedure whereby a “best” kernel is selected such that the loss of accuracy incurred by removing some part of the dataset (typically half of it) is minimized. A second class of algorithms is called spectral kernel ridge regression, and aims at selecting a “best” kernel such that the norm of the function to be approximated is minimal in the associated RKHS. Within Mercer's theorem framework, we obtain an explicit construction of that “best” kernel in terms of the main features of the target function. Both approaches of learning kernels from data are illustrated by numerical examples on synthetic test functions, and on a classical test case in turbulence modeling validation for transonic flows about a two-dimensional airfoil.}
}
@article{ZHANG2022111419,
title = {Test case prioritization using partial attention},
journal = {Journal of Systems and Software},
volume = {192},
pages = {111419},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111419},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001285},
author = {Quanjun Zhang and Chunrong Fang and Weisong Sun and Shengcheng Yu and Yutao Xu and Yulei Liu},
keywords = {Software testing, Regression testing, Test case prioritization, Greedy algorithm},
abstract = {Test case prioritization (TCP) aims to reorder the regression test suite with a goal of increasing the fault detection rate. Various TCP techniques have been proposed based on different prioritization strategies. Among them, the greedy-based techniques are the most widely-used TCP techniques. However, existing greedy-based techniques usually reorder all candidate test cases in prioritization iterations, resulting in both efficiency and effectiveness problems. In this paper, we propose a generic partial attention mechanism, which adopts the previous priority values (i.e., the number of additionally-covered code units) to avoid considering all candidate test cases. Incorporating the mechanism with the additional-greedy strategy, we implement a novel coverage-based TCP technique based on partition ordering (OCP). OCP first groups the candidate test cases into different partitions and updates the partitions on the descending order. We conduct a comprehensive experiment on 19 versions of Java programs and 30 versions of C programs to compare the effectiveness and efficiency of OCP with six state-of-the-art TCP techniques: total-greedy, additional-greedy, lexicographical-greedy, unify-greedy, art-based, and search-based. The experimental results show that OCP achieves a better fault detection rate than the state-of-the-arts. Moreover, the time costs of OCP are found to achieve 85%–99% improvement than most state-of-the-arts.}
}
@article{GAROUSI201840,
title = {Multi-objective regression test selection in practice: An empirical study in the defense software industry},
journal = {Information and Software Technology},
volume = {103},
pages = {40-54},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2018.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0950584918301186},
author = {Vahid Garousi and Ramazan Özkan and Aysu Betin-Can},
keywords = {Regression testing, Multi-objective optimization, Genetic algorithms, Empirical study, Defence software industry, Action-research},
abstract = {Context
Executing an entire regression test-suite after every code change is often costly in large software projects. To cope with this challenge, researchers have proposed various regression test-selection techniques.
Objective
This paper was motivated by a real industrial need to improve regression-testing practices in the context of a safety-critical industrial software in the defence domain in Turkey. To address our objective, we set up and conducted an “action-research” collaborative project between industry and academia.
Method
After a careful literature review, we selected a conceptual multi-objective regression-test selection framework (called MORTO) and adopted it to our industrial context by developing a custom-built genetic algorithm (GA) based on that conceptual framework. GA is able to provide full coverage of the affected (changed) requirements while considering multiple cost and benefit factors of regression testing. e.g., minimizing the number of test cases, and maximizing cumulative number of detected faults by each test suite.
Results
The empirical results of applying the approach on the Software Under Test (SUT) demonstrate that this approach yields a more efficient test suite (in terms of costs and benefits) compared to the old (manual) test-selection approach, used in the company, and another applicable approach chosen from the literature. With this new approach, regression selection process in the project under study is not ad-hoc anymore. Furthermore, we have been able to eliminate the subjectivity of regression testing and its dependency on expert opinions.
Conclusion
Since the proposed approach has been beneficial in saving the costs of regression testing, it is currently in active use in the company. We believe that other practitioners can apply our approach in their regression-testing contexts too, when applicable. Furthermore, this paper contributes to the body of evidence in regression testing by offering a success story of successful implementation and application of multi-objective regression testing in practice.}
}
@article{MA2016182,
title = {Estimation of the building energy use intensity in the urban scale by integrating GIS and big data technology},
journal = {Applied Energy},
volume = {183},
pages = {182-192},
year = {2016},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2016.08.079},
url = {https://www.sciencedirect.com/science/article/pii/S0306261916311679},
author = {Jun Ma and Jack C.P. Cheng},
keywords = {Artificial Neural Network (ANN), Big Data, Energy use intensity (EUI), Feature selection, Geographic information system (GIS), Support Vector Regression (SVR)},
abstract = {Buildings are the major source of energy consumption in urban areas. Accurate modeling and forecasting of the building energy use intensity (EUI) in the urban scale have many important applications, such as energy benchmarking and urban energy infrastructure planning. The use of Big Data technology is expected to have the capability of integrating a large number of predictors and giving an accurate prediction of the energy use intensity of buildings in the urban scale. However, past research has often used Big Data technology in estimating energy consumption of a single building rather than the urban scale, due to several challenges such as data collection and feature engineering. This paper therefore proposes a geographic information system integrated data mining methodology framework for estimating the building EUI in the urban scale, including preprocessing, feature selection, and algorithm optimization. Based on 216 prepared features, a case study on estimating the site EUI of 3640 multi-family residential buildings in New York City, was tested and validated using the proposed methodology framework. A comparative study on the feature selection strategies and the commonly used regression algorithms was also included in the case study. The results show that the framework was able to help produce lower estimation errors than previous research, and the model built by the Support Vector Regression algorithm on the features selected by Elastic Net has the least cross-validation mean squared error.}
}
@article{ALKHATIB201482,
title = {Φ-indices approach and multivariable regression analysis for prediction of discharge in asymmetric straight compound open channel flows},
journal = {Flow Measurement and Instrumentation},
volume = {38},
pages = {82-91},
year = {2014},
issn = {0955-5986},
doi = {https://doi.org/10.1016/j.flowmeasinst.2014.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0955598614000545},
author = {Issam A. Al-Khatib and Mustafa Gogus},
keywords = {-indices, Compound channel, Division line, Flood plain, Discharge estimation, Regression analysis},
abstract = {This study is related to flow measurement structures of asymmetric compound cross section mostly suggested for sediment laden-rivers, streams and wadis. Nine different models of asymmetrical rectangular cross sections were tested for a wide range of discharges. In each model, the stages and corresponding discharges were measured. From these measurements, the average discharges utilizing the Φ-indices Approach were determined. In addition, a multivariable regression model was derived with high accuracy for the prediction of discharge in asymmetric compound channels using five dimensionless parameters. The measured discharges were compared with the predicted ones obtained from the Φ-indices methods with vertical, horizontal and diagonal interface planes; FI-V, FI-D and FI-H, respectively, with the use of three well-known methods for the computation of the apparent shear stress acting on the interface perimeter, τa, and the multivariable regression model for discharge prediction. At lower relative depth values, almost all the tested methods predict discharge with acceptable accuracy. In addition, as the relative depth increases, the results demonstrate a suitable accuracy of the FI-V with the vertical division lines and the multivariable regression model method. The multivariable regression model presented has been identified as the best-fit model in 26 cases out of 29 through minimization of the mean squared errors.}
}
@article{MOROZOVA2022112146,
title = {A CFD-based surrogate model for predicting flow parameters in a ventilated room using sensor readings},
journal = {Energy and Buildings},
volume = {266},
pages = {112146},
year = {2022},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2022.112146},
url = {https://www.sciencedirect.com/science/article/pii/S0378778822003176},
author = {Nina Morozova and Francesc Xavier Trias and Roser Capdevila and Eugenio Schillaci and Assensi Oliva},
keywords = {Computational fluid dynamics, Surrogate models, Indoor airflow prediction, Machine learning, Mixed convection},
abstract = {In this work, we develop a computational fluid dynamics (CFD)-based surrogate model, which predicts flow parameters under different geometrical configurations and boundary conditions in a benchmark case of a mechanically ventilated room with mixed convection. The model inputs are the temperature and velocity values in different locations, which act as a surrogate of the sensor readings. The model’s output is a set of comfort-related flow parameters, such as the average Nusselt number on the hot wall, jet separation point, average kinetic energy, average enstrophy, and average temperature. We tested four different machine learning methods, among which we chose the gradient boosting regression due to its accurate performance. We also adapted the developed model for indoor environment control applications by determining the optimal combinations of sensor positions which minimize the prediction error. This model does not require the repetition of CFD simulations in order to be applied since the structure of the input data imitates sensor readings. Furthermore, the low computational cost of the model execution and good accuracy makes it an effective alternative to CFD for applications where rapid predictions of complex flow configurations are required, such as model predictive control.}
}
@article{HAMMADKHALIQ2023101907,
title = {Spatiotemporal landslide susceptibility mapping using machine learning models: A case study from district Hattian Bala, NW Himalaya, Pakistan},
journal = {Ain Shams Engineering Journal},
volume = {14},
number = {3},
pages = {101907},
year = {2023},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2022.101907},
url = {https://www.sciencedirect.com/science/article/pii/S2090447922002180},
author = {Ahmad {Hammad Khaliq} and Muhammad Basharat and Malik {Talha Riaz} and Muhammad {Tayyib Riaz} and Saad Wani and Nadhir Al-Ansari and Long {Ba Le} and Nguyen {Thi Thuy Linh}},
keywords = {Hattian Bala, Landslide susceptibility, Logistic regression, Machine learning, Random forest},
abstract = {The Himalayan region, a rugged mountain zone is among the most susceptible zones to the landslide hazard due to its terrain, geography, and active tectonics. Machine learning (ML) techniques are most advanced and precise methods to develop landslide susceptibility model (LSM). The current study was designed to analyze and assess the landslide susceptibility using ML approaches for District Hattian Bala, NW Himalayas, Pakistan. The historical satellite imageries are used to generate spatiotemporal landslide inventories of year 2005, 2007 and 2012. A spatial database was created pertaining to topographic, environmental, geologic, and anthropogenic factors including slope, aspect, elevation, curvature, plane curvature, profile curvature, topographic wetness index (TWI), lithology, distance to faults, distance to streams, distance to roads, normalized difference vegetation index (NDVI) and land use/ land cover (LULC). These LCFs were selected to analyze periodic landslide susceptibility in the region. The experimental design utilized 349, 393, and 735 landslide inventory of 2005, 2007, and 2012 respectively. Two ML models, i.e., Random Forest (RF) and Logistic Regression (LR) were applied to assess landslide susceptibility determine by thirteen landslide causative factors (LCFs). The spatiotemporal landslide inventory was partitioned into training (70%) and testing (30%) landslides for respective years to check the prediction accuracies of selected ML models. Comparative analysis of different LSMs was performed by the Receiver Operator Curves – Area Under Curves (ROC-AUC). The resultant accuracy, MAE, RMSE, Kappa, Precision, Recall, F1 indicated that RF outperformed the LR model. The study aims to minimize losses to lives and potential economic damage linked with recurrent slope instabilities in the region. It is anticipated that use of ML algorithms would support concerned authorities and organizations to effectively plan and manage landslide hazard in the region.}
}
@article{BROEKMEULEN2019265,
title = {Quantifying the potential to improve on food waste, freshness and sales for perishables in supermarkets},
journal = {International Journal of Production Economics},
volume = {209},
pages = {265-273},
year = {2019},
note = {The Proceedings of the 19th International Symposium on Inventories},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2017.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0925527317303067},
author = {Rob A.C.M. Broekmeulen and Karel H. {van Donselaar}},
keywords = {Food waste, Retail operations, Empirical data, Freshness, On Shelf Availability, Perishable},
abstract = {The focus of this paper is on improving the performance of fresh departments in supermarkets by reducing food waste, increasing freshness and/or increasing sales. First, two concepts will be introduced to quantify the improvement potential. Next, these concepts will be applied on empirical data for 3 product categories in 27 stores from 3 large retailers in Europe. The two concepts to quantify the improvement potential are called the Fresh Case Cover and the Efficient Frontier. The Fresh Case Cover is defined as the case pack size divided by the average demand during the store shelf life. A regression analysis shows that this single variable explains 42% of the variation in waste. The Efficient Frontier represents a lower bound on the waste needed in a store for any given On-Shelf Availability (OSA). It is demonstrated how the Efficient Frontier can be used to quantify the benefits from supply chain improvement projects and to evaluate fresh departments within a store. To quantify product freshness, an exact expression is derived and an approximation is developed and tested. To quantify waste an existing approximation is generalized. The results show that the improvement potential is very large. For example, increasing the store shelf life with just one day results in 43.1% less waste and 17% more freshness (or in 3.4% higher OSA) and unpacking in the DC results in 34.8% less waste and 1.6% more freshness (or in 2.0% higher OSA). Improving the store replenishment and execution is especially beneficial for medium and large stores.}
}
@article{PORTA2020109723,
title = {Relevance of sex, age and gait kinematics when predicting fall-risk and mortality in older adults},
journal = {Journal of Biomechanics},
volume = {105},
pages = {109723},
year = {2020},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2020.109723},
url = {https://www.sciencedirect.com/science/article/pii/S0021929020301391},
author = {S. Porta and A. Martínez and N. Millor and M. Gómez and M. Izquierdo},
keywords = {Prediction of falls/mortality risk, Logistic regression model, Feature selection for maximum accuracy prediction, Sex stratification importance},
abstract = {Approximately one-third of elderly people fall each year with severe consequences, including death. The aim of this study was to identify the most relevant features to be considered to maximize the accuracy of a logistic regression model designed for prediction of fall/mortality risk among older people. This study included 261 adults, aged over 65 years. Men and women were analyzed separately because sex stratification was revealed as being essential for our purposes of feature ranking and selection. Participants completed a 3-m walk test at their own gait velocity. An inertial sensor attached to their lumbar spine was used to record acceleration data in the three spatial directions. Signal processing techniques allowed the extraction of 21 features representative of gait kinematics, to be used as predictors to train and test the model. Age and gait speed data were also considered as predictors. A set of 23 features was considered. These features demonstrate to be more or less relevant depending on the sex of the cohort under analysis and the classification label (risk of falls and mortality). In each case, the minimum size subset of relevant features is provided to show the maximum accuracy prediction capability. Gait speed has been largely used as the single feature for the prediction fall risk among older adults. Nevertheless, prediction accuracy can be substantially improved, reaching 70% in some cases, if the task of training and testing the model takes into account some other features, namely, sex, age and gait kinematic parameters. Therefore we recommend considering sex, age and step regularity to predict fall-risk.}
}
@article{DORNAIKA2016275,
title = {Inductive and flexible feature extraction for semi-supervised pattern categorization},
journal = {Pattern Recognition},
volume = {60},
pages = {275-285},
year = {2016},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2016.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0031320316300929},
author = {F. Dornaika and Y. El Traboulsi and A. Assoum},
keywords = {Feature extraction, Semi-supervised discriminant analysis, Graph-based embedding, Out-of-sample extension, Pattern categorization},
abstract = {This paper proposes a novel discriminant semi-supervised feature extraction method for generic classification and recognition tasks. This method, called inductive flexible semi-supervised feature extraction, is a graph-based embedding method that seeks a linear subspace close to a non-linear one. It is based on a criterion that simultaneously exploits the discrimination information provided by the labeled samples, maintains the graph-based smoothness associated with all samples, regularizes the complexity of the linear transform, and minimizes the discrepancy between the unknown linear regression and the unknown non-linear projection. We extend the proposed method to the case of non-linear feature extraction through the use of kernel trick. This latter allows to obtain a nonlinear regression function with an output subspace closer to the learned manifold than that of the linear one. Extensive experiments are conducted on ten benchmark databases in order to study the performance of the proposed methods. Obtained results demonstrate a significant improvement over state-of-the-art algorithms that are based on label propagation or semi-supervised graph-based embedding.}
}
@article{MACEDO2021106795,
title = {Machine-learning-based predictive models for estimating seismically-induced slope displacements},
journal = {Soil Dynamics and Earthquake Engineering},
volume = {148},
pages = {106795},
year = {2021},
issn = {0267-7261},
doi = {https://doi.org/10.1016/j.soildyn.2021.106795},
url = {https://www.sciencedirect.com/science/article/pii/S0267726121002177},
author = {Jorge Macedo and Chenying Liu and Farahnaz Soleimani},
keywords = {Seismically-induced slope displacements, Machine-learning, Seismic performance, Slope systems},
abstract = {Engineers often use semiempirical models, which estimate the amount of seismically-induced slope displacements (D), to evaluate the seismic performance of earth structures and natural slopes. These procedures often use as inputs slope properties, earthquake parameters, and ground motion intensity measures (IMs). In this study, we propose a new set of machine learning (ML) based models to estimate D using the NGA-West2 shallow crustal ground motion database. We consider both the classification of negligible D and its estimation. The selection of features to explain D (which is based on LASSO, Forward Selection, and Random Forest) suggests that the most efficient features are the slope's yield coefficient (ky), its fundamental period (Ts), the earthquake magnitude (Mw), the peak ground velocity (PGV), and the degraded spectral acceleration at 1.3 Ts. Moreover, the feature selection suggests that there is no significant gain in accuracy beyond five features. We formulate 19 different models, considering various ML-based algorithms such as Generalized Linear Models (GLM), Partial Least Square Regressions (PLSR), Principal Component Regressions (PCR), Bagging and Boosting, Random Forest, Polynomial-based regressions, Multi-order regressions, and Kernel-based models. We assess the performance of the proposed models by evaluating test errors, their predictive performance in case histories, and comparisons against existing models. Based on the assessments, we recommend 6 ML-based models to estimate D in engineering practice.}
}
@article{ISCRA20244600,
title = {Optimizing machine learning models for classification of stroke patients with epileptiform EEG pattern: the impact of dataset balancing techniques},
journal = {Procedia Computer Science},
volume = {246},
pages = {4600-4609},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.324},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924023494},
author = {Katerina Iscra and Alessandro Biscontin and Aleksandar Miladinovic and Andrea Bonini and Giovanni Furlanis and Gabriele Prandin and Michele Malesani and Marcello Naccarato and Paolo Manganotti and Agostino Accardo and Miloš Ajčević},
keywords = {Dataset balancing techniques, Classification Models, Stroke, Epileptiform EEG patterns},
abstract = {Epileptiform electroencephalogram (EEG) patterns are commonly observed in stroke patients and can significantly impact clinical management and patient outcomes. Therefore, the classification of the stroke patients in order to identify the subjects with high probability of epileptiform EEG patterns may improve the stroke management. In recent years, there has been a notable increase in interest and utilization of machine learning, especially in the domain of classification tasks. Nevertheless, the presence of imbalanced datasets presents hurdles for machine learning algorithms, resulting in skewed predictions toward dominant classes and diminished accuracy, especially for underrepresented ones. Hence, the study aims to evaluate the effects of dataset balancing methods on the classification efficacy of machine learning models for classification of stroke patients with epileptiform EEG patterns by conducting a comparative analysis between models trained on imbalanced and balanced datasets. Four different sampling techniques were employed: an oversampling technique, SMOTENC; an undersampling technique, NearMiss; and two techniques that combine over- and undersampling methods, SMOTEToken and SMOTEENN. The features selection was made using the ReliefF scoring method and for model construction, only features that presented a contribution value greater than 0.01 were utilized. Five different machine learning models were considered in the study: classification tree, logistic regression, naïve Bayes, artificial neural network and support vector machine. The produced models were trained on the original and resampled training set and subsequently the models’ performances were evaluated on the test set. The results showed that SMOTENC was the most effective among the considered dataset balancing techniques, showing superior classification performance compared to other methods and the original dataset. Models utilizing SMOTENC exhibited significant improvements in AUC (0.76 vs 0.67) and specificity values (0.73 vs 0.43) while maintaining comparable accuracy (0.72 vs 0.74) to those trained on the original dataset, respectively. Furthermore, it has been noted that different sampling techniques result in different selection of the most predictive features. In conclusion, our study highlights the crucial role of utilizing dataset balancing methods to improve the classification performances of predictive models in case of highly unbalanced datasets such as case of stratification of stroke patients with epileptiform EEG patterns.}
}
@article{ROMANO201862,
title = {SPIRITuS: a SimPle Information Retrieval regressIon Test Selection approach},
journal = {Information and Software Technology},
volume = {99},
pages = {62-80},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2018.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0950584918300405},
author = {Simone Romano and Giuseppe Scanniello and Giuliano Antoniol and Alessandro Marchetto},
keywords = {SPIRITuS, Regression test case selection, Regression testing},
abstract = {Context:Regression Test case Selection (RTS) approaches aim at selecting only those test cases of a test suite that exercise changed parts of the System Under Test (SUT) or parts affected by changes. Objective:We present SPIRITuS (SimPle Information Retrieval regressIon Test Selection approach). It uses method code coverage information and a Vector Space Model to select test cases to be run. In a nutshell, the extent of a lexical modification to a method is used to decide if a test case has to be selected. The main design goals of SPIRITuS are to be: (i) easy to adapt to different programming languages and (ii) tunable via an easy to understand threshold. Method:To assess SPIRITuS, we conducted a large experiment on 389 faulty versions of 14 open-source programs implemented in Java. We were mainly interested in investigating the tradeoff between the number of selected test cases from the original test suite and fault detection effectiveness. We also compared SPIRITuS against well-known RTS approaches. Results:SPIRITuS selects a number of test cases significantly smaller than the number of test cases the other approaches select at the price of a slight reduction in fault detection capability. Conclusions:SPIRITuS can be considered a viable competitor of existing test case selection approaches especially when the average number of test cases covering a modified method increases (such information can be easily derived before test case selection takes place).}
}
@article{OZENER2020110632,
title = {An effective formulation of the multi-criteria test suite minimization problem},
journal = {Journal of Systems and Software},
volume = {168},
pages = {110632},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110632},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301059},
author = {O. Örsan Özener and Hasan Sözer},
keywords = {Software testing, Regression testing, Test suite minimization, Integer programming, Multi-objective optimization},
abstract = {Test suite minimization problem has been mainly addressed by employing heuristic techniques or integer linear programming focusing on a specific criterion or bi-criteria. These approaches fall short to compute optimal solutions especially when there exists overlap among test cases in terms of various criteria such as code coverage and the set of detected faults. Nonlinear formulations have also been proposed recently to address such cases. However, these formulations require significantly more computational resources compared to linear ones. Moreover, they are also subject to shortcomings that might still lead to sub-optimal solutions. In this paper, we identify such shortcomings and we propose an alternative formulation of the problem. We have empirically evaluated the effectiveness of our approach based on a publicly available dataset and compared it with respect to the state-of-the-art based on the same objective function and the same set of criteria including statement coverage, fault-revealing capability, and test execution time. Results show that our formulation leads to either better results or the same results, when the previously obtained results were already the optimal ones. In addition, our formulation is a linear formulation, which can be solved much more efficiently compared to non-linear formulations.}
}
@article{LU2022102486,
title = {SlideGraph+: Whole slide image level graphs to predict HER2 status in breast cancer},
journal = {Medical Image Analysis},
volume = {80},
pages = {102486},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102486},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522001335},
author = {Wenqi Lu and Michael Toss and Muhammad Dawood and Emad Rakha and Nasir Rajpoot and Fayyaz Minhas},
keywords = {Computational pathology, Breast cancer, Weak supervision, Human epidermal growth factor receptor, Graph neural networks},
abstract = {Human epidermal growth factor receptor 2 (HER2) is an important prognostic and predictive factor which is overexpressed in 15–20% of breast cancer (BCa). The determination of its status is a key clinical decision making step for selection of treatment regimen and prognostication. HER2 status is evaluated using transcriptomics or immunohistochemistry (IHC) through in-situ hybridisation (ISH) which incurs additional costs and tissue burden and is prone to analytical variabilities in terms of manual observational biases in scoring. In this study, we propose a novel graph neural network (GNN) based model (SlideGraph+) to predict HER2 status directly from whole-slide images of routine Haematoxylin and Eosin (H&E) stained slides. The network was trained and tested on slides from The Cancer Genome Atlas (TCGA) in addition to two independent test datasets. We demonstrate that the proposed model outperforms the state-of-the-art methods with area under the ROC curve (AUC) values > 0.75 on TCGA and 0.80 on independent test sets. Our experiments show that the proposed approach can be utilised for case triaging as well as pre-ordering diagnostic tests in a diagnostic setting. It can also be used for other weakly supervised prediction problems in computational pathology. The SlideGraph+ code repository is available at https://github.com/wenqi006/SlideGraph along with an IPython notebook showing an end-to-end use case at https://github.com/TissueImageAnalytics/tiatoolbox/blob/develop/examples/full-pipelines/slide-graph.ipynb.}
}
@article{IBIAS2021106498,
title = {Using mutual information to test from Finite State Machines: Test suite selection},
journal = {Information and Software Technology},
volume = {132},
pages = {106498},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106498},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920302408},
author = {Alfredo Ibias and Manuel Núñez and Robert M. Hierons},
keywords = {Formal approaches to testing, Information Theory, Mutual information, Finite State Machines},
abstract = {Context:
Mutual Information is an information theoretic measure designed to quantify the amount of similarity between two random variables ranging over two sets. In this paper, we adapt this concept and show how it can be used to select a good test suite to test from a Finite State Machine (FSM) based on a maximise diversity approach.
Objective:
The main goal of this paper is to use Mutual Information in order to select test suites to test from FSMs and evaluate whether we obtain better results, concerning the quality of the selected test suite, than current state-of-the-art measures.
Method:
First, we defined our scenario. We considered the case where we receive two (or more) test suites and we have to choose between them. We were interested in this scenario because it is a recurrent case in regression testing. Second, we defined our notion based on Mutual Information: Biased Mutual Information. Finally, we carried out experiments in order to evaluate the measure.
Results:
We obtained experimental evidence that demonstrates the potential value of the measure. We also showed that the time needed to compute the measure is negligible when compare to the time needed to apply extra testing. We compared our measure with a state-of-the-art test selection measure and showed that our proposal outperforms it. Finally, we have compared our measure with a notion of transition coverage. Our experiments showed that our measure is slightly worse than transition coverage, as expected, but its computation is 10 times faster.
Conclusion:
Our experiments showed that Biased Mutual Information is a good measure for selecting test suites, outperforming the current state-of-the-art measure, and having a (negative) correlation to fault coverage. Therefore, we can conclude that our new measure can be used to select the test suite that is likely to find more faults. As a result, it has the potential to be used to automate test generation.}
}
@article{ABOLGHASEMI2020107892,
title = {Demand forecasting in the presence of systematic events: Cases in capturing sales promotions},
journal = {International Journal of Production Economics},
volume = {230},
pages = {107892},
year = {2020},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2020.107892},
url = {https://www.sciencedirect.com/science/article/pii/S0925527320302553},
author = {Mahdi Abolghasemi and Jason Hurley and Ali Eshragh and Behnam Fahimnia},
keywords = {Demand forecasting, Systematic events, Time series regression models, Sales promotions, Judgmental forecasting, Supply chain},
abstract = {Reliable demand forecasts are critical for effective supply chain management. Several endogenous and exogenous variables can influence the dynamics of demand, and hence a single statistical model that only consists of historical sales data is often insufficient to produce accurate forecasts. In practice, the forecasts generated by baseline statistical models are often judgmentally adjusted by forecasters to incorporate factors and information that are not incorporated in the baseline models. There are however systematic events whose effect can be quantified and modeled to help minimize human intervention in adjusting the baseline forecasts. In this paper, we develop and test a novel regime-switching approach to quantify systematic information/events and objectively incorporate them into the baseline statistical model. Our simple yet practical and effective model can help limit forecast adjustments to only focus on the impact of less systematic events such as sudden climate change or dynamic market activities. The model is validated empirically using sales and promotional data from two Australian companies. The model is also benchmarked against commonly employed statistical and machine learning forecasting models. Discussions focus on thorough analysis of promotions impact and benchmarking results. We show that the proposed model can successfully improve forecast accuracy and avoid poor forecasts when compared to the current industry practice which heavily relies on human judgment to factor in all types of information/events. The proposed model also outperforms sophisticated machine learning methods by mitigating the generation of extremely poor forecasts that drastically differ from actual sales due to changes in demand states.}
}
@article{CHIOU2024,
title = {Recruitment for Voluntary Video and Mobile HIV Testing on Social Media Platforms During the COVID-19 Pandemic: Cross-Sectional Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/54420},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124008768},
author = {Piao-Yi Chiou and Wei-Wen Tsao and Chia-Lin Li and Jheng-Min Yu and Wen-Han Su and Zhi-Hua Liu and Cheng-Ru He and Yu-Chun Chang and Yi-Hsuan Tsai},
keywords = {COVID-19, HIV testing, mobile health, risk-taking behavior, social media, video, mobile phone},
abstract = {Background
The COVID-19 pandemic prompted social distancing policies and caused misinformation that hindered in-person HIV screening for high-risk groups. Social media platforms provide additional options for voluntary counseling and testing (VCT) for HIV, overcoming these limitations. However, there is a lack of data on HIV testing recruitment through social media platforms and its outcomes during the pandemic.
Objective
This study aimed to measure the rate of face-to-face mobile and video VCT conducted after recruitment through social media platforms and friend referrals during the pandemic and compare the geographic distribution, risk feature targeting, testing outcome, and cost between the 2 models.
Methods
Data were collected from March 3 to December 31, 2021, during the COVID-19 outbreak in Taiwan. Participants engaging in unprotected sex were recruited. After one-on-one message discussions through the platforms, the well-trained research assistants provided mobile or video VCT based on the participants’ availability. Primary outcomes were completion rate, testing results, and CD4 count. Secondary outcomes included demographic and HIV risk-taking and protective features from a questionnaire. Selection bias was controlled by adjusting for the testing site (Taipei vs non-Taipei) using univariable multinomial logistic regression.
Results
This study gathered 5142 responses on the social media platforms, recruiting 1187 participants. Video VCT had a completion rate of 31.8% (207/651), higher than mobile VCT’s 21.8% (980/4491). Both rates were higher than those before the COVID-19 pandemic. Recruitment through friend referrals, instant messaging apps (eg, Line [LY Corporation]), and geosocial dating apps (eg, Hornet [Queer Networks Inc], Grindr [Grindr LLC], and Gsland [Tien-Hao Tsai]) resulted in higher acceptance and completion rates than social networks (eg, Facebook [Meta], X [formerly Twitter], and Instagram [Meta]). Mobile VCT had higher recruitment among urban residents and screening density, while video VCT reached a broader geographic area. The mobile group was more likely to have had more than 10 sexual partners (odds ratio [OR] 1.92, 95% CI 1.05-3.50; P=.03), history of sex work (OR 4.19, 95% CI 1.68-10.43; P=.002), and sexually transmitted diseases (OR 2.23, 95% CI 1.18-4.23; P=.01) within the past 3 months. The video group was more likely to meet sexual partners through social media. The HIV-positive rate in the mobile group was 0.7% (7/973) with an average CD4 count of 460/μL, while in the video group, it was 1% (2/205) with an average CD4 count of 347/μL, indicating a later diagnosis. Both positivity rates were higher than those before the COVID-19 pandemic, with no significant difference between the groups. The video group cost US $54.68 per participant, slightly higher than the US $50.36 for the mobile group.
Conclusions
Recruiting through social media platforms that facilitate one-on-one message discussions can effectively target high-risk groups for mobile and video VCT. This approach should be integrated into the current screening model to enhance HIV case finding.}
}
@article{LIU2022107323,
title = {Machine learning-based models for estimating seismically-induced slope displacements in subduction earthquake zones},
journal = {Soil Dynamics and Earthquake Engineering},
volume = {160},
pages = {107323},
year = {2022},
issn = {0267-7261},
doi = {https://doi.org/10.1016/j.soildyn.2022.107323},
url = {https://www.sciencedirect.com/science/article/pii/S0267726122001725},
author = {Chenying Liu and Jorge Macedo},
abstract = {The assessment of the seismic performance of slope systems often relies on estimating the amount of seismically-induced slope displacements (D) using semi-empirical D models. These models take as inputs the slope properties and ground motion intensity measures (IMs) to provide D estimates that are used in engineering design. However, most of the available D models have been developed for regions affected by shallow crustal seismicity. Comparatively, the available D models for subduction tectonic settings are scarce. Moreover, most existing models have been developed using traditional statistical methods that do not take advantage of modern data-driven approaches. In this study, we develop new machine learning (ML) based D models applicable to subduction earthquake zones (considering both interface and intraslab mechanisms) using the NGA-Sub ground motion database. A systematic feature selection is performed using three ML procedures, finding that the yield coefficient (ky), the initial fundamental period of the slope system (Ts), the earthquake magnitude (M), the peak ground velocity (PGV), and the pseudo-spectral acceleration at 1.3Ts(Sa(1.3Ts)) are efficient features for estimating D in subduction earthquake zones. Based on the selected features, we develop five ML-based D models by using modern ML procedures (i.e., ridge regression, random forest, gradient boosting decision tree (GBDT), support vector regression (SVR), and residual neural network (ResNet)). The developed ML-based D models do not need to be restricted to predefined fixed functional forms, as has often been the case for previously developed D models. The ridge regression model is used to represent generic traditional D models as it has a polynomial-based functional form. Compared to the ridge regression model, the other developed ML-based models are able to better capture the complex relationship between D and the slope properties and IMs, showing a better predictive performance on test tests; hence, they outperform traditional models. In addition, we compare the performance of the developed ML-based models in terms of predictive performance, model trends, and computational cost for training. Lastly, the developed ML-based models also enhance the treatment of epistemic uncertainty in the estimation of D, given the scarcity of available robust D models for subduction zone tectonic settings.}
}
@article{FORYS20213449,
title = {Lasso Penalty method for variable selection in database construction process and developing house value models in RUA},
journal = {Procedia Computer Science},
volume = {192},
pages = {3449-3456},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.09.118},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921018573},
author = {Iwona Foryś},
keywords = {variable selection, lasso penatly method, house value, regression models},
abstract = {The aim of this paper is to confirm that in the case of the analysis of large data sets, the Lasso Penalty Method (LASSO) gives better results in the process of eliminating variables for the purpose of real estate value models than classical methods such as Ridge Regression. The selection of variables for an econometric model is closely related to its quality and suitability for intelligent decision support systems applied in the processes of real estate value management in the vicinity of airports. Airports face huge compensation payments as a result of the negative noise externalities they generate for neighbouring properties. Both the scale and complexity of this phenomenon require the development of intelligent systems to support airport decisions on compensation management and to monitor the environmental effects of these decisions. The selection of variables describing property characteristics is the first step in building a cost-effective system, as many of these characteristics are qualitative in nature. While systems can feed spatial information and data available in official registers, qualitative data often requires individual assessments and field visits. Hence, assessing the suitability of a given piece of information for a model is crucial at the data collection stage, especially when long time series are being constructed. For this purpose, it is proposed to use LASSO and then to model the value of developments consisting of detached houses on sets of variables selected with this method. The results obtained for LASSO are promising. They give the best set of qualitative and quantitative explanatory variables. The method has less variability than other subset selection methods tested. LASSO reduces some coefficients and zeros others, while retaining the positive attributes of subset selection and ridge regression. Furthermore, LASSO performs variable selection and coefficient estimation simultaneously. In the perspective of large set formation, this method of variable selection can also be used in Data Mining methods for estimating the value of large sets of properties. The obtained results can successfully support the process of property value management in the vicinity of airports}
}
@article{BOUASSALE2024104336,
title = {Development of a methodology for prediction and calibration of parameters of DEM simulations based on machine learning},
journal = {Mechanics Research Communications},
volume = {141},
pages = {104336},
year = {2024},
issn = {0093-6413},
doi = {https://doi.org/10.1016/j.mechrescom.2024.104336},
url = {https://www.sciencedirect.com/science/article/pii/S009364132400096X},
author = {Nasr-Eddine Bouassale and Mohamed Sallaou and Abdelmajid Aittaleb},
keywords = {Discrete element method (DEM), Calibration, Machine learning (ML), Support vector regression (SVR), Angle of repose},
abstract = {This research work aims to develop a robust methodology for the global estimation of interaction parameters based on machine learning, applicable to the discrete element method (DEM) in the study of granular materials. The specific objectives include establishing a theoretical framework that relates the interaction micro-parameters with the macro-parameters and the physical behaviour of the material; performing DEM simulations for different material parameters; developing a machine learning-based model for global parameter estimation; and consolidating the methodology for obtaining micro-parameters for a given material and behaviour. The methodology will be applied specifically to the case of dry copper ore, evaluating its limitations and the possibility of extension to materials with other characteristics. This approach does not consider direct experimental tests, but focuses on the characterisation of the relationship between the input parameters of the material and its response through simulations, validating the response and sensitivity of the model in its different stages. The methodology is expected to allow the systematic estimation of interaction properties for a DEM model, considering micro-parameter duplicities and their global selection, aspects little addressed in the literature. The final verification includes mechanisms and key questions that facilitate future modifications and improvements, allowing its application to materials of different characteristics beyond the specific case study.}
}
@article{TAVARES2015164,
title = {Extreme learning machine with parallel layer perceptrons},
journal = {Neurocomputing},
volume = {166},
pages = {164-171},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215004622},
author = {L.D. Tavares and R.R. Saldanha and D.A.G. Vieira},
keywords = {Parallel layer perceptrons, Extreme learning machine, Structural risk minimization, Least square estimate},
abstract = {This paper proposes using the Parallel Layer Perceptron (PLP) network, instead of the Single Layer Feedforward neural network (SLFN) in the Extreme Learning Machine (ELM) framework. Differently from the SLFNs which consider cascade layers, the PLP is designed to accomplish also parallel layers, being the SLFN its particular case. This paper explores a particular PLP configuration which considers a nonlinear layer in parallel with a linear layer. For n inputs and m nonlinear neurons, it provides (n+1)m linear parameters, while the SLFN would have only m linear parameters (one for each hidden neuron). Since the ELM is based on adjusting only the linear parameters using the least squares estimate (LSE), the PLP network provides more freedom for the proper adjustment. Results from 12 regression and 6 classification problems are presented considering the training and test errors, the linear vector norm and the system condition number. They point out that the PLP-ELM framework is more efficient than the SLFN-ELM approach.}
}
@article{DEOLIVEIRANETO2016124,
title = {Full modification coverage through automatic similarity-based test case selection},
journal = {Information and Software Technology},
volume = {80},
pages = {124-137},
year = {2016},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2016.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0950584916301392},
author = {Francisco G. {de Oliveira Neto} and Richard Torkar and Patrícia D.L. Machado},
keywords = {Regression testing, Test case selection, Model-based testing, Experimental study},
abstract = {Context: This paper presents the similarity approach for regression testing (SART), where a similarity-based test case selection technique (STCS) is used in a model-based testing process to provide selection of test cases exercising modified parts of a specification model. Unlike other model-based regression testing techniques, SART relies on similarity analysis among test cases to identify modifications, instead of comparing models, hence reducing the dependency on specific types of model. Objective: To present convincing evidence of the usage of similarity measures for modification-traversing test case selection. Method: We investigate SART in a case study and an experiment. The case study uses artefacts from industry and should be seen as a sanity check of SART, while the experiment focuses on gaining statistical power through the generation of synthetical models in order to provide convincing evidence of SART’s effectiveness. Through posthoc analysis we obtain p-values and effect sizes to observe statistically significant differences between treatments with respect to transition and modification coverage. Results: The case study with industrial artefacts revealed that SART is able to uncover the same number of defects as known similarity-based test case selection techniques. In turn, the experiment shows that SART, unlike the other investigated techniques, presents 100% modification coverage. In addition, all techniques covered a similar percentage of model transitions. Conclusions: In summary, not only does SART provide transition and defect coverage equal to known STCS techniques, but it exceeds greatly in covering modified parts of the specification model, being a suitable candidate for model-based regression testing.}
}
@article{AJWAD2024112055,
title = {A component method approach for single-sided beam-to-column joints with CHS column and welded double-tee beam},
journal = {Thin-Walled Structures},
volume = {202},
pages = {112055},
year = {2024},
issn = {0263-8231},
doi = {https://doi.org/10.1016/j.tws.2024.112055},
url = {https://www.sciencedirect.com/science/article/pii/S0263823124004981},
author = {Ali Ajwad and Sabatino {Di Benedetto} and Massimo Latour and Gianvittorio Rizzano},
keywords = {Tubular joints, Experimental tests, Finite element modelling, Parametric analysis, Regression analysis, Component method approach},
abstract = {This paper focuses on predicting the flexural stiffness and strength of beam-to-column joints with Circular-Hollow-Section (CHS) columns and externally welded double-tee beams using the Component Method approach. Currently, Eurocode 3 Part 1.8 lacks guidelines for assessing the stiffness of these joints, resulting in their practical modelling using extreme assumptions like pin or full restraint. Nevertheless, the literature demonstrates that these joints can exhibit semi-rigid behaviour due to the relatively high local deformability of the tube in the joint area. Another concern relates to the strength of these joints. In fact, recent studies have shown that Eurocode 3 Part 1.8 formula for predicting the yield resistance of these joints is over-conservative. Within this framework, the purpose of this study is to fill the current knowledge gaps (over-conservative strength prediction and lack of rules for determining the stiffness) by undertaking a thorough investigation involving numerical and analytical activities. Specifically, the research presents a component-based modelling approach for predicting stiffness and strength of CHS to double-tee beam connections. In this regard, the work presented in this paper has involved the selection of experimental tests from literature to validate a Finite Element (FE) model, specifically focusing on X- and T-joints and internal and external beam-to-column joints. The validated numerical models have been then employed to simulate the response under monotonic loading conditions of additional sets comprising forty T-joints and thirty external beam-to-column joints, respectively. The currently available formulations for predicting the resistance of T-joints were applied to the forty cases simulated, evaluating their accuracy. This allowed the individuation of the most accurate literature formula for the strength prediction of T-joints, showing that the recent proposal of Voth and Packer (2012) yields sufficiently accurate results. Instead, analytical formulations for predicting the stiffness of T-joints were properly derived in a closed-form solution and were validated against the results of the parametric study. Finally, drawing upon knowledge regarding the stiffness and strength of T-joints, the flexural response of external beam-to-columns connections was evaluated proposing a component model, whose accuracy was verified against the cases simulated in the parametric analysis.}
}
@article{LEALNETO2020104263,
title = {Prioritizing COVID-19 tests based on participatory surveillance and spatial scanning},
journal = {International Journal of Medical Informatics},
volume = {143},
pages = {104263},
year = {2020},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2020.104263},
url = {https://www.sciencedirect.com/science/article/pii/S1386505620308534},
author = {O.B Leal-Neto and F.A.S Santos and J.Y Lee and J.O Albuquerque and W.V Souza},
keywords = {Participatory surveillance, Epidemiology, Spatial scanning, COVID-19},
abstract = {Objectives
This study aimed to identify, describe and analyze priority areas for COVID-19 testing combining participatory surveillance and traditional surveillance.
Design
It was carried out a descriptive transversal study in the city of Caruaru, Pernambuco state, Brazil, within the period of 20/02/2020 to 05/05/2020. Data included all official reports for influenza-like illness notified by the municipality health department and the self-reports collected through the participatory surveillance platform Brasil Sem Corona.
Methods
We used linear regression and loess regression to verify a correlation between Participatory Surveillance (PS) and Traditional Surveillance (TS). Also a spatial scanning approach was deployed in order to identify risk clusters for COVID-19.
Results
In Caruaru, the PS had 861 active users, presenting an average of 1.2 reports per user per week. The platform Brasil Sem Corona started on March 20th and since then, has been officially used by the Caruaru health authority to improve the quality of information from the traditional surveillance system. Regarding the respiratory syndrome cases from TS, 1588 individuals were positive for this clinical outcome. The spatial scanning analysis detected 18 clusters and 6 of them presented statistical significance (p-value < 0.1). Clusters 3 and 4 presented an overlapping area that was chosen by the local authority to deploy the COVID-19 serology, where 50 individuals were tested. From there, 32 % (n = 16) presented reagent results for antibodies related to COVID-19.
Conclusion
Participatory surveillance is an effective epidemiological method to complement the traditional surveillance system in response to the COVID-19 pandemic by adding real-time spatial data to detect priority areas for COVID-19 testing.}
}
@article{BELHOUCHET2021136,
title = {A new empirical model for enhancing well log permeability prediction, using nonlinear regression method: Case study from Hassi-Berkine oil field reservoir – Algeria},
journal = {Journal of King Saud University - Engineering Sciences},
volume = {33},
number = {2},
pages = {136-145},
year = {2021},
issn = {1018-3639},
doi = {https://doi.org/10.1016/j.jksues.2020.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S1018363920302270},
author = {H.E. Belhouchet and M.S. Benzagouta and A. Dobbi and A. Alquraishi and J. Duplay},
keywords = {Permeability, Reservoir characterization, Rock typing, Hydraulic unite, Flow zone indicator},
abstract = {The reservoir permeability (K) factor is the key parameter for reservoir characterization. This parameter is considered as a determinant reservoir quality index. Depending on the data required and procedure availability, permeability can be defined from several methods such as; well test interpretation, wireline formation tester, and core data. These approaches can also be in assumption with permeability prediction targeting the non-cored sections. According to a similar status, well logs records can be an interesting support tool in use to reach the planned objectives. Thus, this investigation consists of finding out a model able to estimate the well log permeability and adjusting the outcome to the core permeability results. In this led research, the applied approach to the core data, to start with, was aimed to determine the reservoir rock types (RRT) using the flow zone indicator (FZI) method. The obtained classification allows stating a permeability model for each rock type. In order to calculate permeability from well logs, FZI has been founded out. A multi-regression technique was used to analyze the relationship of FZI with respect to specific logs such as Gamma-ray (GR), Density Log (RHOB), and Sonic log (DT). An objective function has been designated to minimize the quadratic error between the observed normalized FZI coming from core data, and the normalized FZI calculated from well logs. This process is carried out to identify a mathematical correlation allowing the estimation of FZI from porosity logs, leading to permeability determination. As results, permeability from logs was supporting relatively permeability defined from cores. The final results can be an accurate and real test for associating the exactitude performance of logging data records in boreholes with respect to the overall reservoir characterization sections. Thus, the applied investigation can be a genuine and quick method for essentially a specific deduction regarding the non-cored reservoir sections, with reference to rock typing, permeability and probably further reservoir factors.}
}
@article{BOBROWSKI2015105,
title = {Estimation of the lifetime distribution of mechatronic systems in the presence of a covariate: A comparison among parametric, semiparametric and nonparametric models},
journal = {Reliability Engineering & System Safety},
volume = {139},
pages = {105-112},
year = {2015},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2015.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0951832015000575},
author = {Sebastian Bobrowski and Hong Chen and Maik Döring and Uwe Jensen and Wolfgang Schinköthe},
keywords = {Failure time models, Lifetime distribution prediction, Regression with covariates, Model selection},
abstract = {In practice manufacturers may have lots of failure data of similar products using the same technology basis under different operating conditions. Thus, one can try to derive predictions for the distribution of the lifetime of newly developed components or new application environments through the existing data using regression models based on covariates. Three categories of such regression models are considered: a parametric, a semiparametric and a nonparametric approach. First, we assume that the lifetime is Weibull distributed, where its parameters are modelled as linear functions of the covariate. Second, the Cox proportional hazards model, well-known in Survival Analysis, is applied. Finally, a kernel estimator is used to interpolate between empirical distribution functions. In particular the last case is new in the context of reliability analysis. We propose a goodness of fit measure (GoF), which can be applied to all three types of regression models. Using this GoF measure we discuss a new model selection procedure. To illustrate this method of reliability prediction, the three classes of regression models are applied to real test data of motor experiments. Further the performance of the approaches is investigated by Monte Carlo simulations.}
}
@article{EBRAHIMI2021102193,
title = {A reinforcement learning approach for finding optimal policy of adaptive radiation therapy considering uncertain tumor biological response},
journal = {Artificial Intelligence in Medicine},
volume = {121},
pages = {102193},
year = {2021},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2021.102193},
url = {https://www.sciencedirect.com/science/article/pii/S093336572100186X},
author = {Saba Ebrahimi and Gino J. Lim},
keywords = {Reinforcement learning, Radiotherapy, Biological tumor response, Adaptive radiation therapy.},
abstract = {Recent studies have shown that a tumor's biological response to radiation varies over time and has a dynamic nature. Dynamic biological features of tumor cells underscore the importance of using fractionation and adapting the treatment plan to tumor volume changes in radiation therapy treatment. Adaptive radiation therapy (ART) is an iterative process to adjust the dose of radiation in response to potential changes during the treatment. One of the key challenges in ART is how to determine the optimal timing of adaptations corresponding to tumor response to radiation. This paper aims to develop an automated treatment planning framework incorporating the biological uncertainties to find the optimal adaptation points to achieve a more effective treatment plan. First, a dynamic tumor-response model is proposed to predict weekly tumor volume regression during the period of radiation therapy treatment based on biological factors. Second, a Reinforcement Learning (RL) framework is developed to find the optimal adaptation points for ART considering the uncertainty in biological factors with the goal of achieving maximum final tumor control while minimizing or maintaining the toxicity level of the organs at risk (OARs) per the decision-maker's preference. Third, a beamlet intensity optimization model is solved using the predicted tumor volume at each adaptation point. The performance of the proposed RT treatment planning framework is tested using a clinical non-small cell lung cancer (NSCLC) case. The results are compared with the conventional fractionation schedule (i.e., equal dose fractionation) as a reference plan. The results show that the proposed approach performed well in achieving a robust optimal ART treatment plan under high uncertainty in the biological parameters. The ART plan outperformed the reference plan by increasing the mean biological effective dose (BED) value of the tumor by 2.01%, while maintaining the OAR BED within +0.5% and reducing the variability, in terms of the interquartile range (IQR) of tumor BED, by 25%.}
}
@article{LOYOLAFUENTES2024123043,
title = {A framework for data regression of heat transfer data using machine learning},
journal = {Applied Thermal Engineering},
volume = {248},
pages = {123043},
year = {2024},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2024.123043},
url = {https://www.sciencedirect.com/science/article/pii/S1359431124007117},
author = {Jose Loyola-Fuentes and Nima Nazemzadeh and Emilio Diaz-Bejarano and Simone Mancin and Francesco Coletti},
keywords = {Heat transfer, Machine learning, Two-phase flow, Heat transfer coefficient, Condensation, Microfin tubes, Data regression},
abstract = {Machine Learning (ML) algorithms are emerging in various industries as a powerful complement/alternative to traditional data regression methods. A major reason is that, unlike deterministic models, they can be used even in the absence of detailed phenomenological knowledge. Not surprisingly, the use of ML algorithms is being explored also in heat transfer applications. It is of particular interest in systems dealing with complex geometries and underlying phenomena (e.g. fluid phase change, multi-phase flow, heavy fouling build-up). However, heat transfer systems present specific challenges that need addressing, such as the scarcity of high-quality data, the inconsistencies across published data sources, the complex (and often correlated) influence of inputs, the split of data between training and testing sets, and the limited extrapolation capabilities to unseen conditions. In an attempt to help overcome some of these challenges and, more importantly, to provide a systematic approach, this article reviews and analyses past efforts in the application of ML algorithms to heat transfer applications, and proposes a regression framework for their deployment to estimate key quantities (e.g. heat transfer coefficient), to be used for improved design and operation of heat exchangers. The framework consists of six steps: i) data pre-treatment, ii) feature selection, iii) data splitting philosophy, iv) training and testing, v) tuning of hyperparameters, and vi) performance assessment with specific indicators, to support the choice of accurate and robust models. A relevant case study involving the estimation of the condensation heat transfer coefficient in microfin tubes is used to illustrate the proposed framework. Two data-driven algorithms, Deep Neural Networks and Random Forest, are tested and compared in terms of their estimation and extrapolation capabilities. The results show that ML algorithms are generally more accurate in predicting the heat transfer coefficient than a well-known semi-empirical correlation proposed in past studies, where the mean absolute error of the most suitable ML model is 535 [Wm2K-1], compared to the error using the correlation of 1061 [Wm2K-1]. In terms of extrapolation, the selected ML model has a mean absolute error of 1819 [Wm2K-1], while for the correlation is 1111 [Wm2K-1], indicating a disadvantage of the use of semi-empirical models, although the comparison was not entirely suitable, given that the correlation was used as is and no training was done. In addition, feature selection enables simpler models that depend only on features that are potentially most related to the target variable. Special attention is needed however, as overfitting and limited extrapolation capabilities are common difficulties that are encountered when deploying these models.}
}
@article{SHEN2022,
title = {Foundations for Meaningful Consent in Canada’s Digital Health Ecosystem: Retrospective Study},
journal = {JMIR Medical Informatics},
volume = {10},
number = {3},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/30986},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422001168},
author = {Nelson Shen and Iman Kassam and Haoyu Zhao and Sheng Chen and Wei Wang and Sarah Wickham and Gillian Strudwick and Abigail Carter-Langford},
keywords = {consent, eConsent, privacy, trust, digital health, health information exchange, patient perspective, health informatics, Canada},
abstract = {Background
Canadians are increasingly gaining web-based access to digital health services, and they expect to access their data from these services through a central patient access channel. Implementing data sharing between these services will require patient trust that is fostered through meaningful consent and consent management. Understanding user consent requirements and information needs is necessary for developing a trustworthy and transparent consent management system.
Objective
The objective of this study is to explore consent management preferences and information needs to support meaningful consent.
Methods
A secondary analysis of a national survey was conducted using a retrospective descriptive study design. The 2019 cross-sectional survey used a series of vignettes and consent scenarios to explore Canadians’ privacy perspectives and preferences regarding consent management. Nonparametric tests and logistic regression analyses were conducted to identify the differences and associations between various factors.
Results
Of the 1017 total responses, 716 (70.4%) participants self-identified as potential users. Of the potential users, almost all (672/716, 93.8%) felt that the ability to control their data was important, whereas some (385/716, 53.8%) believed that an all or none control at the data source level was adequate. Most potential users preferred new data sources to be accessible by health care providers (546/716, 76.3%) and delegated parties (389/716, 54.3%) by default. Prior digital health use was associated with greater odds of granting default access when compared with no prior use, with the greatest odds of granting default access to digital health service providers (odds ratio 2.17, 95% CI 1.36-3.46). From a list of 9 information elements found in consent forms, potential users selected an average of 5.64 (SD 2.68) and 5.54 (SD 2.85) items to feel informed in consenting to data access by care partners and commercial digital health service providers, respectively. There was no significant difference in the number of items selected between the 2 scenarios (P>.05); however, there were significant differences (P<.05) in information types that were selected between the scenarios.
Conclusions
A majority of survey participants reported that they would register and use a patient access channel and believed that the ability to control data access was important, especially as it pertains to access by those outside their care. These findings suggest that a broad all or none approach based on data source may be accepted; however, approximately one-fifth of potential users were unable to decide. Although vignettes were used to introduce the questions, this study showed that more context is required for potential users to make informed consent decisions. Understanding their information needs will be critical, as these needs vary with the use case, highlighting the importance of prioritizing and tailoring information to enable meaningful consent.}
}
@article{PEDEMONTE20161145,
title = {A Systolic Genetic Search for reducing the execution cost of regression testing},
journal = {Applied Soft Computing},
volume = {49},
pages = {1145-1161},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616303441},
author = {Martín Pedemonte and Francisco Luna and Enrique Alba},
keywords = {Regression testing, Evolutionary algorithms, Parallel metaheuristics, GPU, CUDA},
abstract = {The Test Suite Minimization Problem (TSMP) is a NP-hard real-world problem that arises in the field of software engineering. It consists in selecting a minimal set of test cases from a large test suite, ensuring that the test cases selected cover a given set of requirements of a piece of software at the same time as it minimizes the amount of resources required for its execution. In this paper, we propose a Systolic Genetic Search (SGS) algorithm for solving the TSMP. SGS is a recently proposed optimization algorithm capable of taking advantage of the high degree of parallelism available in modern GPU architectures. The experimental evaluation conducted on a large number of test suites generated for seven real-world programs and seven large test suites generated for a case study from a real-world program shows that SGS is highly effective for the TSMP. SGS not only outperforms two competitive genetic algorithms, but also outperforms four heuristics specially conceived for this problem. The results also show that the GPU implementation of SGS has achieved a high performance, obtaining a large runtime reduction with respect to the CPU implementation for solutions with similar quality. The GPU implementation of SGS also shows an excellent scalability behavior when solving instances with a large number of test cases. As a consequence, the GPU-based SGS stands as a state of the art alternative for solving the TSMP in real-world software testing environments.}
}
@article{LIU2022126085,
title = {Studies on the validity of strain sensors for pavement monitoring: A case study for a fiber Bragg grating sensor and resistive sensor},
journal = {Construction and Building Materials},
volume = {321},
pages = {126085},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2021.126085},
url = {https://www.sciencedirect.com/science/article/pii/S0950061821038174},
author = {Zhen Liu and Xingyu Gu and Chunying Wu and Hua Ren and Zhou Zhou and Shi Tang},
keywords = {Asphalt pavement monitoring, Finite element simulation, FBG sensor, Resistive sensor, Validity, Sensitivity},
abstract = {To address the problems associated with the validity of pavement sensor measurement, a method of combining indoor experiments with finite element (FE) simulations for strain measurement in asphalt pavement is developed in this paper to analyze the validity of strain sensors for practical measurements. First, correlation analysis and one-way analysis of variance (ANOVA) between the simulated strain and the measured strain of the resistive (R) sensor and the fiber Bragg grating (FBG) sensor are developed, and the results show that the strain simulation of asphalt mixtures with sensors by means of FE simulation is feasible for short-term loading tests; therefore, the simulated strain without sensors is considered the true strain. The FBG sensor is more appropriate than the R sensor for use in the measurement of horizontal strain based on the stability of the regression model. Furthermore, creep experiments and FE simulations with a modified Burgers model are developed, and the results demonstrate that the FE simulation is also effective for long-term dynamic loading tests. Finally, the effect of the ratio of the modulus of the FBG sensor to that of the asphalt mixture on the stability of the regression model is analyzed, and the results suggest that the stability worsens as the modulus ratio increases at the same temperature, which could guide the selection of encapsulating materials. Moreover, the research method could also provide resources for studying the validity of sensors under more complex loading modes.}
}
@article{CHEN2023761,
title = {A fractional study based on the economic and environmental mathematical model},
journal = {Alexandria Engineering Journal},
volume = {65},
pages = {761-770},
year = {2023},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2022.09.033},
url = {https://www.sciencedirect.com/science/article/pii/S1110016822006275},
author = {Qiliang Chen and Zulqurnain Sabir and Muhammad {Asif Zahoor Raja} and Wei Gao and Haci {Mehmet Baskonus}},
keywords = {Fractional order, Economic and environmental, Scaled conjugate gradient, Reference solutions, Neural networks},
abstract = {The purpose of this investigation is to provide the numerical study based on the fractional order (FO) economic and environmental mathematical model (EEMM) called as FO-EEMM. The motive of this work is to find more realistic results of the EEMM of the non-integer and FO derivatives. The structure of the FO-EEMM is categorized into three dynamics, control accomplishment cost, capability of the manufacturing elements and the diagnostics cost of the technical exclusion. The solution of the FO-EEMM is numerically presented by using the scaled conjugate gradient neural networks (SCGNNs). Three cases based on the FO-EEMM have been scrutinized to indicate the numerical performances along with the selection of the statics as 76% for training, 13% for testing and 11% for certification. The correctness of the designed SCGNNs is authenticated by using the matching of the achieved and the reference solutions (Adams-Bashforth-Moulton). The validity, exactness, dependability, and competence of the SCGNNs is observed through the performances of the mean square error, regression, state transitions, error histograms and correlation.}
}
@article{VAGLIANO2022104688,
title = {Can we reliably automate clinical prognostic modelling? A retrospective cohort study for ICU triage prediction of in-hospital mortality of COVID-19 patients in the Netherlands},
journal = {International Journal of Medical Informatics},
volume = {160},
pages = {104688},
year = {2022},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2022.104688},
url = {https://www.sciencedirect.com/science/article/pii/S1386505622000028},
author = {I. Vagliano and S. Brinkman and A. Abu-Hanna and M.S Arbous and D.A. Dongelmans and P.W.G. Elbers and D.W. {de Lange} and M. {van der Schaar} and N.F. {de Keizer} and M.C. Schut},
abstract = {Background
Building Machine Learning (ML) models in healthcare may suffer from time-consuming and potentially biased pre-selection of predictors by hand that can result in limited or trivial selection of suitable models. We aimed to assess the predictive performance of automating the process of building ML models (AutoML) in-hospital mortality prediction modelling of triage COVID-19 patients at ICU admission versus expert-based predictor pre-selection followed by logistic regression.
Methods
We conducted an observational study of all COVID-19 patients admitted to Dutch ICUs between February and July 2020. We included 2,690 COVID-19 patients from 70 ICUs participating in the Dutch National Intensive Care Evaluation (NICE) registry. The main outcome measure was in-hospital mortality. We asessed model performance (at admission and after 24h, respectively) of AutoML compared to the more traditional approach of predictor pre-selection and logistic regression.
Findings
Predictive performance of the autoML models with variables available at admission shows fair discrimination (average AUROC = 0·75-0·76 (sdev = 0·03), PPV = 0·70-0·76 (sdev = 0·1) at cut-off = 0·3 (the observed mortality rate), and good calibration. This performance is on par with a logistic regression model with selection of patient variables by three experts (average AUROC = 0·78 (sdev = 0·03) and PPV = 0·79 (sdev = 0·2)). Extending the models with variables that are available at 24h after admission resulted in models with higher predictive performance (average AUROC = 0·77-0·79 (sdev = 0·03) and PPV = 0·79-0·80 (sdev = 0·10-0·17)).
Conclusions
AutoML delivers prediction models with fair discriminatory performance, and good calibration and accuracy, which is as good as regression models with expert-based predictor pre-selection. In the context of the restricted availability of data in an ICU quality registry, extending the models with variables that are available at 24h after admission showed small (but significantly) performance increase.}
}
@article{OPARA2022108286,
title = {Regularization and concave loss functions for estimation of chemical kinetic models},
journal = {Applied Soft Computing},
volume = {116},
pages = {108286},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.108286},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621010930},
author = {Karol R. Opara and Pin Pin Oh},
keywords = {Regularization, Loss function, Global optimization, Curve fitting, Reaction rate, Non-linear regression, Transesterification, Biodiesel},
abstract = {Non-linear regression is the primary tool for estimating kinetic models of chemical reactions. The default approach of minimizing the sum of squared residuals tends to underperform in the presence of systematic errors, non-normal distribution of residuals or identifiability issues such as a high correlation between parameters. Therefore, we argue for a careful choice of the fit criteria and propose new, concave loss functions. Together with regularization, they form a robust objective for the regression procedure. Discussion of the rationale behind the proposed approach and its effects is illustrated by laboratory data on the transesterification of palm oil. A dedicated simulation study complements qualitative examples. All of the top-performing methods use regularization. Concave loss functions were among the best in 6–7 out of 8 test cases, compared to 2–3 for the classical square loss confirming both statistical and practical usefulness of the novel fit criteria. This result holds for a variety of modern optimizers. In 76% of our simulations, we obtained results not significantly worse than the best, whereas methods currently used in the literature provide 38% for the relative and 0% for the square loss.}
}
@article{SEBASTIANI2023419,
title = {Numerical evaluation of multivariate power curves for wind turbines in wakes using nacelle lidars},
journal = {Renewable Energy},
volume = {202},
pages = {419-431},
year = {2023},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2022.11.081},
url = {https://www.sciencedirect.com/science/article/pii/S0960148122017219},
author = {Alessandro Sebastiani and Alfredo Peña and Niels Troldborg},
keywords = {Nacelle lidars, Power curves, Turbulence, Wakes, Multivariable regression},
abstract = {The IEC standards describe how to measure the power performance of an isolated wake-free wind turbine. However, most wind turbines operate under waked conditions for a substantial amount of time, calling for the need of a new methodology for power performance evaluation. We define multivariate power curves in the form of multivariate polynomial regressions, whose input variables are several wind speed and turbulence measurements retrieved with nacelle lidars. We use a dataset of synthetic power performance tests including both waked and wake-free conditions. The dataset is generated through aeroelastic simulations combined with both virtual nacelle lidars and the dynamic wake meandering model. A feature-selection algorithm is used to select the input variables among the available measurements, showing that the optimal model includes four input variables: three correspondent to wind speed and one to turbulence measures. Additionally, we give insights on the optimal nacelle-lidar scanning geometry needed to implement the multivariate power curve. Results show that the multivariate power curves predict the power output with accuracy of the same order under both waked and wake-free operation. For the in-wake cases, the accuracy is much higher than that of the IEC standard power curve, with an error reduction of up to 88%.}
}
@incollection{ESCOBAR2024189,
title = {Chapter 9 - Case studies},
editor = {Carlos A. Escobar and Ruben Morales-Menendez},
booktitle = {Machine Learning in Manufacturing},
publisher = {Elsevier},
pages = {189-205},
year = {2024},
isbn = {978-0-323-99029-5},
doi = {https://doi.org/10.1016/B978-0-323-99029-5.00010-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323990295000108},
author = {Carlos A. Escobar and Ruben Morales-Menendez},
keywords = {Case studies, Jupyter notebook, Structured data, Unstructured data},
abstract = {This chapter illustrates the machine learning and coding aspects of learning quality control. Two case studies are developed using structured and unstructured data. The main objective is to illustrate the main concepts presented in this book and for the readers to access to a basic code that can be used in the solution process of another problem. The first case study uses a publicly available dataset, it focuses on training a classifier to predict low quality wine. The random forest, XGBoost, and logistic regression algorithms are trained for this task. We illustrate the application of data preprocessing techniques, grid search for hyperparameter optimization, and feature selection methods. In the second case study, we generated a dataset of images from a toy car replica. Then, a convolutional neural network classifier is developed to automatically identify misalignments in the body of the cars. The classifier correctly detects all misalignments in the test set. This example illustrates how human-based monitoring systems are replaced by learning quality control systems.}
}
@article{MOHAMMADI2021187,
title = {Efficient uncertainty quantification of CFD problems by combination of proper orthogonal decomposition and compressed sensing},
journal = {Applied Mathematical Modelling},
volume = {94},
pages = {187-225},
year = {2021},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2021.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X21000214},
author = {Arash Mohammadi and Koji Shimoyama and Mohamad Sadeq Karimi and Mehrdad Raisee},
keywords = {Uncertainty quantification, Proper orthogonal decomposition, Multifidelity, Compressed sensing, Polynomial chaos expansion},
abstract = {In the current paper, an efficient surrogate model based on combination of Proper Orthogonal Decomposition (POD) and compressed sensing is developed for affordable representation of high dimensional stochastic fields. In the developed method, instead of the full (or classical) Polynomial Chaos Expansion (PCE), the ℓ1-minimization approach is utilized to reduce the computational work-load of the low-fidelity calculations. To assess the model capability in the real engineering problems, two challenging high-dimensional CFD test cases namely; i) turbulent transonic flow around RAE2822 airfoil with 18 geometrical uncertainties and ii) turbulent transonic flow around NASA Rotor 37 with 3 operational and 21 geometrical uncertainties are considered. Results of Uncertainty Quantification (UQ) analysis in both test cases showed that the proposed multi-fidelity approach is able to reproduce the statistics of quantities of interest with much lower computational cost than the classical regression-based PCE method. It is shown that the combination of the POD with the compressed sensing in RAE2822 and Rotor 37 test cases gives respectively computational gains between 1.26–7.72 and 1.79–9.05 times greater than the combination of the POD with the full PCE.}
}
@article{GE20141454,
title = {Active learning strategy for smart soft sensor development under a small number of labeled data samples},
journal = {Journal of Process Control},
volume = {24},
number = {9},
pages = {1454-1461},
year = {2014},
issn = {0959-1524},
doi = {https://doi.org/10.1016/j.jprocont.2014.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959152414001784},
author = {Zhiqiang Ge},
keywords = {Soft sensor, Smart, Active learning, Unlabeled data samples, Data-based modeling},
abstract = {This contribution proposes a new active learning strategy for smart soft sensor development. The main objective of the smart soft sensor is to opportunely collect labeled data samples in such a way as to minimize the error of the regression process while minimizing the number of labeled samples used, and thus to reduce the costs related to labeling training samples. Instead of randomly labeling data samples, the smart soft sensor only labels those data samples which can provide the most significant information for construction of the soft sensor. In this paper, without loss of generality, the smart soft sensor is built based on the widely used principal component regression model. For performance evaluation, an industrial case study is provided. Compared to the random sample labeling strategy, both accuracy and stability have been improved by the active learning strategy based smart soft sensor.}
}
@article{BREWICK201746,
title = {Enabling reduced-order data-driven nonlinear identification and modeling through naïve elastic net regularization},
journal = {International Journal of Non-Linear Mechanics},
volume = {94},
pages = {46-58},
year = {2017},
note = {A Conspectus of Nonlinear Mechanics: A Tribute to the Oeuvres of Professors G. Rega and F. Vestroni},
issn = {0020-7462},
doi = {https://doi.org/10.1016/j.ijnonlinmec.2017.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0020746217300732},
author = {Patrick T. Brewick and Sami F. Masri and Biagio Carboni and Walter Lacarbonara},
keywords = {Elastic net, Lasso regression, Nonlinear identification, Data-driven},
abstract = {This work discusses an improved method of reduced-order modeling for existing data-driven nonlinear identification techniques through the incorporation of naïve elastic net regularization. The data-driven methods considered for this study operate using basis functions to represent the observed nonlinearity. Elastic net regularization is used to minimize the number of non-zero coefficients, thus modifying the basis functions and providing a compact representation. The ability of the naïve elastic net to provide reduced-order nonlinear models that can both accurately fit various data sets and computationally simulate new responses is illustrated through studies considering both synthetic data and experimental data. In both cases, the results obtained with the naïve elastic net are shown to match or outperform those from other traditional methods.}
}
@article{LITY201946,
title = {Retest test selection for product-line regression testing of variants and versions of variants},
journal = {Journal of Systems and Software},
volume = {147},
pages = {46-63},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.09.090},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218302176},
author = {Sascha Lity and Manuel Nieke and Thomas Thüm and Ina Schaefer},
keywords = {Regression testing, Software evolution, Software product lines},
abstract = {Testing is a crucial activity of product-line engineering. Due to shared commonality, testing each variant individually results in redundant testing processes. By adopting regression testing strategies, variants are tested incrementally by focusing on the variability between variants to reduce the overall testing effort. However, product lines evolve during their life-cycle to adapt, e.g., to changing requirements. Hence, quality assurance has also to be ensured after product-line evolution by efficiently testing respective versions of variants. In this paper, we propose retest test selection for product-line regression testing of variants and versions of variants. Based on delta-oriented test modeling, we capture the commonality and variability of an evolving product line by means of differences between variants and versions of variants. We exploit those differences to apply change impact analyses, where we reason about changed dependencies to be retested when stepping from a variant or a version of a variant to its subsequent one by selecting test cases for reexecution. We prototypically implemented our approach and evaluated its effectiveness and efficiency by means of two evolving product lines showing positive results.}
}
@article{IBRAR2021107706,
title = {PrePass-Flow: A Machine Learning based technique to minimize ACL policy violation due to links failure in hybrid SDN},
journal = {Computer Networks},
volume = {184},
pages = {107706},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107706},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620313025},
author = {Muhammad Ibrar and Lei Wang and Gabriel-Miro Muntean and Aamir Akbar and Nadir Shah and Kaleem Razzaq Malik},
keywords = {Hybrid SDN, Machine Learning, ACL, Link Failure Prediction, Network reachability},
abstract = {The centralized architecture of Software-Defined Networking (SDN) reduces networking complexity and improves network manageability by omitting the need for box-by-box troubleshooting and management. However, due to both budget constraints and maturity level of the SDN-capable devices, organizations often are reluctant to adopt SDN in practice. Therefore, instead of migrating to a pure SDN architecture, an incremental SDN deployment strategy is preferred in practice. In this paper, we consider an incremental SDN deployment strategy known as hybrid SDN - involving simultaneous use of both SDN switches and legacy switches. The links connected to an SDN switch are called SDN links, and the rest are called legacy links. An SDN controller can directly poll the status of the SDN links via the connected SDN switches. At the same time, the status of the legacy links passes through SDN switches and reaches the controller, causing delay. As a result, the controller does not have the current status of legacy links in real-time. This delay may lead to undesired outcomes. For example, it causes network reachability problems due to Access Control List (ACL) policies. Therefore, to minimize the impact of network-layer failure in hybrid SDN, we propose a Machine Learning (ML) based technique called PrePass-Flow. PrePass-Flow predicts link failures before their occurrence, recomputes the locations of ACL policies, and installs the ACL policies in the recomputed locations in a proactive manner. The main objective of PrePass-Flow is to minimize the ACL policy violations and network reachability problems due to ACL policies in case of link failures. For the link status prediction, PrePass-Flow uses two supervised ML-based models: 1) a Logistic Regression (LR) model, and 2) a Support Vector Machine (SVM) model. Testing results show that the LR model performs better than both the SVM model and an existing approach in terms of Packet Delivery Ratio (PDR) and ACL policy violations. For instance, the LR model’s accuracy is 4% better, precision is 5% higher, sensitivity is 10% better, and Area Under the Curve (AUC) is 6% greater than the SVM model’s corresponding results.}
}
@article{FLASCHEL2023115867,
title = {Automated discovery of generalized standard material models with EUCLID},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {405},
pages = {115867},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2022.115867},
url = {https://www.sciencedirect.com/science/article/pii/S0045782522008234},
author = {Moritz Flaschel and Siddhant Kumar and Laura {De Lorenzis}},
keywords = {Unsupervised learning, Constitutive models, Generalized standard materials, Interpretable models, Sparse regression, Inverse problems},
abstract = {We extend the scope of our recently developed approach for unsupervised automated discovery of material laws (denoted as EUCLID) to the general case of a material belonging to an unknown class of constitutive behavior. To this end, we leverage the theory of generalized standard materials, which encompasses a plethora of important constitutive classes including elasticity, viscosity, plasticity and arbitrary combinations thereof. We show that, based only on full-field kinematic measurements and net reaction forces, EUCLID is able to automatically discover the two scalar thermodynamic potentials, namely, the Helmholtz free energy and the dissipation potential, which completely define the behavior of generalized standard materials. The a priori enforced constraint of convexity on these potentials guarantees by construction stability and thermodynamic consistency of the discovered model; balance of linear momentum acts as a fundamental constraint to replace the availability of stress–strain labeled pairs; sparsity promoting regularization enables the automatic selection of a small subset from a possibly large number of candidate model features and thus leads to a parsimonious, i.e., simple and interpretable, model. Importantly, since model features go hand in hand with the correspondingly active internal variables, sparse regression automatically induces a parsimonious selection of the few internal variables needed for an accurate but simple description of the material behavior. A fully automatic procedure leads to the selection of the hyperparameter controlling the weight of the sparsity promoting regularization term, in order to strike a user-defined balance between model accuracy and simplicity. By testing the method on synthetic data including artificial noise, we demonstrate that EUCLID is able to automatically discover the true hidden material model from a large catalogue of constitutive classes, including elasticity, viscoelasticity, elastoplasticity, viscoplasticity, isotropic and kinematic hardening.}
}
@article{FOUAD2023105266,
title = {Identification of Alzheimer’s disease from central lobe EEG signals utilizing machine learning and residual neural network},
journal = {Biomedical Signal Processing and Control},
volume = {86},
pages = {105266},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.105266},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423006997},
author = {Islam A. Fouad and Fatma {El-Zahraa M. Labib}},
keywords = {Alzheimer's disease, EEG signals, Pre-processing, Feature extraction, Classification, Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (LR), Resnet-50 CNN},
abstract = {Cognitive and behavioral deficits are some of the symptoms of Alzheimer's disease, a neurological disease caused by brain deterioration. Early diagnosis of the disease minimizes the disease's progression. In this way, patients' living standards can be maintained. An experienced specialist will assess the results of grueling diagnostic tests and a costly diagnosis process. This motivation led to the creation of a fully automated computer system, which uses the proposed methods to detect Alzheimer's disease from EEG signals acquired from a minimum number of electrodes: three central lobe electrodes. This work presents the advantages of implementing the proposed system. Two different datasets were presented to evaluate the system’s performance. After preprocessing the raw EEG data, wavelet transforms were applied to calculate statistical properties. First, the paper discusses the performance of different traditional machine learning classifiers: Diagonal Discriminant Analysis, Support Vector Machine (LSVM, RBF), K-Nearest Neighbors, Random Forest, Logistic Regression, and Naïve Bayes. By comparing the classifiers’ performance, it is found that Naïve Bayes and LSVM classifiers yield the highest performance of 96.55% and 95.69% when applied to the first dataset and 96.55% and 94.52% for the second dataset, respectively. “ResNet-50” Convolutional Neural Network classifier was implemented to demonstrate the capability of constructing an effective AD diagnosing system. It yields an accuracy of 97.8261% when applied to the first dataset. This work shows how Deep Learning improves the performance of classification in early medical diagnosis, which will enhance different diseases’ treatment, as “Resnet – 50” convolutional neural network classifier outperformed Naïve Bayes Classifier.}
}
@article{ALEDDA2015698,
title = {Improvements in disruption prediction at ASDEX Upgrade},
journal = {Fusion Engineering and Design},
volume = {96-97},
pages = {698-702},
year = {2015},
note = {Proceedings of the 28th Symposium On Fusion Technology (SOFT-28)},
issn = {0920-3796},
doi = {https://doi.org/10.1016/j.fusengdes.2015.03.045},
url = {https://www.sciencedirect.com/science/article/pii/S0920379615002148},
author = {R. Aledda and B. Cannas and A. Fanni and A. Pau and G. Sias},
keywords = {Disruption prediction, Nuclear fusion, Logistic regressor, Mahalanobis distance},
abstract = {In large-scale tokamaks disruptions have the potential to create serious damage to the facility. Hence disruptions must be avoided, but, when a disruption is unavoidable, minimizing its severity is mandatory. A reliable detection of a disruptive event is required to trigger proper mitigation actions. To this purpose machine learning methods have been widely studied to design disruption prediction systems at ASDEX Upgrade. The training phase of the proposed approaches is based on the availability of disrupted and non-disrupted discharges. In literature disruptive configurations were assumed appearing into the last 45ms of each disruption. Even if the achieved results in terms of correct predictions were good, it has to be highlighted that the choice of such a fixed temporal window might have limited the prediction performance. In fact, it generates confusing information in cases of disruptions with disruptive phase different from 45ms. The assessment of a specific disruptive phase for each disruptive discharge represents a relevant issue in understanding the disruptive events. In this paper, the Mahalanobis distance is applied to define a specific disruptive phase for each disruption, and a logistic regressor has been trained as disruption predictor. The results show that enhancements on the achieved performance on disruption prediction are possible by defining a specific disruptive phase for each disruption.}
}
@article{JUNSWANG20225015,
title = {Intelligent Networks for Chaotic Fractional-Order Nonlinear Financial Model},
journal = {Computers, Materials and Continua},
volume = {72},
number = {3},
pages = {5015-5030},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.027523},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822009043},
author = {Prem Junswang and Zulqurnain Sabir and Muhammad Asif Zahoor Raja and Waleed Adel and Thongchai Botmart and Wajaree Weera},
keywords = {Financial model, chaotic, fractional-order, reference dataset, artificial neural networks, levenberg-marquardt backpropagation},
abstract = {The purpose of this paper is to present a numerical approach based on the artificial neural networks (ANNs) for solving a novel fractional chaotic financial model that represents the effect of memory and chaos in the presented system. The method is constructed with the combination of the ANNs along with the Levenberg-Marquardt backpropagation (LMB), named the ANNs-LMB. This technique is tested for solving the novel problem for three cases of the fractional-order values and the obtained results are compared with the reference solution. Fifteen numbers neurons have been used to solve the fractional-order chaotic financial model. The selection of the data to solve the fractional-order chaotic financial model are selected as 75% for training, 10% for testing, and 15% for certification. The results indicate that the presented approximate solutions fit exactly with the reference solution and the method is effective and precise. The obtained results are testified to reduce the mean square error (MSE) for solving the fractional model and verified through the various measures including correlation, MSE, regression histogram of the errors, and state transition (ST).}
}
@article{BIRCHLER2023102926,
title = {Cost-effective simulation-based test selection in self-driving cars softwareImage 1},
journal = {Science of Computer Programming},
volume = {226},
pages = {102926},
year = {2023},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2023.102926},
url = {https://www.sciencedirect.com/science/article/pii/S0167642323000084},
author = {Christian Birchler and Nicolas Ganz and Sajad Khatiri and Alessio Gambi and Sebastiano Panichella},
keywords = {Self-driving cars, Software simulation, Regression testing, Test case selection, Continuous integration},
abstract = {Simulation environments are essential for the continuous development of complex cyber-physical systems such as self-driving cars (SDCs). Previous results on simulation-based testing for SDCs have shown that many automatically generated tests do not strongly contribute to the identification of SDC faults, hence do not contribute towards increasing the quality of SDCs. Because running such “uninformative” tests generally leads to a waste of computational resources and a drastic increase in the testing cost of SDCs, testers should avoid them. However, identifying “uninformative” tests before running them remains an open challenge. Hence, this paper proposes SDC-Scissor, a framework that leverages Machine Learning (ML) to identify SDC tests that are unlikely to detect faults in the SDC software under test, thus enabling testers to skip their execution and drastically increase the cost-effectiveness of simulation-based testing of SDCs software. Our evaluation concerning the usage of six ML models on two large datasets characterized by 22'652 tests showed that SDC-Scissor achieved a classification F1-score up to 96%. Moreover, our results show that SDC-Scissor outperformed a randomized baseline in identifying more failing tests per time unit. Webpage & Video: https://github.com/ChristianBirchler/sdc-scissor}
}
@article{QUIROZ2021,
title = {Development and Validation of a Machine Learning Approach for Automated Severity Assessment of COVID-19 Based on Clinical and Imaging Data: Retrospective Study},
journal = {JMIR Medical Informatics},
volume = {9},
number = {2},
year = {2021},
issn = {2291-9694},
doi = {https://doi.org/10.2196/24572},
url = {https://www.sciencedirect.com/science/article/pii/S2291969421000946},
author = {Juan Carlos Quiroz and You-Zhen Feng and Zhong-Yuan Cheng and Dana Rezazadegan and Ping-Kang Chen and Qi-Ting Lin and Long Qian and Xiao-Fang Liu and Shlomo Berkovsky and Enrico Coiera and Lei Song and Xiaoming Qiu and Sidong Liu and Xiang-Ran Cai},
keywords = {algorithm, clinical data, clinical features, COVID-19, CT scans, development, imaging, imbalanced data, machine learning, oversampling, severity assessment, validation},
abstract = {Background
COVID-19 has overwhelmed health systems worldwide. It is important to identify severe cases as early as possible, such that resources can be mobilized and treatment can be escalated.
Objective
This study aims to develop a machine learning approach for automated severity assessment of COVID-19 based on clinical and imaging data.
Methods
Clinical data—including demographics, signs, symptoms, comorbidities, and blood test results—and chest computed tomography scans of 346 patients from 2 hospitals in the Hubei Province, China, were used to develop machine learning models for automated severity assessment in diagnosed COVID-19 cases. We compared the predictive power of the clinical and imaging data from multiple machine learning models and further explored the use of four oversampling methods to address the imbalanced classification issue. Features with the highest predictive power were identified using the Shapley Additive Explanations framework.
Results
Imaging features had the strongest impact on the model output, while a combination of clinical and imaging features yielded the best performance overall. The identified predictive features were consistent with those reported previously. Although oversampling yielded mixed results, it achieved the best model performance in our study. Logistic regression models differentiating between mild and severe cases achieved the best performance for clinical features (area under the curve [AUC] 0.848; sensitivity 0.455; specificity 0.906), imaging features (AUC 0.926; sensitivity 0.818; specificity 0.901), and a combination of clinical and imaging features (AUC 0.950; sensitivity 0.764; specificity 0.919). The synthetic minority oversampling method further improved the performance of the model using combined features (AUC 0.960; sensitivity 0.845; specificity 0.929).
Conclusions
Clinical and imaging features can be used for automated severity assessment of COVID-19 and can potentially help triage patients with COVID-19 and prioritize care delivery to those at a higher risk of severe disease.}
}
@article{QI2023,
title = {Influence of E-consultation on the Intention of First-Visit Patients to Select Medical Services: Results of a Scenario Survey},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/40993},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123002972},
author = {Miaojie Qi and Jiyu Cui and Xing Li and Youli Han},
keywords = {e-consultation, medical selection, influence mechanism, scenario survey},
abstract = {Background
E-consultation is expected to improve the information level of patients, affect patients’ subsequent judgments of medical services, and guide patients to make a reasonable medical selection in the future. Thus, it is important to understand the influence mechanism of e-consultation on patients’ medical selection.
Objective
This study aims to explore the changes in first-visit patients’ understanding of disease and medical resources after e-consultation as well as the choice of follow-up medical services.
Methods
Patients’ medical selection before and after e-consultation was compared using a scenario survey. Based on the service characteristics of the e-consultation platform, representative simulation scenarios were determined, and parallel control groups were set up considering the order effect in comparison. Finally, a total of 4 scenario simulation questionnaires were designed. A total of 4164 valid questionnaires were collected through the online questionnaire collection platform. Patients’ perception of disease severity, evaluation of treatment capacity of medical institutions, selection of hospitals and doctors, and other outcome indicators were tested to analyze the differences in patients’ evaluation and choice of medical services before and after e-consultation. Additionally, the results’ stability was tested by regression analysis.
Results
In scenario 1 (mild case), before e-consultation, 14.1% (104/740) of participants considered their conditions as not serious. After e-consultation, 69.5% (539/775) of them considered their diseases as not serious. Furthermore, participants’ evaluation of the disease treatment capacity of medical institutions at all levels had improved after using e-consultation. In scenario 3 (severe case), before e-consultation, 54.1% (494/913) of the participants believed their diseases were very serious. After e-consultation, 16.6% (157/945) considered their diseases were very serious. The evaluation of disease treatment capacity of medical institutions in nontertiary hospitals decreased, whereas that of tertiary hospitals improved. In both mild and severe cases, before e-consultation, all of the participants were inclined to directly visit the hospital. After e-consultation, more than 71.4% (553/775) of the patients with mild diseases chose self-treatment, whereas those with severe diseases still opted for a face-to-face consultation. After e-consultation, patients who were set on being treated in a hospital, regardless of the disease severity, preferred to select the tertiary hospitals. Of the patients with mild diseases who chose to go to a hospital, 25.7% (57/222) wanted to consult online doctors face-to-face. By contrast, 56.4% (506/897) of the severe cases wanted to consult online doctors face-to-face.
Conclusions
E-consultation can help patients accurately enhance their awareness of the disease and guide them to make a more reasonable medical selection. However, it is likely that e-consultation makes online medical services centralized. Additionally, the guiding effect of e-consultation is limited, and e-consultation needs to be combined with other supporting systems conducive to medical selection to play an improved role.}
}
@article{MARQUESSOUDRE2024111261,
title = {A novel GPU-based approach for embedded NARMAX/FROLS system identification},
journal = {Mechanical Systems and Signal Processing},
volume = {211},
pages = {111261},
year = {2024},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2024.111261},
url = {https://www.sciencedirect.com/science/article/pii/S0888327024001596},
author = {Marlon {Marques Soudré} and Helon Vicente {Hultmann Ayala} and Alba Cristina Melo and Carlos H. Llanos},
keywords = {Embedded system software design, Nonlinear system identification parallelism, GPU, FROLS, Performance gain, Power consumption measurement},
abstract = {Identifying system dynamics is an essential task for several research areas that deal with real systems intended for purposes such as control, monitoring, or fault detection. However, the nonlinear characteristics of most real systems have led to the development of techniques with high computational complexity, which can make their use unfeasible in systems with restrictions, such as embedded systems. In this case, few studies have been done on how best to map nonlinear system identification techniques to embedded system platforms that may have parallelism capabilities, such as those incorporating GPUs. This work proposes a novel software architecture for parallel model term selection and estimation for Nonlinear AutoRegressive Moving Average with eXogenous inputs (NARMAX) models, addressed to GPU-based embedded platforms. Namely, we devise a new parallel strategy to perform Forward Regression Orthogonal Least Squares (FROLS) in nonlinear black-box system identification. The architecture presented was tested in the new NVIDIA Jetson Developer Kit, which contains a 128-core Maxwell-GPU, and compared to serial versions of the algorithm run in standard Intel Core i7 CPU and ARM A57. Using a theoretical example, we defined a parallelization strategy and validated it with an electro-mechanical positioning system representing time-invariant nonlinear systems. As a result, the time spent in the proposed parallel GPU algorithm is more than 24.5x faster, and the energy-efficiency is 22x better if compared to its serial version. This represents a significant improvement in speedup and energetic demand, allowing NARMAX/FROLS models to be constructed online using low-cost and low-power embedded platforms.}
}
@article{ZHANG2018105,
title = {A new solar power output prediction based on hybrid forecast engine and decomposition model},
journal = {ISA Transactions},
volume = {81},
pages = {105-120},
year = {2018},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2018.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0019057818302246},
author = {Weijiang Zhang and Hongshe Dang and Rolando Simoes},
keywords = {Empirical mode decomposition, IMF, Support vector regression, Feature selection, Solar energy},
abstract = {Regarding to the growing trend of photovoltaic (PV) energy as a clean energy source in electrical networks and its uncertain nature, PV energy prediction has been proposed by researchers in recent decades. This problem is directly effects on operation in power network while, due to high volatility of this signal, an accurate prediction model is demanded. A new prediction model based on Hilbert Huang transform (HHT) and integration of improved empirical mode decomposition (IEMD) with feature selection and forecast engine is presented in this paper. The proposed approach is divided into three main sections. In the first section, the signal is decomposed by the proposed IEMD as an accurate decomposition tool. To increase the accuracy of the proposed method, a new interpolation method has been used instead of cubic spline curve (CSC) fitting in EMD. Then the obtained output is entered into the new feature selection procedure to choose the best candidate inputs. Finally, the signal is predicted by a hybrid forecast engine composed of support vector regression (SVR) based on an intelligent algorithm. The effectiveness of the proposed approach has been verified over a number of real-world engineering test cases in comparison with other well-known models. The obtained results prove the validity of the proposed method.}
}
@article{TANEJA20202221,
title = {A Novel technique for test case minimization in object oriented testing},
journal = {Procedia Computer Science},
volume = {167},
pages = {2221-2228},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.274},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920307407},
author = {Divya Taneja and Rajvir Singh and Ajmer Singh and Himanshu Malik},
keywords = {Object oriented metrics, Test Case Minimization, machine learning, object oriented testing},
abstract = {Software maintenance is the costliest phase of software life cycle and it consumes almost 70 percent of resources of development process. Software testing involves the examining the built software with the intension to find the defects in it. Exhaustive testing of the software for all possible test cases is not feasible as may take infinitely large amount of time and may consume large number of other resources. Researchers in the field of the software testing are exploring the different possibilities to reduce the required number of test cases to test given software. In case of an object oriented (OO) software, the complexities like inheritance, coupling and cohesion, make the software modules more prone to the faults. This problem gets augmented in case of very large software systems. Many researchers have solved the problem of test case minimization from the different perspectives like requirements coverage; statement coverage and risk coverage. But negligible research has been done of the basis of security metrics coverage. In this paper, a technique has been presented for minimization of test cases for the OO systems. The research reported in the paper has considered security as a perspective for test cases evaluation and minimization. Publically available data sets pertaining to open source software Camel 1.6.1 have been used for the evaluation of proposed methodology. Linear Regression (LR) model for the bugs present in the data and various object oriented metrics for security have been developed. The proposed model dissects the given metrics sets into effective and non-effective metrics. Effective metrics are then utilized for giving weights to the test cases, further with the help of weights obtained the test suite is minimized. The performance results of proposed approach are encouraging.}
}
@article{GJAROY2024101530,
title = {A recall-optimised machine learning framework for small data improves risk stratification for Hirschsprung's disease},
journal = {Informatics in Medicine Unlocked},
volume = {48},
pages = {101530},
year = {2024},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2024.101530},
url = {https://www.sciencedirect.com/science/article/pii/S2352914824000868},
author = {Emilie {G. Jaroy} and Gabriel T. Risa and Inger Nina Farstad and Ragnhild Emblem and Rune Ougland},
keywords = {Machine learning, Imbalanced data, Rare diseases, Paediatric surgery, Hirschsprung's disease, Diagnostics},
abstract = {Objective
To improve the selection of patients with suspected Hirschsprung's disease for rectal biopsy with a recall-optimised machine learning framework that strongly penalises missed diagnoses, identify the most important clinical features, and investigate if this methodology is superior to the current practice of conventional logistic regression analysis.
Study design
The study data comprised the medical records of 178 children older than one month who underwent a rectal biopsy for the evaluation of Hirschsprung's disease. Each medical record contained the clinical features recorded before the rectal biopsy and the biopsy result. However, only 20 of the 178 children were diagnosed with Hirschsprung's disease. Thus, as is frequently the case for rare diseases, the dataset was small and imbalanced. We present a machine learning framework that, based on these data, produces a champion machine learning model for predicting the presence of Hirschsprung's disease in patients. Notably, the machine learning framework is recall-optimised, i.e., it strongly penalises missed diagnoses. This is achieved using a combination of synthetic minority over-sampling techniques, Bayesian hyper-parameter optimisation, and bootstrapping-based prediction thresholding for a competing set of models comprised of a logistic regression model, a random forest classifier, and a gradient-boosted classifier. Finally, the machine learning framework evaluates the performance of these three competing models and conventional logistic regression with 5-fold stratified cross-validation using an 80:20 train-test split. Model performance is ranked by the average recall across the cross-validation folds. The model with the highest recall is selected as the champion. The model with the highest accuracy is chosen in case of a tie.
Results
This study revealed that about 35% of our cohort's children without Hirschsprung's disease could have been spared a rectal biopsy while incurring no missed diagnoses using our machine learning framework. Given our aim of avoiding missed diagnosis, the champion model was vastly superior to conventional logistic regression, i.e., the status quo, which missed 40% of HD-positive cases. Moreover, the champion model pointed to a new hierarchy for the importance of clinical features associated with Hirschsprung's disease. Among all features, “gross abdominal distention” was the most important.
Conclusion
There is considerable scope for a stricter selection when referring constipated children for a rectal biopsy to diagnose or exclude Hirschsprung's disease. This study demonstrates that a recall-optimised pipeline based on classical supervised machine learning is superior to the conventional statistical and heuristic approaches used today, also for small and imbalanced datasets. This finding opens a path to better care for patients with rare diseases while alleviating pressures on healthcare systems.}
}
@article{SHAHPOURI2021826,
title = {Soot Emission Modeling of a Compression Ignition Engine Using Machine Learning},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {20},
pages = {826-833},
year = {2021},
note = {Modeling, Estimation and Control Conference MECC 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.11.274},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321023181},
author = {Saeid Shahpouri and Armin Norouzi and Christopher Hayduk and Reza Rezaei and Mahdi Shahbakhti and Charles Robert Koch},
keywords = {Diesel engines, Soot emissions, Machine learning, grey-box modeling, Physical model, data-driven modeling},
abstract = {Control of real driving soot emissions in diesel vehicles requires accurate predictive models for engine-out soot emissions. This paper presents an innovative modeling approach that combines a physics-based model and a black-box model to predict soot from a 4.5-liter compression ignition engine under varying load and speed conditions. The physical model is based on an experimentally validated 1D engine model in GT-power. In contrast, the black-box model is designed by investigating different machine learning approaches, including a Bayesian neural network (BNN), support vector machine (SVM), regression tree, and an ensemble of regression tree. The experimental data from running the engine at 219 load and speed conditions are collected and used for training and testing the soot model. The least absolute shrinkage and selection operator (LASSO) feature selection method is used on the GT model outputs to find the most critical parameters in soot prediction. The grey-box modeling results are compared with those from the black-box as well as the physical model. The results show that the grey-box SVM and black-box single hidden layer BNN method provide the best performance with a coefficient of determination (R2) of 0.95. For most cases, grey-box models outperform the black-box models with the same Machine Learning (ML) algorithm by comparing R2 of the test data, but this difference becomes negligible when a single hidden layer neural network is used.}
}
@article{SALEH2022127447,
title = {A comprehensive evaluation of existing and new model-identification approaches for non-destructive concrete strength assessment},
journal = {Construction and Building Materials},
volume = {334},
pages = {127447},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2022.127447},
url = {https://www.sciencedirect.com/science/article/pii/S0950061822011242},
author = {Eman F. Saleh and Ahmad N. Tarawneh and Hasan N. Katkhuda},
keywords = {Concrete strength assessment, NDT techniques, Conversion model, Cores, Concrete variability, Mean concrete strength, Characteristic strength},
abstract = {The common practice of concrete strength assessment is to combine non-destructive techniques (NDT) with core test measurements to develop a conversion model that is used to estimate the strengths at NDT test locations. In this work, different model identification approaches to develop this conversion model are investigated, namely regularized regression, quantile regression, Deming regression, bi-objective approach, geometric mean regression, orthogonal regression, and support vector machine (SVM) regression intending to improve the conversion model prediction capability so that accurate estimates of concrete strength can be obtained with a small number of cores. These approaches: in addition to other existing approaches, are first assessed using synthetic datasets and then tested on a real data case study by developing a set of cumulative distribution functions that provides information regarding the risk of a wrong prediction of concrete strength, outside a tolerable level. The results showed that concrete variability was best estimated using Deming regression, orthogonal regression, and bi-objective approach while local strengths were best estimated using quantile and regularized regression. Further, mean concrete strength estimation was observed to be not significantly affected by the choice of a model identification approach. Based on these results, a hybrid conversion model identification system that uses the bi-objective approach for mean and variability estimation and quantile regression for local strengths estimation is proposed. This study also proposes new tabular displays for the selection of the minimum number of cores required for reliable estimation of strength using information related to the NDT measurements and a choice of an accepted risk in the estimation. These tabular displays were produced using extensive analysis of synthetic data to determine the minimum number of cores required to limit the probability of the wrong estimation of strength within an admissible margin of error. Lastly, a web app was developed to easily provide the conversion models and the minimum number of cores for reliable concrete assessment.}
}
@article{FEDORKO201430,
title = {Failure analysis of belt conveyor damage caused by the falling material. Part I: Experimental measurements and regression models},
journal = {Engineering Failure Analysis},
volume = {36},
pages = {30-38},
year = {2014},
issn = {1350-6307},
doi = {https://doi.org/10.1016/j.engfailanal.2013.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S1350630713003075},
author = {Gabriel Fedorko and Vieroslav Molnar and Daniela Marasova and Anna Grincova and Miroslav Dovica and Jozef Zivcak and Teodor Toth and Nikoleta Husakova},
keywords = {Conveyor belt, Test device, Experimental measurement, Regression model},
abstract = {The most common case of conveyor belts damage is their puncture by falling sharp material. One of the ways, how to minimize this type of damage, is using of suitable type of conveyor belt. Therefore, the analysis of conveyor belts on the part of their puncture resistance is an important factor for their use in operation conditions. The aim of the paper is to determine the dependence among the weight of sharp material falling on the conveyor belt, shatter height and force conditions in the conveyor belt on the base of experimental measurements by the help of regression mathematical model and to determine conditions under which the conveyor belt is damaged. The experimental results enable the operator of a conveyor belt to set the shatter height and maximum weight of falling weight below the threshold values in order to prevent conveyor belt damage.}
}
@article{OMER2023200261,
title = {An adjustable machine learning gradient boosting-based controller for PV applications},
journal = {Intelligent Systems with Applications},
volume = {19},
pages = {200261},
year = {2023},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2023.200261},
url = {https://www.sciencedirect.com/science/article/pii/S2667305323000868},
author = {Zahi M. Omer and Hussain Shareef},
keywords = {Feature engineering, Gradient boosting, Machine learning, SHAP values, Photovoltaics, PI controller},
abstract = {Traditional Proportional, Integral, and Derivative (PID) controllers are employed in most industrial control applications because they are simple and easy to implement. However, they are fallible and exhibit poor performance in complicated, non-linear, time-delayed systems, and noisy feedback loops. In photovoltaic systems applications such as maximum power point (MPP) tracking, PI controller performance in low irradiance levels, varying load conditions, and partial shading scenarios is considerably inefficient in tracking the corresponding reference current, which generates MPP and causes considerable steady-state error. Machine learning can be used with selective input/output data from the PI controller to build a model that has the ability to adjust in case of steady-state error. Thus, an adjustable Machine Learning Gradient Boosting-based (MLGB) controller with a PV module and a DC-DC boost converter is proposed in this work. To create the raw dataset, a PI controller was simulated, and the input/output signals were recorded. Data preprocessing, utilizing feature engineering and Shapley Additive Explanations (SHAP) values, was used to explain the dynamic behavior of each feature, the inter-feature dependability, and their significance with reference to the model output. Hyperparameters were tuned with cross-validation while the model was being created using the CatBoost method. To assess the adjustment of each feature to minimize the error, particularly for lower irradiance values, varying load conditions, and partial shading, a regression model was built. Using the MATLAB Simulink Environment, a complete system controlled by both the PI and the MLGB controller was developed and tested. A random irradiance level fluctuation profile, along with varying load and partial shading scenarios, was used to compare three controllers, namely the PI, conventional MLGB, and adjusted MLGB controllers, to see how they respond to rapidly changing environmental conditions. It has been proven through a thorough simulation analysis that the novel adjustable MLGB controller exhibits good tracking performance to follow the DC-DC boost converter's inductor current. When compared to the traditional PI controller, the new controller exhibits better results in terms of steady-state behavior and transient responsiveness in general, with a much lower mean (3.059E-03), median (1.908E-03), and RMS value (2.168E-02) of the signal error under various conditions.}
}
@article{SHARIFZADEH2014211,
title = {Supervised feature selection for linear and non-linear regression of L⁎a⁎b⁎ color from multispectral images of meat},
journal = {Engineering Applications of Artificial Intelligence},
volume = {27},
pages = {211-227},
year = {2014},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2013.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0952197613001784},
author = {Sara Sharifzadeh and Line H. Clemmensen and Claus Borggaard and Susanne Støier and Bjarne K. Ersbøll},
keywords = {L a b color space, Multispectral imaging, Sparse regression, Artificial neural networks, Support vector machine, Supervised feature selection},
abstract = {In food quality monitoring, color is an important indicator factor of quality. The CIELab (L⁎a⁎b⁎) color space as a device independent color space is an appropriate means in this case. The commonly used colorimeter instruments can neither measure the L⁎a⁎b color in a wide area over the target surface nor in a contact-less mode. However, developing algorithms for conversion of food items images into L⁎a⁎b color space can solve both of these issues. This paper addresses the problem of L⁎a⁎b color prediction from multispectral images of different types of raw meat. The efficiency of using multispectral images instead of the standard RGB is investigated. In addition, it is demonstrated that due to the fiber structure and transparency of raw meat, the prediction models built on the standard color patches do not work for raw meat test samples. As a result, multispectral images of different types of meat samples (430–970nm) were used for training and testing of the L⁎a⁎b prediction models. Finding a sparse solution or the use of a minimum number of bands is of particular interest to make an industrial vision set-up simpler and cost effective. In this paper, a wide range of linear, non-linear, kernel-based regression and sparse regression methods are compared. In order to improve the prediction results of these models, we propose a supervised feature selection strategy which is compared with the Principal component analysis (PCA) as a pre-processing step. The results showed that the proposed feature selection method outperforms the PCA for both linear and non-linear methods. The highest performance was obtained by linear ridge regression applied on the selected features from the proposed Elastic net (EN) -based feature selection strategy. All the best models use a reduced number of wavelengths for each of the L⁎a⁎b components.}
}
@article{WANG2017274,
title = {Optimal control based regression test selection for service-oriented workflow applications},
journal = {Journal of Systems and Software},
volume = {124},
pages = {274-288},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.06.065},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300942},
author = {Hongda Wang and Jianchun Xing and Qiliang Yang and Ping Wang and Xuewei Zhang and Deshuai Han},
keywords = {Software cybernetics, Optimal control, Service-oriented workflow applications, Regression test selection, Behavioral difference, BPEL program dependence graph, Safe},
abstract = {Regression test selection, which is well known as an effective technology to ensure the quality of modified BPEL applications, is regarded as an optimal control issue. The BPEL applications under test serves as a controlled object and the regression test selection strategy functions as the corresponding controller. The performance index is to select fewest test cases to test modified BPEL applications. In addition, a promising controller (regression test selection approach) should be safe, which means that it can select all test cases in which faults might be exposed in modified versions under controlled regression testing from the original test suite. However, existing safe controllers may rerun some test cases without exposing fault. In addition, the unique features (e.g., dead path elimination semantics, communication mechanism, multi-assignment etc.) of BPEL applications also raise enormous problems in regression test selection. To address these issues, we present in this paper a safe optimal controller for BPEL applications. Firstly, to handle the unique features mentioned above, we transform BPEL applications and their modified versions into universal BPEL forms. Secondly, For our optimal controller, BPEL program dependence graphs corresponding to the two universal BPEL forms are established. Finally, guided by behavioral differences between the two versions, we construct an optimal controller and select test cases to be rerun. By contrast with the previous approaches, our approach can eliminate some unnecessary test cases to be selected. We conducted experiments with 8 BPEL applications to compare our approach with other typical approaches. Experimental results show that the test cases selected using our approach are fewer than other approaches.}
}
@article{KAKAR201556,
title = {Investigating the penalty reward calculus of software users and its impact on requirements prioritization},
journal = {Information and Software Technology},
volume = {65},
pages = {56-68},
year = {2015},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2015.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0950584915000798},
author = {Adarsh Kumar Kakar},
keywords = {User satisfaction, Requirements prioritization, Multiplicative effect, Asymmetric effect, Penalty reward contrast analysis},
abstract = {Context
The current requirements engineering techniques for prioritization of software requirements implicitly assume that each user requirement will have an independent and symmetric impact on user satisfaction. For example, it is assumed that implementing a high priority user requirement will positively impact his satisfaction and not implementing a high priority user requirement will negatively impact his satisfaction. Further, the impacts of implementing multiple user requirements on his satisfaction are expected to be additive. But is this always the case?
Objective
This paper empirically examines whether the assumptions of symmetric and multiplicative impacts of user requirements on his satisfaction are valid. Further, the study assesses the relative efficacy of 5 methods of requirements prioritization in managing these effects as reflected by the user satisfaction with the prioritized requirement sets.
Method
To test for existence and mitigation of asymmetric effects an adaptation of the widely accepted PRCA (Penalty Reward Contrast Analysis) method was used for 5 requirements prioritization techniques. To test for existence and mitigation of multiplicative effects MHMR (Moderated Hierarchical Multiple Regression) a well-accepted technique for testing interaction effects was used.
Results
Both asymmetric and multiplicative effects of software requirements on user satisfaction were observed for requirements prioritized using all 5 requirements prioritization methods raising questions about the efficacy of present day requirements prioritization techniques. Further, the results of the experiment led to proposing a new method for requirements prioritization for managing these effects.
Conclusion
The study empirically demonstrates the complexities of prioritizing software requirements and calls for a new generation of methods to address them. Understanding and resolving these complexities will enable software providers to conserve resources by enabling them to parsimoniously selecting only those requirements for implementation in the software product that have maximum incremental impact on user satisfaction.}
}
@article{ZHOU2021111228,
title = {BP neural network based reconstruction method for radiation field applications},
journal = {Nuclear Engineering and Design},
volume = {380},
pages = {111228},
year = {2021},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2021.111228},
url = {https://www.sciencedirect.com/science/article/pii/S0029549321001801},
author = {Wen Zhou and Guomin Sun and Zihui Yang and Hui Wang and Li Fang and Jianye Wang},
keywords = {Radiation field, Shielding calculation, Regression analysis, BP neural network, SuperMC},
abstract = {In order to achieve optimal radiation protection, rapid and accurate reconstruction of radiation field has vital significance in the selection of working paths during the overhaul of nuclear power plants and the decommissioning of nuclear facilities. The radiation field is usually reconstructed by various interpolation methods, but the reconstruction accuracy of such methods is insufficient, With the improvement of AI technology, neural networks have great potential in radiation field reconstruction, but conventional neural networks is prone to local minima and vanishing grandient problem. This paper aims to develop a radiation field reconstruction method based on an adaptive Back-propagation (BP) neural network neural network method with learning rate decay and a corresponding sampling method for multisampling in places where flux gradient changes drastically, and verify its accuracy and feasibility. The proposed method achieves global optimality and avoids vanishing grandient problem by virtue of adaptive algorithm and learning rate decay, ensuring that the radiation field is reconstructed with the smallest relative average error when the sampling point is determined, moreover, the proposed sampling method can greatly improve the accuracy of radiation field reconstruction. The accuracy of the proposed method was tested with three MC simulated radiation fields with simpler cases, and the feasibility of the proposed method was further validated with two MC simulated, more complex and realistic scenes. The results of the proposed method show that the errors of the three test cases are 1.7%, 6.8%, and 7.8%, and the errors of the two validated cases are 8.8% and 7.7%, respectively. The merit of this method was preliminarily verified, further validation is underway to validate its application in real world scenarios.}
}
@article{FATHI2022100421,
title = {High-quality fracture network mapping using high frequency logging while drilling (LWD) data: MSEEL case study},
journal = {Machine Learning with Applications},
volume = {10},
pages = {100421},
year = {2022},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2022.100421},
url = {https://www.sciencedirect.com/science/article/pii/S2666827022000962},
author = {Ebrahim Fathi and Timothy R. Carr and Mohammad Faiq Adenan and Brian Panetta and Abhash Kumar and B.J. Carney},
keywords = {Logging while drilling, Acceleration data, Natural fracture mapping, Marcellus Shale, Machine learning},
abstract = {The Marcellus Shale and Energy Environmental Laboratory (MSEEL) provides a comprehensive dataset and field tests that can be used to study the significance of preexisting natural fractures in different subsurface engineering problems such as the effectiveness of the stimulation of an unconventional reservoir, optimized geothermal fluids movement and integrity of the CO2 storage site. Conventionally natural fracture intensity is obtained using sonic and micro-resistivity imaging logs. However, these techniques significantly suffer from two major deficiencies: Human bias in log interpretation and extremely long interpretation time. These two deficiencies are well-recognized in the industry; however, no standard procedures exist to address them. In this study, a new automated machine learning workflow (AMLW) is introduced that uses the LWD high-resolution acceleration data along the horizontal laterals to predict the natural fracture intensities originally obtained using sonic and micro-resistivity imaging. The accuracy and robustness of the new workflow to predict the near wellbore fracture intensities are tested using both regression and classification approaches. Both the regression and classification approaches were able to predict the fracture intensities with high accuracy (average Mean Squared Error of 0.0085 for regression and average accuracy of 0.94 in the confusion matrix for classification). We have shown that only 10%–15% of the labeled resistivity image log is required for training and validation of the machine-learning model. The Automated workflow resulted in K-Neighbors Regressor and classifier algorithms as the best algorithms with a 52.74% and 139.3% improvement in comparison to the Gradient Boosting Regression algorithm (i.e. the fifth best algorithm).}
}
@article{HUSNAYAIN2020,
title = {Understanding the Community Risk Perceptions of the COVID-19 Outbreak in South Korea: Infodemiology Study},
journal = {Journal of Medical Internet Research},
volume = {22},
number = {9},
year = {2020},
issn = {1438-8871},
doi = {https://doi.org/10.2196/19788},
url = {https://www.sciencedirect.com/science/article/pii/S1438887120009279},
author = {Atina Husnayain and Eunha Shim and Anis Fuad and Emily Chia-Yu Su},
keywords = {Google Trends, risk, perception, communication, COVID-19, South Korea, outbreak, infodemiology},
abstract = {Background
South Korea is among the best-performing countries in tackling the coronavirus pandemic by using mass drive-through testing, face mask use, and extensive social distancing. However, understanding the patterns of risk perception could also facilitate effective risk communication to minimize the impacts of disease spread during this crisis.
Objective
We attempt to explore patterns of community health risk perceptions of COVID-19 in South Korea using internet search data.
Methods
Google Trends (GT) and NAVER relative search volumes (RSVs) data were collected using COVID-19–related terms in the Korean language and were retrieved according to time, gender, age groups, types of device, and location. Online queries were compared to the number of daily new COVID-19 cases and tests reported in the Kaggle open-access data set for the time period of December 5, 2019, to May 31, 2020. Time-lag correlations calculated by Spearman rank correlation coefficients were employed to assess whether correlations between new COVID-19 cases and internet searches were affected by time. We also constructed a prediction model of new COVID-19 cases using the number of COVID-19 cases, tests, and GT and NAVER RSVs in lag periods (of 1-3 days). Single and multiple regressions were employed using backward elimination and a variance inflation factor of <5.
Results
The numbers of COVID-19–related queries in South Korea increased during local events including local transmission, approval of coronavirus test kits, implementation of coronavirus drive-through tests, a face mask shortage, and a widespread campaign for social distancing as well as during international events such as the announcement of a Public Health Emergency of International Concern by the World Health Organization. Online queries were also stronger in women (r=0.763-0.823; P<.001) and age groups ≤29 years (r=0.726-0.821; P<.001), 30-44 years (r=0.701-0.826; P<.001), and ≥50 years (r=0.706-0.725; P<.001). In terms of spatial distribution, internet search data were higher in affected areas. Moreover, greater correlations were found in mobile searches (r=0.704-0.804; P<.001) compared to those of desktop searches (r=0.705-0.717; P<.001), indicating changing behaviors in searching for online health information during the outbreak. These varied internet searches related to COVID-19 represented community health risk perceptions. In addition, as a country with a high number of coronavirus tests, results showed that adults perceived coronavirus test–related information as being more important than disease-related knowledge. Meanwhile, younger, and older age groups had different perceptions. Moreover, NAVER RSVs can potentially be used for health risk perception assessments and disease predictions. Adding COVID-19–related searches provided by NAVER could increase the performance of the model compared to that of the COVID-19 case–based model and potentially be used to predict epidemic curves.
Conclusions
The use of both GT and NAVER RSVs to explore patterns of community health risk perceptions could be beneficial for targeting risk communication from several perspectives, including time, population characteristics, and location.}
}
@article{LI2022128303,
title = {Surface layer modulus prediction of asphalt pavement based on LTPP database and machine learning for Mechanical-Empirical rehabilitation design applications},
journal = {Construction and Building Materials},
volume = {344},
pages = {128303},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2022.128303},
url = {https://www.sciencedirect.com/science/article/pii/S0950061822019638},
author = {Miaomiao Li and Qingli Dai and Peifeng Su and Zhanping You and Yunxiang Ma},
keywords = {Asphalt pavement, Layer modulus, LTPP, Machine learning, ME rehabilitation design, Prediction},
abstract = {Evaluating the modulus of the existing asphalt concrete (AC) layer is a critical procedure in Mechanical-Empirical (ME) rehabilitation analysis. Generally, the modulus could be back-calculated by the Falling Weight Deflectometer (FWD) test. However, the raw FWD data of each pavement section is not always readily prepared for local highway agencies. To address this issue, the main objective of this study is to establish a reliable model by machine learning (ML) methods to predict AC layer modulus for the existing flexible pavement with data readily available from the local pavement management system, which could be an auxiliary tool for network-level sections with no FWD tests. The long-term pavement performance (LTPP) database was used to collect the original data for model training and testing, including pavement structures, service age, climate records, and pavement distresses. After preliminary data processing, matrix correlation analysis, and feature selection, the prepared dataset (total data points = 6477) with 14 predictors was fed into three regression models, including Ordinary Least-Squares regression (OLS), Random Forest regression (RF), and Gradient Boosting regression Method (GBM). The related key hyperparameters were optimized by grid search and 5-folds cross-validation. By comparison, the GBM model was finally selected due to its considerably higher prediction accuracy (R2 = 0.7921) than RF model (R2 = 0.7525) and OLS model (R2 = 0.4371) in the test set. According to the variable importance given by GBM model, surface temperature and AC layer thickness are more dominant variables in modulus estimation. In addition, a case study with predicted AC layer moduli in ME rehabilitation design was provided to verify the model application. In summary, the trained GBM model can be utilized to predict AC layer modulus for pavement evaluation and then ME rehabilitation when FWD data is not available.}
}
@article{RENDALL201999,
title = {Wide spectrum feature selection (WiSe) for regression model building},
journal = {Computers & Chemical Engineering},
volume = {121},
pages = {99-110},
year = {2019},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2018.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0098135418306999},
author = {Ricardo Rendall and Ivan Castillo and Alix Schmidt and Swee-Teng Chin and Leo H. Chiang and Marco Reis},
keywords = {Feature selection, Filtering methods, Predictive analytics, Effect sparsity, Symmetrical uncertainty},
abstract = {Developing predictive models from industrial datasets implies the consideration of many possible predictor variables (features). Using all available features for data-driven modelling is not recommended, as most of them are expected to be irrelevant and their inclusion in the model may compromise robustness and accuracy. In this work, we present, test and compare a new two-stage feature selection method called wide spectrum feature selection for regression (WiSe). In the first stage, a combination of efficient bivariate filters analyzes linear and non-linear association patterns between predictors and responses, screening out clearly noisy features. In the second stage, the reduced set of retained features is subject to further selection in the scope of the predictive methods considered, optimizing their predictive performance. Three simulated datasets and an industrial case illustrate the effectiveness and benefits of applying WiSe to support model development in a wide range of high-dimensional regression problems.}
}
@article{SHEN2023110157,
title = {Machine learning–assisted prediction of heat fluxes through thermally anisotropic building envelopes},
journal = {Building and Environment},
volume = {234},
pages = {110157},
year = {2023},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2023.110157},
url = {https://www.sciencedirect.com/science/article/pii/S0360132323001841},
author = {Zhenglai Shen and Som Shrestha and Daniel Howard and Tianli Feng and Diana Hun and Buxin She},
keywords = {Thermally anisotropic building envelope (TABE), Machine learning, Heat flux prediction, Building energy management},
abstract = {Thermally anisotropic building envelope (TABE) is a novel active building envelope that can save energy use to maintain thermal comfort in buildings by redirecting heat and coolness from building envelopes to thermal loops. Finite element models (FEMs) can be used to compute the heat fluxes through TABEs, but the high computational cost of finite element simulations has prevented parametric studies and design optimizations. This paper proposes a domain knowledge–informed, finite element–based machine learning framework to reduce the computation cost for the energy management of buildings installed with TABE that uses a ground thermal loop. First, the training heat flux data set was generated by FEM simulations with different thermal loop schedules. Then, both shallow learning models (i.e., multivariate linear regression and eXtreme Gradient Boost, or XGBoost) and a deep learning model (i.e., deep neural network, or DNN) were trained to predict the heat fluxes. Domain knowledge was used for data preprocessing and feature selection. Finally, the suitability of the selected machine learning model was tested under different thermal loop schedules. The case study results showed that: (1) XGBoost can be as accurate as DNN (coefficient of determination equal to 0.81) with much less training time; (2) the annual energy cost savings for different thermal loop schedules obtained by the XGBoost-predicted and FEM-calculated heat fluxes are consistent, having a difference of only 4%; and (3) XGBoost can reduce the computation time for the annual energy analysis of the case study building with a given thermal loop schedule from around 12 h by using FEM to less than 1 min.}
}
@article{MENDONCA2020105314,
title = {Matrix of Lags: A tool for analysis of multiple dependent time series applied for CAP scoring},
journal = {Computer Methods and Programs in Biomedicine},
volume = {189},
pages = {105314},
year = {2020},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2020.105314},
url = {https://www.sciencedirect.com/science/article/pii/S0169260719315871},
author = {Fábio Mendonça and Sheikh Shanawaz Mostafa and Fernando Morgado-Dias and Antonio G. Ravelo-García},
keywords = {Time series analysis, Matrix of Lags, CAP, Sleep quality, ECG},
abstract = {Background
Multiple methods have been developed to assess what happens between and within time series. In a particular type of these series, the previous values of the currently observed series are contingent on the lagged values of another series. These cases can commonly be addressed by regression. However, a model selection criteria should be employed to evaluate the compromise between the amount of information provided and the model complexity. This is the basis for the development of the Matrix of Lags (MoL), a tool to study dependent time series.
Methods
For each input, multiple regressions were applied to produce a model for each lag and a model selection criterion identifies the lags that will populate an auxiliary matrix. Afterwards, the energy of the lags (that are in the auxiliary matrix) was used to define a row of the MoL. Therefore, each input corresponds to a row of the MoL. To test the proposed tool, the heart rate variability and the electrocardiogram derived respiration were employed to perform the indirect estimation of the electroencephalography cyclic alternating pattern (CAP) cycles. Therefore, a support vector machine was fed with the MoL to perform the CAP cycle classification for each input signal. Multiple tests were carried out to further examine the proposed tool, including the effect of balancing the datasets, application of other regression methods and employment of two feature section models. The first was based on sequential backward selection while the second examined characteristics of a return map.
Results
The best performance of the subject independent model was attained by feeding the lags, selected by sequential backward selection, to a support vector machine, achieving an average accuracy, sensitivity, specificity and area under the receiver operating characteristic curve of, respectively, 77%, 71%, 82% and 0.77.
Conclusions
The developed model allows to perform a measurement of a characteristic marker of sleep instability (the CAP cycle) and the results are in the upper bound of the specialist agreement range with visual analysis. Thus, the developed method could possibly be used for clinical diagnosis.}
}
@article{GUILLEN2022111737,
title = {Topology optimization of an airfoil fin microchannel heat exchanger using artificial intelligence},
journal = {Nuclear Engineering and Design},
volume = {391},
pages = {111737},
year = {2022},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2022.111737},
url = {https://www.sciencedirect.com/science/article/pii/S0029549322000917},
author = {Donna Post Guillen and Alexander W. Abboud and James Bennink},
keywords = {Computational fluid dynamics, Airfoil fin, Microchannel heat exchanger, Latin hypercube sampling, Topology optimization, Genetic algorithm},
abstract = {High-performance microchannel heat exchangers are needed to supply heat for power conversion for nuclear microreactors. An airfoil fin microchannel design, constructed of Alloy 617 with helium as the working fluid, is analyzed and optimized using a design of experiments with artificial intelligence techniques. The use of airfoil fins offers the potential to reduce pressure drop across the heat exchanger, as compared to other types of channel configurations. A framework for topology optimization of airfoil fin printed circuit heat exchangers (PCHEs) has been developed that can be readily extended to different fin sizes and shapes, as well as different inlet and operating conditions, materials of construction, and working fluids. An optimization procedure is developed that employs computational fluid dynamics for a set of design points identified using Latin hypercube sampling. Computational fluid dynamics is used to analyze a simplified two-channel configuration where five design parameters are varied – inlet angle, fin scale, extent of staggering, transverse and longitudinal pitches. Two methods (a 5D polynomial and a regression neural network) are compared for generating surrogate models and the resulting response surface approximation is input to a genetic algorithm that is used to identify a set of optimal parameters. The optimal geometries are found across six channel Reynolds numbers ranging from 1000 to 5000, since inlet conditions affect flow through the heat exchanger. A set of optimal designs that maximizes heat transfer and minimizes pressure drop is identified, and a thermal stress analysis is performed on the optimal design. Correlations for the Nusselt number and Darcy friction factor are developed that can be useful for thermal hydraulic analyses using system codes. Thermal stresses are analyzed and a brief discussion of the status of code cases of PCHEs for nuclear applications is given. Testing and thermomechanical modeling is needed to facilitate future code compliance of PCHEs for high pressure and high temperature applications.}
}
@article{XIAO201915,
title = {A domain decomposition non-intrusive reduced order model for turbulent flows},
journal = {Computers & Fluids},
volume = {182},
pages = {15-27},
year = {2019},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2019.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0045793019300350},
author = {D. Xiao and C.E. Heaney and F. Fang and L. Mottet and R. Hu and D.A. Bistrian and E. Aristodemou and I.M. Navon and C.C. Pain},
keywords = {Non-intrusive reduced order modelling, Domain decomposition, Machine learning, Gaussian process regression, Urban flows, Turbulent flows, Finite element method},
abstract = {In this paper, a new Domain Decomposition Non-Intrusive Reduced Order Model (DDNIROM) is developed for turbulent flows. The method works by partitioning the computational domain into a number of subdomains in such a way that the summation of weights associated with the finite element nodes within each subdomain is approximately equal, and the communication between subdomains is minimised. With suitably chosen weights, it is expected that there will be approximately equal accuracy associated with each subdomain. This accuracy is maximised by allowing the partitioning to occur through areas of the domain that have relatively little flow activity, which, in this case, is characterised by the pointwise maximum Reynolds stresses. A Gaussian Process Regression (GPR) machine learning method is used to construct a set of local approximation functions (hypersurfaces) for each subdomain. Each local hypersurface represents not only the fluid dynamics over the subdomain it belongs to, but also the interactions of the flow dynamics with the surrounding subdomains. Thus, in this way, the surrounding subdomains may be viewed as providing boundary conditions for the current subdomain. We consider a specific example of turbulent air flow within an urban neighbourhood at a test site in London and demonstrate the effectiveness of the proposed DDNIROM.}
}
@article{BHANDARI2023107140,
title = {Integrative gene expression analysis for the diagnosis of Parkinson’s disease using machine learning and explainable AI},
journal = {Computers in Biology and Medicine},
volume = {163},
pages = {107140},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107140},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523006054},
author = {Nikita Bhandari and Rahee Walambe and Ketan Kotecha and Mehul Kaliya},
keywords = {Parkinson's disease diagnosis, Machine learning, Peripheral blood, Gene expression, Explainable artificial intelligence},
abstract = {Parkinson's disease (PD) is a progressive neurodegenerative disorder. Various symptoms and diagnostic tests are used in combination for the diagnosis of PD; however, accurate diagnosis at early stages is difficult. Blood-based markers can support physicians in the early diagnosis and treatment of PD. In this study, we used Machine Learning (ML) based methods for the diagnosis of PD by integrating gene expression data from different sources and applying explainable artificial intelligence (XAI) techniques to find the significant set of gene features contributing to diagnosis. We utilized the Least Absolute Shrinkage and Selection Operator (LASSO), and Ridge regression for the feature selection process. We utilized state-of-the-art ML techniques for the classification of PD cases and healthy controls. Logistic regression and Support Vector Machine showed the highest diagnostic accuracy. SHapley Additive exPlanations (SHAP) based global interpretable model-agnostic XAI method was utilized for the interpretation of the Support Vector Machine model. A set of significant biomarkers that contributed to the diagnosis of PD were identified. Some of these genes are associated with other neurodegenerative diseases. Our results suggest that the utilization of XAI can be useful in making early therapeutic decisions for the treatment of PD. The integration of datasets from different sources made this model robust. We believe that this research article will be of interest to clinicians as well as computational biologists in translational research.}
}
@article{KRISHNAMOORTHY202444,
title = {A novel and secured email classification and emotion detection using hybrid deep neural network},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {5},
pages = {44-57},
year = {2024},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666307424000019},
author = {Parthiban Krishnamoorthy and Mithileysh Sathiyanarayanan and Hugo Pedro Proença},
keywords = {Email classification, DNN-BiLSTM, AES algorithm, Rabit algorithm, Random forests (RF)},
abstract = {Compared to other social media data, email data differs from it in various topic-specific ways, including extensive replies, formal language, significant length disparities, high levels of anomalies, and indirect linkages. In this paper, the creation of a potent and computationally effective classifier to categorize spam and ham email documents is proposed. To assess and validate spam texts, this paper employs a variety of data mining-based classification approaches. On the benchmark Enron dataset, which is open to the public, tests were run. The final 7 Enron datasets were created by combining the six different types of Enron datasets that we had acquired. We preprocess the dataset at an early stage to exclude any useless phrases. This method falls under several categories, including Logistic Regression (LR), Convolutional Neural Networks (CNN), Random Forests (RF), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and suggested Deep Neural Networks (DNN). Using Bidirectional Long Short-Term Memory (BiLSTM), email documents may be screened for spam and labeled as such. In performance comparisons, DNN-BiLSTM outperforms other classifiers in terms of accuracy on all seven Enron datasets. In comparison to other machine learning classifiers, the findings demonstrate that DNN-BiLSTM and Convolutional Neural Networks can categorize spam with 96.39 % and 98.69 % accuracy, respectively. The report also covers the dangers of managing cloud data and the security problems that might occur. To safeguard data in the cloud while maintaining privacy, hybrid encryption is examined in this white paper. In the AES-Rabit hybrid encryption system, the symmetric session key exchange-based Rabit technique is combined with the benefits of the AES algorithm for faster data encryption.}
}
@article{LIANG2022125431,
title = {Selection of backfill grouting materials and ratios for shield tunnel considering stratum suitability},
journal = {Construction and Building Materials},
volume = {314},
pages = {125431},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2021.125431},
url = {https://www.sciencedirect.com/science/article/pii/S0950061821031706},
author = {Xiaoming Liang and Kaichen Ying and Fei Ye and Enjie Su and Tianhan Xia and Xingbo Han},
keywords = {Shield tunnel, Backfill grouting, Grout ratio, Modified material, Stratum suitability},
abstract = {In shield tunnel engineering, there is no uniform standard for the selection of backfill grouting materials and ratios. In this study, to facilitate the selection of a grout, the applications of grout types, materials, and ratios were summarized based on a statistical analysis of engineering cases. Through laboratory tests and range analysis, the relationships among the basic grout performance and ratios were examined. The reference values of the grout ratios and performance requirements in different strata were obtained using statistical methods and by regression analysis. The results showed that the grout type used in engineering is mainly a single-component grout; in strata with groundwater, the usage rate of modified grouts is significantly high. The single-component grout ratio for clay is the most affected by groundwater; for all strata, the change in the B/S ratio is the most significant. The W/B ratio is the most important factor affecting the basic grout performance, and the demand for compressive strength varies the most in all strata.}
}
@article{SAHIN2020104592,
title = {Developing comprehensive geocomputation tools for landslide susceptibility mapping: LSM tool pack},
journal = {Computers & Geosciences},
volume = {144},
pages = {104592},
year = {2020},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2020.104592},
url = {https://www.sciencedirect.com/science/article/pii/S009830042030577X},
author = {Emrehan Kutlug Sahin and Ismail Colkesen and Suheda Semih Acmali and Aykut Akgun and Arif Cagdas Aydinoglu},
keywords = {Landslide susceptibility, Feature selection, Statistically significance, ArcGIS and R integration, Random forest},
abstract = {The primary aim of this research paper is to develop an easy-to-use tool package called Landslide Susceptibility Mapping Tool Pack (LSM Tool Pack) for producing landslide susceptibility maps based on integrating R with ArcMap Software. The proposed tool contains 5 main modules namely: (1) Data Preparation (DP), (2) Feature (Factor) Selection (FS), (3) Logistic Regression (LR), (4) Random Forest (RF) and (5) Performance Evaluation (PE). The FS module brings a novel approach to determine the best factor subset in the production of landslide susceptibility maps. The feature ranking values of factors were calculated by several feature ranging methods (i.e. chi-square, information gain, rank correlation, and random forest feature importance). The logistic regression method was used at the model prediction stage for each feature ranking and different models were produced for each ranking result. And, in the last step of the FS analysis, tests of statistical significance (i.e. Wilcoxon signed-rank test, F- Test, Kolmogorov Smirnov test, and One-Sample t-test) were used to determine the significance of the difference between models. As a result, the best factor sets determined by the FS module were used as input factors in the LR Module and the RF Module to produce LSMs. Also, users can calculate the performance metric of landslide susceptibility maps by several performance metrics (overall accuracy, Area under the ROC Curve (AUC) value, kappa, F1 score, and more) with additional integrated the PE Module in ArcMap Software. The LSM Tool Pack is applied to the Sinop province of the Black Sea region of Turkey. Considered the FS module, Case 1 was selected as the experimental dataset for this present study. In the selected Case 1, feature ranking method and statistically significant analysis were determined by Chi-square and F-Test, respectively. As a result, Model-12, which is contained 12 landslide causative factors, was determined as the optimum subset. According to the results obtained by the accuracy assessment process, the RF model showed the best prediction performance with an AUC value of 0.8898. On the other hand, the calculated AUC value was 0.8119 for the LR model. The experimental results (using with dataset in actual study area) confirm the ability of the proposed feature selection approach in the landslide susceptibility mapping process.}
}
@article{ANJAIAH2022533,
title = {Detection of faults and DG islanding in PV-Wind DC ring bus microgrid by using optimized VMD based improved broad learning system},
journal = {ISA Transactions},
volume = {131},
pages = {533-551},
year = {2022},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2022.05.037},
url = {https://www.sciencedirect.com/science/article/pii/S0019057822002713},
author = {Kanche Anjaiah and P.K. Dash and Mrutyunjaya Sahani},
keywords = {Adaptive variational mode decomposition, DC-ring microgrid, DG islanding, Fault detection, Faults classification, Improved broad learning system, Improved whale optimization algorithm, dSPACE interface},
abstract = {This paper presents a novel approach for the detection and classification of photovoltaic with wind based DC ring bus microgrid DC faults and DG (distributed generation) islanding events. This novel approach consists of adaptive variational mode decomposition (AVMD) and an improved broad learning system (IBLS). Initially, DC fault current signals are captured from the DC bus under different operating conditions and processed through the AVMD to decompose the signals into intrinsic mode functions (IMFs). The VMD is made adaptive by minimizing the objective function of the L-kurtosis index for optimal modal number (K) and penalty factor (σ) through the improved whale optimization (IWO) algorithm. From the optimal IMFs, the most significant IMFs are chosen based on the threshold of the L-kurtosis index, and they are passed through statistical features to extract efficient data. Further, the training and testing of this data set is carried out through IBLS for obtaining the accurate detection and discrimination of DC faults. The conventional BLS method is improved through elastic net ridge regression for calculating the weights. The effectiveness of the proposed AVMD based IBLS algorithm is verified by its superiority in terms of relative computation time (RCT), classification accuracy (CA) with the confusion matrix, and their performance indices by comparing with other existing methods under different case studies. Finally, the simplicity and practicability of the proposed work are tested and implemented in the dSPACE 1104 embedded processor.}
}
@incollection{DECARVALHOSERVIA202333,
title = {Automated Kinetic Model Discovery – A Methodological Framework},
editor = {Antonios C. Kokossis and Michael C. Georgiadis and Efstratios Pistikopoulos},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {52},
pages = {33-38},
year = {2023},
booktitle = {33rd European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-15274-0.50006-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443152740500068},
author = {Miguel Ángel {de Carvalho Servia} and Ilya Orson Sandoval and Dongda Zhang and Klaus Hellgardt and King {Kuok Mimi Hii} and Ehecatl Antonio {del Rio Chanona}},
keywords = {catalysis, kinetic model generation, automated knowledge discovery, information criteria, machine learning},
abstract = {The industrialization of catalytic processes benefits strongly from kinetic models for optimization and control purposes. Nevertheless, mechanistic models are difficult to construct; data-driven and hybrid models lack interpretability and the flexibility to leverage physical knowledge. Thus, a different approach called automated knowledge discovery has been recently popularized. Existing methods in literature suffer from important drawbacks: necessitating assumptions about model structures, a lack of model selection automation, and sensitivity to noise. To overcome these challenges, the present work constructs a methodological framework for the automated generation of catalytic kinetic models. We leverage symbolic regression for model generation, a hybrid optimization algorithm for parameter estimation, and a robust criterion for model selection. The framework is tested with an illustrative isomerization case study, where it showcases the ability to retrieve the underlying kinetic model with a limited amount of noisy data from the catalytic system.}
}
@article{CHAPALOGLOU2022118906,
title = {Data-driven energy management of isolated power systems under rapidly varying operating conditions},
journal = {Applied Energy},
volume = {314},
pages = {118906},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.118906},
url = {https://www.sciencedirect.com/science/article/pii/S0306261922003294},
author = {Spyridon Chapaloglou and Damiano Varagnolo and Francesco Marra and Elisabetta Tedeschi},
keywords = {Stochastic model predictive control, Quantile regression, Random forests, Isolated power systems, Offshore wind power, Energy storage, Mixed-integer linear programming, Economic MPC},
abstract = {We propose an energy management algorithm for isolated industrial power systems that integrate uncertain renewable generation and energy storage. The proposed strategy is designed to ensure sustainable and cost-effective operations by managing the energy flows in the grid, and is structured so to cope with: (1) high levels of renewable power penetration, and (2) load profiles characterized by non-smooth patterns and irregular events (i.e., events such as those occurring from connections/disconnections of large scale equipment, or from large wind speed ramps). The proposed algorithm leverages a stochastic economic model predictive control (MPC) scheme capable of dealing simultaneously with the dispatch and scheduling of the local generation units. More precisely, the scheme embeds a mixed-integer linear programming (MILP) optimal control policy formulation together with a stochastic programming approach. Moreover, the optimization problem accounts for multiple techno-economical objectives, such as minimization of operational costs, battery degradation, and non-utilized energy. We test the algorithm on a case study of an isolated offshore Oil & Gas platform producing energy onsite with conventional gas turbines and a local wind farm, while integrating a battery energy storage system. The results show that the proposed approach can issue ensemble predictions that successfully capture the potential irregular variations just by using recent past information of the associated random variable, even when no particular sudden events are anticipated in the near-future (i.e., step changes/trend reversals). In this way, the approach provides useful future information for the optimal management of the grid. This effect is numerically quantified via simulations that compare the performance of the proposed stochastic optimization approach against its deterministic MPC version in several realistic operating conditions. The empirical results suggest that the stochastic version leads to better scheduling of the conventional generators, with up to 12.86% reductions of the operating cost, 2.56% reduction in fuel consumption and emissions, and 35.29% reduction in status transitions (on/off) of the gas turbines, while keeping dumped energy and battery degradation as low as possible.}
}
@article{LOPEZMARTIN2020110592,
title = {Transformed k-nearest neighborhood output distance minimization for predicting the defect density of software projects},
journal = {Journal of Systems and Software},
volume = {167},
pages = {110592},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110592},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300728},
author = {Cuauhtémoc López-Martín and Yenny Villuendas-Rey and Mohammad Azzeh and Ali {Bou Nassif} and Shadi Banitaan},
keywords = {Software defect density prediction, Case-based reasoning, Transformed k-nearest neighborhood output distance minimization, Support vector regression, Neural networks, ISBSG},
abstract = {Background
Software defect prediction is one of the most important research topics in software engineering. An important product measure to determine the effectiveness of software processes is the defect density (DD). Cased-based reasoning (CBR) has been the prediction technique most widely applied in the software prediction field. The CBR involves k-nearest neighborhood for finding the number (k) of similar software projects selected to be involved in the prediction process.
Objective
To propose the application of a transformed k-nearest neighborhood output distance minimization (TkDM) algorithm to predict the DD of software projects to compare its prediction accuracy with those obtained from statistical regression, support vector regression, and neural networks.
Method
Data sets were obtained from the ISBSG release 2018. A leave-one-out cross validation method was performed. Absolute residual was used as the prediction accuracy criterion for models.
Results
Statistical significance tests among models showed that the TkDM had the best prediction accuracy than those ones from statistical regression, support vector regression, and neural networks.
Conclusions
A TkDM can be used for predicting the DD of new and enhanced software projects developed and coded in specific platforms and programming languages types.}
}
@article{HUANG2023109046,
title = {Online monitoring of the voltage stability margin using local minimax concave penalty regression and adaptive database},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {149},
pages = {109046},
year = {2023},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2023.109046},
url = {https://www.sciencedirect.com/science/article/pii/S0142061523001035},
author = {Zongwu Huang and Xun Xu and Youping Fan and Zijiang Wang and Ben Shang and Maolin Shang and Wenxiang Yu and Yiming Wu and Dongjie Li and Mingqi Lin},
keywords = {Voltage stability margin, Local regression, Minimax concave penalty, Adaptive database, Online monitoring},
abstract = {A novel online monitoring method for the voltage stability margin (VSM) based on local minimax concave penalties (LocMCP) regression and adaptive database is proposed to ameliorate the weak model interpretability and insufficient generalization ability of the existing online monitoring methods. In this paper, the minimax concave penalty (MCP) is applied for VSM online monitoring for the first time. Compared with the multiple linear regression model (MLRM) and the local least absolute shrinkage and selection operator (LocLASSO), better prediction accuracy can be obtained through LocMCP. The MCP and local regression are combined to find the mapping relationship between VSM and reactive power reserves (RPRs) and to obtain the VSM online monitoring model composed of various local models. To further enhance the generalization ability of the model, an adaptive database is proposed. The data updating of the database is triggered when the local root mean square error (LocRMSE) exceeds the limit or is triggered in the case that the planned operation is performed. Furthermore, the local model can be updated according to the data updating results of the database. The 3-bus system, IEEE 30-bus system, and 1951-bus system are selected for verification, and the test results show that the proposed method is effective and has better generalization ability compared with other parameter regression methods.}
}
@article{SHANG2018269,
title = {Enhanced support vector regression based forecast engine to predict solar power output},
journal = {Renewable Energy},
volume = {127},
pages = {269-283},
year = {2018},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2018.04.067},
url = {https://www.sciencedirect.com/science/article/pii/S0960148118304750},
author = {Chuanfu Shang and Pengcheng Wei},
keywords = {Improved support vector regression, Feature selection, Enhanced empirical mode decomposition, PV},
abstract = {The critical role of photovoltaic (PV) energy as renewable sources in network can make some problems in power grids operation. Due to high volatility of PV signal, the prediction and its evaluation in planning and operation is very difficult. For this purpose, an accurate prediction approach is developed in this paper to tackle the mentioned problem. The proposed approach is based on enhanced empirical model decomposition (EEMD), a new feature selection method and hybrid forecast engine. The proposed feature selection is formulated by different criteria to select the best candidate inputs of forecast engine. And finally the hybrid forecast engine composed of improved support vector regression (ISVR) plus optimization algorithm to fine tune the related free parameters. Effectiveness of proposed method is applied over real-world engineering test cases through comparison with various prediction models.}
}
@article{YU202465,
title = {A performance-based hybrid deep learning model for predicting TBM advance rate using Attention-ResNet-LSTM},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
volume = {16},
number = {1},
pages = {65-80},
year = {2024},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2023.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1674775523001968},
author = {Sihao Yu and Zixin Zhang and Shuaifeng Wang and Xin Huang and Qinghua Lei},
keywords = {Tunnel boring machine (TBM), Advance rate, Deep learning, Attention-ResNet-LSTM, Evolutionary polynomial regression},
abstract = {The technology of tunnel boring machine (TBM) has been widely applied for underground construction worldwide; however, how to ensure the TBM tunneling process safe and efficient remains a major concern. Advance rate is a key parameter of TBM operation and reflects the TBM-ground interaction, for which a reliable prediction helps optimize the TBM performance. Here, we develop a hybrid neural network model, called Attention-ResNet-LSTM, for accurate prediction of the TBM advance rate. A database including geological properties and TBM operational parameters from the Yangtze River Natural Gas Pipeline Project is used to train and test this deep learning model. The evolutionary polynomial regression method is adopted to aid the selection of input parameters. The results of numerical experiments show that our Attention-ResNet-LSTM model outperforms other commonly-used intelligent models with a lower root mean square error and a lower mean absolute percentage error. Further, parametric analyses are conducted to explore the effects of the sequence length of historical data and the model architecture on the prediction accuracy. A correlation analysis between the input and output parameters is also implemented to provide guidance for adjusting relevant TBM operational parameters. The performance of our hybrid intelligent model is demonstrated in a case study of TBM tunneling through a complex ground with variable strata. Finally, data collected from the Baimang River Tunnel Project in Shenzhen of China are used to further test the generalization of our model. The results indicate that, compared to the conventional ResNet-LSTM model, our model has a better predictive capability for scenarios with unknown datasets due to its self-adaptive characteristic.}
}
@article{WANG2021114172,
title = {Efficient structural reliability analysis based on adaptive Bayesian support vector regression},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {387},
pages = {114172},
year = {2021},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2021.114172},
url = {https://www.sciencedirect.com/science/article/pii/S004578252100503X},
author = {Jinsheng Wang and Chenfeng Li and Guoji Xu and Yongle Li and Ahsan Kareem},
keywords = {Structural reliability analysis, Adaptive surrogate models, Support vector regression, Bayesian inference, Learning function},
abstract = {To reduce the computational burden for structural reliability analysis involving complex numerical models, many adaptive algorithms based on surrogate models have been developed. Among the various surrogate models, the support vector machine for regression (SVR) which is derived from statistical learning theory has demonstrated superior performance to handle nonlinear problems and to avoid overfitting with excellent generalization. Therefore, to take the advantage of the desirable features of SVR, an Adaptive algorithm based on the Bayesian SVR model (ABSVR) is proposed in this study. In ABSVR, a new learning function is devised for the effective selection of informative sample points following the concept of the penalty function method in optimization. To improve the uniformity of sample points in the design of experiments (DoE), a distance constraint term is added to the learning function. Besides, an adaptive sampling region scheme is employed to filter out samples with weak probability density to further enhance the efficiency of the proposed algorithm. Moreover, a hybrid stopping criterion based on the error-based stopping criterion using the bootstrap confidence estimation is developed to terminate the active learning process to ensure that the learning algorithm stops at an appropriate stage. The proposed ABSVR is easy to implement since no embedded optimization algorithm nor iso-probabilistic transformation is required. The performance of ABSVR is evaluated using six numerical examples featuring different complexity, and the results demonstrate the superior performance of ABSVR for structural reliability analysis in terms of accuracy and efficiency.}
}
@article{LEGUENNEC2018186,
title = {A parametric and non-intrusive reduced order model of car crash simulation},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {338},
pages = {186-207},
year = {2018},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2018.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0045782518301221},
author = {Y. Le Guennec and J.-P. Brunet and F.-Z. Daim and M. Chau and Y. Tourbier},
keywords = {Reduced order model, Crash simulation, Regression analysis, Linear programming},
abstract = {Industrials have an intensive use of numerical simulations in order to avoid physical testing and to speed up the design stages of their products. The numerical testing is indeed quicker to set-up, less expensive, and supplies a lot of information about the system under study. Moreover, it can be much closer to the physical tests as the computation power increases. Despite the rise of this power, time consuming simulations remain challenging to be used in design process, especially in an optimization study. Crash simulations belong to this category. These rapid dynamic computations are used by RENAULT during the sizing of the vehicle structure in order to ensure that it meets specifications set up to reach safety criteria in case of accidents. They are completed using finite element software such as VPS (Virtual Performance Solver) developed by ESI group that will be used in this study. For car manufacturers, the goal of the optimization study is to minimize the mass of the vehicle (and thus its consumption) by modifying the thicknesses of some parts (from 20 to 100 variables). Industrials such as RENAULT currently perform optimization studies based on numerical design of experiments. The number of computations required by this technique is from 3 to 10 times the number of variables. This is too much in order to be intensively used in a design process. In order to decrease the time-to-market and to explore alternative technical solutions, we explore the potential of using a parametrized reduced order model in the optimization studies. The parametrized reduced order model gives an estimation of the high-fidelity result for a new set of parameters without using the solver, by analysing the existing results of previous computations with various sets of parameters. The developed reduced order model is called ReCUR. It is partly based on a CUR approach embedded in a regression analysis. The regression statistical model uses the data of a few calculations made with the solver. Other tools such as clustering and linear programming are used to get the regression analysis more efficient. It is hoped to drastically reduce the number of required simulations of a standard optimization study. In this paper, the construction of the reduced order model will be presented. Then, the relevancy of using the reduced order model into a design process will be exhibited through the treatment of two industrial test-cases. Some improvements of the method as well as several potential uses will then be outlined. The applications will highlight the promising power of the method to shorten design process using optimization and long-run simulations.}
}
@article{VISSER2022118280,
title = {An operational bidding framework for aggregated electric vehicles on the electricity spot market},
journal = {Applied Energy},
volume = {308},
pages = {118280},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.118280},
url = {https://www.sciencedirect.com/science/article/pii/S0306261921015403},
author = {L.R. Visser and M.E. Kootte and A.C. Ferreira and O. Sicurani and E.J. Pauwels and C. Vuik and W.G.J.H.M. {Van Sark} and T.A. AlSkaif},
keywords = {Smart charging, Forecast, Electric Vehicles, Day ahead electricity market, Operational bidding framework, Market trading, Machine learning},
abstract = {Fluctuating electricity prices offer potential economic savings for the consumption of electricity by flexible assets such as Electric Vehicles (EVs). This study proposes an operational bidding framework that minimizes the charging costs of an EV fleet by submitting an optimized bid to the day-ahead electricity market. The framework consists of a bidding module that determines the most cost-effective bid by considering an electricity price and an EV charging demand forecast module. In this study we develop and evaluate several regression and machine learning models that forecast the electricity price and EV charging demand. Furthermore, we examine the composition of a most optimal operational bidding framework by comparing the outcome of the bidding module when fed with each of the forecast models. This is determined by considering the day-ahead electricity price and imbalance costs due to forecast errors. The study demonstrates that the best performing self-contained forecast models with the objective of electricity price and EV charging demand forecasting, do not deliver the best overall results when included in the bidding framework. Additionally, the results show that the best performing framework obtains a 26% cost savings compared to a reference case where EVs are charged inflexibly. This corresponds to an achieved savings potential of 92%. Consequently, along with the developed bidding framework, these results provide a fundamental basis for effective electricity trading on the day-ahead market.}
}
@article{ALBAIJAN2024109776,
title = {Estimating the initial fracture energy of concrete using various machine learning techniques},
journal = {Engineering Fracture Mechanics},
volume = {295},
pages = {109776},
year = {2024},
issn = {0013-7944},
doi = {https://doi.org/10.1016/j.engfracmech.2023.109776},
url = {https://www.sciencedirect.com/science/article/pii/S0013794423007348},
author = {Ibrahim Albaijan and Arsalan Mahmoodzadeh and Adil {Hussein Mohammed} and Mokhtar Mohammadi and Sohaib Gutub and Omar {Mutab Alsalami} and Hawkar {Hashim Ibrahim} and Yasser Alashker},
keywords = {Simple three-point load on single-edge notched beams, Machine learning, Initial fracture energy of concrete, User-friendly software},
abstract = {The assessment of the energy required for crack propagation in concrete structures has been fascinating since fracture mechanics was applied to concrete. In the case of concrete, considered a quasi-brittle material, the fracture energy has proven to be a crucial factor in the reliable design of structures and modeling failure behavior. However, due to the complex, time-consuming, and expensive laboratory tests, there has been ongoing and intense debate regarding the methods to estimate the fracture energy of concrete. The advent of machine learning (ML) methods in this domain can hold great promise for resolving such issues once and for all. This study used a comprehensive analysis of twelve ML algorithms for estimating the initial fracture energy of concrete (IFEC), utilizing a more extensive and diverse database (500 data points) than previous studies. The performance of the ML models was evaluated using several metrics, such as coefficient of determination (R2) and variance accounted for (VAF). The findings revealed that all the ML models employed in this study demonstrate remarkable accuracy in estimating the IFEC value, with R2 and VAF values of more than 0.86 and 93.10 %, respectively. A ranking of the models based on their estimation accuracy was provided, facilitating the selection of the support vector regression (R2 = 0.9897; VAF = 99.50 %) and long-short-term memory (R2 = 0.9804; VAF = 99.00 %) methods as the most reliable models for IFEC estimation. Both the laboratory test and ML models presented the highest IFEC value for a water-to-cement ratio of 0.35. Additionally, by increasing the values of each of the parameter's maximum size of aggregates (from 7 mm to 35 mm) and the specimen’s age (from 3 days to 180 days), the IFEC value was increased by about 100 %. Notably, a user-friendly software based on the ML models was developed, enabling fast and highly accurate estimation of IFEC, thereby eliminating the need for time-consuming and expensive laboratory tests.}
}
@article{RAUF2023107577,
title = {A novel smart feature selection strategy of lithium-ion battery degradation modelling for electric vehicles based on modern machine learning algorithms},
journal = {Journal of Energy Storage},
volume = {68},
pages = {107577},
year = {2023},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2023.107577},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X2300974X},
author = {Huzaifa Rauf and Muhammad Khalid and Naveed Arshad},
keywords = {Battery degradation, Li-ion batteries, Electric vehicles, Machine learning, Capacity loss, Prediction},
abstract = {Lithium-ion batteries are a key storage technology for electric vehicles and renewable energy applications. However, the complex degrading behaviour of batteries impacts their capacity and lifetime. Thus, battery capacity loss prediction is crucial for ensuring the longevity, safety, and reliable operation of the battery. This research proposes a smart feature selection (SFS) strategy-based machine learning framework for battery calendar and cyclic loss prediction. The presented methodology selects input parameters from the battery data of the current time step as well as the previous time step which are then utilized for model training and testing. Results demonstrate that the proposed SFS method in combination with the ML algorithms enhances the prediction accuracy and reduces the mean absolute error for all the machine learning algorithms applied in this study. The proposed SFS method is capable of excavating the useful features, therefore offering good generalization ability and accurate prediction results for capacity loss of the lithium-ion battery under real EV usage conditions. Furthermore, the results also depict that the performance accuracy of ML methods for battery calendar and cyclic loss prediction improves when combined with the SFS method. Greater improvement in prediction accuracy of battery capacity loss is observed for Gaussian Process Regression (GPR), random forest (RF), and XGBoost methods when applied in combination with the proposed SFS. This is the first-known feature selection-based ML application that is utilized to independently perform battery calendar and cyclic loss prognosis.}
}
@article{CARRILLOGALVEZ2022119070,
title = {Effect of models uncertainties on the emission constrained economic dispatch. A prediction interval-based approach},
journal = {Applied Energy},
volume = {317},
pages = {119070},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.119070},
url = {https://www.sciencedirect.com/science/article/pii/S0306261922004615},
author = {Adrian Carrillo-Galvez and Fabián Flores-Bazán and Enrique López Parra},
keywords = {Environmental constrained economic dispatch, Multiple linear regression, Prediction interval},
abstract = {Although electricity is a clean and relatively safe form of energy when it is used, the generation and transmission of electricity have severe effects on the environment. An alternative to diminish the polluting emissions released by the generating units is the Emission Constrained Economic Dispatch (ECED). This is an optimization problem where the total fuel cost is minimized while treating emissions as a constraint with a pre-specified limit. Usually, the fuel cost and emission functions of the generating units must be experimentally derived, introducing then uncertainties in the obtained models. However, these uncertainties are often neglected and the ECED problem is solved considering the coefficients of the functions involved as exact (totally known) values. In this investigation we analyzed the effect of the uncertainties associated to the experimental derivation of the input–output curves of thermal power plants. Particularly, when polynomial models are fitted through multiple linear regression, we proposed an approach that, based on the respectively prediction intervals, can provide solutions immunized, in some sense, against variability in the coefficients estimates. We tested the proposed approach in a real system from the Chilean electrical power network. For the analyzed system we noted that, when uncertainties are not considered, the deterministic optimal solutions can be environmentally infeasible in some scenarios; whereas solutions obtained through the proposed approach, can significantly diminish the risk of environmental violations. The robustness of the prediction interval-based solutions was obtained with a negligible increase of the total fuel cost in all the cases studied.}
}
@article{CHEN2021114339,
title = {Framework of airfoil max lift-to-drag ratio prediction using hybrid feature mining and Gaussian process regression},
journal = {Energy Conversion and Management},
volume = {243},
pages = {114339},
year = {2021},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.114339},
url = {https://www.sciencedirect.com/science/article/pii/S019689042100515X},
author = {Yaoran Chen and Zhikun Dong and Jie Su and Yan Wang and Zhaolong Han and Dai Zhou and Yongsheng Zhao and Yan Bao},
keywords = {Airfoil, Max lift-to-drag ratio, Gaussian process regression, Feature pool, Feature selection},
abstract = {The maximum lift-to-drag coefficient of an airfoil directly affects the aerodynamic performance of wind turbine. Machine learning methods are known for being really effective in helping to predict this parameter in a faster and more accurate way. So far, the majority of related studies have focused on the use of artificial neural networks to make this prediction, but this model has issues with its poor interpretation and the confidence level of its results was unclear. In this paper, a novel framework is proposed, involving the Gaussian process regression and a hybrid feature mining process. The aim is to use the new framework to evaluate the maximum lift-to-drag ratio of given airfoils under a turbulent flow condition, where the Reynolds number is around 100,000. The feature mining process here designed contains a hybrid feature pool that comprises various geometric characters, and a hybrid feature selector that can assist the prediction performance and make it better. Based on the airfoil dataset of the University of Illinois at Urbana-Champaign that contains a total of 1432 profiles, a comparative analysis was conducted. The results showed that the current framework can provide a more accurate estimate than parallel models in both single-point and interval aspects of view. Noticeably, the model reached an overall precision of 95.2% and 94.1% on training and testing sets, respectively. Moreover, the simplicity and the confidence reference from the model output were further illustrated with a case study, which also verified that how it can serve real engineering application.}
}
@article{SILHAVY20181,
title = {Evaluating subset selection methods for use case points estimation},
journal = {Information and Software Technology},
volume = {97},
pages = {1-9},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2017.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0950584917305153},
author = {Radek Silhavy and Petr Silhavy and Zdenka Prokopova},
keywords = {Software Development Effort Estimation, Software size estimation, Clustering techniques, Spectral Clustering, K-means, Moving Window, Use Case Points},
abstract = {When the Use Case Points method is used for software effort estimation, users are faced with low model accuracy which impacts on its practical application. This study investigates the significance of using subset selection methods for the prediction accuracy of Multiple Linear Regression models, obtained by the stepwise approach. K-means, Spectral Clustering, the Gaussian Mixture Model and Moving Window are evaluated as appropriate subset selection techniques. The methods were evaluated according to several evaluation criteria and then statistically tested. Evaluation was performing on two independent datasets - which differ in project types and size. Both were cut by the hold-out method. If clustering were used, the training sets were clustered into 3 classes; and, for each of class, an independent regression model was created. These were later used for the prediction of testing sets. If Moving Window was used, then window of sizes 5, 10 and 15 were tested. The results show that clustering techniques decrease prediction errors significantly when compared to Use Case Points or moving windows methods. Spectral Clustering was selected as the best-performing solution, because it achieves a Sum of Squared Errors reduction of 32% for the first dataset, and 98% for the second dataset. The Mean Absolute Percentage Error is less than 1% for the second dataset for Spectral Clustering; 9% for moving window; and 27% for Use Case Points. When the first dataset is used, then prediction errors are significantly higher – 53% for Spectral Clustering, but Use Case Points produces a 165% result. It can be concluded that this study proves subset selection techniques as a significant method for improving the prediction ability of linear regression models - which are used for software development effort prediction. It can also be concluded that the clustering method performs better than the moving window method.}
}
@article{ROGSTAD20131781,
title = {Test case selection for black-box regression testing of database applications},
journal = {Information and Software Technology},
volume = {55},
number = {10},
pages = {1781-1795},
year = {2013},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2013.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0950584913000980},
author = {Erik Rogstad and Lionel Briand and Richard Torkar},
keywords = {Test case selection, Regression testing, Database applications, Similarity measures},
abstract = {Context
This paper presents an approach for selecting regression test cases in the context of large-scale database applications. We focus on a black-box (specification-based) approach, relying on classification tree models to model the input domain of the system under test (SUT), in order to obtain a more practical and scalable solution. We perform an experiment in an industrial setting where the SUT is a large database application in Norway’s tax department.
Objective
We investigate the use of similarity-based test case selection for supporting black box regression testing of database applications. We have developed a practical approach and tool (DART) for functional black-box regression testing of database applications. In order to make the regression test approach scalable for large database applications, we needed a test case selection strategy that reduces the test execution costs and analysis effort. We used classification tree models to partition the input domain of the SUT in order to then select test cases. Rather than selecting test cases at random from each partition, we incorporated a similarity-based test case selection, hypothesizing that it would yield a higher fault detection rate.
Method
An experiment was conducted to determine which similarity-based selection algorithm was the most suitable in selecting test cases in large regression test suites, and whether similarity-based selection was a worthwhile and practical alternative to simpler solutions.
Results
The results show that combining similarity measurement with partition-based test case selection, by using similarity-based test case selection within each partition, can provide improved fault detection rates over simpler solutions when specific conditions are met regarding the partitions.
Conclusions
Under the conditions present in the experiment the improvements were marginal. However, a detailed analysis concludes that the similarity-based selection strategy should be applied when a large number of test cases are contained in each partition and there is significant variability within partitions. If these conditions are not present, incorporating similarity measures is not worthwhile, since the gain is negligible over a random selection within each partition.}
}
@article{IMTIAZ20191,
title = {A systematic literature review of test breakage prevention and repair techniques},
journal = {Information and Software Technology},
volume = {113},
pages = {1-19},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919300990},
author = {Javaria Imtiaz and Salman Sherin and Muhammad Uzair Khan and Muhammad Zohaib Iqbal},
keywords = {Test case repair, Regression testing, Automated testing, Systematic literature review},
abstract = {Context
When an application evolves, some of the developed test cases break. Discarding broken test cases causes a significant waste of effort and leads to test suites that are less effective and have lower coverage. Test repair approaches evolve test suites along with applications by repairing the broken test cases.
Objective
Numerous studies are published on test repair approaches every year. It is important to summarise and consolidate the existing knowledge in the area to provide directions to researchers and practitioners. This research work provides a systematic literature review in the area of test case repair and breakage prevention, aiming to guide researchers and practitioners in the field of software testing.
Method
We followed the standard protocol for conducting a systematic literature review. First, research goals were defined using the Goal Question Metric (GQM). Then we formulate research questions corresponding to each goal. Finally, metrics are extracted from the included papers. Based on the defined selection criteria a final set of 41 primary studies are included for analysis.
Results
The selection process resulted in 5 journal papers, and 36 conference papers. We present a taxonomy that lists the causes of test case breakages extracted from the literature. We found that only four proposed test repair tools are publicly available. Most studies evaluated their approaches on open-source case studies.
Conclusion
There is significant room for future research on test repair techniques. Despite the positive trend of evaluating approaches on large scale open source studies, there is a clear lack of results from studies done in a real industrial context. Few tools are publicly available which lowers the potential of adaption by industry practitioners.}
}
@article{FENTON2024111523,
title = {Embodied greenhouse gas emissions of buildings—Machine learning approach for early stage prediction},
journal = {Building and Environment},
volume = {257},
pages = {111523},
year = {2024},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.111523},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324003652},
author = {Sandie Kate Fenton and Adrian Munteanu and Klaas {De Rycke} and Lars {De Laet}},
keywords = {Embodied GHG emissions, Building, Machine learning, Design tool, Climate change mitigation},
abstract = {Observations made in architecture and engineering practices have highlighted the need to access buildings embodied greenhouse gas (GHG) emissions at early stages as well as a general understanding of the impacts of design decisions. This research addresses this need, and lack of readily available methods by leveraging knowledge from existing building’s databases, and using contextual and descriptive data, such as structure typology and location, to quantify the total embodied GHG emissions. It uses machine learning to develop a methodology for early and hands-on approximation of embodied GHG emissions, allowing to compare buildings, explain feature impacts, and verify computed results. The methodology, tested on the Embodied Carbon of European Buildings database, is generic and can be trained on other building databases and provide predictions tailored to their content. Alongside direct applications for design and decision-making, it provides a systematic analysis of features and emission standards, which, applied to a national database, could help inform policy models and mitigation strategies and transition towards a low emission and sustainable built environment.}
}
@article{DONG2024107869,
title = {Kernel functions embed into the autoencoder to identify the sparse models of nonlinear dynamics},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {131},
pages = {107869},
year = {2024},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2024.107869},
url = {https://www.sciencedirect.com/science/article/pii/S1007570424000558},
author = {Xin Dong and Yu-Long Bai and Wen-Di Wan},
keywords = {Model identification, SINDy, Kernel functions, Autoencoder},
abstract = {Numerous researches have shown that there are three main challenges in data-driven model identification methods: high-dimensional measurements, system complexity and unknown underlying dynamical properties. For most nonlinear dynamics, the feature space defined by the coefficients of their control equations is sparse. Therefore, sparse regression methods are used to learn the sparse coefficients of the control equations of nonlinear dynamics. However, this method strongly depends on the appropriate selection of the sparse basis vectors. In this essay, the autoencoder is combined with the sparse regression method to simultaneously identify the sparse coordinate and a parsimonious, interpretable and generalizable model of the specified system. It also integrates kernel functions to map the intractable measurements in the hidden space of the autoencoder into a linearly distinguishable kernel space, which kernelizes the candidate function library of the sparse identification of nonlinear dynamics (SINDy) model as the sparse dictionaries. Therefore, the flexible representation of neural networks, the simplicity of sparse regression methods and the implicit non-linear representation of kernel functions are consolidated in this article. To inspect the reliability of the proposed model in this paper, a set of nonlinear dynamics formulated by ordinary differential equations (ODEs), second-order trigonometric functions and partial differential equations (PDEs) are utilized as test cases. And the comparisons between the proposed model and other model identification methods illustrate that the performance of the former is the best.}
}
@article{TSAI2024,
title = {Building Dual AI Models and Nomograms Using Noninvasive Parameters for Aiding Male Bladder Outlet Obstruction Diagnosis and Minimizing the Need for Invasive Video-Urodynamic Studies: Development and Validation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/58599},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124004023},
author = {Chung-You Tsai and Jing-Hui Tian and Chien-Cheng Lee and Hann-Chorng Kuo},
keywords = {bladder outlet obstruction, lower urinary tract symptoms, machine learning, nomogram, artificial intelligence, video urodynamic study},
abstract = {Background
Diagnosing underlying causes of nonneurogenic male lower urinary tract symptoms associated with bladder outlet obstruction (BOO) is challenging. Video-urodynamic studies (VUDS) and pressure-flow studies (PFS) are both invasive diagnostic methods for BOO. VUDS can more precisely differentiate etiologies of male BOO, such as benign prostatic obstruction, primary bladder neck obstruction, and dysfunctional voiding, potentially outperforming PFS.
Objective
These examinations’ invasive nature highlights the need for developing noninvasive predictive models to facilitate BOO diagnosis and reduce the necessity for invasive procedures.
Methods
We conducted a retrospective study with a cohort of men with medication-refractory, nonneurogenic lower urinary tract symptoms suspected of BOO who underwent VUDS from 2001 to 2022. In total, 2 BOO predictive models were developed—1 based on the International Continence Society’s definition (International Continence Society–defined bladder outlet obstruction; ICS-BOO) and the other on video-urodynamic studies–diagnosed bladder outlet obstruction (VBOO). The patient cohort was randomly split into training and test sets for analysis. A total of 6 machine learning algorithms, including logistic regression, were used for model development. During model development, we first performed development validation using repeated 5-fold cross-validation on the training set and then test validation to assess the model’s performance on an independent test set. Both models were implemented as paper-based nomograms and integrated into a web-based artificial intelligence prediction tool to aid clinical decision-making.
Results
Among 307 patients, 26.7% (n=82) met the ICS-BOO criteria, while 82.1% (n=252) were diagnosed with VBOO. The ICS-BOO prediction model had a mean area under the receiver operating characteristic curve (AUC) of 0.74 (SD 0.09) and mean accuracy of 0.76 (SD 0.04) in development validation and AUC and accuracy of 0.86 and 0.77, respectively, in test validation. The VBOO prediction model yielded a mean AUC of 0.71 (SD 0.06) and mean accuracy of 0.77 (SD 0.06) internally, with AUC and accuracy of 0.72 and 0.76, respectively, externally. When both models’ predictions are applied to the same patient, their combined insights can significantly enhance clinical decision-making and simplify the diagnostic pathway. By the dual-model prediction approach, if both models positively predict BOO, suggesting all cases actually resulted from medication-refractory primary bladder neck obstruction or benign prostatic obstruction, surgical intervention may be considered. Thus, VUDS might be unnecessary for 100 (32.6%) patients. Conversely, when ICS-BOO predictions are negative but VBOO predictions are positive, indicating varied etiology, VUDS rather than PFS is advised for precise diagnosis and guiding subsequent therapy, accurately identifying 51.1% (47/92) of patients for VUDS.
Conclusions
The 2 machine learning models predicting ICS-BOO and VBOO, based on 6 noninvasive clinical parameters, demonstrate commendable discrimination performance. Using the dual-model prediction approach, when both models predict positively, VUDS may be avoided, assisting in male BOO diagnosis and reducing the need for such invasive procedures.}
}
@article{ALAMANIOTIS2018138,
title = {Probabilistic kernel machines for predictive monitoring of weld residual stress in energy systems},
journal = {Engineering Applications of Artificial Intelligence},
volume = {71},
pages = {138-154},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618300307},
author = {Miltiadis Alamaniotis and Jino Mathew and Alexander Chroneos and Michael E. Fitzpatrick and Lefteri H. Tsoukalas},
keywords = {Probabilistic kernel machines, Gaussian process regression, Machine learning, Welding, Residual stresses, Support vector regression},
abstract = {Predictive monitoring supports the a priori scheduling of critical component maintenance and contributes significantly in attaining a safe yet economic operation and management of complex energy systems by mitigating the risk of accidents and minimizing the number of operational pauses. The current work studies the learning ability of probabilistic kernel machines, and more particularly of Gaussian Processes (GP) equipped with various kernels for the estimation of weld residual stress profiles of stainless steel pipe welds. The GP models are tested on experimentally-obtained data of axial and hoop residual stresses in two different stainless-steel pipes. The results exhibit the ability of GP to accurately predict the weld residual stress profile in the axial and hoop direction by providing a predictive distribution, i.e., mean and variance values. Furthermore, performance of GP is compared to a non-probabilistic kernel machine, such as support vector regression (SVR) equipped with the same kernels, and to multivariate linear regression (MLR). Comparison results exhibit the robustness of GP over SVR and MLR with respect to prediction accuracy of weld residual stress in terms of root mean square error. With respect to a second metric, namely, correlation coefficient between measured and predicted values, GP is superior to SVR and MLR in the majority of the cases.}
}
@article{LI2022444,
title = {A novel remaining useful life prediction method based on multi-support vector regression fusion and adaptive weight updating},
journal = {ISA Transactions},
volume = {131},
pages = {444-459},
year = {2022},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2022.04.042},
url = {https://www.sciencedirect.com/science/article/pii/S001905782200204X},
author = {Yuxiong Li and Xianzhen Huang and Chengying Zhao and Pengfei Ding},
keywords = {Remaining useful life, Small sample cases, Support vector machine, Parameters optimization, Bayesian optimization algorithm, Adaptive updated weight},
abstract = {Remaining useful life prediction is of huge significance in preventing equipment malfunctions and reducing maintenance costs. Currently, machine learning algorithms have become hotspots in remaining useful life prediction due to their high flexibility and convenience. However, machine learnings require large amounts of data, and their prediction performance depends heavily on the selection of hyper-parameters. To overcome these shortcomings, a novel remaining useful life prediction method for small sample cases is proposed based on multi-support vector regression fusion. In the offline training phase, the fusion model is established, consisting of multiple support vector regression sub-models To obtain the optimal sub-model parameters, the Bayesian optimization algorithm is applied and an improved optimization target is formulated with various metrics describing regression and prediction performance. In the online prediction phase, an adaptive weight updating algorithm based on dynamic time warping is developed to measure the fitness of each sub-model and determine the corresponding weight value. The C-MAPSS engine dataset is used to test the performance of the proposed method, along with some existing machine learning methods as comparison. The proposed method only requires 30% of the training data sample to achieve high accuracy, with a root mean square error of 14.98, which is superior to other state-of-the-art methods. The results demonstrate the superiority of the proposed method.}
}
@article{LI2023114480,
title = {Construction and application of numerical diagram for high-skew propeller based on machine learning},
journal = {Ocean Engineering},
volume = {278},
pages = {114480},
year = {2023},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2023.114480},
url = {https://www.sciencedirect.com/science/article/pii/S0029801823008648},
author = {Liang Li and Yihong Chen and Yiming Qiang and Bin Zhou and Weizheng Chen},
keywords = {High-skew propeller, Numerical diagram, Machine learning, CFD method, Propeller design},
abstract = {The field of machine learning has experienced rapid growth, and it has introduced a new methodology for constructing propeller diagrams. To meet the high demand for designing high-skew propellers, a series of high-skew propeller schemes are generated, utilizing the INSEAN E1619 as the parent propeller. The Computational Fluid Dynamics (CFD) method was validated using the E1619 test results and was subsequently employed to perform virtual open water tests for all the series schemes. This effort produced 819 open water performance data of 42 propellers. The study trained and validated the traditional multivariate polynomial regression model and five conventional machine learning regression models based on the CFD calculation data. The analysis of the model prediction accuracy indicated that the Support Vector Machine (SVM) model had the least error among them for the digital expression of diagram hydrodynamic data. The prediction error of KT, KQ, and η decreased by over 20% compared to the LM model. The study subsequently developed a high-skew propeller diagram design program using the SVM regression model and applied it to a specific underwater vehicle's propeller design. The design results demonstrated that, compared to the B-series propeller, the design scheme provided by this numerical diagram had a comparable efficiency and a 6% smaller optimum diameter under unlimited diameter and a 7% higher efficiency under limited diameter for this case. Consequently, the developed numerical diagram in this paper provides a new tool for the propulsion performance evaluation and parameter selection of the propulsion system in the preliminary design stage for the high-skew propeller.}
}
@article{AHN2014195,
title = {The attribute impact concept: Applications in case-based reasoning and parametric cost estimation},
journal = {Automation in Construction},
volume = {43},
pages = {195-203},
year = {2014},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2014.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0926580514000636},
author = {Joseph Ahn and Sae-Hyun Ji and Moonseo Park and Hyun-Soo Lee and Sooyoung Kim and Sang-Wook Suh},
keywords = {Cost, Estimation, Attribute, Weight, Case-based reasoning, Regression analysis},
abstract = {The success of every construction project depends on the satisfactory achievement of a client's needs relating to cost, duration, and quality. Among them, costs must be managed with special awareness. In an effort to improve the estimate accuracy of cost during the initial stages of a building project, this research introduces the concept of ‘attribute impact’ (AI), which can measure the weights of attributes quantitatively and prioritize them. This study will also explain AI development, which adopts the impulse–momentum theorem of physics. For a case study, the project analyzes 163 public apartment buildings from 15 housing complex projects in Korea. To examine the validity of the proposed AI, the case study carries out two types of validation in terms of estimate accuracy using the parametric method and the case-based reasoning (CBR) applicability test. The validation results support the acceptable use of the suggested AI in measuring the weights of attributes and its estimate accuracy when combined with parametric or CBR estimation.}
}
@article{WU2022114699,
title = {Modelling of masonry infills in existing steel moment-resisting frames: Nonlinear force-displacement relationship},
journal = {Engineering Structures},
volume = {267},
pages = {114699},
year = {2022},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2022.114699},
url = {https://www.sciencedirect.com/science/article/pii/S014102962200791X},
author = {Jing-Ren Wu and Luigi {Di Sarno} and Fabio Freddi and Mario D'Aniello},
keywords = {Moment Resisting Frames, Steel Structures, Masonry Infills, Equivalent strut models, Genetic Algorithm},
abstract = {The study described and summarised in this paper was aimed at developing a framework for the definition of force-displacement relationships for single-strut models for masonry infill walls within steel moment-resisting frames. The methodology is based on a genetic algorithm optimisation and can be used for the calibration of force–displacement curves based on databases from either experiments or numerical simulation. A case study is also tested to demonstrate the framework in detail. Due to limited available experimental data on the seismic response of existing steel frames with masonry infills, a set of comprehensive finite element micro-models developed in Abaqus are used to generate a database. The optimal values of the parameters to feed a force–displacement relationship of the single-strut model of the masonry infills are obtained for each micro-model by solving optimisation problems with a genetic algorithm. The optimisation problem involves the minimisation of the discrepancies between the global responses from the database and their corresponding single-strut models through least square minimisation. With the optimal values as the input variables, a generalised quadrilinear model of the masonry strut is obtained through regression analysis and is validated against additional micro-models of infilled steel frames.}
}
@article{TSIRIKOGLOU2017139,
title = {A hyperparameters selection technique for support vector regression models},
journal = {Applied Soft Computing},
volume = {61},
pages = {139-148},
year = {2017},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2017.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S1568494617304283},
author = {P. Tsirikoglou and S. Abraham and F. Contino and C. Lacor and G. Ghorbaniasl},
keywords = {Hyperparameters optimization, Support vector regression, Evolutionary algorithms},
abstract = {Support vector regression models are powerful surrogates used in various fields of engineering. Due to the quality of their predictions and their efficiency, those models are considered as a suitable tool for surrogate evaluation. Despite their advantages, support vector regression models require an accurate selection of the configuration parameters in order to achieve good generalization performance. To overcome this limitation, a new hyperparameter selection method is developed. This method takes into account the training error to identify the optimal parameters set using evolutionary optimization schemes. Moreover, building on state-of-the-art techniques, an alternative analytically-assisted genetic algorithm is proposed in order to enhance the accuracy and robustness of the optimization scheme. The configuration is elaborated from a new search strategy in the design space. The results verify that the proposed technique improve the prediction accuracy and its robustness. Several test cases are used to demonstrate the capabilities of the method and its application potential to real engineering problems. The results prove that a surrogate model coupled with this adaptive configuration technique provides a useful prediction model suitable for various types of numerical experiments.}
}
@incollection{DONG2024107,
title = {Chapter 4 - Regression},
editor = {Qiao Dong and Xueqin Chen and Baoshan Huang},
booktitle = {Data Analysis in Pavement Engineering},
publisher = {Elsevier},
pages = {107-140},
year = {2024},
series = {Woodhead Publishing Series in Civil and Structural Engineering},
isbn = {978-0-443-15928-2},
doi = {https://doi.org/10.1016/B978-0-443-15928-2.00018-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443159282000185},
author = {Qiao Dong and Xueqin Chen and Baoshan Huang},
keywords = {Simple linear regression, Multiple linear regressions, Ordinary least squares, Maximum likelihood estimation, -test, -test, Residual diagnostic, Stepwise regression, Polynomial regression, Nonlinear regression},
abstract = {This chapter introduces regression, which is a widely used data analysis method in pavement engineering. It starts with a literature review on the applications of different regression methods in pavement data analysis. Then it introduces the definitions, parameter estimates, and significance tests of simple and multiple linear regression. Two significance tests are introduced. The F-test is used to test the significance of the model, while the t-test is used to test the significance of a variable. The model assumptions, residual diagnostic, multicollinearity, and Box-Cox transformations are discussed. The procedures and variable selections for stepwise regression, polynomial regression, and nonlinear regression are introduced. Finally, three cases on pavement maintenance effectiveness evaluation and performance prediction using multiple linear regression and nonlinear regression are presented.}
}
@article{LIU2023106486,
title = {Feature selection combined with top-down and bottom-up strategies for survival analysis: A case of prognostic prediction in glioblastoma},
journal = {Computers in Biology and Medicine},
volume = {153},
pages = {106486},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106486},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522011945},
author = {Yanan Liu and Xudong Zhao and Jilong Bian and Guohua Wang},
keywords = {Feature selection, Expression profiles, Survival analysis, Glioblastoma},
abstract = {Over the last decades, molecular signatures have attracted extensive attention in cancer research. However, most of the reported biomarkers show a weak distinguishing ability in predicting the survival risks of patients. Actually, univariate analysis is generally considered in regression analysis, which makes the existing statistical methods ineffective. Furthermore, there is too much human involvement in the ways of classifying patients with high and low risk. Last but not least, the participation of therapy after conservative surgery also makes the survival analysis more complex. In order to solve these problems, we propose a solid method of feature selection which combines top-down and bottom-up strategies. The top-down strategy is to randomly extract some genes each time and select candidate genes through cumulative voting. The bottom-up strategy is to fully enumerate the selected genes and to use a clustering algorithm to classify samples. We analyzed glioblastoma data from the Cancer Genome Atlas (TCGA) and got candidate signatures. The results of simulation data, as well as an independent test set the Chinese Glioma Genome Atlas (CGGA), verified the reliability of the method and validity of the selected features.}
}
@article{TABAIE2024,
title = {Evaluation of a Natural Language Processing Approach to Identify Diagnostic Errors and Analysis of Safety Learning System Case Review Data: Retrospective Cohort Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/50935},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005193},
author = {Azade Tabaie and Alberta Tran and Tony Calabria and Sonita S Bennett and Arianna Milicia and William Weintraub and William James Gallagher and John Yosaitis and Laura C Schubel and Mary A Hill and Kelly Michelle Smith and Kristen Miller},
keywords = {diagnostic error, electronic health records, machine learning, natural language processing, NLP, mortality, hospital, risk, length of stay, patient harm, diagnostic, EHR},
abstract = {Background
Diagnostic errors are an underappreciated cause of preventable mortality in hospitals and pose a risk for severe patient harm and increase hospital length of stay.
Objective
This study aims to explore the potential of machine learning and natural language processing techniques in improving diagnostic safety surveillance. We conducted a rigorous evaluation of the feasibility and potential to use electronic health records clinical notes and existing case review data.
Methods
Safety Learning System case review data from 1 large health system composed of 10 hospitals in the mid-Atlantic region of the United States from February 2016 to September 2021 were analyzed. The case review outcome included opportunities for improvement including diagnostic opportunities for improvement. To supplement case review data, electronic health record clinical notes were extracted and analyzed. A simple logistic regression model along with 3 forms of logistic regression models (ie, Least Absolute Shrinkage and Selection Operator, Ridge, and Elastic Net) with regularization functions was trained on this data to compare classification performances in classifying patients who experienced diagnostic errors during hospitalization. Further, statistical tests were conducted to find significant differences between female and male patients who experienced diagnostic errors.
Results
In total, 126 (7.4%) patients (of 1704) had been identified by case reviewers as having experienced at least 1 diagnostic error. Patients who had experienced diagnostic error were grouped by sex: 59 (7.1%) of the 830 women and 67 (7.7%) of the 874 men. Among the patients who experienced a diagnostic error, female patients were older (median 72, IQR 66-80 vs median 67, IQR 57-76; P=.02), had higher rates of being admitted through general or internal medicine (69.5% vs 47.8%; P=.01), lower rates of cardiovascular-related admitted diagnosis (11.9% vs 28.4%; P=.02), and lower rates of being admitted through neurology department (2.3% vs 13.4%; P=.04). The Ridge model achieved the highest area under the receiver operating characteristic curve (0.885), specificity (0.797), positive predictive value (PPV; 0.24), and F1-score (0.369) in classifying patients who were at higher risk of diagnostic errors among hospitalized patients.
Conclusions
Our findings demonstrate that natural language processing can be a potential solution to more effectively identifying and selecting potential diagnostic error cases for review and therefore reducing the case review burden.}
}
@article{ARAUJO2018515,
title = {Polynomial regression with reduced over-fitting—The PALS technique},
journal = {Measurement},
volume = {124},
pages = {515-521},
year = {2018},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2018.04.045},
url = {https://www.sciencedirect.com/science/article/pii/S0263224118303208},
author = {António Araújo},
keywords = {Data fitting, Over-fitting, Polynomial, Least-squares, Linear regression},
abstract = {In order to reduce over-fitting, a new polynomial least-squares technique, named polynomial area least-squares (PALS), was developed. The technique is based on the minimization of the sum of the squared areas defined between the polynomial fitting function and the line segments connecting every two consecutive data points. A relatively simple system of linear equations was developed to compute the free parameters of the polynomial using the available training data. The ability of the PALS technique to generalize was evaluated through the generation of test data and statistical simulations. The PALS technique produces polynomials with reduced over-fitting, with little dependency on the order of the polynomial, especially when the polynomial order is high, so that, in some cases, increasing the order of the polynomial may even contribute to further over-fitting reduction. The major advantage of PALS is that it does not depend on any case-dependent parameter necessary for the data fitting procedure; the major limitation is that it can only be applied to polynomial regression with a single independent variable.}
}
@article{SHAH201998,
title = {A feature-based soft sensor for spectroscopic data analysis},
journal = {Journal of Process Control},
volume = {78},
pages = {98-107},
year = {2019},
issn = {0959-1524},
doi = {https://doi.org/10.1016/j.jprocont.2019.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S095915241830146X},
author = {Devarshi Shah and Jin Wang and Q. Peter He},
keywords = {Soft sensor, Variable selection, Multivariate regression, Partial least squares, Kernel partial least squares, Statistics pattern analysis, NIR, UV/Vis, Chemometrics},
abstract = {In the last few decades, spectroscopic techniques such as near-infrared (NIR) and UV/vis spectroscopies have gained wide applications. As a result, various soft sensors have been developed to predict sample properties from its spectroscopic readings. Because the readings at different wavelengths are highly correlated, it has been shown that variable selection could significantly improve a soft sensor’s prediction performance and reduce the model complexity. Currently, almost all variable selection methods focus on how to select the variables (i.e., wavelengths or wavelength segments) that are strongly correlated with the dependent variable to improve the prediction performance. Although many successful applications have been reported, such variable selection methods do have their limitations, such as high sensitivity to the choice of training data, and deteriorated performance when testing on new samples. One possible reason is the removal of useful wavelengths or segments of wavelengths during the calibration process, which could be “tilted” to overfit or capture the noise or unknown disturbances contained in the calibration data. As a result, the model prediction performance may deteriorate significantly when the model is extrapolated or applied to new samples. To address this limitation, we propose a feature-based soft sensor approach utilizing statistics pattern analysis (SPA). Instead of selecting certain wavelengths or wavelength segments, the SPA-based method considers the whole spectrum which is divided into segments, and extracts different features over each spectrum segment to build the soft sensor. In other words, the SPA model contains the complete information from the full spectrum without any selection or removal, which we believe is the main reason for the high robustness of the SPA-based method. In addition, we propose a Monte Carlo validation and testing (MCVT) procedure and three MCVT-based performance indices for consistent and fair comparison of different soft sensor methods across different datasets. The MCVT procedure and indices are generally applicable for model comparison in other applications. Four case studies are presented to demonstrate the performance of the feature-based soft sensor and to compare it with a full partial least squares (PLS), a least absolute shrinkage and selection operator (Lasso), and a synergy interval PLS (SiPLS) based models following the proposed MCVT procedure. In addition, we examine the potential of kernel PLS (KPLS) based soft sensor approaches, examine their performances, and discuss their pros and cons.}
}
@article{ZHOU2017199,
title = {A sequential multi-fidelity metamodeling approach for data regression},
journal = {Knowledge-Based Systems},
volume = {134},
pages = {199-212},
year = {2017},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2017.07.033},
url = {https://www.sciencedirect.com/science/article/pii/S0950705117303556},
author = {Qi Zhou and Yan Wang and Seung-Kyum Choi and Ping Jiang and Xinyu Shao and Jiexiang Hu},
keywords = {Multi-fidelity information, Gaussian process model, Sequential design, Prediction accuracy},
abstract = {Multi-fidelity (MF) metamodeling approaches have attracted significant attention recently for data regression because they can make a trade-off between high accuracy and low computational expense by integrating the information from high-fidelity (HF) and low-fidelity (LF) models. To facilitate the usage of the MF metamodeling approaches, there are still challenging issues on the sample size ratio between HF and LF models and the locations of samples since these two components have profound effects on the prediction accuracy of the MF metamodels. In this study, a sequential multi-fidelity (SMF) metamodeling approach is proposed to address the issues of 1) where to allocate the LF and HF sample points, and 2) how to obtain an optimal combination of the high and low-fidelity sample sizes for a given computational budget and a high-to-low simulation cost ratio. Firstly, sequential objective formulations, with the objective to reduce the estimation of prediction error of MF metamodel, are constructed to update the LF and HF sampling data. Secondly, a decision criterion is proposed to determine whether one HF experiment or several LF experiments with the equivalent computational cost should be selected to update the MF metamodel. The proposed criterion is developed according to which selection will have a greater potential value to improve the prediction accuracy of the MF metamodel. To demonstrate the effectiveness and merits of the proposed SMF metamodeling approach, two numerical examples and a practical aerospace application example are used. Results show that the proposed approach can generate more accurate MF metamodels by providing the optimal high-to-low sample size ratio and sample locations.}
}
@article{LIANG20131519,
title = {An edge detection with automatic scale selection approach to improve coherent visual attention model},
journal = {Pattern Recognition Letters},
volume = {34},
number = {13},
pages = {1519-1524},
year = {2013},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2013.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167865513002298},
author = {Jiayu Liang and Shiu Yin Yuen},
keywords = {Edge detection, Scale selection, Visual attention, Biological vision},
abstract = {An automatic scale selection approach is developed to improve the coherent visual attention model (Le Meur, O., Le Callet, P., Barba, D., Thoreau, D., 2006. A coherent computational approach to model bottom-up visual attention. IEEE Trans. Pattern Anal. Machine Intell. 28 (5), 802–817). The new approach uses linear regression to combine the automatic scale selection attention model with the coherent visual attention model. It is biologically more plausible because two important properties (i.e. edge detection and scale selection) of human vision are taken into account. Its performance is evaluated using a large human fixation dataset. The t-test indicates that the improved model outperforms the coherent visual attention model highly significantly in both the non-weighting and weighting cases. The new model also outperforms seven other state-of-the-art saliency prediction models highly significantly (p<0.01). Thus it furnishes a more accurate model for human visual attention prediction.}
}
@article{FARSHAD2014127,
title = {Transmission line fault location using hybrid wavelet-Prony method and relief algorithm},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {61},
pages = {127-136},
year = {2014},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2014.03.045},
url = {https://www.sciencedirect.com/science/article/pii/S0142061514001471},
author = {Mohammad Farshad and Javad Sadeh},
keywords = {Artificial intelligence, Fault location, Feature extraction, Feature selection, Transmission line},
abstract = {Context: Intelligent fault locating in transmission lines consists of three main steps: feature extraction, feature selection, and utilizing a learning tool. Objective: The main objective of this paper is to propose a systematic approach for intelligent fault locating in transmission lines. Method: This paper extracts a group of candidate features by applying a combination of the Wavelet Packet Decomposition (WPD) and Improved Prony Analysis (IPA) methods on single-ended voltage measurements. To have an accurate fault location estimate, useful and efficient features are selected among the candidate features using the regression relief algorithm. In this paper, performances of three regression learning tools including the Generalized Regression Neural Network (GRNN), k-Nearest Neighbor (k-NN) and the Random Forests (RF) in the fault location problem are evaluated and compared, and the best tool is introduced. Results: Numerous training and test patterns are generated through simulation of various fault types in an untransposed transmission line based on different values of fault location, fault resistance, fault inception angle, and magnitude and direction of load current. The results of evaluation using theses patterns show the high efficiency and accuracy of the proposed approach. For various fault types in the test cases, the average values of fault location estimation errors are in the range of 0.153–0.202%. Conclusion: Besides accuracy, the proposed fault locating method is immune against current signal measurement errors and it does not face the problems and costs related to the transmitting and synchronizing data of both line ends.}
}
@article{XU201625,
title = {A selective fuzzy ARTMAP ensemble and its application to the fault diagnosis of rolling element bearing},
journal = {Neurocomputing},
volume = {182},
pages = {25-35},
year = {2016},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215019359},
author = {Zengbing Xu and Yourong Li and Zhigang Wang and Jianping Xuan},
keywords = {Modified distance discriminant technique, Fuzzy ARTMAP, Correlation measure, Bayesian belief method, Selective ensemble of multiple classifiers, Fault diagnosis},
abstract = {A novel intelligent fault diagnosis method based on feature extraction methods, features selection using modified distance discriminant technique and selective ensemble of multiple fuzzy ARTMAP (FAM) classifiers is proposed in this paper. The method consists of three stages. Firstly, different features in multiple symptom domains, such as time-domain features, frequency-domain features, wavelet grey moments, wavelet packet energy spectrum and auto-regression model parameters, are extracted from the raw vibration signals. Secondly, with the modified distance discriminant technique five salient feature sets are selected from the five original feature sets in different symptom domains respectively. Finally, these optimal feature sets are input the selective ensemble of multiple FAM classifiers based on the correlation measure method and Bayesian belief method to identify different abnormal cases. The proposed method is applied to the fault diagnosis of rolling element bearings, the test result shows that the selective ensemble of four FAM classifiers can identify the different fault conditions accurately and has a better classification performance compared to the single FAM and ensemble of all FAM classifiers. Besides, the diagnosis performance of the selective ensemble is analyzed by the bootstrap method. All experiment results have demonstrated that the selective ensemble of FAM classifiers has the effectiveness, stability, generalization, reliability and robustness.}
}
@article{SOUSA201484,
title = {Evaluation of artificial intelligence tool performance and uncertainty for predicting sewer structural condition},
journal = {Automation in Construction},
volume = {44},
pages = {84-91},
year = {2014},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2014.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0926580514000909},
author = {Vitor Sousa and José P. Matos and Natércia Matias},
keywords = {Artificial neural networks, Optimization, Sewer structural condition, Support vector machines},
abstract = {The implementation of a risk-informed asset management system by a wastewater infrastructure utility requires information regarding the probability and the consequences of component failures. This paper focuses on the former, evaluating the performance of artificial intelligence tools, namely artificial neural networks (ANNs) and support vector machines (SVMs), in predicting the structural condition of sewers. The performance of these tools is compared with that of logistic regression on the case study of the wastewater infrastructures of SANEST — Sistema de Saneamento da Costa do Estoril (Costa do Estoril Wastewater System). The uncertainty associated to ANNs and SVMs is quantified and the results of a trial and error approach and the use of optimization algorithms to develop SVMs are compared. The results highlight the need to account for both the performance and the uncertainty in the process of choosing the best model to estimate the sewer condition, since the ANNs present the highest average performance (78.5% correct predictions in the test sample) but also the highest dispersion of performance results (73% to 81% correct predictions in the test sample), whereas the SVMs have lower average performance (71.1% without optimization and 72.6% with the parameters optimized using the Covariance Matrix Adaptation Evolution Strategy) but little variability.}
}
@article{TOHME2020107141,
title = {A generalized Bayesian approach to model calibration},
journal = {Reliability Engineering & System Safety},
volume = {204},
pages = {107141},
year = {2020},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2020.107141},
url = {https://www.sciencedirect.com/science/article/pii/S0951832020306426},
author = {Tony Tohme and Kevin Vanslette and Kamal Youcef-Toumi},
keywords = {Calibration and Validation, Reliability and Safety, Regression, Bayesian Validation Metric, Bayesian Model Testing, Bayesian Probability Theory, Inference},
abstract = {In model development, model calibration and validation play complementary roles toward learning reliable models. In this article, we expand the Bayesian Validation Metric framework to a general calibration and validation framework by inverting the validation mathematics into a generalized Bayesian method for model calibration and regression. We perform Bayesian regression based on a user’s definition of model-data agreement. This allows for model selection on any type of data distribution, unlike Bayesian and standard regression techniques, that “fail” in some cases. We show that our tool is capable of representing and combining least squares, likelihood-based, and Bayesian calibration techniques in a single framework while being able to generalize aspects of these methods. This tool also offers new insights into the interpretation of the predictive envelopes (also known as confidence bands) while giving the analyst more control over these envelopes. We demonstrate the validity of our method by providing three numerical examples to calibrate different models, including a model for energy dissipation in lap joints under impact loading. By calibrating models with respect to the validation metrics one desires a model to ultimately pass, reliability and safety metrics may be integrated into and automatically adopted by the model in the calibration phase.}
}
@article{ALAMANIOTIS2014188,
title = {Regression to fuzziness method for estimation of remaining useful life in power plant components},
journal = {Mechanical Systems and Signal Processing},
volume = {48},
number = {1},
pages = {188-198},
year = {2014},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2014.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0888327014000727},
author = {Miltiadis Alamaniotis and Austin Grelle and Lefteri H. Tsoukalas},
keywords = {RUL, Fuzzy sets, Regression, Power plant components},
abstract = {Mitigation of severe accidents in power plants requires the reliable operation of all systems and the on-time replacement of mechanical components. Therefore, the continuous surveillance of power systems is a crucial concern for the overall safety, cost control, and on-time maintenance of a power plant. In this paper a methodology called regression to fuzziness is presented that estimates the remaining useful life (RUL) of power plant components. The RUL is defined as the difference between the time that a measurement was taken and the estimated failure time of that component. The methodology aims to compensate for a potential lack of historical data by modeling an expert׳s operational experience and expertise applied to the system. It initially identifies critical degradation parameters and their associated value range. Once completed, the operator׳s experience is modeled through fuzzy sets which span the entire parameter range. This model is then synergistically used with linear regression and a component׳s failure point to estimate the RUL. The proposed methodology is tested on estimating the RUL of a turbine (the basic electrical generating component of a power plant) in three different cases. Results demonstrate the benefits of the methodology for components for which operational data is not readily available and emphasize the significance of the selection of fuzzy sets and the effect of knowledge representation on the predicted output. To verify the effectiveness of the methodology, it was benchmarked against the data-based simple linear regression model used for predictions which was shown to perform equal or worse than the presented methodology. Furthermore, methodology comparison highlighted the improvement in estimation offered by the adoption of appropriate of fuzzy sets for parameter representation.}
}
@article{SILHAVY20171,
title = {Analysis and selection of a regression model for the Use Case Points method using a stepwise approach},
journal = {Journal of Systems and Software},
volume = {125},
pages = {1-14},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.11.029},
url = {https://www.sciencedirect.com/science/article/pii/S016412121630231X},
author = {Radek Silhavy and Petr Silhavy and Zdenka Prokopova},
keywords = {Software size estimation, Stepwise approach, Multiple linear regression, Use Case Points, Dataset, Variables analysis},
abstract = {This study investigates the significance of use case points (UCP) variables and the influence of the complexity of multiple linear regression models on software size estimation and accuracy. Stepwise multiple linear regression models and residual analysis were used to analyse the impact of model complexity. The impact of each variable was studied using correlation analysis. The estimated size of software depends mainly on the values of the weights of unadjusted UCP, which represent a number of use cases. Moreover, all other variables (unadjusted actors' weights, technical complexity factors, and environmental complexity factors) from the UCP method also have an impact on software size and therefore cannot be omitted from the regression model. The best performing model (Model D) contains an intercept, linear terms, and squared terms. The results of several evaluation measures show that this model's estimation ability is better than that of the other models tested. Model D also performs better when compared to the UCP model, whose Sum of Squared Error was 268,620 points on Dataset 1 and 87,055 on Dataset 2. Model D achieved a greater than 90% reduction in the Sum of Squared Errors compared to the Use Case Points method on Dataset 1 and a greater than 91% reduction on Dataset 2. The medians of the Sum of Squared Errors for both methods are significantly different at the 95% confidence level (p < 0.01), while the medians for Model D (312 and 37.26) are lower than Use Case Points (3134 and 3712) on Datasets 1 and 2, respectively.}
}
@incollection{BIANCOLILLO2019157,
title = {Chapter 6 - The Sequential and Orthogonalized PLS Regression for Multiblock Regression: Theory, Examples, and Extensions},
editor = {Marina Cocchi},
series = {Data Handling in Science and Technology},
publisher = {Elsevier},
volume = {31},
pages = {157-177},
year = {2019},
booktitle = {Data Fusion Methodology and Applications},
issn = {0922-3487},
doi = {https://doi.org/10.1016/B978-0-444-63984-4.00006-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780444639844000065},
author = {Alessandra Biancolillo and Tormod Næs},
keywords = {Classification, Multiblock regression, Multiway, SO-N-PLS, SO-N-PLS-LDA, SO-PLS, SO-PLS-LDA, Variable selection},
abstract = {In this chapter, the sequentially orthogonalized-PLS (SO-PLS) method and some of its main extensions are described and illustrated. Both theoretical aspects and applications on real data are discussed. SO-PLS is a multiblock regression method in which the information is extracted sequentially from the predictor blocks and there is no limitation in the number of predictors that can be handled. Moreover, the significance of the addition of any predictor block can be tested. An extension of the method for handling multiway arrays is also described and illustrated. SO-PLS and its extensions are versatile methods for both regression and classification; in both cases, they are particularly suitable from an interpretation point of view.}
}
@article{WILL2013168,
title = {On the use of niching genetic algorithms for variable selection in solar radiation estimation},
journal = {Renewable Energy},
volume = {50},
pages = {168-176},
year = {2013},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2012.06.039},
url = {https://www.sciencedirect.com/science/article/pii/S0960148112003904},
author = {A. Will and J. Bustos and M. Bocco and J. Gotay and C. Lamelas},
keywords = {Niching genetic algorithms, Solar radiation, Variables selection, Meteorology},
abstract = {Prediction of climatic variables, in particular those related to wind and solar radiation, has developed a huge interest in recent years, mainly due to its applications to renewable energy. In many cases there is a large number of factors that influence the climatic variable of interest, and the researcher chooses the most relevant ones (based on previous knowledge of the region, availability, etc.) and runs a series of experiments combining the available data in order to find the combination that provides the best prediction. In this work we present two applications of Niching Genetic Algorithms to solve the problem of selection of variables for the estimation of Solar Radiation. On one hand, this methodology is able to estimate a given climatic variable using databases with missing data, since the algorithm can compensate it by the use of others. On the other hand, we present a methodology that allows us to select the relevant input variables for a given climatic variable estimation or prediction problem, in a systematic way, using the same Genetic Algorithm with different parameters. Both methods were tested in the estimation of daily Global Solar Radiation in El Colmenar (Tucumán, Argentina), using linear regression on data from 14 weather stations spread along the north of Argentina. The results obtained show that the methodology is appropriate, providing an RMSE = 2.36 [MJ/m2] and R = 0.926 using an average of 64 out of 329 initial variables, on a 70 individuals/85 generations combination. For a 200 individuals/150 generations combination it obtained an RMSE = 2.34 [MJ/m2] and R = 0.928 using an average of 54 variables.}
}
@article{THALER2019108851,
title = {Sparse identification of truncation errors},
journal = {Journal of Computational Physics},
volume = {397},
pages = {108851},
year = {2019},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2019.07.049},
url = {https://www.sciencedirect.com/science/article/pii/S0021999119305352},
author = {Stephan Thaler and Ludger Paehler and Nikolaus A. Adams},
keywords = {Sparse regression, Truncation error, Modified differential equation analysis, Data-driven scientific computing, Preconditioning},
abstract = {This work presents a data-driven approach to the identification of spatial and temporal truncation errors for linear and nonlinear discretization schemes of Partial Differential Equations (PDEs). Motivated by the central role of truncation errors, for example in the creation of implicit Large Eddy schemes, we introduce the Sparse Identification of Truncation Errors (SITE) framework to automatically identify the terms of the modified differential equation from simulation data. We build on recent advances in the field of data-driven discovery and control of complex systems and combine it with classical work on modified differential equation analysis of Warming, Hyett, Lerat and Peyret. We augment a sparse regression-rooted approach with appropriate preconditioning routines to aid in the identification of the individual modified differential equation terms. The construction of such a custom algorithm pipeline allows attenuating of multicollinearity effects as well as automatic tuning of the sparse regression hyperparameters using the Bayesian information criterion (BIC). As proof of concept, we constrain the analysis to finite difference schemes and leave other numerical schemes open for future inquiry. Test cases include the linear advection equation with a forward-time, backward-space discretization, the Burgers' equation with a MacCormack predictor-corrector scheme and the Korteweg-de Vries equation with a Zabusky and Kruska discretization scheme. Based on variation studies, we derive guidelines for the selection of discretization parameters, preconditioning approaches and sparse regression algorithms. The results showcase highly accurate predictions underlining the promise of SITE for the analysis and optimization of discretization schemes, where analytic derivation of modified differential equations is infeasible.}
}
@article{CHENG2015349,
title = {A non-linear case-based reasoning approach for retrieval of similar cases and selection of target credits in LEED projects},
journal = {Building and Environment},
volume = {93},
pages = {349-361},
year = {2015},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2015.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0360132315300676},
author = {Jack C.P. Cheng and Lucky J. Ma},
keywords = {Artificial neural network, Case-based reasoning, Decision support tool, LEED-NC v2009, Non-linear, Target credit selection},
abstract = {Leadership in Energy and Environmental Design (LEED) is a widely used international green building certification program developed by the U.S. Green Building Council (USGBC). Although the need for LEED certification has grown significantly, LEED managers still face challenges in target credit selection and green building technology design. They frequently meet new types of projects with different project characteristics and requirements. Therefore, it would be helpful if LEED managers could refer to other similar certified green building cases when planning and designing LEED projects. However, this is not supported in current studies and research. This paper proposes a case-based reasoning (CBR) approach to provide case studies of similar certified green building projects and suggestions on target LEED credits. Currently, linear formation of Local-Global method is commonly used in the retrieval step of CBR. This paper presents a non-linear formation of Local-Global retrieval based on Artificial Neural Network (ANN), which can provide a higher accuracy. LEED for New Construction (LEED-NC) is the focus of this paper, and 1000 LEED-NC v2009 certified cases were collected for the case base. Pairwise comparison was conducted to generate the local distance (attribute similarity) and the target for training the ANN model. The proposed non-linear CBR approach was tested and evaluated using 20 recently certified projects, and the results showed a prediction accuracy of 80.75% on the LEED credit selection. The results were also compared with those calculated by commonly used linear CBR approaches: Multiple Regression Analysis, Correlation Analysis, and the k-NN approach. The accuracy achieved by these methods was between 71.23% and 77.54%, which was lower than the proposed approach.}
}
@article{PATRICK2015328,
title = {Subdomain-based test data generation},
journal = {Journal of Systems and Software},
volume = {103},
pages = {328-342},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.11.033},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214002647},
author = {Matthew Patrick and Rob Alexander and Manuel Oriol and John A. Clark},
keywords = {Search based testing, Input distributions, Evolution strategy},
abstract = {Considerable effort is required to test software thoroughly. Even with automated test data generation tools, it is still necessary to evaluate the output of each test case and identify unexpected results. Manual effort can be reduced by restricting the range of inputs testers need to consider to regions that are more likely to reveal faults, thus reducing the number of test cases overall, and therefore reducing the effort needed to create oracles. This article describes and evaluates search-based techniques, using evolution strategies and subset selection, for identifying regions of the input domain (known as subdomains) such that test cases sampled at random from within these regions can be used efficiently to find faults. The fault finding capability of each subdomain is evaluated using mutation analysis, a technique that is based on faults programmers are likely to make. The resulting subdomains kill more mutants than random testing (up to six times as many in one case) with the same number or fewer test cases. Optimised subdomains can be used as a starting point for program analysis and regression testing. They can easily be comprehended by a human test engineer, so may be used to provide information about the software under test and design further highly efficient test suites.}
}
@article{OKNINSKI20181,
title = {On use of hybrid rocket propulsion for suborbital vehicles},
journal = {Acta Astronautica},
volume = {145},
pages = {1-10},
year = {2018},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2018.01.027},
url = {https://www.sciencedirect.com/science/article/pii/S0094576517313012},
author = {Adam Okninski},
keywords = {Rocket, Sounding rocket, Hybrid rocket motor, Rocket propulsion, Optimisation, Suborbital flight},
abstract = {While the majority of operating suborbital rockets use solid rocket propulsion, recent advancements in the field of hybrid rocket motors lead to renewed interest in their use in sounding rockets. This paper presents results of optimisation of sounding rockets using hybrid propulsion. An overview of vehicles under development during the last decade, as well as heritage systems is provided. Different propellant combinations are discussed and their performance assessment is given. While Liquid Oxygen, Nitrous Oxide and Nitric Acid have been widely tested with various solid fuels in flight, Hydrogen Peroxide remains an oxidiser with very limited sounding rocket applications. The benefits of hybrid propulsion for sounding rockets are given. In case of hybrid rocket motors the thrust curve can be optimised for each flight, using a flow regulator, depending on the payload and mission. Results of studies concerning the optimal burn duration and nozzle selection are given. Specific considerations are provided for the Polish ILR-33 “Amber” sounding rocket. Low regression rates, which up to date were viewed as a drawback of hybrid propulsion may be used to the benefit of maximising rocket performance if small solid rocket boosters are used during the initial flight period. While increased interest in hybrid propulsion is present, no up-to-date reference concerning use of hybrid rocket propulsion for sounding rockets is available. The ultimate goal of the paper is to provide insight into the sensitivity of different design parameters on performance of hybrid sounding rockets and delve into the potential and challenges of using hybrid rocket technology for expendable suborbital applications.}
}
@article{DARAIO2014358,
title = {Directional distances and their robust versions: Computational and testing issues},
journal = {European Journal of Operational Research},
volume = {237},
number = {1},
pages = {358-369},
year = {2014},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2014.01.064},
url = {https://www.sciencedirect.com/science/article/pii/S0377221714001118},
author = {Cinzia Daraio and Léopold Simar},
keywords = {Directional distances, Free Disposal Hull (FDH), Conditional efficiency measures, Nonparametric frontiers, Significance test, Bootstrap},
abstract = {Directional distance functions provide very flexible tools for investigating the performance of Decision Making Units (DMUs). Their flexibility relies on their ability to handle undesirable outputs and to account for non-discretionary inputs and/or outputs by fixing zero values in some elements of the directional vector. Simar and Vanhems, 2012, Simar et al., 2012 indicate how the statistical properties of Farrell–Debreu type of radial efficiency measures can be transferred to directional distances. Moreover, robust versions of these distances are also available, for conditional and unconditional measures. Bădin, Daraio, and Simar (2012) have shown how conditional radial distances are useful to investigate the effect of environmental factors on the production process. In this paper we develop the operational aspects for computing conditional and unconditional directional distances and their robust versions, in particular when some of the elements of the directional vector are fixed at zero. After that, we show how the approach of Bădin et al. (2012) can be adapted in a directional distance framework, including bandwidth selection and two-stage regression of conditional efficiency scores. Finally, we suggest a procedure, based on bootstrap techniques, for testing the significance of environmental factors on directional efficiency scores. The procedure is illustrated through simulated and real data.}
}
@article{CARRILLO20226205,
title = {Using a statistical efficiency methodology for predictors’ selection in the bedload transport problem: A high gradient experimental channel case},
journal = {Alexandria Engineering Journal},
volume = {61},
number = {8},
pages = {6205-6219},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.11.052},
url = {https://www.sciencedirect.com/science/article/pii/S1110016821007857},
author = {Veronica Carrillo and Daniel Mendoza and John Petrie and Pedro Matovelle and Sebastian Torres and Esteban Pacheco and Felipe Cisneros and Luis Timbe},
keywords = {High gradient, Bedload transport, Akaike-information-criterion, Best predictors, Laboratory experiments},
abstract = {Bedload transport rates for high-gradient gravel bed rivers has been studied through a physical model that replicated the typical features of these channels. A stepwise regression was performed to identify the best predictors from a set of independent variables. As independent variables channel slope, the ratio of area occupied by large particles to the total plan area, flow discharge, mean flow depth, mean flow velocity, water surface velocity, boundary shear stress, and shear velocity were considered. Different characteristic diameters (d16, d50, d84, and d90) were used to nondimensionalize the variables as well as to test the influence of grain size. A linear and a potential model were obtained for each characteristic diameter. Based on the correlation coefficients (R2) with the data used to build the models, the d50 and d84 linear and potential models were selected to perform further analysis. A set of independent data was used to verify the selected models. Better performance was observed for the potential models with 96% of the data falling within ½ order of the magnitude bands both for d50 and d84 . R2 for the d50 and d84 potential models were 0.63 and 0.76, respectively. Therefore, the d84 potential model can be selected as the present study representative model.}
}
@article{KONDO2018408,
title = {Estimation of binaural speech intelligibility using machine learning},
journal = {Applied Acoustics},
volume = {129},
pages = {408-416},
year = {2018},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2017.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X17303304},
author = {Kazuhiro Kondo and Kazuya Taira},
keywords = {Speech intelligibility, Binaural speech, Objective estimation, Machine learning, Diagnostic rhyme test},
abstract = {We proposed and evaluated a speech intelligibility estimation method for binaural signals. The assumption here was that both the speech and competing noise are directional sources. In this case, when the speech and noise are located away from each other, the intelligibility generally improves since the auditory system can segregate these two streams. However, since intelligibility tests as well as its estimation is conducted based on monaurally-recorded signals, this potential increase in the intelligibility due to the segregation of sources is not accounted for, and the intelligibility is often under-estimated. Accordingly, in order to estimate the intelligibility taking into account this binaural advantage, we trained a mapping function between the subjective intelligibility and objective measures that account for the binaural advantage stated above. We attempted SNR calculation on (1) a simple binaural to monaural mix-down, which models the conventional estimation, (2) simple pooling of both binaural channels (pooled channel), (3) channel signal selection with the better SNR from left and right channels (better-ear), and (4) sub-band wise better-ear selection (band-wise better-ear). For the mapping function training, we tried neural networks (NN), support vector regression (SVR), and random forests (RF), and compared these to simple logistic regression (LR). We also investigated the sub-band configuration that gives the best estimation accuracy by balancing the frequency resolution and the amount of training data. It was found that the combination of the better-ear model and RF gave the best results, with root mean square error (RMSE) of about 0.11 and correlation of 0.92 in an open set test.}
}
@article{LIANG20131209,
title = {Adaptive weighted learning for linear regression problems via Kullback–Leibler divergence},
journal = {Pattern Recognition},
volume = {46},
number = {4},
pages = {1209-1219},
year = {2013},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2012.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0031320312004517},
author = {Zhizheng Liang and Youfu Li and ShiXiong Xia},
keywords = {Linear regression, KL divergence, Weighted learning, Alternative optimization, Image classification},
abstract = {In this paper, we propose adaptive weighted learning for linear regression problems via the Kullback–Leibler (KL) divergence. The alternative optimization method is used to solve the proposed model. Meanwhile, we theoretically demonstrate that the solution of the optimization algorithm converges to a stationary point of the model. In addition, we also fuse global linear regression and class-oriented linear regression and discuss the problem of parameter selection. Experimental results on face and handwritten numerical character databases show that the proposed method is effective for image classification, particularly for the case that the samples in the training and testing set have different characteristics.}
}
@incollection{PODDER2021175,
title = {9 - Application of machine learning for the diagnosis of COVID-19},
editor = {Utku Kose and Deepak Gupta and Victor Hugo C. {de Albuquerque} and Ashish Khanna},
booktitle = {Data Science for COVID-19},
publisher = {Academic Press},
pages = {175-194},
year = {2021},
isbn = {978-0-12-824536-1},
doi = {https://doi.org/10.1016/B978-0-12-824536-1.00008-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128245361000083},
author = {Prajoy Podder and Subrato Bharati and M. Rubaiyat Hossain Mondal and Utku Kose},
keywords = {Classification, COVID-19, Decision tree, Disease prediction, Logistic regression, Machine learning, Random forest},
abstract = {This chapter focuses on the application of machine learning algorithms on the diagnosis of the novel coronavirus disease (COVID-19). First, data visualization is provided on increases in confirmed deaths and recovered cases of COVID-19 using currently available data from Johns Hopkins University. Next, the machine learning algorithms are used for the automatic diagnosis of COVID-19. Data-driven diagnosis is performed using a dataset of 5644 samples with 111 attributes provided by Hospital Israelita Albert Einstein, Brazil. As a preprocessing step, null values and categorical data are processed and standardization is performed. Next, feature selection is performed to find attributes that are most important for a COVID-19 diagnosis. A number of algorithms including random forest logistic regression, XGBoost, and decision tree are considered and their kernel parameters are optimized. The performance of classification algorithms is evaluated in terms of a number of factors including the testing accuracy, precision, recall, miss rate, receiver operating characteristic curve and area under the receiver operating characteristic curve. Experimental results show that serum glucose is the most influential attribute in predicting COVID-19. Our results also show that for the case of cross-validation, XGBoost has the highest accuracy value of 92.67% and logistic regressions have the second highest accuracy of 92.58%, whereas both XGBoost and LR have a 93% value for precision, recall, and F1 score. Moreover, for the case of the holdout method with 20% testing data, logistic regression with an accuracy of 94.06% outperforms other classifiers in terms of accuracy, precision, recall, and F1 score.}
}
@article{GE2022105173,
title = {Design of a rapid diagnostic model for bladder compliance based on real-time intravesical pressure monitoring system},
journal = {Computers in Biology and Medicine},
volume = {141},
pages = {105173},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.105173},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521009677},
author = {Zicong Ge and Liangfeng Tang and Yunsong Peng and Mingming Zhang and Jialong Tang and Xiaodong Yang and Yu Li and Zhongyi Wu and Gang Yuan},
abstract = {Objective
The diagnosis of bladder dysfunction for children depends on the confirmation of abnormal bladder shape and bladder compliance. The existing gold standard needs to conduct voiding cystourethrogram (VCUG) examination and urodynamic studies (UDS) examination on patients separately. To reduce the time and injury of children's inspection, we propose a novel method to judge the bladder compliance by measuring the intravesical pressure during the VCUG examination without extra UDS.
Methods
Our method consisted of four steps. We firstly developed a single-tube device that can measure, display, store, and transmit real-time pressure data. Secondly, we conducted clinical trials with the equipment on a cohort of 52 patients (including 32 negative and 20 positive cases). Thirdly, we preprocessed the data to eliminate noise and extracted features, then we used the least absolute shrinkage and selection operator (LASSO) to screen out important features. Finally, several machine learning methods were applied to classify and predict the bladder compliance level, including support vector machine (SVM), Random Forest, XGBoost, perceptron, logistic regression, and Naive Bayes, and the classification performance was evaluated.
Results
73 features were extracted, including first-order and second-order time-domain features, wavelet features, and frequency domain features. 15 key features were selected and the model showed promising classification performance. The highest AUC value was 0.873 by the SVM algorithm, and the corresponding accuracy was 84%.
Conclusion
We designed a system to quickly obtain the intravesical pressure during the VCUG test, and our classification model is competitive in judging patients’ bladder compliance.
Significance
This could facilitate rapid auxiliary diagnosis of bladder disease based on real-time data. The promising result of classification is expected to provide doctors with a reliable basis in the auxiliary diagnosis of some bladder diseases prior to UDS.}
}
@article{SEKA20199,
title = {Identification of maize (Zea mays L.) progeny genotypes based on two probabilistic approaches: Logistic regression and naïve Bayes},
journal = {Artificial Intelligence in Agriculture},
volume = {1},
pages = {9-13},
year = {2019},
issn = {2589-7217},
doi = {https://doi.org/10.1016/j.aiia.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2589721719300030},
author = {D. Seka and B.S. Bonny and A.N. Yoboué and S.R. Sié and B.A. Adopo-Gourène},
keywords = {Gaussian naïve Bayes, Logistic regression, Maize genotype, Prediction, Selection},
abstract = {We used two probabilistic methods, Gaussian Naïve Bayes and Logistic Regression to predict the genotypes of the offspring of two maize strains, the BLC and the JNE genotypes, based on the phenotypic traits of the parents. We determined the prediction performance of the two models with the overall accuracy and the area under the receiver operating curve (AUC). The overall accuracy for both models ranged between 82% and 87%. The values of the area under the receiver operating curve were 0.90 or higher for Logistic Regression models, and 0.85 or higher for Gaussian Naïve Bayes models. These statistics indicated that the two models were very effective in predicting the genotypes of the offspring. Furthermore, both models predicted the BLC genotype with higher accuracy than they did the JNE genotype. The BLC genotype appeared more homogeneous and more predictable. A Chi-square test for the homogeneity of the confusion matrices showed that in all cases the two models produced similar prediction results. That finding was in line with the assertion by Mitchell (2010) who theoretically showed that the two models are essentially the same. With logistic regression, each subset of the original data or its corresponding principal components produced exactly the same prediction results. The AUC value may be viewed as a criterion for parent-offspring resemblance for each set of phenotypic traits considered in the analysis.}
}
@incollection{MASRI201679,
title = {Chapter Four - Coverage-Based Software Testing: Beyond Basic Test Requirements},
editor = {Atif M. Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {103},
pages = {79-142},
year = {2016},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2016.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0065245816300274},
author = {W. Masri and F.A. Zaraket},
keywords = {Software testing, Structural coverage, Logic coverage, User-defined coverage, Specification-based coverage, Property-based coverage, Regression testing, Profiling for coverage, Test case intent verification},
abstract = {Code coverage is one of the core quality metrics adopted by software testing practitioners nowadays. Researchers have devised several coverage criteria that testers use to assess the quality of test suites. A coverage criterion operates by: (1) defining a set of test requirements that need to be satisfied by the given test suite and (2) computing the percentage of the satisfied requirements, thus yielding a quality metric that quantifies the potential adequacy of the test suite at revealing program defects. What differentiates one coverage criterion from another is the set of test requirements involved. For example, function coverage is concerned with whether every function in the program has been called, and statement coverage is concerned with whether every statement in the program has executed. The use of code coverage in testing is not restricted to assessing the quality of test suites. For example, researchers have devised test suite minimization and test case generation techniques that also leverage coverage. Early coverage-based software testing techniques involved basic test requirements such as functions, statements, branches, and predicates, whereas recent techniques involved (1) test requirements that are complex code constructs such as paths, program dependences, and information flows or (2) test requirements that are not necessarily code constructs such as program properties and user-defined test requirements. The focus of this chapter is to compare these two generations of techniques in regard to their effectiveness at revealing defects. The chapter will first present preliminary background and definitions and then describe impactful early coverage techniques followed by selected recent work.}
}
@article{MENASSA201357,
title = {Optimizing hybrid ventilation in public spaces of complex buildings – A case study of the Wisconsin Institutes for Discovery},
journal = {Building and Environment},
volume = {61},
pages = {57-68},
year = {2013},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2012.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0360132312003319},
author = {Carol C. Menassa and Nathan Taylor and John Nelson},
keywords = {Hybrid ventilation, Energy savings, Complex buildings, Natural ventilation, Experimental method},
abstract = {Complex buildings such as hospitals and laboratories require intensive ventilation and cooling loads in order to meet operational demands. One way to reduce energy use while meeting these demanding requirements in complex buildings is the incorporation of hybrid ventilation in areas that do not require high and continuous loads such as public spaces. This research establishes an experimental approach to test and analyze various hybrid ventilation strategies in an occupied, complex building utilizing hybrid ventilation in public spaces. To optimize the use of hybrid ventilation, this research focuses on tracking three performance criteria: energy savings, occupant comfort and indoor-air quality. The framework establishes a variety of hybrid ventilation strategies to test, and outlines how to analyze results graphically and through linear regression modeling. This experimental approach is illustrated through a case study example of a laboratory building located in Madison–Wisconsin. The selection of the ideal hybrid ventilation strategy for the public space studied resulted in 56 percent average savings in ventilation and cooling load when HV is in use, and established a potential to use hybrid ventilation for 28 percent of the 111 day cooling season (20 percent savings in mechanical cooling over the summer).}
}
@article{RIBEIRO2020105837,
title = {Ensemble approach based on bagging, boosting and stacking for short-term prediction in agribusiness time series},
journal = {Applied Soft Computing},
volume = {86},
pages = {105837},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.105837},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619306180},
author = {Matheus Henrique Dal Molin Ribeiro and Leandro {dos Santos Coelho}},
keywords = {Bagging, Boosting, Agricultural commodity, Ensemble regression, Stacking, Time series},
abstract = {The investigation of the accuracy of methods employed to forecast agricultural commodities prices is an important area of study. In this context, the development of effective models is necessary. Regression ensembles can be used for this purpose. An ensemble is a set of combined models which act together to forecast a response variable with lower error. Faced with this, the general contribution of this work is to explore the predictive capability of regression ensembles by comparing ensembles among themselves, as well as with approaches that consider a single model (reference models) in the agribusiness area to forecast prices one month ahead. In this aspect, monthly time series referring to the price paid to producers in the state of Parana, Brazil for a 60 kg bag of soybean (case study 1) and wheat (case study 2) are used. The ensembles bagging (random forests — RF), boosting (gradient boosting machine — GBM and extreme gradient boosting machine — XGB), and stacking (STACK) are adopted. The support vector machine for regression (SVR), multilayer perceptron neural network (MLP) and K-nearest neighbors (KNN) are adopted as reference models. Performance measures such as mean absolute percentage error (MAPE), root mean squared error (RMSE), mean absolute error (MAE), and mean squared error (MSE) are used for models comparison. Friedman and Wilcoxon signed rank tests are applied to evaluate the models’ absolute percentage errors (APE). From the comparison of test set results, MAPE lower than 1% is observed for the best ensemble approaches. In this context, the XGB/STACK (Least Absolute Shrinkage and Selection Operator-KNN-XGB-SVR) and RF models showed better performance for short-term forecasting tasks for case studies 1 and 2, respectively. Better APE (statistically smaller) is observed for XGB/STACK and RF in relation to reference models. Besides that, approaches based on boosting are consistent, providing good results in both case studies. Alongside, a rank according to the performances is: XGB, GBM, RF, STACK, MLP, SVR and KNN. It can be concluded that the ensemble approach presents statistically significant gains, reducing prediction errors for the price series studied. The use of ensembles is recommended to forecast agricultural commodities prices one month ahead, since a more assertive performance is observed, which allows to increase the accuracy of the constructed model and reduce decision-making risk.}
}
@article{SHARAFODDINI2019,
title = {A New Insight Into Missing Data in Intensive Care Unit Patient Profiles: Observational Study},
journal = {JMIR Medical Informatics},
volume = {7},
number = {1},
year = {2019},
issn = {2291-9694},
doi = {https://doi.org/10.2196/11605},
url = {https://www.sciencedirect.com/science/article/pii/S2291969419000048},
author = {Anis Sharafoddini and Joel A Dubin and David M Maslove and Joon Lee},
keywords = {electronic health records, clinical laboratory tests, machine learning, hospital mortality},
abstract = {Background
The data missing from patient profiles in intensive care units (ICUs) are substantial and unavoidable. However, this incompleteness is not always random or because of imperfections in the data collection process.
Objective
This study aimed to investigate the potential hidden information in data missing from electronic health records (EHRs) in an ICU and examine whether the presence or missingness of a variable itself can convey information about the patient health status.
Methods
Daily retrieval of laboratory test (LT) measurements from the Medical Information Mart for Intensive Care III database was set as our reference for defining complete patient profiles. Missingness indicators were introduced as a way of representing presence or absence of the LTs in a patient profile. Thereafter, various feature selection methods (filter and embedded feature selection methods) were used to examine the predictive power of missingness indicators. Finally, a set of well-known prediction models (logistic regression [LR], decision tree, and random forest) were used to evaluate whether the absence status itself of a variable recording can provide predictive power. We also examined the utility of missingness indicators in improving predictive performance when used with observed laboratory measurements as model input. The outcome of interest was in-hospital mortality and mortality at 30 days after ICU discharge.
Results
Regardless of mortality type or ICU day, more than 40% of the predictors selected by feature selection methods were missingness indicators. Notably, employing missingness indicators as the only predictors achieved reasonable mortality prediction on all days and for all mortality types (for instance, in 30-day mortality prediction with LR, we achieved area under the curve of the receiver operating characteristic [AUROC] of 0.6836±0.012). Including indicators with observed measurements in the prediction models also improved the AUROC; the maximum improvement was 0.0426. Indicators also improved the AUROC for Simplified Acute Physiology Score II model—a well-known ICU severity of illness score—confirming the additive information of the indicators (AUROC of 0.8045±0.0109 for 30-day mortality prediction for LR).
Conclusions
Our study demonstrated that the presence or absence of LT measurements is informative and can be considered a potential predictor of in-hospital and 30-day mortality. The comparative analysis of prediction models also showed statistically significant prediction improvement when indicators were included. Moreover, missing data might reflect the opinions of examining clinicians. Therefore, the absence of measurements can be informative in ICUs and has predictive power beyond the measured data themselves. This initial case study shows promise for more in-depth analysis of missing data and its informativeness in ICUs. Future studies are needed to generalize these results.}
}
@article{SHANBEHZADEH2022101009,
title = {Performance evaluation of machine learning for breast cancer diagnosis: A case study},
journal = {Informatics in Medicine Unlocked},
volume = {31},
pages = {101009},
year = {2022},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2022.101009},
url = {https://www.sciencedirect.com/science/article/pii/S2352914822001526},
author = {Mostafa Shanbehzadeh and Hadi Kazemi-Arpanahi and Mohammad {Bolbolian Ghalibaf} and Azam Orooji},
keywords = {Machine learning, Artificial intelligence, Data mining, Breast neoplasms},
abstract = {Introduction
Breast cancer (BC) is one of the most common and aggressive malignancies in women worldwide. It is proven that machine learning (ML) could rapidly and cost-effectively diagnose BC. This study aimed to develop and test predictive models for BC based on women's lifestyle factors using several basic and ensemble machine learning (ML) classifiers.
Methods
Data of 1503 suspected BC cases were retrospectively extracted from a hospital-based electronic database. First, important risk factors were identified using wrapper-J48, wrapper-SVM, wrapper-NB, logistic regression (LR), and correlation-based feature selection (CFS) methods. Then the performance of five basic ML algorithms, including Naïve Bayes (NB), Bayesian network (BNeT), random forest (RF), multilayer perceptron (MLP), support vector machine (SVM), C4.5, eXtreme Gradient Boosting (XGBoost), decision tree and two ensemble algorithms, including Confidence weighted voting and Voting were compared to predict BC before and after performing feature section (FS). We utilized SPSS 20 and Weka software version 3.8.4 to analyze the data. Implementation of ML models was also performed in R 3.5.0.
Results
The RF algorithm presented the best performance before and after performing FS with AUC of 0.799 and 0.798, respectively. Also, the best model's combination using the Confidence weighted voting method improved the classifier performance and achieved the best result with an 80% AUC.
Conclusions
The results showed that ensemble ML algorithms represented higher ability than basic methods. The developed models can accurately classify individuals who are at high risk for BC, and can be employed as a screening tool for the early BC detection.}
}
@article{DUMONT2015118,
title = {Thermal and hyperspectral imaging for Norway spruce (Picea abies) seeds screening},
journal = {Computers and Electronics in Agriculture},
volume = {116},
pages = {118-124},
year = {2015},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2015.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168169915001672},
author = {Jennifer Dumont and Tapani Hirvonen and Ville Heikkinen and Maxime Mistretta and Lars Granlund and Katri Himanen and Laure Fauch and Ilkka Porali and Jouni Hiltunen and Sarita Keski-Saari and Markku Nygren and Elina Oksanen and Markku Hauta-Kasari and Markku Keinänen},
keywords = {Classification, Hyperspectral imaging, , Thermal imaging, Seed sorting, Insect damage},
abstract = {The quality of seeds used in agriculture and forestry is tightly linked to the plant productivity. Thus, the development of high-throughput nondestructive methods to classify the seeds is of prime interest. Visible and near infrared (VNIR, 400–1000nm range) and short-wave infrared (SWIR, 1000–2500nm range) hyperspectral imaging techniques were compared to an infrared lifetime imaging technique to evaluate Norway spruce (Picea abies (L.) Karst.) seed quality. Hyperspectral image and thermal data from 1606 seeds were used to identify viable seeds, empty seeds and seeds infested by Megastigmus sp. larvae. The spectra of seeds obtained from hyperspectral imaging, especially in SWIR range and the thermal signal decay of seeds following an exposure to a short light pulse were characteristic of the seed status. Classification of the seeds to three classes was performed with a Support Vector Machine (nu-SVM) and sparse logistic regression based feature selection. Leave-One-Out classification resulted to 99% accuracy using either thermal or spectral measurements compared to radiography classification. In spectral imaging case, all important features were located in the SWIR range. Furthermore, the classification results showed that accurate (93.8%) seed sorting can be achieved with a simpler method based on information from only three hyperspectral bands at 1310nm, 1710nm and 1985nm locations, suggesting a possibility to build an inexpensive screening device. The results indicate that combined classification methods with hyperspectral imaging technique and infrared lifetime imaging technique constitute practically high performance fast and non-destructive techniques for high-throughput seed screening.}
}
@article{HEGDE2019100254,
title = {Development of non-invasive diabetes risk prediction models as decision support tools designed for application in the dental clinical environment},
journal = {Informatics in Medicine Unlocked},
volume = {17},
pages = {100254},
year = {2019},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2019.100254},
url = {https://www.sciencedirect.com/science/article/pii/S2352914819302758},
author = {Harshad Hegde and Neel Shimpi and Aloksagar Panny and Ingrid Glurich and Pamela Christie and Amit Acharya},
keywords = {Dental informatics, Decision-support systems, Electronic health records, Evidence-based practice, Machine leaning, Modeling healthcare services},
abstract = {The objective was to develop a predictive model using medical-dental data from an integrated electronic health record (iEHR) to identify individuals with undiagnosed diabetes mellitus (DM) in dental settings. Retrospective data retrieved from Marshfield Clinic Health System's data-warehouse was pre-processed prior to conducting analysis. A subset was extracted from the preprocessed dataset for external evaluation (Nvalidation) of derived predictive models. Further, subsets of 30%–70%, 40%–60% and 50%–50% case-to-control ratios were created for training/testing. Feature selection was performed on all datasets. Four machine learning (ML) classifiers were evaluated: logistic regression (LR), multilayer perceptron (MLP), support vector machines (SVM) and random forests (RF). Model performance was evaluated on Nvalidation. We retrieved a total of 5319 cases and 36,224 controls. From the initial 116 medical and dental features, 107 were used after performing feature selection. RF applied to the 50%–50% case-control ratio outperformed other predictive models over Nvalidation achieving a total accuracy (94.14%), sensitivity (0.941), specificity (0.943), F-measure (0.941), Mathews-correlation-coefficient (0.885) and area under the receiver operating curve (0.972). Future directions include incorporation of this predictive model into iEHR as a clinical decision support tool to screen and detect patients at risk for DM triggering follow-ups and referrals for integrated care delivery between dentists and physicians.}
}
@article{GAUTHIER2017134,
title = {Sound quality prediction based on systematic metric selection and shrinkage: Comparison of stepwise, lasso, and elastic-net algorithms and clustering preprocessing},
journal = {Journal of Sound and Vibration},
volume = {400},
pages = {134-153},
year = {2017},
issn = {0022-460X},
doi = {https://doi.org/10.1016/j.jsv.2017.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S0022460X1730281X},
author = {Philippe-Aubert Gauthier and William Scullion and Alain Berry},
keywords = {Sound quality, Listening tests, Stepwise regression, Lasso, Elastic-net, Clustering},
abstract = {Sound quality is the impression of quality that is transmitted by the sound of a device. Its importance in sound and acoustical design of consumer products no longer needs to be demonstrated. One of the challenges is the creation of a prediction model that is able to predict the results of a listening test while using metrics derived from the sound stimuli. Often, these models are either derived using linear regression on a limited set of experimenter-selected metrics, or using more complex algorithms such as neural networks. In the former case, the user-selected metrics can bias the model and reflect the engineer pre-conceived idea of sound quality while missing potential features. In the latter case, although prediction might be efficient, the model is often in the form of a black-box which is difficult to use as a sound design guideline for engineers. In this paper, preprocessing by participants clustering and three different algorithms are compared in order to construct a sound quality prediction model that does not suffer from these limitations. The lasso, elastic-net and stepwise algorithms are tested for listening tests of consumer product for which 91 metrics are used as potential predictors. Based on the reported results, it is shown that the most promising algorithm is the lasso which is able to (1) efficiently limit the number of metrics, (2) most accurately predict the results of listening tests, and (3) provide a meaningful model that can be used as understandable design guidelines.}
}
@article{LI2014162,
title = {Selection of smoothing parameter estimators for general regression neural networks – Applications to hydrological and water resources modelling},
journal = {Environmental Modelling & Software},
volume = {59},
pages = {162-186},
year = {2014},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2014.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S1364815214001418},
author = {Xuyuan Li and Aaron C. Zecchin and Holger R. Maier},
keywords = {General regression neural networks, Smoothing parameter estimators, Artificial neural networks, Multi-layer perceptrons, Extreme and average events, Hydrology and water resources},
abstract = {Multi-layer perceptron artificial neural networks are used extensively in hydrological and water resources modelling. However, a significant limitation with their application is that it is difficult to determine the optimal model structure. General regression neural networks (GRNNs) overcome this limitation, as their model structure is fixed. However, there has been limited investigation into the best way to estimate the parameters of GRNNs within water resources applications. In order to address this shortcoming, the performance of nine different estimation methods for the GRNN smoothing parameter is assessed in terms of accuracy and computational efficiency for a number of synthetic and measured data sets with distinct properties. Of these methods, five are based on bandwidth estimators used in kernel density estimation, and four are based on single and multivariable calibration strategies. In total, 5674 GRNN models are developed and preliminary guidelines for the selection of GRNN parameter estimation methods are provided and tested.}
}
@article{HASSANZADEH2019103321,
title = {Quantifying semantic similarity of clinical evidence in the biomedical literature to facilitate related evidence synthesis},
journal = {Journal of Biomedical Informatics},
volume = {100},
pages = {103321},
year = {2019},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2019.103321},
url = {https://www.sciencedirect.com/science/article/pii/S1532046419302400},
author = {Hamed Hassanzadeh and Anthony Nguyen and Karin Verspoor},
keywords = {Clinical semantic similarity, Clinical evidence, Evidence based medicine, Systematic review},
abstract = {Objective
Published clinical trials and high quality peer reviewed medical publications are considered as the main sources of evidence used for synthesizing systematic reviews or practicing Evidence Based Medicine (EBM). Finding all relevant published evidence for a particular medical case is a time and labour intensive task, given the breadth of the biomedical literature. Automatic quantification of conceptual relationships between key clinical evidence within and across publications, despite variations in the expression of clinically-relevant concepts, can help to facilitate synthesis of evidence. In this study, we aim to provide an approach towards expediting evidence synthesis by quantifying semantic similarity of key evidence as expressed in the form of individual sentences. Such semantic textual similarity can be applied as a key approach for supporting selection of related studies.
Material and methods
We propose a generalisable approach for quantifying semantic similarity of clinical evidence in the biomedical literature, specifically considering the similarity of sentences corresponding to a given type of evidence, such as clinical interventions, population information, clinical findings, etc. We develop three sets of generic, ontology-based, and vector-space models of similarity measures that make use of a variety of lexical, conceptual, and contextual information to quantify the similarity of full sentences containing clinical evidence. To understand the impact of different similarity measures on the overall evidence semantic similarity quantification, we provide a comparative analysis of these measures when used as input to an unsupervised linear interpolation and a supervised regression ensemble. In order to provide a reliable test-bed for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing.
Results
The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity.
Conclusion
Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.}
}
@article{WEI2013109,
title = {A dynamic particle filter-support vector regression method for reliability prediction},
journal = {Reliability Engineering & System Safety},
volume = {119},
pages = {109-116},
year = {2013},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2013.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S095183201300152X},
author = {Zhao Wei and Tao Tao and Ding ZhuoShu and Enrico Zio},
keywords = {Time series regression, Support vector machines, Particle filter, Reliability prediction},
abstract = {Support vector regression (SVR) has been applied to time series prediction and some works have demonstrated the feasibility of its use to forecast system reliability. For accuracy of reliability forecasting, the selection of SVR's parameters is important. The existing research works on SVR's parameters selection divide the example dataset into training and test subsets, and tune the parameters on the training data. However, these fixed parameters can lead to poor prediction capabilities if the data of the test subset differ significantly from those of training. Differently, the novel method proposed in this paper uses particle filtering to estimate the SVR model parameters according to the whole measurement sequence up to the last observation instance. By treating the SVR training model as the observation equation of a particle filter, our method allows updating the SVR model parameters dynamically when a new observation comes. Because of the adaptability of the parameters to dynamic data pattern, the new PF–SVR method has superior prediction performance over that of standard SVR. Four application results show that PF–SVR is more robust than SVR to the decrease of the number of training data and the change of initial SVR parameter values. Also, even if there are trends in the test data different from those in the training data, the method can capture the changes, correct the SVR parameters and obtain good predictions.}
}
@article{AKBARI2021102917,
title = {Schizophrenia recognition based on the phase space dynamic of EEG signals and graphical features},
journal = {Biomedical Signal Processing and Control},
volume = {69},
pages = {102917},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.102917},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421005140},
author = {Hesam Akbari and Sedigheh Ghofrani and Pejman Zakalvand and Muhammad {Tariq Sadiq}},
keywords = {Electroencephalography (EEG), Phase space dynamic, Schizophrenic, Graphical feature, Classification},
abstract = {Schizophrenia is a mental disorder that causes adverse effects on the mental capacity of a person, emotional inclinations, and quality of personal and social life. The official statistics reported that about 20 million people suffer from this severe mental illness worldwide. The manual screening of schizophrenic patients is tedious, time-consuming, costly, and prone to human error. Thus, it is necessary to provide a fully automatic, fairly accurate, and reasonably inexpensive system to diagnose schizophrenia patients. Electroencephalography (EEG) is commonly employed to evaluate and detect the brain's functions and disorders. The purpose of this study is to introduce, apply, and examine a novel framework to automatically diagnose schizophrenia disorders. This procedure is performed by using the phase space dynamic (PSD) of EEG signals. The two-dimensional PSD of EEG signals is first plotted on Cartesian space. Then, fifteen graphical features are extracted to evaluate the chaotic behavior of PSD based on healthy and schizophrenic subjects. Also, a sizeable number of remarkable features and optimum channels are obtained by the forward selection algorithm (FSA). Finally, eight different classifiers are tested for schizophrenia detection. In this case, the K-nearest neighbor (KNN) and generalized regression neural network (GRNN) showed better performance than the others. As a result, using a 10-fold cross-validation strategy, the KNN classifier with City-block distance reached the level of the average classification accuracy (ACC) of 94.80%, the sensitivity (SEN) of 94.30%, and the specificity (SPE) of 95.20%. The findings of the study confirmed that the PSD shape of the Cz channel for schizophrenia groups is more regular than the healthy ones. It can be applied as a biomarker for the medical team to diagnose schizophrenia disorder. It was found that the frontal and parietal lobes reflect the effects of schizophrenia disorder better than the other lobes. Consequently, the proposed framework contributes to realizing a real-time, easily accessible, and fairly inexpensive method in clinics and hospitals to quickly detect schizophrenia disorder.}
}
@article{CASTROGAMA2014250,
title = {Flood inference simulation using surrogate modelling for the Yellow River multiple reservoir system},
journal = {Environmental Modelling & Software},
volume = {55},
pages = {250-265},
year = {2014},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2014.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364815214000528},
author = {M.E. Castro-Gama and I. Popescu and S. Li and A. Mynett and A. {van Dam}},
keywords = {Reservoir operation, Yellow River, Flood modeling, Surrogate modeling},
abstract = {The Yellow River, in China, is one of the largest hydro systems in the world. Flooding is a major problem for the river, and therefore over the last 50 years a large number of interventions have been made in its reaches and tributaries, in order to control the flooding events in the lowland area, downstream of the Huayuankou hydrological station. The development of new technologies and approaches to decision support has raised possibilities for creating new ways of managing the river and reducing loss of life, in the case of flooding, for the people living within the embankment area of the river. Given the importance of the river for the development of economic activity in China, it is essential to increase the understanding of the general flooding processes triggered by several reservoir operation scenarios, and then, after applying them to a flooding model of a specific area, to test the findings. The main goal of the research presented here is to investigate and develop the statistical inference between the operation of reservoirs on the Yellow River and a set of variables related to the downstream flooding, such as the total flooding volume and the peak discharge. The research shows that it is possible to use such inference models as decision support tools, by reducing the number of explanatory variables to be included in the simulations carried out to determine the appropriate reservoir operation.}
}
@article{SHEN2021107431,
title = {Fast and robust identification of railway track stiffness from simple field measurement},
journal = {Mechanical Systems and Signal Processing},
volume = {152},
pages = {107431},
year = {2021},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2020.107431},
url = {https://www.sciencedirect.com/science/article/pii/S0888327020308177},
author = {Chen Shen and Rolf Dollevoet and Zili Li},
keywords = {Railway track stiffness, Structural identification, Frequency response function, Field hammer test, Gaussian process regression},
abstract = {We propose to combine a physics-based finite element (FE) track model and a data-driven Gaussian process regression (GPR) model to directly infer railpad and ballast stiffness from measured frequency response functions (FRF) by field hammer tests. Conventionally, only the rail resonance and full track resonance are used as the FRF features to identify track stiffness. In this paper, eleven features, including sleeper resonances, from a single FRF curve are selected as the predictors of the GPR. To deal with incomplete measurements and uncertainties in the FRF features, we train multiple candidate GPR models with different features, kernels and training sets. Predictions by the candidate models are fused using a weighted Product of Experts method that automatically filters out unreliable predictions. We compare the performance of the proposed method with a model updating method using the particle swam optimization (PSO) on two synthesis datasets in a wide range of scenarios. The results show that the enriched features and the proposed fusion strategy can effectively reduce prediction errors. In the worst-case scenario with only three features and 5% injected noise, the average prediction errors for the railpad and ballast stiffness are approximately 12% and 6%, outperforming the PSO by about 6% and 3%, respectively. Moreover, the method enables fast predictions for large datasets. The predictions for 400 samples takes only approximately 10 s compared with 40 min using the PSO. Finally, a field application example shows that the proposed method is capable of extracting the stiffness values using a simple setup, i.e., with only one accelerometer and one impact location.}
}
@article{NAM2021,
title = {Discovery of Depression-Associated Factors From a Nationwide Population-Based Survey: Epidemiological Study Using Machine Learning and Network Analysis},
journal = {Journal of Medical Internet Research},
volume = {23},
number = {6},
year = {2021},
issn = {1438-8871},
doi = {https://doi.org/10.2196/27344},
url = {https://www.sciencedirect.com/science/article/pii/S1438887121005811},
author = {Sang Min Nam and Thomas A Peterson and Kyoung Yul Seo and Hyun Wook Han and Jee In Kang},
keywords = {depression, epidemiology, machine learning, network, prediction model, XGBoost},
abstract = {Background
In epidemiological studies, finding the best subset of factors is challenging when the number of explanatory variables is large.
Objective
Our study had two aims. First, we aimed to identify essential depression-associated factors using the extreme gradient boosting (XGBoost) machine learning algorithm from big survey data (the Korea National Health and Nutrition Examination Survey, 2012-2016). Second, we aimed to achieve a comprehensive understanding of multifactorial features in depression using network analysis.
Methods
An XGBoost model was trained and tested to classify “current depression” and “no lifetime depression” for a data set of 120 variables for 12,596 cases. The optimal XGBoost hyperparameters were set by an automated machine learning tool (TPOT), and a high-performance sparse model was obtained by feature selection using the feature importance value of XGBoost. We performed statistical tests on the model and nonmodel factors using survey-weighted multiple logistic regression and drew a correlation network among factors. We also adopted statistical tests for the confounder or interaction effect of selected risk factors when it was suspected on the network.
Results
The XGBoost-derived depression model consisted of 18 factors with an area under the weighted receiver operating characteristic curve of 0.86. Two nonmodel factors could be found using the model factors, and the factors were classified into direct (P<.05) and indirect (P≥.05), according to the statistical significance of the association with depression. Perceived stress and asthma were the most remarkable risk factors, and urine specific gravity was a novel protective factor. The depression-factor network showed clusters of socioeconomic status and quality of life factors and suggested that educational level and sex might be predisposing factors. Indirect factors (eg, diabetes, hypercholesterolemia, and smoking) were involved in confounding or interaction effects of direct factors. Triglyceride level was a confounder of hypercholesterolemia and diabetes, smoking had a significant risk in females, and weight gain was associated with depression involving diabetes.
Conclusions
XGBoost and network analysis were useful to discover depression-related factors and their relationships and can be applied to epidemiological studies using big survey data.}
}
@article{ARGHA2018,
title = {Effect of Seasonal Variation on Clinical Outcome in Patients with Chronic Conditions: Analysis of the Commonwealth Scientific and Industrial Research Organization (CSIRO) National Telehealth Trial},
journal = {JMIR Medical Informatics},
volume = {6},
number = {1},
year = {2018},
issn = {2291-9694},
doi = {https://doi.org/10.2196/medinform.9680},
url = {https://www.sciencedirect.com/science/article/pii/S2291969418000133},
author = {Ahmadreza Argha and Andrey Savkin and Siaw-Teng Liaw and Branko George Celler},
keywords = {telehealth, telemonitoring, seasonal variation, clinical trial, vital signs, chronic disease},
abstract = {Background
Seasonal variation has an impact on the hospitalization rate of patients with a range of cardiovascular diseases, including myocardial infarction and angina. This paper presents findings on the influence of seasonal variation on the results of a recently completed national trial of home telemonitoring of patients with chronic conditions, carried out at five locations along the east coast of Australia.
Objective
The aim is to evaluate the effect of the seasonal timing of hospital admission and length of stay on clinical outcome of a home telemonitoring trial involving patients (age: mean 72.2, SD 9.4 years) with chronic conditions (chronic obstructive pulmonary disease coronary artery disease, hypertensive diseases, congestive heart failure, diabetes, or asthma) and to explore methods of minimizing the influence of seasonal variations in the analysis of the effect of at-home telemonitoring on the number of hospital admissions and length of stay (LOS).
Methods
Patients were selected from a hospital list of eligible patients living with a range of chronic conditions. Each test patient was case matched with at least one control patient. A total of 114 test patients and 173 control patients were available in this trial. However, of the 287 patients, we only considered patients who had one or more admissions in the years from 2010 to 2012. Three different groups were analyzed separately because of substantially different climates: (1) Queensland, (2) Australian Capital Territory and Victoria, and (3) Tasmania. Time series data were analyzed using linear regression for a period of 3 years before the intervention to obtain an average seasonal variation pattern. A novel method that can reduce the impact of seasonal variation on the rate of hospitalization and LOS was used in the analysis of the outcome variables of the at-home telemonitoring trial.
Results
Test patients were monitored for a mean 481 (SD 77) days with 87% (53/61) of patients monitored for more than 12 months. Trends in seasonal variations were obtained from 3 years’ of hospitalization data before intervention for the Queensland, Tasmania, and Australian Capital Territory and Victoria subgroups, respectively. The maximum deviation from baseline trends for LOS was 101.7% (SD 42.2%), 60.6% (SD 36.4%), and 158.3% (SD 68.1%). However, by synchronizing outcomes to the start date of intervention, the impact of seasonal variations was minimized to a maximum of 9.5% (SD 7.7%), thus improving the accuracy of the clinical outcomes reported.
Conclusions
Seasonal variations have a significant effect on the rate of hospital admission and LOS in patients with chronic conditions. However, the impact of seasonal variation on clinical outcomes (rate of admissions, number of hospital admissions, and LOS) of at-home telemonitoring can be attenuated by synchronizing the analysis of outcomes to the commencement dates for the telemonitoring of vital signs.
Trial Registration
Australian New Zealand Clinical Trial Registry ACTRN12613000635763; https://www.anzctr.org.au/Trial/Registration/TrialReview.aspx?id=364030&isReview=true (Archived by WebCite at http://www.webcitation.org/ 6xLPv9QDb)}
}
@article{SCHMIDT2021103963,
title = {Bayesian hierarchical and measurement uncertainty model building for liquefaction triggering assessment},
journal = {Computers and Geotechnics},
volume = {132},
pages = {103963},
year = {2021},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2020.103963},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X20305267},
author = {Jonathan Schmidt and Robb Moss},
keywords = {Liquefaction, Bayesian statistics, Predictive modeling, Earthquake engineering, Natural hazards},
abstract = {This study examines the details of creating and validating an empirical liquefaction model, using a worldwide cone penetration test (CPT) liquefaction database with the intent of incorporating the rigor found in predictive modeling in other fields and addressing shortcomings of existing models. Our study implements a logistic regression within a Bayesian measurement error framework to incorporate uncertainty in predictor variables and allow for a probabilistic interpretation of model parameters when making future predictions. The model is built using a hierarchal approach to account for intra-event correlation in loading variables and differences in event sample sizes. The model is tested using an independent set of recent case histories. We found that the Bayesian measurement error model considering two predictor variables, normalized CPT tip resistance and cyclic stress ratio decreased model uncertainty while maintaining predictive utility for new data. Hierarchical models revealed high model uncertainty potentially due to the database lacking in high loading non-liquefaction sites. Models considering friction ratio as a predictor variable performed worse than the two variable case and will require more data or informative priors to be adequately estimated. The framework developed is flexible and can be extended using different methods of predictor variable selection, model function forms, and validation processes.}
}
@article{GONG2020101455,
title = {Heat load prediction of residential buildings based on discrete wavelet transform and tree-based ensemble learning},
journal = {Journal of Building Engineering},
volume = {32},
pages = {101455},
year = {2020},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2020.101455},
url = {https://www.sciencedirect.com/science/article/pii/S2352710219324799},
author = {Mingju Gong and Jin Wang and Yin Bai and Bo Li and Lei Zhang},
keywords = {District heating system, Load prediction, Feature selection, Discrete wavelet transform, Ensemble learning},
abstract = {Currently, the high energy consumption of district heating system represents a problem. Thus, accurate prediction of future heat load is the key to ensure energy saving and improve system operation efficiency. However, the accuracy of the prediction model based on single machine learning algorithms need to be improved, and the hybrid prediction model suffers from redundant inputs. The objective of this study was to obtain the most accurate prediction of the short-term heat load consumption. The discrete wavelet transform, two tree-based ensemble learning algorithms, extremely randomized trees regression and gradient boosting decision tree were used to establish hybrid models for predicting the heat load 1 h in advance. Pearson and least absolute shrinkage and selection operator (LASSO) methods were used to optimize the feature set, including system parameters, meteorological parameters and time steps. This resulted in four feature sets. In addition, the effect of the historical heat load on the performance of the prediction model was analysed. Actual operation data of an established heating system were collected to test the performance of the models. The results were then compared with those of the models established by artificial neural network and support vector regression. The results show that the historical heat load had a significant impact on the prediction accuracy of the heat load of the upcoming hour, and the extreme random tree model based on discrete wavelet transform showed a better prediction performance and lower model complexity in case of using the feature set selected by the LASSO method.}
}
@article{JACKEL2020101817,
title = {Design of an aeronautic pitot probe with a redundant heating system incorporating phase change materials},
journal = {Flow Measurement and Instrumentation},
volume = {76},
pages = {101817},
year = {2020},
issn = {0955-5986},
doi = {https://doi.org/10.1016/j.flowmeasinst.2020.101817},
url = {https://www.sciencedirect.com/science/article/pii/S095559862030159X},
author = {Robert Jäckel and Fidencio Tapia and Geydy Gutiérrez-Urueta and Cintia {Monreal Jiménez}},
keywords = {Aeronautical pitot probe, Phase change materials, Design of experiment method, Heating element, Aircraft icing},
abstract = {The aim of this work is the design of a pitot probe (PP) prototype in order to retard the cool down of the tip, in case of a heating element failure. The viability of operation in flight conditions is evaluated. The design consists of a redundant heating system incorporating phase change materials (PCM). Combining experimental observations of ice formation with the implementation of the conjugate heat transfer (CHT) model, with the addition of the heat release due to the phase change of the PCM, the numerical evaluation is developed. The modelling assumptions and numerical implementation of the phase change process are presented. Then, the selection an appropriate PCM is based on the low flammability and volume dilation and the quantitative effects of the material properties on the heat transfer. A commercial PCM solution based on salt hydrates was chosen as the most adequate for the design. The parametric design of the prototype, based on the design of experiment method and fractional factorial testing, is established. A multiple linear regression model was obtained in order to maximize the cooling retardation. The numerical simulations demonstrate that the prototype PP tip temperature remains 194 s longer above 0 °C than that of the conventional model analyzed.}
}
@article{CHANG2023,
title = {Comparing Natural Language Processing and Structured Medical Data to Develop a Computable Phenotype for Patients Hospitalized Due to COVID-19: Retrospective Analysis},
journal = {JMIR Medical Informatics},
volume = {11},
year = {2023},
issn = {2291-9694},
doi = {https://doi.org/10.2196/46267},
url = {https://www.sciencedirect.com/science/article/pii/S2291969423000182},
author = {Feier Chang and Jay Krishnan and Jillian H Hurst and Michael E Yarrington and Deverick J Anderson and Emily C O'Brien and Benjamin A Goldstein},
keywords = {natural language processing, NLP, computable phenotype, machine learning, COVID, coronavirus, hospitalize, hospitalization, electronic health record, EHR, health record, structured data, data element, free text, unstructured data, provider note, classify, classification, algorithm, COVID-19},
abstract = {Background
Throughout the COVID-19 pandemic, many hospitals conducted routine testing of hospitalized patients for SARS-CoV-2 infection upon admission. Some of these patients are admitted for reasons unrelated to COVID-19 and incidentally test positive for the virus. Because COVID-19–related hospitalizations have become a critical public health indicator, it is important to identify patients who are hospitalized because of COVID-19 as opposed to those who are admitted for other indications.
Objective
We compared the performance of different computable phenotype definitions for COVID-19 hospitalizations that use different types of data from electronic health records (EHRs), including structured EHR data elements, clinical notes, or a combination of both data types.
Methods
We conducted a retrospective data analysis, using clinician chart review–based validation at a large academic medical center. We reviewed and analyzed the charts of 586 hospitalized individuals who tested positive for SARS-CoV-2 in January 2022. We used LASSO (least absolute shrinkage and selection operator) regression and random forests to fit classification algorithms that incorporated structured EHR data elements, clinical notes, or a combination of structured data and clinical notes. We used natural language processing to incorporate data from clinical notes. The performance of each model was evaluated based on the area under the receiver operator characteristic curve (AUROC) and an associated decision rule based on sensitivity and positive predictive value. We also identified top words and clinical indicators of COVID-19–specific hospitalization and assessed the impact of different phenotyping strategies on estimated hospital outcome metrics.
Results
Based on a chart review, 38.2% (224/586) of patients were determined to have been hospitalized for reasons other than COVID-19, despite having tested positive for SARS-CoV-2. A computable phenotype that used clinical notes had significantly better discrimination than one that used structured EHR data elements (AUROC: 0.894 vs 0.841; P<.001) and performed similarly to a model that combined clinical notes with structured data elements (AUROC: 0.894 vs 0.893; P=.91). Assessments of hospital outcome metrics significantly differed based on whether the population included all hospitalized patients who tested positive for SARS-CoV-2 or those who were determined to have been hospitalized due to COVID-19.
Conclusions
These findings highlight the importance of cause-specific phenotyping for COVID-19 hospitalizations. More generally, this work demonstrates the utility of natural language processing approaches for deriving information related to patient hospitalizations in cases where there may be multiple conditions that could serve as the primary indication for hospitalization.}
}
@article{CASTILLOBARNES2020153,
title = {Autosomal dominantly inherited alzheimer disease: Analysis of genetic subgroups by machine learning},
journal = {Information Fusion},
volume = {58},
pages = {153-167},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S1566253519309959},
author = {Diego Castillo-Barnes and Li Su and Javier Ramírez and Diego Salas-Gonzalez and Francisco J. Martinez-Murcia and Ignacio A. Illan and Fermin Segovia and Andres Ortiz and Carlos Cruchaga and Martin R. Farlow and Chengjie Xiong and Neil R. Graff-Radford and Peter R. Schofield and Colin L. Masters and Stephen Salloway and Mathias Jucker and Hiroshi Mori and Johannes Levin and Juan M. Gorriz and Dominantly Inherited Alzheimer Network (DIAN)},
keywords = {Dominantly-inherited Alzheimer’s disease (DIAD), DIAN, Alzheimer’s disease (AD), Neuroimaging, Machine learning},
abstract = {Despite subjects with Dominantly-Inherited Alzheimer’s Disease (DIAD) represent less than 1% of all Alzheimer’s Disease (AD) cases, the Dominantly Inherited Alzheimer Network (DIAN) initiative constitutes a strong impact in the understanding of AD disease course with special emphasis on the presyptomatic disease phase. Until now, the 3 genes involved in DIAD pathogenesis (PSEN1, PSEN2 and APP) have been commonly merged into one group (Mutation Carriers, MC) and studied using conventional statistical analysis. Comparisons between groups using null-hypothesis testing or longitudinal regression procedures, such as the linear-mixed-effects models, have been assessed in the extant literature. Within this context, the work presented here performs a comparison between different groups of subjects by considering the 3 genes, either jointly or separately, and using tools based on Machine Learning (ML). This involves a feature selection step which makes use of ANOVA followed by Principal Component Analysis (PCA) to determine which features would be realiable for further comparison purposes. Then, the selected predictors are classified using a Support-Vector-Machine (SVM) in a nested k-Fold cross-validation resulting in maximum classification rates of 72–74% using PiB PET features, specially when comparing asymptomatic Non-Carriers (NC) subjects with asymptomatic PSEN1 Mutation-Carriers (PSEN1-MC). Results obtained from these experiments led to the idea that PSEN1-MC might be considered as a mixture of two different subgroups including: a first group whose patterns were very close to NC subjects, and a second group much more different in terms of imaging patterns. Thus, using a k-Means clustering algorithm it was determined both subgroups and a new classification scenario was conducted to validate this process. The comparison between each subgroup vs. NC subjects resulted in classification rates around 80% underscoring the importance of considering DIAN as an heterogeneous entity.}
}
@article{RAO2017103,
title = {A multi-objective algorithm for optimization of modern machining processes},
journal = {Engineering Applications of Artificial Intelligence},
volume = {61},
pages = {103-125},
year = {2017},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2017.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0952197617300465},
author = {R. Venkata Rao and Dhiraj P. Rai and Joze Balic},
keywords = {Modern machining processes, Process parameters, Multi-objective optimization, A posteriori approach, Jaya algorithm, Population based algorithms},
abstract = {Multi-objective optimization aspects of four modern machining processes namely wire-electro discharge machining process, laser cutting process, electrochemical machining process and focused ion beam micro-milling process are considered in this work. In WEDM process cutting velocity and surface quality are important objectives which are mutually conflicting in nature. Minimization of kerf taper is vital in the laser cutting process which increases with the increase in material removal rate. The ECM process is characterized by high material removal rate, but poor dimensional accuracy, high tool wear rate and high over cut. FIB micro-milling process is useful in applications where a nano-level surface finish is desired but this process is characterized by a very low material removal rate. All the above mentioned objectives are vital as they closely govern the performance of the machining processes considered in this work. Therefore, the aim of this work is to achieve these objectives through process parameter optimization. In order to handle multiple objectives simultaneously a new posteriori multi-objective optimization algorithm named as multi-objective Jaya (MO-Jaya) algorithm is proposed which can provide multiple optimal solutions in a single simulation run. The regression models for the above mentioned machining processes which were developed by previous researchers are used as fitness function for MO-Jaya algorithm. In the case of WEDM process the optimization problem is an unconstrained, linear and parameter bounded. In the case of laser cutting process the optimization problem is a non-linear, unconstrained, quadratic and parameter bounded. In the ECM process the optimization problem is a non-linear, unconstrained, quadratic and parameter bounded. The second case study of ECM process the optimization problem is a non-linear, constrained, non-quadratic and parameter bounded. In the case of FIB micro-milling process, the optimization problem is a non-linear, unconstrained, quadratic and parameter bounded. In addition, the performance of MO-Jaya algorithm is also tested on a non-linear, non-quadratic unconstrained multi-objective benchmark function of CEC2009. In order to handle the constraints effectively a heuristic approach for handling constraints known as the constrained-dominance concept is used in MO-Jaya algorithm. In order to ensure that the newly generated solutions are within the parameter bounds a parameter-bounding strategy is used in MO-Jaya algorithm. The results of MO-Jaya algorithm are compared with the results of GA, NSGA, NSGA-II, BBO, NSTLBO, PSO, SQP and Monte Carlo simulations. The results have shown the better performance of the proposed algorithm.}
}
@article{VESELY201620,
title = {Multi-parameter approximation of the stress field in a cracked body in the more distant surroundings of the crack tip},
journal = {International Journal of Fatigue},
volume = {89},
pages = {20-35},
year = {2016},
note = {Special Issue: Crack Tip Fields 3},
issn = {0142-1123},
doi = {https://doi.org/10.1016/j.ijfatigue.2016.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S014211231600061X},
author = {Václav Veselý and Jakub Sobek and Petr Frantík and Stanislav Seitl},
keywords = {Crack-tip fields, Williams power series, Higher order terms, Stress field reconstruction, Multi-parameter approximation accuracy},
abstract = {The accuracy of the multi-parameter approximation of the stress fields in a cracked body is studied in the paper. This approximation, which uses the Williams power series expansion (WE), is intended to be used to estimate the extent of the nonlinear zone, which plays a significant role within tensile failure and the fatigue assessment of non-brittle materials. The characteristics of this zone could be potentially incorporated into methods of determining the true values of fracture parameters and the fatigue behaviour descriptors of materials exhibiting nonlinear failure. Considering the fact that in the case of elastic–plastic and especially quasi-brittle materials the size of this zone is substantial in comparison to specimen dimensions, it is necessary to consider a large region around the crack tip for this task. An automatic routine implemented as a Java application was created to determine the values of coefficients of the higher order terms of the WE that describe crack-tip fields. These values are calculated using the Over-Deterministic Method (ODM), which is applied to the results of the finite element (FE) analysis of an arbitrary mode I test geometry. Furthermore, another Java application developed by the authors provides an analytical reconstruction of the crack-tip stress field by means of the truncated WE, and enables detailed analysis of the crack-tip stress field approximation. The developed procedures simplify the analysis of the description of mechanical fields at a greater distance from the crack tip considerably. The presented research is focused on the optimisation of the selection of FE nodal results entering the ODM procedure used to determine the values of coefficients of the higher order terms of the WE. The aim is to improve the accuracy of the approximation.}
}
@article{HONG201626,
title = {A spatially autoregressive and heteroskedastic space-time pedestrian exposure modeling framework with spatial lags and endogenous network topologies},
journal = {Analytic Methods in Accident Research},
volume = {10},
pages = {26-46},
year = {2016},
issn = {2213-6657},
doi = {https://doi.org/10.1016/j.amar.2016.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2213665716300112},
author = {Jungyeol Hong and Venky N. Shankar and Narayan Venkataraman},
keywords = {Pedestrian exposure, Network topology, Spatial autoregressive, GMM estimation},
abstract = {The main objective of this study is to derive a modeling framework for characterizing the space-time exposure of pedestrians in crosswalks, where the spatial measure is characterized by pedestrian density and the temporal measure is characterized by crosswalk time occupancy. This characterization has not been observed in the literature, but is a characterization that allows one to differentiate the components of pedestrian exposure with enhanced resolution in space and time. However, real-time observations to generate space-time data are time consuming and expensive over a large urban network. A hybrid microsimulation-statistical approach is utilized for data generation and statistical analysis in this study. The exposure models predicting crosswalk density and occupancy were estimated using spatial autoregressive models with spatial lags, autoregressive and heteroskedastic spatial disturbances and endogenous regressors. An instrumental variables generalized method of moments (IV-GMM) approach was used for estimation, and the spatial models account for spatial dependence among crosswalks through the estimation of spatial lag and spatial correlation parameters. In a case study of the downtown crosswalk grid in Seattle, Washington, 688 crosswalks were modeled using ten network topology measures capturing node degree, centrality, clustering, modularity, attractiveness and eccentricity measures. The models utilized these network topology variables to account for stochasticity in network design effects on pedestrian dynamics. Several important findings resulted from this study. First, and most important, it was found that network topology measures had an endogenous impact on pedestrian density. Second, the pedestrian time occupancy equation is characterized by endogenous selection effects. That is, in crosswalks with persistent pedestrian volumes and positive densities, the impact of pedestrian trip generation volumes and pedestrian density were corrected for endogeneity and selection bias. The combined results of the pedestrian density and time occupancy equations indicate that endogeneity and selection bias are critical issues that should not be ignored in pedestrian exposure modeling. Pedestrian trip generation volumes representing block level facility generation were found to be elastic. This finding indicates the utility of our modeling framework for estimating the impact of land use on pedestrian space-time exposure at the block level. Out-of-sample prediction tests of the density and time occupancy models and comparisons with pedestrian count data from field observations indicated substantial predictive accuracies. Finally, it was determined that degree and hub were highly sensitive network design parameters in terms of their influence on density. The average total impact (marginal effect) of these measures indicates that attention should be paid to crosswalk network design from the standpoint of degree and hub characteristics. These results show that our space-time density-occupancy modeling framework is a plausible and efficient predictive tool that can be used to estimate pedestrian crosswalk exposure using building level and network topology data alone. We find that the IV-GMM technique is a useful approach for the emergent problem of inference in hybrid simulation-statistical transportation datasets, due to fewer assumptions on distributional assumptions about the data, while accounting for statistical effects relating to endogeneity, potential selection effects and heteroscedasticity.}
}
@article{SHEN2021101283,
title = {Many-to-many comprehensive relative importance analysis and its applications to analysis of semiconductor electrical testing parameters},
journal = {Advanced Engineering Informatics},
volume = {48},
pages = {101283},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101283},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621000379},
author = {Zixin Shen and Amos Hong and Argon Chen},
keywords = {Canonical correlation analysis, Semiconductor yield analysis, Feature selection, Multivariate analysis, Relative importance, Relative weight},
abstract = {Most engineering systems have multiple inputs and multiple outputs. For example, a semiconductor manufacturing system consists of thousands of fabrication steps with numerous inline production parameters affecting multiple electrical characteristics of final chips. Many-to-many analysis is thus needed to more effectively discover critical factors causing poor product qualities or a low production yield. Though methodologies of many-to-many correlation analysis have been proposed in the literature, difficulties arise, especially when there exist multicollinearity effects among features, to measure the relative importance of a feature’s contribution. Relative weight analysis offers a general framework for determining the relative importance of features in multiple linear regression models. In this article, we propose a many-to-many comprehensive relative importance analysis based on canonical correlation analysis to effectively summarize the relationship between two sets of features. Simulation and actual semiconductor yield-analysis cases are used to show the proposed method, as compared to other conventional methods, in analysis of two sets of features.}
}
@article{MADARY2021259,
title = {A Bayesian Framework for Large-Scale Identification of Nonlinear Hybrid Systems},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {5},
pages = {259-264},
year = {2021},
note = {7th IFAC Conference on Analysis and Design of Hybrid Systems ADHS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.508},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321012830},
author = {Ahmad Madary and Hamid Reza Momeni and Alessandro Abate and Kim G. Larsen},
keywords = {Nonlinear hybrid systems, Switched nonlinear ARX models, Bayesian inference, System identification, Occam’s Razor principle, Large data sets},
abstract = {In this paper, a two-level Bayesian framework is proposed for the identification of nonlinear hybrid systems from large data sets by embedding it in a four-stage procedure. At the first stage, feature vector selection techniques are used to generate a reduced-size set from the given training data set. The resulting data set then is used to identify the hybrid system using a Bayesian method, where the objective is to assign each data point to a corresponding sub-mode of the hybrid model. At the third stage, this data assignment is used to train a Bayesian classifier to separate the original data set and determine the corresponding sub-mode for all the original data points. Finally, once every data point is assigned to a sub-mode, a Bayesian estimator is used to estimate a regressor for each sub-system independently. The proposed method tested on three case studies.}
}
@article{LI2016183,
title = {Bayesian hazard modeling based on lifetime data with latent heterogeneity},
journal = {Reliability Engineering & System Safety},
volume = {145},
pages = {183-189},
year = {2016},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2015.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0951832015002719},
author = {Mingyang Li and Jian Liu},
keywords = {Bayesian inference, Mixture model, Hazard regression, Gibbs sampler, Model selection},
abstract = {Lifetime data collected from reliability tests or field operations often exhibit significant heterogeneity patterns caused by latent factors. Such latent heterogeneity indicates that lifetime observations may belong to different sub-populations with different distribution parameters. As a result, the assumption on data homogeneity adopted by conventional reliability modeling techniques becomes inappropriate. Effective identification and quantification of such heterogeneity is crucial for more reliable model estimation and subsequent optimal decision making in a variety of reliability assurance activities. This research proposes a full Bayesian modeling framework for statistical hazard modeling of latent heterogeneity in lifetime data. The proposed framework is generic and comprehensive by systematically addressing different modeling aspects, which include modeling sub-populations with different hazard rates changing over time and different responses to the same stress factors, determining the number of sub-populations, identifying the most appropriate sub-population model structures, estimating model parameters and performing predictive inference. A numerical case study demonstrates the validity and effectiveness of the proposed approach.}
}
@article{OLALUSI2021111470,
title = {Shear capacity prediction of slender reinforced concrete structures with steel fibers using machine learning},
journal = {Engineering Structures},
volume = {227},
pages = {111470},
year = {2021},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2020.111470},
url = {https://www.sciencedirect.com/science/article/pii/S0141029620340712},
author = {Oladimeji Benedict Olalusi and Paul O. Awoyera},
keywords = {Steel fiber reinforced concrete beam, Shear capacity, Structural design, Model uncertainty, Partial safety factors, Structural reliability, Artificial intelligence},
abstract = {Shear failure in reinforced concrete beams poses a critical safety issue since it may occur without any prior signs of damage in some cases. Many of the existing shear design equations for steel fiber reinforced concrete (SFRC) beams include significant uncertainty due to failure in reflecting the phenomenology of shear resistance accurately. Given these, adequate reliability evaluation of shear design provisions for SFRC beam is of high significance, and increased accuracy and minimisation of variability in the predictive model is essential. This contribution proposes machine learning (ML) based methods - Gaussian Process regression (GPR) and the Random Forest (RF) techniques - to predict the ultimate shear resistance of SFRC slender beams without stirrups. The models were developed using a database of 326 experimental SFRC slender beams obtained from previous studies, utilising 75% for model training and the remainder for testing. The performance of the proposed models was assessed by statistical comparison to experimental results and to that of the state-of-practice existing shear design models (fib Model Code 2010, German guideline, Bernat et al. model). The proposed ML-based models are in close alignment with the experimentally observed shear strength and the existing predictive models, but provide more accurate and unbiased predictions. Furthermore, the model uncertainty of the various resistance models was characterised and investigated. The ML-based models displayed the lowest bias and variability, with no significant trend with input parameters. The inconsistencies observed in the predictions by the existing shear design formulations at the variation of shear span to effective depth ratio is a major cause for concern; reliability analysis is required. Finally, partial resistance safety factors were proposed for the model uncertainty associated with the existing shear design equations.}
}
@article{EVORA2017116,
title = {Neural network models for supporting drug and multidrug resistant tuberculosis screening diagnosis},
journal = {Neurocomputing},
volume = {265},
pages = {116-126},
year = {2017},
note = {New Trends for Pattern Recognition: Theory & Applications},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.08.151},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217310160},
author = {L.H.R.A. Évora and J.M. Seixas and A.L. Kritski},
keywords = {Tuberculosis, Multidrug-resistant tuberculosis, Drug-resistant tuberculosis, Drug-sensitive tuberculosis, Neural networks, Clinical score},
abstract = {Tuberculosis (TB) is the leading cause of global mortality among communicable diseases. The diagnosis of Drug-Resistant Tuberculosis (DR-TB) demands even more attention, leading to longer treatments and higher deceased rates. All diagnostic methods available have deficiencies in their detection rates, time release results, or have a higher cost and need a complex infrastructure to setup. New molecular diagnostics, such as the Xpert MTB/RIF assay, have great potential for revolutionizing the diagnosis of Rifampicin Resistance (RR). But, a positive RR result with this test should be carefully interpreted and take into consideration the risk of Multidrug-Resistant TB (MDR-TB) according to its prevalence, locally. Therefore, the development of screening approaches for DR/MDR-TB suspects would help to identify those should be tested by Xpert MTB/RIF. This work develops Artificial Neural Network (ANN) models considering data from presumed DR/MDR-TB subjects according to the National Guidelines at Rio de Janeiro/Brazil, attended in reference centers in Rio de Janeiro, from Feb 2011 and May 2013. Subjects aged 18 years or older, and results were compared with models based on Classification And Regression Trees (CART). Practical operation at different epidemiological scenarios are considered by constructing models using different variable selection criteria, so that environments with low resource conditions can be assisted. Among 280 presumed DR-TB cases included, 38 were DR-TB, 48-MDR, 32-Drug-Sensitive and 162 with no TB. Between DR-TB and non DR-TB, the sensitivity and specificity reached 95.1%(±5.0) and 85.0%(±4.9), respectively. The promising results of clinical score for DR/MDR-TB diagnosis indicate that this approach may be used in the evaluation of presumed DR/MDR-TB.}
}
@article{SIRCAR2021112308,
title = {Study and characterization of potential adsorbent materials for the design of the hydrogen isotopes extraction and analysis system},
journal = {Fusion Engineering and Design},
volume = {166},
pages = {112308},
year = {2021},
issn = {0920-3796},
doi = {https://doi.org/10.1016/j.fusengdes.2021.112308},
url = {https://www.sciencedirect.com/science/article/pii/S0920379621000843},
author = {Amit Sircar and V. Gayathri Devi and Deepak Yadav and Jyoti Shankar Mishra and Ranjana Gangradey and Gayathry J. and Rahul Tomar and Pragnesh B. Dhorajiya and Purvi Dave},
keywords = {Fuel cycle, Extraction, Adsorbent, Isotherm, Zeolites, Enthalpy of adsorption},
abstract = {One of the most challenging tasks in the design of the inner fuel cycle system lies in the effective design of Tritium Extraction System (TES), which involves proper extraction and purification of tritium in a fusion reactor. A prototype Hydrogen Isotopes Recovery System (HIRS) is being developed to validate the concepts for tritium extraction by adsorption mass transfer mechanism. The two main systems of HIRS are Atmospheric Molecular Sieve Bed (AMSB) adsorber and Cryogenic Molecular Sieve Bed (CMSB) adsorber. AMSB removes ppm levels of water vapour while CMSB removes ppm levels of hydrogen isotopes, oxygen and nitrogen gas from Helium purge gas. Selection of appropriate adsorbents for the HIRS is important for its efficient functioning. Adsorbents, namely, Zeolites 3A, 4A, 5A, 13X and Activated Carbon have been studied in detail at cryogenic temperatures to understand their surface characteristics and adsorption potential. In this work, we have generated the adsorption isotherms for hydrogen isotopes on potential adsorbents using a volumetric adsorption apparatus for a wide range of pressure from 1 Pa to 105 Pa. The BET and DFT models are applied for the determination of the textural properties of the adsorbents and the Langmuir-Freundlich composite model is used to fit the isotherm data. The parameters of the model were determined using nonlinear regression analysis. The enthalpy of adsorption is determined and is in the range of 8–11.5 kJ/mol for the adsorbate loadings corresponding to the partial pressure of hydrogen isotopes of ∼ 50–500 Pa in the TES. At low pressures of hydrogen isotopes, the free energy plot followed Henry’s law. The isotherms and enthalpy of adsorption clearly indicate reversible physisorption and monolayer formation of hydrogen isotopes on the potential adsorbents. Amongst hydrogen and deuterium, hydrogen is more strongly adsorbed on Zeolites 4A, whereas deuterium is more strongly adsorbed on Zeolites 13X. In case of activated carbon, no isotopic selectivity was observed. This study facilitates the selection of potential adsorbents for the CMSB and quantification of the parameters associated with the adsorbents.}
}
@article{SALCEDOSANZ201879,
title = {An efficient neuro-evolutionary hybrid modelling mechanism for the estimation of daily global solar radiation in the Sunshine State of Australia},
journal = {Applied Energy},
volume = {209},
pages = {79-94},
year = {2018},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2017.10.076},
url = {https://www.sciencedirect.com/science/article/pii/S0306261917314976},
author = {Sancho Salcedo-Sanz and Ravinesh C. Deo and Laura Cornejo-Bueno and Carlos Camacho-Gómez and Sujan Ghimire},
keywords = {Solar radiation estimation, Coral Reefs Optimization, Extreme Learning Machines, Grouping Genetic Algorithms, Hybrid modelling system},
abstract = {This research paper aims to develop a hybrid neuro-evolutionary wrapper-based model for daily global solar radiation estimation in the solar-rich Sunshine State of Queensland, Australia. To design a robust hybrid modelling mechanism, the Interim-ERA European Centre for Medium Range Weather Forecasting (ECMWF) Reanalysis data are employed to train and cross-validate the estimation model that is formulated by an evolutionary-type algorithm: the Coral Reefs Optimization (CRO) integrated with an Extreme Learning Machine (ELM) model. The hybrid CRO-(ELM) algorithm is applied in two stages: first for the feature selection process guided by an ELM algorithm (a class of fast training neural network tool) as the model’s fitness function to screen an optimal set of predictor variables and second, for the estimation of the solar radiation using the optimally screened variables by the final hybrid CRO-(ELM)-ELM system. To benchmark the performance of the hybrid CRO-ELM algorithm for this estimation problem we apply an alternative, yet a similar feature screening approach: the Grouping Genetic Algorithm encoded into the ELM-based model (GGA-(ELM) used as the predictor mechanism). After the feature selection process is performed by the CRO algorithm that extracts the data patterns for accurate estimation the alternative objective algorithm is applied (in this case the ELM again) to formulate the hybrid CRO-(ELM)-ELM modelling system. To provide a rigorous evaluation of the CRO-(ELM)-ELM hybrid system, alternative estimation approaches are considered: the Multivariate Adaptive Regression Splines (MARS), Multiple Linear Regression (MLR) and the Support Vector Regression (SVR). The hybrid CRO-(ELM)-ELM system is tested in a real problem where the results are evaluated by means of several statistical score metrics and diagnostic plots of the observed and the estimated daily global solar radiation in the testing phase. We show that the hybrid CRO-(ELM)-ELM model is able to yield promising results; thus improving those attained by the 7 alternative models (i.e., hybrid CRO-(ELM)-MARS, CRO-(ELM)-MLR and CRO-(ELM)-SVR and the GGA equivalent models). The study ascertains that the CRO-based hybrid system where a large pool of predictor data are carefully screened through a wrapper-based modelling system and the ELM model is applied as a objective estimation tool can be adopted as a qualified stratagem in solar radiation estimation problems. The proposed hybrid CRO-(ELM)-ELM system exhibits clear advantages over the alternative machine learning approaches tested and also over the other machine learning algorithms used without the feature selection tool; thus advocating its scientific utility in renewable energy applications.}
}
@article{HE2022123148,
title = {Application of deep-learning method in the conjugate heat transfer optimization of full-coverage film cooling on turbine vanes},
journal = {International Journal of Heat and Mass Transfer},
volume = {195},
pages = {123148},
year = {2022},
issn = {0017-9310},
doi = {https://doi.org/10.1016/j.ijheatmasstransfer.2022.123148},
url = {https://www.sciencedirect.com/science/article/pii/S0017931022006196},
author = {Qingfu He and Weicheng Zhao and Zhongran Chi and Shusheng Zang},
keywords = {Conjugate heat transfer, Genetic algorithm, Film cooling, Generative adversarial network, Optimization},
abstract = {Cooling design optimization with complex nonuniform heat loads is a typical challenge in the development of new generation gas turbines. Combined inlet hot streaks and swirls caused by lean-burn combustor force film cooling to attenuate uneven heat loads on the blade surface, especially in the spanwise direction. Besides, the complex coupling relationship among hundreds of design variables of film cooling arrangement hinders the development of the optimal design. The deep learning model shows a strong fitting ability when dealing with high-dimensional nonlinear problems, which could fit the mapping relationship between design variables and the temperature field. In this paper, a turbine cooling design optimization methodology based on conjugate heat transfer (CHT) simulation and conditional generative adversarial network (cGAN) is developed, and the film cooling design of the 1st stage turbine vanes is optimized through the multi-objective genetic algorithm (MOGA). An initial sample containing 96 cases is constructed by CHT computational fluid dynamics (CFD) simulation with inlet hot streaks and swirls. Based on the initial sample, a cGAN model that predicts the temperature distribution of the vane surface is trained and tested. The film hole arrangement of the vane surface is described by a 276-bit binary optimization variable. The 5% maximum temperature predicted by cGAN and the regressed coolant mass flow is used as the dual optimization objectives. The optimal film hole arrangements in rows and the scattered film hole arrangements found by MOGA are compared, which shows that the optimal scattered arrangements perform better due to well adaptability to the nonuniform thermal load in the spanwise direction. The impact of sample size and sample selection on the performance of the cGAN model is discussed. The retrained cGAN model indicates that a proper abundance of specific samples can improve the prediction of complex coupling phenomena such as backflow.}
}
@article{DUONG201880,
title = {Application of multi-output Gaussian process regression for remaining useful life prediction of light emitting diodes},
journal = {Microelectronics Reliability},
volume = {88-90},
pages = {80-84},
year = {2018},
note = {29th European Symposium on Reliability of Electron Devices, Failure Physics and Analysis ( ESREF 2018 )},
issn = {0026-2714},
doi = {https://doi.org/10.1016/j.microrel.2018.07.106},
url = {https://www.sciencedirect.com/science/article/pii/S0026271418306723},
author = {Pham Luu Trung Duong and Hyunseok Park and Nagarajan Raghavan},
keywords = {Light emitting diode, Gaussian process regression, Prognostic health management, Remaining useful life},
abstract = {Light-emitting diodes (LEDs) are the preferred technology today when it comes to lighting both for indoor and outdoor applications, predominantly due to their high efficiency, environmental resilience and prolonged lifetime. Given their widespread use, there is a need to quickly qualify them and accurately predict the reliability of these devices. Due to their inherently long operational life, most LED reliability studies involve the use of degradation tests and application of filter-based prognostic techniques for dynamic update of degradation model parameters and estimation of the remaining useful life (RUL). Although they are in general very effective, the main drawback is the need for a specific state-space model that describes the degradation. In many cases, LED degradation trends are affected by a multitude of unknown factors such as unidentified failure modes, varying operational conditions, process and measurement variance, and environmental fluctuations. These variable factors that are hard to control tend to complicate the selection of a suitable state-space model and in some cases; there may not be a single model that could be used for the entire lifespan of the device. If the degradation patterns of LEDs under test deviate from the state space models, the resulting predictions will be inaccurate. This paper introduces a prognostics-based qualification method using a multi-output Gaussian process regression (MO-GPR) and applies it to RUL prediction of high-power LED devices. The main idea here is to use MO-GPR to learn the correlation between similar degradation patterns from multiple similar components under test and thereby, bypass the need for a specific state space model using available data of past units tested to failure.}
}
@article{THOMSON2023108275,
title = {Comparing the predictive ability of Sentinel-2 multispectral imagery and a proximal hyperspectral sensor for the estimation of pasture nutritive characteristics in an intensive rotational grazing system},
journal = {Computers and Electronics in Agriculture},
volume = {214},
pages = {108275},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.108275},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923006634},
author = {A. Thomson and J. Jacobs and E. Morse-McNabb},
keywords = {Sentinel-2, Satellite, Multispectral, Perennial Ryegrass, Nutritive Characteristics},
abstract = {Using remote sensing to estimate the nutritive characteristics of pasture in livestock systems is a rapidly developing area that has the potential to improve pasture management and utilisation and in turn improve livestock productivity. The Copernicus Sentinel-2 paired satellites have shown promise in predicting pasture nutritive characteristics and have a pixel size small enough to be able to identify intra-paddock nutrient variation in rotational dairy grazing systems where paddock sizes are small. This study sought to develop nutrient prediction models using a dataset of nine Sentinel-2A and -2B satellite images, by linking imagery to perennial ryegrass dairy pasture samples cut within known pixels of the images in the days directly after each cloud-free overpass. Just before destructive pasture sampling, a handheld, proximal, hyperspectral sensor was used to gather spectral signatures (400–2500 nm) from areas to be sampled. Pasture samples (n = 200) were analysed using wet chemistry techniques for seven nutritive characteristics. The dry matter concentration of the samples was also measured, creating eight variates to be modelled in total. The Sentinel-2 data from within the selected pixels was extracted and used to create input features for Random Forest prediction models. Input features included the raw multispectral bands, common vegetation indices, and independent variables ‘season’ and ‘month’. Predictive models were also developed from the hyperspectral sensor data using Partial Least Squares Regression. For both modelling types, variable selection was used to reduce model inputs to only those sensitive to each nutrient. Results comparing the final models in an independent validation test showed similar predictive performance of the Sentinel-2 satellite and the proximal hyperspectral sensor for all variates of interest, shown by mean absolute errors that were not significantly different. In each case, the dry matter concentration was the best predicted variable (Lin’s concordance correlation coefficient (LCCC) > 0.90) with excellent potential to be quantified by Sentinel-2 satellites. Crude protein, metabolisable energy, neutral detergent fibre, non-fibre carbohydrate, and water-soluble carbohydrate concentrations were also predicted with good to moderate accuracy by both sensors (LCCC between 0.50 and 0.80). These models would be sufficiently accurate for making qualitative predictions (e.g., grouping into high to low categories). Ash and acid detergent fibre concentrations were poorly predicted (LCCC < 0.50) and these models would not be recommended for further use. It was concluded that multispectral data from Sentinel-2 has great potential to estimate pasture nutrient concentrations for intensively grazed pastures such as those used in dairy systems in temperate regions.}
}
@article{SUN201441,
title = {Predicting financial distress and corporate failure: A review from the state-of-the-art definitions, modeling, sampling, and featuring approaches},
journal = {Knowledge-Based Systems},
volume = {57},
pages = {41-56},
year = {2014},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2013.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0950705113003869},
author = {Jie Sun and Hui Li and Qing-Hua Huang and Kai-Yu He},
keywords = {Definition of financial distress, Sampling methods, Featuring methods, Review, Financial distress prediction, Corporate failure prediction, Case-based reasoning, Ensemble, Group decision-making, Support vector machine, Hybrid modeling, Neural network, Decision tree, Logistic regression, Multiple discriminant analysis},
abstract = {As a hot topic, financial distress prediction (FDP), or called as corporate failure prediction, bankruptcy prediction, acts as an important role in decision-making of various areas, including: accounting, finance, business, and engineering. Since academic research on FDP has gone on for nearly eighty years, there are abundant literatures on this topic, which may appear chaotic to the researchers of the field and make them feel confused. This paper contributes to the current review researches by making a full summary, analysis and evaluation on the current literatures of FDP. The current literatures of FDP are reviewed from the following four unique aspects: definition of financial distress in the new century, FDP modeling, sampling approaches for FDP, and featuring approaches for FDP. By considering the new state-of-the-art techniques in this area, FDP modeling are classified and reviewed by the following groups: namely, modeling with pure single classifier, modeling with hybrid single classifier, modeling by ensemble techniques, dynamic FDP modeling, and modeling with group decision-making techniques. Sampling methods for FDP are classified and reviewed by the following paired groups, namely: training sampling and testing sampling, single industry sampling and cross-industry sampling, balanced sampling and imbalanced sampling. Featuring methods for FDP are categorized and reviewed by qualitative selection and combination of qualitative and quantitative selection. We comment on the current researches from the view of each category and propose further research topics. The review paper is valuable to guide research and application of the area.}
}
@article{SHAHINFAR2019159,
title = {Prediction of sheep carcass traits from early-life records using machine learning},
journal = {Computers and Electronics in Agriculture},
volume = {156},
pages = {159-177},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.11.021},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918309736},
author = {Saleh Shahinfar and Khama Kelman and Lewis Kahn},
keywords = {Machine learning, Deep learning, Carcass weight, Intramuscular fat, Sheep},
abstract = {Currently hot carcass weight (HCW) and fat score jointly indicate the price grid for sheep meat in Australia. However, experts in the field believe that soon, yield and quality traits such as intramuscular fat (IMF), greville rule fat depth (GRFAT), computed tomography lean meat yield (CTLEAN), and loin weight (LW) are likely to play a role in pricing. Having an accurate prediction of these traits earlier in the life of an animal will allow sheep producers to adjust their management practices in order to achieve the target market requirements. Management, genetics, pasture and climate factors, influence these traits directly and epistatically. Traditional prediction methods may not be powerful enough to capture complex interactions while avoiding overfitting. In this case, learning algorithms that can learn from the current data to predict the animal’s future performance offers promise. In this study, five different types of Machine Learning (ML) algorithm, namely Deep Learning (DL), Gradient Boosting Tree (GBT), K-Nearest Neighbour (KNN), Model Tree (MT), and Random Forest (RF) were employed to predict HCW, IMF, GRFAT, LW and CTLEAN and their performances were compared against linear regression (LR) as the gold standard of multinomial prediction. Four scenarios representing different numbers of weight recordings -from a total of 9 weight measures taken between birth (WT1) and pre-slaughter (WT9)- were used to inform the algorithms and all models were trained and tested under equal conditions with identical training and testing sets. Selection of the most effective subset of predictor features were completed via greedy stepwise search among all the available features jointly with expert opinion. In predicting all the traits, RF was superior while LR and KNN showed the lowest prediction performance. When using the final model for predicting on an independent test set, the scenario with the most accurate prediction performance differed across traits. IMF and GRFAT were most accurately predicted when using birth, weaning, and pre-slaughter weights, while the most accurate scenario for HCW, LW and CTLEAN utilised weaning, six monthly weight measures after weaning and pre-slaughter weight. Across all scenarios the least accurate prediction was for IMF.}
}
@article{SHAH2018369,
title = {A spectroscopic chemometric modeling approach based on statistics pattern analysis},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {18},
pages = {369-374},
year = {2018},
note = {10th IFAC Symposium on Advanced Control of Chemical Processes ADCHEM 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.09.328},
url = {https://www.sciencedirect.com/science/article/pii/S240589631832010X},
author = {Devarshi Shah and Q. {Peter He} and Jin Wang},
keywords = {Soft sensor, Variable selection, Multivariate regression, Partial least squares, Statistics pattern analysis, NIR, UV/Vis, Chemometrics},
abstract = {Spectroscopic techniques such as near-infrared spectroscopy have gained wide applications in the last few decades. As a result, various soft sensors have been developed to predict sample properties from the sample’s spectroscopic readings. Because the readings at different wavelengths are highly correlated, it has been shown that variable selection could significantly improve a soft sensor’s prediction performance and reduce the model complexity. Currently, almost all variable selection methods focus on how to select the variables (i.e., wavelengths or wavelength segments) that are strongly correlated with the dependent variable to improve the prediction performance. Although many successful applications have been reported, such variable selection methods do have their limitations, such as high sensitivity to the choice of training data, and poorer performance when testing on new samples. This is because the variables that are removed from model building may contain useful information about the sample property. To address this limitation, we propose a statistics pattern analysis (SPA) based method. Instead of selecting certain wavelengths or wavelength segments, the SPA-based method considers the whole spectrum which is divided into segments, and extracts different features over each spectrum segment to build the soft sensor. Two case studies are presented to demonstrate the performance of the SPA-based soft sensor and compared with a full partial least squares (PLS) model, and a synergy interval PLS (SiPLS) model.}
}
@article{BALDACCHINO2016178,
title = {Variational Bayesian mixture of experts models and sensitivity analysis for nonlinear dynamical systems},
journal = {Mechanical Systems and Signal Processing},
volume = {66-67},
pages = {178-200},
year = {2016},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2015.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0888327015002307},
author = {Tara Baldacchino and Elizabeth J. Cross and Keith Worden and Jennifer Rowson},
keywords = {Mixture of experts, Variational Bayesian training, Sensitivity analysis, Nonlinear bifurcating systems, Model selection},
abstract = {Most physical systems in reality exhibit a nonlinear relationship between input and output variables. This nonlinearity can manifest itself in terms of piecewise continuous functions or bifurcations, between some or all of the variables. The aims of this paper are two-fold. Firstly, a mixture of experts (MoE) model was trained on different physical systems exhibiting these types of nonlinearities. MoE models separate the input space into homogeneous regions and a different expert is responsible for the different regions. In this paper, the experts were low order polynomial regression models, thus avoiding the need for high-order polynomials. The model was trained within a Bayesian framework using variational Bayes, whereby a novel approach within the MoE literature was used in order to determine the number of experts in the model. Secondly, Bayesian sensitivity analysis (SA) of the systems under investigation was performed using the identified probabilistic MoE model in order to assess how uncertainty in the output can be attributed to uncertainty in the different inputs. The proposed methodology was first tested on a bifurcating Duffing oscillator, and it was then applied to real data sets obtained from the Tamar and Z24 bridges. In all cases, the MoE model was successful in identifying bifurcations and different physical regimes in the data by accurately dividing the input space; including identifying boundaries that were not parallel to coordinate axes.}
}
@article{PAULUS201595,
title = {Algorithm for automating the selection of a temperature dependent change point model},
journal = {Energy and Buildings},
volume = {87},
pages = {95-104},
year = {2015},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2014.11.033},
url = {https://www.sciencedirect.com/science/article/pii/S0378778814009645},
author = {Mitchell T. Paulus and David E. Claridge and Charles Culp},
keywords = {Energy modeling, Regression, EnergyPlus, Measurement and verification},
abstract = {An algorithm was developed to automate the process of selecting a temperature dependent change point model. Regression models based solely on outdoor air temperature for monitoring and verification purposes are common. The correct change point model shape is determined through a series of three tests. The first test checks whether the coefficients of the model are the correct sign for the shape. The second test checks if the coefficients for the model are significant. The final test checks whether enough data points are present in each temperature region of the model. The algorithm was tested with synthetic EnergyPlus electricity and natural gas data for an outpatient hospital, medium office building, large office building, large hotel, secondary school, and warehouse, with weather data from Chicago, Miami, Seattle, and Fairbanks. The algorithm was able to select the most appropriate temperature dependent change point model for all 48 cases tested. The algorithm can be used in an automated energy modeling routine for monitoring and verification or for checking human decision-making in the energy modeling process.}
}
@article{BUASON2022108579,
title = {A sample-based approach for computing conservative linear power flow approximations},
journal = {Electric Power Systems Research},
volume = {212},
pages = {108579},
year = {2022},
issn = {0378-7796},
doi = {https://doi.org/10.1016/j.epsr.2022.108579},
url = {https://www.sciencedirect.com/science/article/pii/S0378779622006526},
author = {Paprapee Buason and Sidhant Misra and Daniel K. Molzahn},
keywords = {Conservative linear approximation, Sample selection, Power flow approximation},
abstract = {Non-convexities induced by the non-linear power flow equations challenge solution algorithms for many power system optimization and control problems. Linear approximations are often used to address these challenges by trading off modeling accuracy for tractability. The accuracy of a power flow linearization depends on the characteristics of the power system and the operational range where the linearization is applied. However, rather than exploiting knowledge of these characteristics for a particular system, many existing power flow linearizations are based on general assumptions for broad classes of systems, thus limiting their accuracy. Moreover, since existing linearizations do not consistently overestimate or underestimate quantities of interest such as voltage magnitudes and line flows, algorithms based on these linearizations may lead to constraint violations when applied to the system. In contrast, this paper computes conservative linear approximations of the power flow equations, i.e., linear approximations that intend to overestimate or underestimate a quantity of interest in order to enable tractable algorithms that avoid constraint violations. Using a sample-based approach, we compute these conservative linearizations by solving a constrained linear regression problem. We analyze and improve the conservative linear approximations via an iterative sampling approach, optimizing over functions of the quantities of interest, and a sample-complexity analysis. Considering the relationships between the voltage magnitudes and the active and reactive power injections, we characterize the performance of the conservative linear approximations for a range of test cases.}
}
@article{PEJOVIC20181,
title = {Sparse regression interaction models for spatial prediction of soil properties in 3D},
journal = {Computers & Geosciences},
volume = {118},
pages = {1-13},
year = {2018},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2018.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S009830041730852X},
author = {Milutin Pejović and Mladen Nikolić and Gerard B.M. Heuvelink and Tomislav Hengl and Milan Kilibarda and Branislav Bajat},
keywords = {Spatial prediction, Lasso, Interactions, Nested cross-validation, Soil organic carbon, 3D},
abstract = {An approach for using lasso (Least Absolute Shrinkage and Selection Operator) regression in creating sparse 3D models of soil properties for spatial prediction at multiple depths is presented. Modeling soil properties in 3D benefits from interactions of spatial predictors with soil depth and its polynomial expansion, which yields a large number of model variables (and corresponding model parameters). Lasso is able to perform variable selection, hence reducing the number of model parameters and making the model more easily interpretable. This also prevents overfitting, which makes the model more accurate. The presented approach was tested using four variable selection approaches – none, stepwise, lasso and hierarchical lasso, on four kinds of models – standard linear model, linear model with polynomial expansion of depth, linear model with interactions of covariates with depth and linear model with interactions of covariates with depth and its polynomial expansion. This framework was used to predict Soil Organic Carbon (SOC) in three contrasting study areas: Bor (Serbia), Edgeroi (Australia) and the Netherlands. Results show that lasso yields substantial improvements in accuracy over standard and stepwise regression — up to 50 % of total variance. It yields models which contain up to five times less nonzero parameters than the full models and that are usually more sparse than models obtained by stepwise regression, up to three times. Extension of the standard linear model by including interactions typically improves the accuracy of models produced by lasso, but is detrimental to standard and stepwise regression. Regarding computation time, it was demonstrated that lasso is several orders of magnitude more efficient than stepwise regression for models with tens or hundreds of variables (including interactions). Proper model evaluation is emphasized. Considering the fact that lasso requires meta-parameter tuning, standard cross-validation does not suffice for adequate model evaluation, hence a nested cross-validation was employed. The presented approach is implemented as publicly available sparsereg3D R package.}
}
@article{KATHARI2020275,
title = {Scalar correlation functions for model structure selection in high-dimensional time-series modelling},
journal = {ISA Transactions},
volume = {100},
pages = {275-288},
year = {2020},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2019.11.033},
url = {https://www.sciencedirect.com/science/article/pii/S0019057819305312},
author = {Sudhakar Kathari and Arun K. Tangirala},
keywords = {Model selection, Order determination, Scalar correlation functions, High-dimensional, Time-series modelling, VARMA models},
abstract = {Model structure selection is an important step in high-dimensional time-series modelling. Traditionally AIC and BIC have been used for this purpose, however, only post model estimation. On the other hand, modern approaches use penalized regression methods, but the optimization is in a user-specified model class. In this work, we propose a pre-estimation approach based on two novel correlation functions, namely, the scalar autocorrelation function (SACF) and the scalar inverse autocorrelation function (SIACF) for identifying the appropriate model class among the vector autoregressive (VAR), vector moving average (VMA), and mixed (VARMA) classes. In addition, these scalar functions theoretically provide the exact order of VAR and VMA processes, and are computationally feather light even for high-dimensional series. The proposed functions are obtained through two linear constructs of the given multivariate process with a lagged-correlation equivalence constraint. The key benefit is that only two correlation functions need to be examined as against the standard M2 correlation and M2 inverse (or partial) correlation plots for an M-dimensional process. This benefit extends to conducting whiteness test in multivariate time-series modelling and is particularly pronounced under small sample conditions, wherein parsimony, structure and class of the identified model is crucial in achieving efficient estimates. Theoretical proofs and case studies are presented to establish the properties and to demonstrate the utility of proposed correlation functions.}
}
@article{ELMASRY202167,
title = {Selection of representative hyperspectral data and image pretreatment for model development in heterogeneous samples: A case study in sliced dry-cured ham},
journal = {Biosystems Engineering},
volume = {201},
pages = {67-82},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020303081},
author = {Gamal M. ElMasry and Elena Fulladosa and Josep Comaposada and Salim S. Al-Rejaie and Pere Gou},
keywords = {Chemical imaging, Dry-cured ham, Hyperspectral imaging, Multivariate analysis, PLS, ROI},
abstract = {Sliced dry-cured ham arranged in ready-to-eat packages is a convenient and widely consumed commodity characterised by heterogeneity in composition not only among different industrial batches but also through their horizontal and vertical profiles, making precise nutrition labelling of the packages a difficult task. Hyperspectral imaging techniques can serve as a steadfast solution not only to predict the overall composition of the major constituents of dry-cured ham but also to visualise their distributions. The main aim of this study was to define the optimal protocol for pretreating hyperspectral images and selecting representative hyperspectral data for developing accurate predictive models in excessively heterogeneous samples, using sliced dry-cured ham as a case study. Hyperspectral images (400–1000 nm) were acquired for heterogeneous sliced dry-cured ham and homogeneous unsliced dry-cured muscles. Partial least squares (PLS) regression models to predict fat, water, salt and protein contents were developed and tested in an independent dataset. The PLS predictive models developed from the whole surface of sliced dry-cured ham were the most accurate ones for predicting fat, water, salt and protein contents with a determination coefficient in prediction (Rp2) of 0.89, 0.85, 83 and 0.63 and standard error in prediction (SEP) of 1.43, 1.21, 0.51 and 1.57%, respectively. The chemical images resulting from the models gave advantages of hyperspectral imaging technique over traditional chemical methods to visualise the spatial distribution of different constituents within the packaged ham slices.}
}
@article{DIMARTINO20168,
title = {A simplified computational fluid-dynamic approach to the oxidizer injector design in hybrid rockets},
journal = {Acta Astronautica},
volume = {129},
pages = {8-21},
year = {2016},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2016.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0094576516306762},
author = {Giuseppe D. {Di Martino} and Paolo Malgieri and Carmine Carmicino and Raffaele Savino},
keywords = {Hybrid rocket motor, Fuel regression rate, Oxidizer injection, Numerical simulation},
abstract = {Fuel regression rate in hybrid rockets is non-negligibly affected by the oxidizer injection pattern. In this paper a simplified computational approach developed in an attempt to optimize the oxidizer injector design is discussed. Numerical simulations of the thermo-fluid-dynamic field in a hybrid rocket are carried out, with a commercial solver, to investigate into several injection configurations with the aim of increasing the fuel regression rate and minimizing the consumption unevenness, but still favoring the establishment of flow recirculation at the motor head end, which is generated with an axial nozzle injector and has been demonstrated to promote combustion stability, and both larger efficiency and regression rate. All the computations have been performed on the configuration of a lab-scale hybrid rocket motor available at the propulsion laboratory of the University of Naples with typical operating conditions. After a preliminary comparison between the two baseline limiting cases of an axial subsonic nozzle injector and a uniform injection through the prechamber, a parametric analysis has been carried out by varying the oxidizer jet flow divergence angle, as well as the grain port diameter and the oxidizer mass flux to study the effect of the flow divergence on heat transfer distribution over the fuel surface. Some experimental firing test data are presented, and, under the hypothesis that fuel regression rate and surface heat flux are proportional, the measured fuel consumption axial profiles are compared with the predicted surface heat flux showing fairly good agreement, which allowed validating the employed design approach. Finally an optimized injector design is proposed.}
}
@article{LIU2016796,
title = {An adaptive online learning approach for Support Vector Regression: Online-SVR-FID},
journal = {Mechanical Systems and Signal Processing},
volume = {76-77},
pages = {796-809},
year = {2016},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2016.02.056},
url = {https://www.sciencedirect.com/science/article/pii/S0888327016001072},
author = {Jie Liu and Enrico Zio},
keywords = {Online learning, Support Vector Regression, Time series data, Pattern drift, Feature vector selection, Incremental and decremental learning},
abstract = {Support Vector Regression (SVR) is a popular supervised data-driven approach for building empirical models from available data. Like all data-driven methods, under non-stationary environmental and operational conditions it needs to be provided with adaptive learning capabilities, which might become computationally burdensome with large datasets cumulating dynamically. In this paper, a cost-efficient online adaptive learning approach is proposed for SVR by combining Feature Vector Selection (FVS) and Incremental and Decremental Learning. The proposed approach adaptively modifies the model only when different pattern drifts are detected according to proposed criteria. Two tolerance parameters are introduced in the approach to control the computational complexity, reduce the influence of the intrinsic noise in the data and avoid the overfitting problem of SVR. Comparisons of the prediction results is made with other online learning approaches e.g. NORMA, SOGA, KRLS, Incremental Learning, on several artificial datasets and a real case study concerning time series prediction based on data recorded on a component of a nuclear power generation system. The performance indicators MSE and MARE computed on the test dataset demonstrate the efficiency of the proposed online learning method.}
}
@incollection{BENER2015453,
title = {Chapter 16 - Lessons Learned from Software Analytics in Practice},
editor = {Christian Bird and Tim Menzies and Thomas Zimmermann},
booktitle = {The Art and Science of Analyzing Software Data},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {453-489},
year = {2015},
isbn = {978-0-12-411519-4},
doi = {https://doi.org/10.1016/B978-0-12-411519-4.00016-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780124115194000161},
author = {Ayse Bener and Ayse Tosun Misirli and Bora Caglayan and Ekrem Kocaguneli and Gul Calikli},
keywords = {Software analytics framework, Industry research projects, Data extraction, Descriptive statistics, Predictive analytics, Prescriptive analytics},
abstract = {In this chapter, we share our experience and views on software data analytics in practice with a review of our previous work. In more than 10 years of joint research projects with industry, we have encountered similar data analytics patterns in diverse organizations and in different problem cases. We discuss these patterns following a “software analytics” framework: problem identification, data collection, descriptive statistics, and decision making. In the discussion, our arguments and concepts are built around our experiences of the research process in six different industry research projects in four different organizations. Methods: Spearman rank correlation, Pearson correlation, Kolmogorov-Smirnov test, chi-square goodness-of-fit test, t test, Mann-Whitney U test, Kruskal-Wallis analysis of variance, k-nearest neighbor, linear regression, logistic regression, naïve Bayes, neural networks, decision trees, ensembles, nearest-neighbor sampling, feature selection, normalization.}
}
@article{DING2020497,
title = {An integrated method based on relevance vector machine for short-term load forecasting},
journal = {European Journal of Operational Research},
volume = {287},
number = {2},
pages = {497-510},
year = {2020},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2020.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0377221720303404},
author = {Jia Ding and Maolin Wang and Zuowei Ping and Dongfei Fu and Vassilios S. Vassiliadis},
keywords = {Short-term load forecasting, Relevance vector machine, Machine learning, Wavelet transform, Feature selection},
abstract = {Short-term electricity load forecasting has become increasingly important due to the privatization and deregulation in the energy market. This study proposes a probabilistic learning method to predict hour-ahead and day-ahead load demand. Unlike methods in previous studies, the proposed method integrates wavelet transform and feature selection as key preprocessing steps. Features are divided into current state related features and historical information related features. Current state related features are forecasted by the regression model before being added into the load prediction model. The entire learning and prediction process is based on the relevance vector machine (RVM) that utilizes load data characteristics. A number of test cases are presented using benchmark datasets from the New York Independent System Operator (NYISO) and ISO New England. Based on the detailed empirical comparison, the proposed RVM-based integrated method outperforms classical time series approaches and state-of-the-art artificial intelligence methods on short-term load forecasting.}
}
@article{KORKUT2018543,
title = {Selection of catalyst and reaction conditions for ultrasound assisted biodiesel production from canola oil},
journal = {Renewable Energy},
volume = {116},
pages = {543-551},
year = {2018},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2017.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0960148117309710},
author = {Ibrahim Korkut and Mahmut Bayramoglu},
keywords = {Biodiesel synthesis, Heterogeneous catalyst, Ultrasound, D-optimal plan, Optimization},
abstract = {In this study, the experimental optimization of ultrasound assisted biodiesel production in presence of heterogeneous catalyst was investigated. Three catalysts namely; CaO, calcined dolomite and calcium diglyceroxide (CaDG) were taken into account for comparative purpose. D-optimal experimental plan was applied to obtain regression models which were subsequently used for the detection of optimum process conditions. Maximum biodiesel yields were calculated as 98.7%, 95.9% and 86.3% for CaO, calcined dolomite and CaDG respectively. Furthermore, supplemental experiments were conducted around optimum process conditions to test the validity of the regression models and to refine the optimum results. Finally, in the case of CaO catalyst, maximum biodiesel yield (99.4%) was obtained at the following conditions; catalyst loading: 5.35% (wt.of oil), methanol/oil ratio: 7.48, ultrasonic power: 40 W, time: 150 min, and reaction temperature: 60 °C.}
}
@article{ARANDIGA20132474,
title = {Learning-based multiresolution transforms with application to image compression},
journal = {Signal Processing},
volume = {93},
number = {9},
pages = {2474-2484},
year = {2013},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2013.03.020},
url = {https://www.sciencedirect.com/science/article/pii/S0165168413000959},
author = {Francesc Aràndiga and Albert Cohen and Dionisio F. Yáñez},
keywords = {Multiresolution transforms, Statistical learning theory, Linear regression, Signal decompositions, Image decompositions},
abstract = {In Harten's framework, multiresolution transforms are defined by predicting finer resolution levels of information from coarser ones using an operator, called prediction operator, and defining details (or wavelet coefficients) that are the difference between the exact and predicted values. In this paper we use tools of statistical learning in order to design a more accurate prediction operator in this framework based on a training sample, resulting in multiresolution decompositions with enhanced sparsity. In the case of images, we incorporate edge detection techniques in the design of the prediction operator in order to avoid Gibbs phenomenon. Numerical tests are presented showing that the learning-based multiresolution transform compares favorably with the standard multiresolution transforms in terms of compression capability.}
}
@article{RIBEIRO2016140,
title = {Assessment of epistemic uncertainties in the shear strength of slender reinforced concrete beams},
journal = {Engineering Structures},
volume = {116},
pages = {140-147},
year = {2016},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2016.02.045},
url = {https://www.sciencedirect.com/science/article/pii/S0141029616300037},
author = {A.B. Ribeiro and J.M.F. Calixto and S.M.C. Diniz},
keywords = {Beams, Epistemic uncertainties, Regression analysis, Reinforced concrete, Shear strength, Shear database},
abstract = {Selection of an appropriate model for shear capacity of reinforced concrete (RC) slender beams poses a number of challenges. First, different models with different levels of conservatism have been proposed in an attempt to describe shear resistance. Second, according to Reineck et al. (2014), code provisions for shear capacity of RC beams with shear reinforcement have been primarily derived from test data with respect to the required amount of shear reinforcement and the calculation of maximum shear capacity. Third, current models have been developed based on databases presenting two major drawbacks: (i) most data points are crowded in the small size range, and (ii) the means of the subsidiary influencing parameters are very different within different intervals of beam size (or beam depth). In this study, a filtered database is used in such a way to circumvent the drawbacks mentioned above. A random variable “model error”, i.e. ratio experimental to predicted shear strength, is associated to each of the shear models analyzed in this work (NBR 6118, ACI 318, EUROCODE 2, and CSA A.23.3). It was observed that in some cases, most notably for the effective depth, a trend exists for a decrease in the “model error” as the effective depth increases. Considering the limitations of the four analyzed models, a nonlinear regression model was proposed. The database presented by Reineck et al. (2014) was used in the assessment of the effectiveness and accuracy of the proposed regression model. No trend was found associated to the most significant variables in the shear strength prediction, i.e. a uniform level of conservatism is attained throughout the range of these variables. The regression model proposed herein and the attendant statistics of the model error (mean, coefficient of variation and type of distribution) can be easily used in a reliability analysis procedure to assess safety levels implicit in different design procedures.}
}
@article{ZHOU2022103840,
title = {Quantitative analysis of contrast-enhanced ultrasound combined with ultrasound in the unifocal papillary thyroid micro-carcinoma},
journal = {Medical Engineering & Physics},
volume = {110},
pages = {103840},
year = {2022},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2022.103840},
url = {https://www.sciencedirect.com/science/article/pii/S1350453322000893},
author = {Xiaohui Zhou and Min Zhang and Linyuan Jin and Xianpeng Tang and Qiang Hu and Guanghui Cheng and Yaocheng Xiao},
keywords = {Unifocal papillary thyroid microcarcinoma, Invasiveness, Us, ceus, diagnostic performance},
abstract = {Objective
To evaluate diagnostic value of ultrasound (US) combined with contrast-enhanced ultrasound (CEUS) in the invasiveness of unifocal papillary thyroid micro-carcinoma (UPTMC) without capsule-invasion.
Methods
This retrospective study included data from patients with UPTMC who received US and CEUS examinations in the Ultrasound Department of the Central Hospital of Changsha, China between June 2019 and September 2021. Univariate and multivariate logistic regression analysis were used to evaluate the risk of US and CEUS parameters for UPTMC. Diagnostic performance was estimated by ROC analysis.
Results
A total of 136 cases were enrolled, including invasive UPTMC (n = 47) and non-invasive UPTMC (n = 89), which were divided into test set (n = 109) and validation set (n = 27). The occurrence of microcalcification and the ratios (R) of each time-intensity curve (TIC) of CEUS parameter were significantly higher in patients with invasive UTPMC than non-invasive UPTMC (all P < 0.05). Additionally, nodular diameter was significantly longer in the invasive group (P < 0.05). Multivariate analysis showed that microcalcification (OR = 2.917, 95% CI: 1.002–8.491, P = 0.050), R-TTP > 1 (OR = 3.376, 95%CI: 1.267–8.994, P = 0.015), R-DS > 1 (OR = 6.558, 95% CI: 2.358–18.243, P < 0.010) were independently associated with invasive UPTMC. The sensitivities of US, CEUS and their combined application were 82.1%, 46.2% and 79.5%, respectively, and their specificities were 37.1%, 88.6% and 61.4%, respectively. The combination of the two methods had the best diagnostic efficiency (AUC=0.775)compared to US (AUC = 0.596) and CEUS (AUC = 0.750).
Conclusion
The combination of US and CEUS might have good diagnostic value for UPTMC with capsule non-invasion.}
}
@article{TAYLOR2021104434,
title = {Finite element analysis informed variable selection for femoral fracture risk prediction},
journal = {Journal of the Mechanical Behavior of Biomedical Materials},
volume = {118},
pages = {104434},
year = {2021},
issn = {1751-6161},
doi = {https://doi.org/10.1016/j.jmbbm.2021.104434},
url = {https://www.sciencedirect.com/science/article/pii/S1751616121001211},
author = {Mark Taylor and Marco Viceconti and Pinaki Bhattacharya and Xinshan Li},
abstract = {Logistic regression classification (LRC) is widely used to develop models to predict the risk of femoral fracture. LRC models based on areal bone mineral density (aBMD) alone are poor, with area under the receiver operator curve (AUROC) scores reported to be as low as 0.63. This has led to researchers investigating methods to extract further information from the image to increase performance. Recently, the use of active shape (ASM) and appearance models (AAM) have resulted in moderate improvements, but there is a risk that inclusion of too many modes will lead to overfitting. In addition, there are concerns that the effort required to extract the additional information does not justify the modest improvement in fracture risk prediction. This raises the question, are we reaching the limits of the information that can be extracted from an image? Finite element analysis was used in combination with active shape and appearance modelling to select variables to develop LRC models of fracture risk. Active shape and active appearance models were constructed based on a previously reported cohort of 94 post-menopausal Caucasian women (47 with and 47 without a fracture). T-tests were used to identify differences between the two groups for each mode of variation. Femur strength was predicted for two load cases, stance and a fall. Stepwise multi-variate linear regression was used to identify shape and appearance modes that were predictors of strength for the femurs in the training set. Femurs were also synthetically generated to explore the influence of the first 10 modes of the shape and appearance models. Identified modes of variation were then used to generate LRC models to predict fracture risk. Only 6 modes, 4 active appearance and 2 active shape modes, were identified that had a significant influence on predicted fracture strength. Of these, only two active appearance modes were needed to substantially improve the predictive mode performance (ΔAUROC = 0.080). The addition of 3 more modes (1 AAM and two ASM) further improved the performance of the classifier (ΔAUROC = 0.123). Further addition of modes did not result in any further substantial improvements. Based on these findings, it is suggested that we are reaching the limits of the information that can be extracted from an image to predict fracture risk.}
}
@article{ROY201916,
title = {A methodology for customizing clinical tests for esophageal cancer based on patient preferences},
journal = {Artificial Intelligence in Medicine},
volume = {95},
pages = {16-26},
year = {2019},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2018.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0933365716305449},
author = {Asis Roy and Sourangshu Bhattacharya and Kalyan Guin},
keywords = {Personalized diagnosis, Personalized test selection, Esophageal cancer, Classification with costs, Unbalanced classification, Electronic health record (EHR), Electronic medical record (EMR)},
abstract = {Background
Clinical tests for diagnosis of any disease may be expensive, uncomfortable, time consuming and can have side effects e.g. barium swallow test for esophageal cancer. Although we can predict non-existence of esophageal cancer with near 100% certainty just using demographics, lifestyle, medical history information, and a few basic clinical tests but our objective is to devise a general methodology for customizing tests with user preferences to avoid expensive or uncomfortable tests.
Method
We propose to use classifiers trained from electronic medical records (EMR) for selection of tests. The key idea is to design classifiers with 100% false normal rates, possibly at the cost of higher false abnormal. We find kernel logistic regression to be most suitable for the task. We propose an algorithm for finding the best probability threshold for kernel LR, based on test set accuracy tuning with help of a validation data set. Using the proposed algorithm, we describe schemes for selecting tests, which appear as features in the automatic classification algorithm, using preferences on costs and discomfort of the users i.e the proposed method is able to detect almost all true patients in the population even with user preferred clinical tests.
Result
We test our methodology with EMRs collected for more than 3000 patients, as a part of project carried out by a reputed hospital in Mumbai, India. We found that kernel SVM and kernel LR with a polynomial kernel of degree 3, yields an accuracy of 99.18% and sensitivity 100% using only demographic, lifestyle, patient history, and basic clinical tests. We demonstrate our test selection algorithm using two case studies, one using cost of clinical tests, and other using “discomfort” values for clinical tests. We compute the test sets corresponding to the lowest false abnormals for each criterion described above, using exhaustive enumeration of 12 and 15 clinical tests respectively. The sets turn out to be different, substantiating our claim that one can customize test sets based on user preferences.}
}
@incollection{BERNARDOGOIS20211,
title = {1 - Predictive models to the COVID-19},
editor = {Utku Kose and Deepak Gupta and Victor Hugo C. {de Albuquerque} and Ashish Khanna},
booktitle = {Data Science for COVID-19},
publisher = {Academic Press},
pages = {1-24},
year = {2021},
isbn = {978-0-12-824536-1},
doi = {https://doi.org/10.1016/B978-0-12-824536-1.00023-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012824536100023X},
author = {Francisco Nauber {Bernardo Gois} and Alex Lima and Khennedy Santos and Ramses Oliveira and Valdir Santiago and Saulo Melo and Rafael Costa and Marcelo Oliveira and Francisco das Chagas Douglas Marques Henrique and José Xavier Neto and Carlos Roberto {Martins Rodrigues Sobrinho} and João Alexandre {Lôbo Marques}},
keywords = {COVID-19, Forecast, Holt Winters, Kalman filter, Machine learning, Prophet, SEIR},
abstract = {Following the World Health Organization proclaims a pandemic due to a disease that originated in China and advances rapidly across the globe, studies to predict the behavior of epidemics have become increasingly popular, mainly related to COVID-19. The critical point of these studies is to discuss the disease's behavior and the progression of the virus's natural course. However, the prediction of the actual number of infected people has proved to be a difficult task, due to a wide range of factors, such as mass testing, social isolation, underreporting of cases, among others. Therefore, the objective of this work is to understand the behavior of COVID-19 in the state of Ceará to forecast the total number of infected people and to aid in government decisions to control the outbreak of the virus and minimize social impacts and economics caused by the pandemic. So, to understand the behavior of COVID-19, this work discusses some forecast techniques using machine learning, logistic regression, filters, and epidemiologic models. Also, this work brings a new approach to the problem, bringing together data from Ceará with those from China, generating a hybrid dataset, and providing promising results. Finally, this work still compares the different approaches and techniques presented, opening opportunities for future discussions on the topic. The study obtains predictions with R2 score of 0.99 to short-term predictions and 0.93 to long-term predictions.}
}
@article{DANG2021103345,
title = {Predicting tensile-shear strength of nugget using M5P model tree and random forest: An analysis},
journal = {Computers in Industry},
volume = {124},
pages = {103345},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2020.103345},
url = {https://www.sciencedirect.com/science/article/pii/S0166361520305790},
author = {Subrat Kumar Dang and Kulwant Singh},
keywords = {Tensile-shear strength prediction, Machine-learning, Random forest (RFs), M5P model tree, Resistance spot welding (RSW)},
abstract = {Predicting the outcomes of a weld based on few metals with respect to its process parameters is a trivial phenomenon. However, the prediction requires complex mathematical formulation when the number of metals grows. The exponential rise in testing data of welding components in recent time, have increased the data inconsistency and complexity by manifolds. Further, the multi-physical characteristic of welding data adds to its chaotic nature. This makes manual or simulation-based extraction of useful information from welded data extremely challenging. Developing predictive models for tensile-shear strength of Resistance Spot Welding (RSW) is highly latency-bound. The recent success of machine learning approaches in variety of fields gives us motivation to address this issue. In this paper, we proposed a machine learning model inspired from random forest (RF) which predicts the tensile-shear strength of nugget from its input parameters and large number of metals. We trained the prediction model using data from 435 spot-welding cases and compared its performance with widely used M5P model tree. For all cases, RF-based prediction model outperforms the M5P model in terms of accuracy. Four different feature extraction techniques namely manual feature selection, correlation attribute eval., classification attribute eval., and reliefF attribute eval. were investigated to improve the performance of random forest model. From these methods, when model is very complex i.e. higher training size, classification attribute eval. provides greater accuracy with RMSETest of 0.5442. Moreover, no overfitting and underfitting was observed in this prediction.}
}
@article{TEISSEYRE2019290,
title = {Cost-sensitive classifier chains: Selecting low-cost features in multi-label classification},
journal = {Pattern Recognition},
volume = {86},
pages = {290-319},
year = {2019},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2018.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0031320318303388},
author = {Paweł Teisseyre and Damien Zufferey and Marta Słomka},
keywords = {Multi-label classification, Cost-sensitive feature selection, Classifier chains, Logistic regression, Stability, Generalization error bounds},
abstract = {Feature selection is one of the trending challenges in multi-label classification. In recent years a lot of methods have been proposed. However the existing approaches assume that all the features have the same cost. This assumption may be inappropriate when the acquisition of the feature values is costly. For example in medical diagnosis each diagnostic value extracted by a clinical test is associated with its own cost. In such cases it may be better to choose a model with an acceptable classification performance but a much lower cost. We propose a novel method which incorporates the feature cost information into the learning process. The method, named Cost-Sensitive Classifier Chains, combines classifier chains and penalized logistic regression with a modified elastic-net penalty which takes into account costs of the features. We prove the stability and provide a bound on generalization error of our algorithm. We also propose the adaptive version in which penalty factors are changing during fitting the consecutive models in the chain. The methods are applied on real datasets: MIMIC-II and Hepatitis for which the cost information is provided by experts. Moreover, we propose an experimental framework in which the features are observed with measurement errors and the costs depend on the quality of the features. The framework allows to compare the cost-sensitive methods on benchmark datasets for which the cost information is not provided. The proposed method can be recommended in a situation when one wants to balance low costs and high prediction performance.}
}
@article{ENGSTROM2013581,
title = {Test overlay in an emerging software product line – An industrial case study},
journal = {Information and Software Technology},
volume = {55},
number = {3},
pages = {581-594},
year = {2013},
note = {Special Issue on Software Reuse and Product Lines},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2012.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0950584912001061},
author = {Emelie Engström and Per Runeson},
keywords = {Product-line, Software testing, Case study, Overlay, Redundancy, Efficiency},
abstract = {Context
In large software organizations with a product line development approach, system test planning and scope selection is a complex task. Due to repeated testing: across different testing levels, over time (test for regression) as well as of different variants, the risk of redundant testing is large as well as the risk of overlooking important tests, hidden by the huge amount of possible tests.
Aims
This study assesses the amount and type of overlaid manual testing across feature, integration and system test in such context, it explores the causes of potential redundancy and elaborates on how to provide decision support in terms of visualization for the purpose of avoiding redundancy.
Method
An in-depth case study was launched including both qualitative and quantitative observations.
Results
A high degree of test overlay is identified originating from distributed test responsibilities, poor documentation and structure of test cases, parallel work and insufficient delta analysis. The amount of test overlay depends on which level of abstraction is studied.
Conclusions
Avoiding redundancy requires tool support, e.g. visualization of test design coverage, test execution progress, priorities of coverage items as well as visualized priorities of variants to support test case selection.}
}
@article{PAVLICEK20192897,
title = {Applicability and comparison of surrogate techniques for modeling of selected heating problems},
journal = {Computers & Mathematics with Applications},
volume = {78},
number = {9},
pages = {2897-2910},
year = {2019},
note = {Applications of Partial Differential Equations in Science and Engineering},
issn = {0898-1221},
doi = {https://doi.org/10.1016/j.camwa.2019.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0898122119300811},
author = {Karel Pavlíček and Václav Kotlan and Ivo Doležel},
keywords = {Induction-assisted laser welding, Surrogate modeling, Metamodeling, Computational cost reduction, Weld depth prediction, Regression analysis},
abstract = {Possibilities of using surrogate techniques for modeling selected strongly nonlinear coupled problems of heating are evaluated. The main purpose is to significantly reduce the computing time in the case of computations of many variants of a given task by the finite element method on the condition of obtaining results of a still acceptable accuracy. Frequently used surrogate techniques (based on Kriging, neural network etc.) are tested on a particular problem of induction-assisted laser welding that represents a very complicated 3D problem. Here, the most important output quantities are the internal structure of weld (decisive for its mechanical parameters) and its depth that depend on a number of input parameters (power of laser beam, velocity of shift of the welded parts, overall geometry and material properties etc.) and must be known before the process of welding itself. The paper presents both full model of this process and considered surrogate algorithms, and compares the results obtained. It is shown that a careful selection of the surrogate technique together with suitable choice of its input data is very beneficial and may result in high savings in design of the process. Implementation performance and suitability of particular techniques of this kind are also evaluated.}
}
@article{GHOUCHANI2019103360,
title = {Investigation on distal femoral strength and reconstruction failure following curettage and cementation: In-vitro tests with finite element analyses},
journal = {Computers in Biology and Medicine},
volume = {112},
pages = {103360},
year = {2019},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2019.103360},
url = {https://www.sciencedirect.com/science/article/pii/S0010482519302379},
author = {Azadeh Ghouchani and Gholamreza Rouhi and Mohammad Hosein Ebrahimzadeh},
keywords = {Distal femoral strength, In-vitro compressive tests, Quantitative computed tomography, Failure analysis, Finite element method, Non-homogeneity, Non-linear behavior},
abstract = {Cement augmentation following benign bone tumor surgery, i.e. curettage and cementation, is recommended in patients at high risk of fracture. Nonetheless, identifying appropriate cases and devices for augmentation remains debatable. Our goal was to develop a validated biomechanical tool to: predict the post-surgery strength of a femoral bone, assess the precision and accuracy of the predicted strength, and discover the mechanisms of reconstruction failure, with the aim of finding a safe biomechanical fixation. Tumor surgery was mimicked in quantitative-CT (QCT) scanned cadaveric human distal femora, and subsequently tested in compression to measure bone strength (FExp). Finite element (FE) models considering bone material non-homogeneity and non-linearity were constructed to predict bone strength (FFE). Analyses of contact, damage, and crack initiation at the bone-cement interface (BCI) were completed to investigate critical failure locations. Results of paired t-tests did not show a significant difference between FExp and FFE (P > 0.05); linear regression analysis resulted in good correlation between FExp and FFE (R2 = 0.94). Evaluation of the models precision using linear regression analysis yielded R2 = 0.89, with the slope = 1.08 and intercept = −324.16 N. FE analyses showed the initiation of damage and crack and a larger cement debonding area at the proximal end and most interior part of BCI, respectively. Therefore, we speculated that devices that reinforce critical failure locations offer the most biomechanical advantage. The QCT-based FE method proved to be a reliable tool to predict distal femoral strength, identify some causes of reconstruction failure, and assist in a safer selection of fixation devices to reduce post-operative fracture risk.}
}
@article{HSU2020,
title = {Machine Learning Model for Risk Prediction of Community-Acquired Acute Kidney Injury Hospitalization From Electronic Health Records: Development and Validation Study},
journal = {Journal of Medical Internet Research},
volume = {22},
number = {8},
year = {2020},
issn = {1438-8871},
doi = {https://doi.org/10.2196/16903},
url = {https://www.sciencedirect.com/science/article/pii/S1438887120006330},
author = {Chien-Ning Hsu and Chien-Liang Liu and You-Lin Tain and Chin-Yu Kuo and Yun-Chun Lin},
keywords = {community-acquired acute kidney injury (CA-AKI), hospitalization, treatment decision making, clinical decision support system, machine learning, feature selection with extreme gradient boost (XGBoost), least absolute shrinkage and selection operator (LASSO), risk prediction},
abstract = {Background
Community-acquired acute kidney injury (CA-AKI)-associated hospitalizations impose significant health care needs and contribute to in-hospital mortality. However, most risk prediction models developed to date have focused on AKI in a specific group of patients during hospitalization, and there is limited knowledge on the baseline risk in the general population for preventing CA-AKI-associated hospitalization.
Objective
To gain further insight into risk exploration, the aim of this study was to develop, validate, and establish a scoring system to facilitate health professionals in enabling early recognition and intervention of CA-AKI to prevent permanent kidney damage using different machine-learning techniques.
Methods
A nested case-control study design was employed using electronic health records derived from a group of Chang Gung Memorial Hospitals in Taiwan from 2010 to 2017 to identify 234,867 adults with at least two measures of serum creatinine at hospital admission. Patients were classified into a derivation cohort (2010-2016) and a temporal validation cohort (2017). Patients with the first episode of CA-AKI at hospital admission were classified into the case group and those without CA-AKI were classified in the control group. A total of 47 potential candidate variables, including age, gender, prior use of nephrotoxic medications, Charlson comorbid conditions, commonly measured laboratory results, and recent use of health services, were tested to develop a CA-AKI hospitalization risk model. Permutation-based selection with both the extreme gradient boost (XGBoost) and least absolute shrinkage and selection operator (LASSO) algorithms was performed to determine the top 10 important features for scoring function development.
Results
The discriminative ability of the risk model was assessed by the area under the receiver operating characteristic curve (AUC), and the predictive CA-AKI risk model derived by the logistic regression algorithm achieved an AUC of 0.767 (95% CI 0.764-0.770) on derivation and 0.761 on validation for any stage of AKI, with positive and negative predictive values of 19.2% and 96.1%, respectively. The risk model for prediction of CA-AKI stages 2 and 3 had an AUC value of 0.818 for the validation cohort with positive and negative predictive values of 13.3% and 98.4%, respectively. These metrics were evaluated at a cut-off value of 7.993, which was determined as the threshold to discriminate the risk of AKI.
Conclusions
A machine learning–generated risk score model can identify patients at risk of developing CA-AKI-related hospitalization through a routine care data-driven approach. The validated multivariate risk assessment tool could help clinicians to stratify patients in primary care, and to provide monitoring and early intervention for preventing AKI while improving the quality of AKI care in the general population.}
}
@article{SCHWEIER2014,
title = {A Web-Based Peer-Modeling Intervention Aimed at Lifestyle Changes in Patients With Coronary Heart Disease and Chronic Back Pain: Sequential Controlled Trial},
journal = {Journal of Medical Internet Research},
volume = {16},
number = {7},
year = {2014},
issn = {1438-8871},
doi = {https://doi.org/10.2196/jmir.3434},
url = {https://www.sciencedirect.com/science/article/pii/S1438887114000363},
author = {Rebecca Schweier and Matthias Romppel and Cynthia Richter and Eike Hoberg and Harry Hahmann and Inge Scherwinski and Gregor Kosmützky and Gesine Grande},
keywords = {coronary artery disease, lifestyle, health behavior, back pain, personal narratives as topic, Internet, diet, exercise, Web-based intervention},
abstract = {Background
Traditional secondary prevention programs often fail to produce sustainable behavioral changes in everyday life. Peer-modeling interventions and integration of peer experiences in health education are a promising way to improve long-term effects in behavior modification. However, effects of peer support modeling on behavioral change have not been evaluated yet. Therefore, we implemented and evaluated a website featuring patient narratives about successful lifestyle changes.
Objective
Our aim is to examine the effects of using Web-based patient narratives about successful lifestyle change on improvements in physical activity and eating behavior for patients with coronary heart disease and chronic back pain 3 months after participation in a rehabilitation program.
Methods
The lebensstil-aendern (“lifestyle-change”) website is a nonrestricted, no-cost, German language website that provides more than 1000 video, audio, and text clips from interviews with people with coronary heart disease and chronic back pain. To test efficacy, we conducted a sequential controlled trial and recruited patients with coronary heart disease and chronic back pain from 7 inpatient rehabilitation centers in Germany. The intervention group attended a presentation on the website; the control group did not. Physical activity and eating behavior were assessed by questionnaire during the rehabilitation program and 12 weeks later. Analyses were conducted based on an intention-to-treat and an as-treated protocol.
Results
A total of 699 patients were enrolled and 571 cases were included in the analyses (control: n=313, intervention: n=258; female: 51.1%, 292/571; age: mean 53.2, SD 8.6 years; chronic back pain: 62.5%, 357/571). Website usage in the intervention group was 46.1% (119/258). In total, 141 trial participants used the website. Independent t tests based on the intention-to-treat protocol only demonstrated nonsignificant trends in behavioral change related to physical activity and eating behavior. Multivariate regression analyses confirmed belonging to the intervention group was an independent predictor of self-reported improvements in physical activity regularity (β=.09, P=.03) and using less fat for cooking (β=.09, P=.04). In independent t tests based on the as-treated protocol, website use was associated with higher self-reported improvements in integrating physical activity into daily routine (d=0.22, P=.02), in physical activity regularity (d=0.23, P=.02), and in using less fat for cooking (d=0.21, P=.03). Multivariate regression analyses revealed that using the website at least 3 times was the only factor associated with improved lifestyle behaviors.
Conclusions
Usage of the lebensstil-aendern website corresponds to more positive lifestyle changes. However, as-treated analyses do not allow for differentiating between causal effects and selection bias. Despite these limitations, the trial indicates that more than occasional website usage is necessary to reach dose-response efficacy. Therefore, future studies should concentrate on strategies to improve adherence to Web-based interventions and to encourage more frequent usage of these programs.}
}
@article{GONZALEZPEREZ2023104359,
title = {AwarNS: A framework for developing context-aware reactive mobile applications for health and mental health},
journal = {Journal of Biomedical Informatics},
volume = {141},
pages = {104359},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104359},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423000801},
author = {Alberto González-Pérez and Miguel Matey-Sanz and Carlos Granell and Laura Díaz-Sanahuja and Juana Bretón-López and Sven Casteleyn},
keywords = {mHealth, Smartphone, Data collection, Intervention, Context-awareness, Digital phenotyping},
abstract = {In recent years, interest and investment in health and mental health smartphone apps have grown significantly. However, this growth has not been followed by an increase in quality and the incorporation of more advanced features in such applications. This can be explained by an expanding fragmentation of existing mobile platforms along with more restrictive privacy and battery consumption policies, with a consequent higher complexity of developing such smartphone applications. To help overcome these barriers, there is a need for robust, well-designed software development frameworks which are designed to be reliable, power-efficient and ethical with respect to data collection practices, and which support the sense-analyse-act paradigm typically employed in reactive mHealth applications. In this article, we present the AwarNS Framework, a context-aware modular software development framework for Android smartphones, which facilitates transparent, reliable, passive and active data sampling running in the background (sense), on-device and server-side data analysis (analyse), and context-aware just-in-time offline and online intervention capabilities (act). It is based on the principles of versatility, reliability, privacy, reusability, and testability. It offers built-in modules for capturing smartphone and associated wearable sensor data (e.g. IMU sensors, geolocation, Wi-Fi and Bluetooth scans, physical activity, battery level, heart rate), analysis modules for data transformation, selection and filtering, performing geofencing analysis and machine learning regression and classification, and act modules for persistence and various notification deliveries. We describe the framework’s design principles and architecture design, explain its capabilities and implementation, and demonstrate its use at the hand of real-life case studies implementing various mobile interventions for different mental disorders used in clinical practice.}
}
@article{YUE2023120481,
title = {A comparison of six metamodeling techniques applied to multi building performance vectors prediction on gymnasiums under multiple climate conditions},
journal = {Applied Energy},
volume = {332},
pages = {120481},
year = {2023},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.120481},
url = {https://www.sciencedirect.com/science/article/pii/S030626192201738X},
author = {Naihua Yue and Mauro Caini and Lingling Li and Yang Zhao and Yu Li},
keywords = {RDPG, A3C, LSTM, CNN, Multi vectors prediction, Gymnasiums},
abstract = {Building performance simulation (BPS) is essential for testing energy demand and indoor environment quality of different building designs. However, software for BPS is computationally intensive and impractical to run thousands even millions of simulations for performance analysis and optimization. Especially for the large space buildings, which usually have complex forms and high energy consumption. The computational problem could be overcome by the adoption of metamodels. Most correlational research focuses on single performance prediction of a particular building, which makes the model less robust when applied to multi vectors prediction for different buildings under multiple weather conditions. This paper leveraged six metamodels, which include recurrent deterministic policy gradient (RDPG), asynchronous advantage actor-critic (A3C), long short-term memory (LSTM), convolution neural network (CNN), artificial neural network (ANN) and support vector regression (SVR), to predict hourly-based multi performance vectors of gymnasiums under various design parameters and multiple weather conditions. Six metamodels are trained and tested on a large scale of datasets simulated by EnergyPlus over four gymnasium cases in different cities of China. The accuracy, efficiency, ease-of-use, robustness and interpretability of the models are investigated. To conduct a fair and detailed comparison, a methodological approach using grid searches for model settings selection assisted by sensitivity analysis is pursued. Principal component analysis (PCA) is also adopted to interpret the work process of the metamodels. The comparison showed that the RDPG model provides the most accurate prediction results with R2 converges at 0.993, 0.982 and 0.941 for energy, temperature and CO2, respectively. LSTM model is more efficient than RDPG, and suitable for users who need emphasis on both time and accuracy. ANN is suitable for users with limited time and require models of ease-of-use and robustness. SVR and ANN could be used for the automatically co-simulation with BPS software. In future research, the influence of occupant behavior also should be investigated.}
}
@article{JING2019364,
title = {A case study of TBM performance prediction using field tunnelling tests in limestone strata},
journal = {Tunnelling and Underground Space Technology},
volume = {83},
pages = {364-372},
year = {2019},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2018.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0886779817306557},
author = {Liu-jie Jing and Jian-bin Li and Chen Yang and Shuai Chen and Na Zhang and Xing-xin Peng},
keywords = {TBM, Performance prediction, Limestone, Normal force of single cutter, Penetration},
abstract = {TBM performance prediction models play important guiding roles in equipment selection, project planning, cost forecast, as well as the optimization of TBM operational parameters. In this study, field tunnelling tests were conducted in the limestone strata of Songhua River water supply project through artificially changing two operational parameters, the rotation speed (RPM) and penetration (p) of TBM cutterhead. Compared the field test and normal tunnelling data, it revealed that penetration (p) and the normal force of single cutter (Fn) had significant linear correlations with consistent rules in the two different types of penetration conditions, whereas the change of cutterhead rotation speed had little effect on the linear relationship. Based on the rules above, TBM performance prediction model for limestone strata was established after analyzing 46 sets of machine and corresponding rock mass parameters obtained during normal tunneling by using stepwise regression method. A linear relationship between the penetration and the normal force of single cutter was established initially by using the initial section data of normal tunneling cycles. Then the final model was obtained based on the analysis of the correlation between rock mass parameters and the undermined coefficients in the previous linear relationship model. The results show that the model was in good agreement with the experimental measurements. Finally, a real time rock mass state perception method based on this model was discussed. This method can be used to optimize the operational parameters and to create a foundation for intelligent control of TBMs.}
}
@article{CHUNGCHAROEN2022107019,
title = {Machine learning-based prediction of nutritional status in oil palm leaves using proximal multispectral images},
journal = {Computers and Electronics in Agriculture},
volume = {198},
pages = {107019},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.107019},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922003362},
author = {Thatchapol Chungcharoen and Irwin Donis-Gonzalez and Kittisak Phetpan and Vasu Udompetaikul and Panmanas Sirisomboon and Rattapong Suwalak},
keywords = {Machine learning, Plant nutrition, Oil palm, Multispectral Image, Image processing},
abstract = {This study evaluated the application of proximal multispectral images accompanied by 4 machine learning approaches for estimating the nutritional status of oil palm leaves. The image responded for five bands: blue, green, red, red edge, and near-infrared regions with a center wavelength of 475, 560, 668, 717, and 840 nm. Average and standard deviation (SD) values from the leaf pixels of each band were extracted, obtaining 5 average and 5 SD values from 5 bands. Thirty-four vegetation variables were generated based on those average and SD values. In total, forty-four variables consisted of 10 average-and SD-based features, and 34 vegetation variables were used as the input candidates for analyses against 10 target variables: nitrogen (N), phosphorus (P), potassium (K), calcium (Ca), magnesium (Mg), iron (Fe), manganese (Mn), zinc (Zn), boron (B), and chlorophyll (SPAD). No significant input came out for modeling with P and Zn based on the stepwise selection. Therefore, 8 nutritional models were proposed in this study. A training set with 50 samples was used to be modeled for each target, and a test set with 15 samples was employed to evaluate the models' performances. Based on random forest (RF), support vector regression (SVR), partial least square regression (PLSR), and artificial neuron network (ANN) applied to be modeled, the models for chlorophyll, N, and Ca predictions were acceptable for screening, and those for K and Mg predictions were acceptable for rough screening. The chlorophyll model developed based on the RF had the predictive statistics in terms of coefficient of determination for prediction (r2), root mean square error of prediction (RMSEP), and standard error of prediction (SEP) of 0.752, 5.46 SPAD, and 5.65 SPAD, respectively. The other 2 screening models developed based on SVR and RF for N and Ca, respectively, gave the performances with the r2, RMSEP, and SEP ranging from 0.655 to 0.718, 0.12 to 0.17%, and 0.12 to 0.18%, respectively. In the case of the 2 rough screening models established using the RF algorithm, the predictive statistics ranged from 0.496 to 0.530 for the r2 and 0.07–0.16% for both RMSEP and SEP. In this study, the Fe, Mn, and B models had poor results presenting the range of r2, RMSEP, and SEP of 0.308–0.491, 2.39–72.9 ppm, and 2.45–62.8 ppm, respectively. Based on the results, this study confirmed that the proximal multispectral information of oil palm leaves had enough significance to account for the status of chlorophyll and macro-nutrients: N, K, Ca, and Mg in the leaves.}
}
@article{MAINO2021100073,
title = {A deep neural network based model for the prediction of hybrid electric vehicles carbon dioxide emissions},
journal = {Energy and AI},
volume = {5},
pages = {100073},
year = {2021},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2021.100073},
url = {https://www.sciencedirect.com/science/article/pii/S2666546821000276},
author = {Claudio Maino and Daniela Misul and Alessandro {Di Mauro} and Ezio Spessa},
keywords = {Deep neural networks, Carbon dioxide emissions, Hybrid electric vehicles, Dynamic programming},
abstract = {Hybrid electric vehicles (HEV) are nowadays proving to be one of the most promising technologies for the improvement of the fuel economy of several transportation segments. As far as the on-road category is concerned, a wise selection of the powertrain design is needed to exploit the best energetic performance achievable by a HEV. Amongst the methodologies developed for comparing different hybrid architectures, global optimizers have demonstrated the capability of leading to optimal design solutions at the expense of a relevant computational burden. In the present paper, an innovative deep neural networks-based model for the prediction of tank-to-wheel carbon dioxide emissions as estimated by a Dynamic Programming (DP) algorithm is presented. The model consists of a pipeline of neural networks aimed at catching the correlations lying between the design parameters of a HEV architecture and the main outcomes of the DP, namely powertrain feasibility and tail pipe CO2 emissions. Moreover, an automatic search tool (AST) has been developed for tuning the main hyper-parameters of the networks. Interesting results have been registered by applying the pipeline to three databases related to three different HEV parallel architectures. The capability of the pipeline has been proved through an extensive testing campaign made up by multiple experiments. Classification performances above 91% as well as average regression errors below 1% have been achieved during an extensive set of simulations. The presented model could hence be considered as an effective tool for supporting HEV design optimization phases.}
}
@article{YI201589,
title = {An integrated energy–emergy approach to building form optimization: Use of EnergyPlus, emergy analysis and Taguchi-regression method},
journal = {Building and Environment},
volume = {84},
pages = {89-104},
year = {2015},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2014.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0360132314003345},
author = {Hwang Yi and Ravi S. Srinivasan and William W. Braham},
keywords = {Energy simulation, Emergy evaluation, Building form optimization, Taguchi-ANOVA method},
abstract = {This research presents a new methodology of environmental building design with an integrated energy–emergy (spelled with an “m”) approach to study building form optimization in the schematic phases. In architecture, selection of sustainability assessment methods critically affects design goals, favoring or restricting choices designers can make. A building subsumes matter and energy to support human lives, but current building performance indicators are still hard to equate technical sides and human dominant sides of various scales in a synthetic metric. Moreover, in order to achieve global sustainability in a building, as a part of the whole built environment, it is necessary to integrate energy and environmental impacts at the highest scope of analysis. Emergy analysis coupled with building energy simulation can be suggested as a holistic indicator for architectural design process. To test the proposed method, a pilot study with a mid-size office building evaluates the consequences of early design decisions such as basic geometry, aspect ratio, window-wall ratio, construction types, etc. The integrated energy–emergy approach to building form optimization consists of three modules namely, Building Energy Simulation (BES) module, Building EMergy Analysis (BEMA) module, and (iii) MetaModel Development (MMD) module. The BES module uses the EnergyPlus tool for whole building energy analysis, while the BEMA module employs analytical methods to estimate emergy quantities, and the MMD module employs the Taguchi method to develop a metamodel for faster and easier whole building emergy simulation. The metamodel developed using Taguchi-ANOVA method for building form optimization was validated with analytical test results to accelerate environmental design decision-making. This study demonstrates possibility of wider applications of emergy synthesis to building energy research and facilitates practical use of emergy simulation in the environmental design process.}
}
@article{MOON2018129,
title = {Computer-aided prediction model for axillary lymph node metastasis in breast cancer using tumor morphological and textural features on ultrasound},
journal = {Computer Methods and Programs in Biomedicine},
volume = {162},
pages = {129-137},
year = {2018},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2018.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0169260717312919},
author = {Woo Kyung Moon and I-Ling Chen and Ann Yi and Min Sun Bae and Sung Ui Shin and Ruey-Feng Chang},
keywords = {Breast cancer, Lymph node metastasis, Ultrasound, Computer-aided prediction, Axillary lymph node},
abstract = {Background and objectives
Axillary lymph node (ALN) status is a key indicator in assessing and determining the treatment strategy for patients with newly diagnosed breast cancer. Previous studies suggest that sonographic features of a primary tumor have the potential to predict ALN status in the preoperative staging of breast cancer. In this study, a computer-aided prediction (CAP) model as well as the tumor features for ALN metastasis in breast cancers were developed using breast ultrasound (US) images.
Methods
A total of 249 malignant tumors were acquired from 247 female patients (ages 20–84 years; mean 55 ± 11 years) to test the differences between the non-metastatic (130) and metastatic (119) groups based on various features. After applying semi-automatic tumor segmentation, 69 quantitative features were extracted. The features included morphology and texture of tumors inside a ROI of breast US image. By the backward feature selection and linear logistic regression, the prediction model was constructed and established to estimate the likelihood of ALN metastasis for each sample collected.
Results
In the experiments, the texture features showed higher performance for predicting ALN metastasis compared to morphology (Az, 0.730 vs 0.667). The difference, however, was not statistically significant (p-values > 0.05). Combining the textural and morphological features, the accuracy, sensitivity, specificity, and Az value achieved 75.1% (187/249), 79.0% (94/119), 71.5% (93/130), and 0.757, respectively.
Conclusions
The proposed CAP model, which combines textural and morphological features of primary tumor, may be a useful method to determine the ALN status in patients with breast cancer.}
}
@article{WESTCOTT2022,
title = {Prediction of Maternal Hemorrhage Using Machine Learning: Retrospective Cohort Study},
journal = {Journal of Medical Internet Research},
volume = {24},
number = {7},
year = {2022},
issn = {1438-8871},
doi = {https://doi.org/10.2196/34108},
url = {https://www.sciencedirect.com/science/article/pii/S1438887122004769},
author = {Jill M Westcott and Francine Hughes and Wenke Liu and Mark Grivainis and Iffath Hoskins and David Fenyo},
keywords = {predictive modeling, maternal morbidity, postpartum hemorrhage, machine learning, obstetrics, pregnancy, post partum, maternal},
abstract = {Background
Postpartum hemorrhage remains one of the largest causes of maternal morbidity and mortality in the United States.
Objective
The aim of this paper is to use machine learning techniques to identify patients at risk for postpartum hemorrhage at obstetric delivery.
Methods
Women aged 18 to 55 years delivering at a major academic center from July 2013 to October 2018 were included for analysis (N=30,867). A total of 497 variables were collected from the electronic medical record including the following: demographic information; obstetric, medical, surgical, and family history; vital signs; laboratory results; labor medication exposures; and delivery outcomes. Postpartum hemorrhage was defined as a blood loss of ≥1000 mL at the time of delivery, regardless of delivery method, with 2179 (7.1%) positive cases observed. Supervised learning with regression-, tree-, and kernel-based machine learning methods was used to create classification models based upon training (21,606/30,867, 70%) and validation (4630/30,867, 15%) cohorts. Models were tuned using feature selection algorithms and domain knowledge. An independent test cohort (4631/30,867, 15%) determined final performance by assessing for accuracy, area under the receiver operating curve (AUROC), and sensitivity for proper classification of postpartum hemorrhage. Separate models were created using all collected data versus models limited to data available prior to the second stage of labor or at the time of decision to proceed with cesarean delivery. Additional models examined patients by mode of delivery.
Results
Gradient boosted decision trees achieved the best discrimination in the overall model. The model including all data mildly outperformed the second stage model (AUROC 0.979, 95% CI 0.971-0.986 vs AUROC 0.955, 95% CI 0.939-0.970). Optimal model accuracy was 98.1% with a sensitivity of 0.763 for positive prediction of postpartum hemorrhage. The second stage model achieved an accuracy of 98.0% with a sensitivity of 0.737. Other selected algorithms returned models that performed with decreased discrimination. Models stratified by mode of delivery achieved good to excellent discrimination but lacked the sensitivity necessary for clinical applicability.
Conclusions
Machine learning methods can be used to identify women at risk for postpartum hemorrhage who may benefit from individualized preventative measures. Models limited to data available prior to delivery perform nearly as well as those with more complete data sets, supporting their potential utility in the clinical setting. Further work is necessary to create successful models based upon mode of delivery and to validate the findings of this study. An unbiased approach to hemorrhage risk prediction may be superior to human risk assessment and represents an area for future research.}
}
