@INPROCEEDINGS{9068003,
  author={Alkawaz, Mohammed Hazim and Silvarajoo, Abrahmi},
  booktitle={2019 IEEE 7th Conference on Systems, Process and Control (ICSPC)}, 
  title={A Survey on Test Case Prioritization and Optimization Techniques in Software Regression Testing}, 
  year={2019},
  volume={},
  number={},
  pages={59-64},
  abstract={Software Testing (ST) is vital for software development to check the degree to which it meets client's prerequisites, watch the errors or bugs in the software code and find a way to correct the mistakes to make software advantageous. For approval of changes in software, Regression Testing (RT) must be connected. RT plays it role during the software maintenance phase. It guarantees mistake free software after change during maintenance. Test cases and test suites are set up for testing, furthermore, it ought to be done in least time where Test Case Prioritization and Optimization (TCPAO) strategies are required. The fundamental point of TCPAO is to test software in least time and with greatest proficiency. This paper discusses, an empirical study on the TCPAO techniques in software RT. This study focouses on the beginners and intermediate researches. The most pertinent studies were chosen from the appropriate repositories by utilizing a lot of search keywords, inclusion/exclusion criteria. The study also discusses on the most recent papers on TCPAO technique.},
  keywords={Software;Testing;Process control;Optimization;Software algorithms;Conferences;Control systems;Software Development Life Cycle (SDLC);Regression Testing;Software Testing;Test Case Prioritization (TCP);Test Case Optimization (TCO);Test Case Selection(TCS);Test Case Minimization(TCM)},
  doi={10.1109/ICSPC47137.2019.9068003},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6818242,
  author={Sun, Shiming and Hou, Xiuping and Gao, Can and Sun, Linlin},
  booktitle={2013 Ninth International Conference on Natural Computation (ICNC)}, 
  title={Research on optimization scheme of regression testing}, 
  year={2013},
  volume={},
  number={},
  pages={1628-1632},
  abstract={Regression testing is an important process during software development. In order to reduce costs of regression testing, research on optimization of scheme of regression testing have been done in this paper. For the purpose of reducing the number of test cases and detecting faults of programs early, this paper proposed to combine test case selection with test case prioritization. Regression testing process has been designed and optimization of testing scheme has been implemented. The criterion of test case selection is modify impact of programs, finding programs which are impacted by program modification according to modify information of programs and dependencies between programs. Test cases would be selected during test case selection. The criterion of test case prioritization is coverage ability and troubleshooting capabilities of test case. Test cases which have been selected during test case selection would be ordering in test case prioritization. Finally, the effectiveness of the new method is discussed.},
  keywords={Testing;Software;Optimization;Circuit faults;Convergence;Educational institutions;Computer aided software engineering;regression testing;test case selection;test case prioritization},
  doi={10.1109/ICNC.2013.6818242},
  ISSN={2157-9563},
  month={July},}@INPROCEEDINGS{9022761,
  author={Butool, Rimsha and Nadeem, Aamer and Sindhu, Muddassar and Zaman, Oamar uz},
  booktitle={2019 22nd International Multitopic Conference (INMIC)}, 
  title={Improving Requirements Coverage in Test Case Prioritization for Regression Testing}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Regression testing is performed whenever software undergoes modifications, which may be due to bug fixes or feature enhancements. The purpose of regression testing is to ensure that modifications to the code do not affect the existing functionality. Regression testing is costly because the test suite might be too large to execute in full. To reduce this cost, regression testing has three main approaches, i.e., test suite minimization, test case selection and test case prioritization. Test case prioritization does not eliminate any test case rather it finds an ordered list of test cases to maximize the fault detection rate. Black box prioritization prioritizes test cases based on requirements coverage, while white box approaches prioritize test cases based on code coverage. The focus of this paper is on the black box test case prioritization using requirements coverage for regression testing. Black box prioritization is independent of the code modifications, therefore, it can be started early. The proposed approach prioritizes test cases based on the complexity of requirements covered. The existing requirements based prioritization techniques assign equal importance to each requirement when prioritizing test cases based on requirements coverage, which may not maximize fault detection rate because complex requirements may need to be tested with multiple test cases. Our proposed approach assigns weights to the requirements based on their complexity, and test cases are prioritized using these weights. Comparison with existing approach shows that the proposed approach results in better prioritization of test cases because of higher average percentage of fault detection (APFD).},
  keywords={Testing;Fault detection;Complexity theory;Software;Minimization;Computer science;Computer bugs;Regression testing;test case prioritization},
  doi={10.1109/INMIC48123.2019.9022761},
  ISSN={2049-3630},
  month={Nov},}@INPROCEEDINGS{9873649,
  author={Alkawaz, Mohammed Hazim and Silvarajoo, Abrahmi and Mohammad, Omar Farook and Raya, Lilysuriazna},
  booktitle={2022 IEEE Symposium on Industrial Electronics & Applications (ISIEA)}, 
  title={A System for Optimizing Software Regression Test Cases using Modified Ant Colony Optimization Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Software Regression Testing (SRT) is directed to existing applications to ensure that an adjustment of code doesn't impact the current functionalities. Test Case Prioritization (TCP) helps with rescheduling test cases and selects according to the course of action. Ant Colony Optimization (ACO) is a streamlining calculation spurred by looking through the conduct of bugs. This paper proposes a system for optimizing SRT test cases using the Modified-Ant Colony(m-ACO) Optimization algorithm. m-ACO is the modification of the ACO strategy. It rearranges the conduct grouping of test cases by switching the marvel of trademark bugs for picking the nourishment. The proposed system has been tried for Zasta Billing Web Application (ZBWA) and contrasted with the days to finish the SRT manually and utilize the suggested approach. The recommended system assists with diminishing the days conducted SRT from 90 days to 45 days to accomplish the period for SRT in that firm.},
  keywords={Software testing;Ant colony optimization;Codes;Computer bugs;Software algorithms;Switches;Trademarks;Software Testing (ST);Software Regression Testing;Test Case Prioritization;Test Case Selection (TCS);Test Case Minimization (TCM);Ant Colony Optimization;Modified Ant Colony Optimization},
  doi={10.1109/ISIEA54517.2022.9873649},
  ISSN={2472-7660},
  month={July},}@INPROCEEDINGS{7561371,
  author={Srisura, Benjawan and Lawanna, Adtha},
  booktitle={2016 13th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)}, 
  title={False test case selection: Improvement of regression testing approach}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Regression testing has been considered as a time-consumed process in software testing. In a recent year, one of interesting research work initiated for minimizing testing time is finding a technique in selecting test cases from a large test suit. Most of test cases selection technique in literature considers test cases that are related to the requirement's changed. During executing test cases that are related to the modified part, a set of fail test case is accidentally emerged and make test suit has become larger. Therefore, this paper proposes a technique in selecting suitable false test cases when they are generated in regression testing. However, in order to ensure that the quality and validity of using the proposed technique are acceptable, an experiment was systematically conducted in this study. And we also found that the false test case selection technique can minimize the size of test suit, effectively.},
  keywords={Software;Software testing;Productivity;Flow graphs;Algorithm design and analysis;Information technology;Test case selection;Regression Test Case Selection;Regression Testing;Sotware Testing},
  doi={10.1109/ECTICon.2016.7561371},
  ISSN={},
  month={June},}@INPROCEEDINGS{6884931,
  author={Tyagi, Manika and Malhotra, Sona},
  booktitle={2014 International Conference on Signal Propagation and Computer Technology (ICSPCT 2014)}, 
  title={Test case prioritization using multi objective particle swarm optimizer}, 
  year={2014},
  volume={},
  number={},
  pages={390-395},
  abstract={The goal of regression testing is to validate the modified software. Due to the resource and time constraints, it becomes necessary to develop techniques to minimize existing test suites by eliminating redundant test cases and prioritizing them. This paper proposes a 3-phase approach to solve test case prioritization. In the first phase, we are removing redundant test cases by simple matrix operation. In the second phase, test cases are selected from the test suite such that selected test cases represent the minimal set which covers all faults and also at the minimum execution time. For this phase, we are using multi objective particle swarm optimization (MOPSO) which optimizes fault coverage and execution time. In the third phase, we allocate priority to test cases obtained from the second phase. Priority is obtained by calculating the ratio of fault coverage to the execution time of test cases, higher the value of the ratio higher will be the priority and the test cases which are not selected in phase 2 are added to the test suite in sequential order. We have also performed experimental analysis based on maximum fault coverage and minimum execution time. The proposed MOPSO approach is compared with other prioritization techniques such as No Ordering, Reverse Ordering and Random Ordering by calculating Average Percentage of fault detected (APFD) for each technique and it can be concluded that the proposed approach outperformed all techniques mentioned above.},
  keywords={Regression Testing;Test case selection;Test case prioritization;Multi objective Particle Swarm Optimization},
  doi={10.1109/ICSPCT.2014.6884931},
  ISSN={},
  month={July},}@INPROCEEDINGS{10048797,
  author={Chaudhary, Sonam and Choudhary, Ankur and Seth, Jyotsna},
  booktitle={2023 13th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={Nature Inspired Approaches for Test Case Selection in Regression Testing: A Review}, 
  year={2023},
  volume={},
  number={},
  pages={644-649},
  abstract={To ensure that the software satisfies all necessary criteria, software testing is done. Regression Testing is an important part of software testing as it plays a crucial role in software testing procedure. It's done to make sure that everything works as it should, such that test cases with greater potential to discover faults are given higher priority. Test case selection is introduced to choose the most effective subset of test cases from a test suite, test case selection reduces the total cost, time, and effort necessary in the process of software testing. It works by removing the obsolete and redundant test cases. Within all the computational intelligence algorithms the nature inspired algorithms are highly demanded due to their increased efficiency in solving complex problems. Nature Inspired Approaches refers to the approaches derived directly from the nature. Nature acts as the main branch of knowledge that provides various solution for the complex problems. Incorporation of Nature Inspired Approaches in test case selection problem generates a subset of test cases from the test suite resulting in time, cost and effort reduction. With the use of research questions, this paper offers a thorough review of Test Case Selection methods utilizing Nature Inspired Approaches.},
  keywords={Software testing;Costs;Software algorithms;Metaheuristics;Search problems;Software;Computational intelligence;Software Testing;Regression Testing;Test Case Selection;Nature Inspired Approaches},
  doi={10.1109/Confluence56041.2023.10048797},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9990042,
  author={Naheed, Misbah and Nadeem, Aamer and Zaman, Qamar Uz},
  booktitle={2022 19th International Bhurban Conference on Applied Sciences and Technology (IBCAST)}, 
  title={A Requirement Based Approach to Test Case Prioritization for Regression Testing}, 
  year={2022},
  volume={},
  number={},
  pages={358-363},
  abstract={Testing is the strategy wherein a program is executed fully intent on tracking down bugs. Whenever modification is done it is verified again to ensure that there are no new flaws have emerged in the previously tested code and that it continues to function effectively. This kind of testing is called regression testing. Original program may have many test cases and executing the whole test suite may increase the cost of testing. Regression test selection, test suite minimization and the test case prioritization are three strategies of regression testing which lower cost of regression testing. In test case selection and minimization techniques, only few test cases are chosen and the leftover test cases are squandered. The risk is that useful test cases with respect to fault detection may be discarded while in prioritization the software tester prioritizes the test and test cases that are more suitable to detect errors early are run first. There is no risk of important test case elimination in this technique as compared to other techniques. Therefore, test case prioritization is more effective and time saving. In test case prioritization technique important test cases are placed first in the prioritization list. Maximize early fault detection is goal of prioritization. In prioritization, technique test cases are ranked according to some coverage criteria. Existing techniques use total coverage strategy for prioritization of test cases by considering the total number of requirements covered. There may be more than one test case that covers the same requirements. Therefore, there is a possibility to repeat the test cases that cover same requirements, which is not desirable. In this research, we offer a new test case prioritizing technique based on prioritized requirements. This algorithm uses the "Additional" coverage strategy. Test case that covers the most requirements and has the highest weight is given high priority by our algorithm. Our suggested prioritization algorithm outperforms than existing techniques as it gives earlier coverage of requirements.},
  keywords={Costs;Codes;Fault detection;Computer bugs;Minimization;Software;Testing;Test case prioritization;Prioritized Requirements;Software Testing},
  doi={10.1109/IBCAST54850.2022.9990042},
  ISSN={2151-1411},
  month={Aug},}@INPROCEEDINGS{10685192,
  author={Sawant, Priyanka Dattatray},
  booktitle={2024 IEEE International Conference on Artificial Intelligence Testing (AITest)}, 
  title={Test Case Prioritization for Regression Testing Using Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={152-153},
  abstract={In order to make sure that recent code changes haven't negatively impacted the software's current functionalities, regression testing is a crucial maintenance step in the software development lifecycle. Time and resource constraints make it impractical to run every test case during regression testing, especially as software systems get larger and more complex. This problem is addressed by test case prioritization (TCP) techniques, which arrange test cases in a way that maximizes the probability of finding errors early on. Several of advanced machine learning (ML) techniques that have recently shown great promise in improving the efficacy and efficiency of the prioritization process when integrated with TCP. The methods, advantages, and drawbacks of these cutting-edge ML-based approaches for TCP are examined in this paper. I present a comparative analysis of their performance metrics and provide an implementation example for TCP using ensemble methods in machine learning. Practical considerations such as data requirements, model selection, and integration with current continuous integration/continuous deployment (CI/CD) pipelines are covered when implementing these advanced ML-based TCP methods in real-world scenarios. The results show that advanced ML based TCP is a useful tactic for contemporary regression testing procedures since it enhances fault detection rates and maximizes resource utilization.},
  keywords={Measurement;Fault detection;Refining;Pipelines;Software systems;Resource management;Ensemble learning;Regression testing;test case prioritization;machine learning;ensemble methods;continuous integration;continuous deployment},
  doi={10.1109/AITest62860.2024.00027},
  ISSN={2835-3560},
  month={July},}@INPROCEEDINGS{7339054,
  author={Gao, Dongdong and Guo, Xiangying and Zhao, Lei},
  booktitle={2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)}, 
  title={Test case prioritization for regression testing based on ant colony optimization}, 
  year={2015},
  volume={},
  number={},
  pages={275-279},
  abstract={Test case prioritization technique is an efficient method to improve regression testing activities. It orders a regression test suite to execute the test cases with higher priority earlier than those with lower priority, and the problem is how to optimize the test case ordering according to some criterion. In this paper, we have proposed an algorithm which prioritizes the test cases based on ant colony optimization (ACO), considering three factors: number of faults detected, execution time and fault severity, and these three factors are used in ant colony optimization algorithm to help to reveal more severe faults at earlier stage of the regression testing process. The effectiveness of the algorithm is demonstrated using the metric named APFD, and the results of experiment show the algorithm optimizes the test case orderings effectively.},
  keywords={Testing;Fault detection;Ant colony optimization;Algorithm design and analysis;Measurement;Software;Optimization;test case prioritization;ant colony optimization;regression testing},
  doi={10.1109/ICSESS.2015.7339054},
  ISSN={2327-0594},
  month={Sep.},}@INPROCEEDINGS{8777692,
  author={Bajaj, Anu and Sangwan, Om Prakash},
  booktitle={2018 4th International Conference on Computing Communication and Automation (ICCCA)}, 
  title={A Survey on Regression Testing Using Nature-Inspired Approaches}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={Efficient regression testing plays an important role for organizations that have large investment in active, ever-changing software development. Efficiency can be obtained by optimizing the test cases as it provides a balance between the safety and precision. Many optimization techniques from various domains have been applied in regression testing for optimizing the search and the solutions. But nature-inspired algorithms are gaining more popularity now a days as the algorithms are more efficient for complex problems. In this paper, we have explored the research work done by various researchers on regression testing using nature-inspired approaches. It is found that biology inspired computation e.g. genetic algorithm have been widely used in regression testing optimization with the intent of maximizing fault or code coverage in minimum time. It is also concluded that nature-inspired approaches have great potential to optimize regression testing problems.},
  keywords={Testing;Genetic algorithms;Optimization;Biology;Minimization;Fault detection;Software;regression testing;test case optimization;test suite minimization;test case prioritization;test case selection;nature-inspired algorithms;genetic algorithm},
  doi={10.1109/CCAA.2018.8777692},
  ISSN={2642-7354},
  month={Dec},}@INPROCEEDINGS{8377903,
  author={Ren, Yijie and Yin, Bei-Bei and Wang, Bin},
  booktitle={2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={Test Case Prioritization for GUI Regression Testing Based on Centrality Measures}, 
  year={2018},
  volume={02},
  number={},
  pages={454-459},
  abstract={Regression testing has been widely used in GUI software testing. For the reason of economy, the prioritization of test cases is particularly important. However, few studies discussed test case prioritization (TCP) for GUI software. Based on GUI software features, a two-layer model is proposed to assist the test case prioritization in this paper, in which, the outer layer is an event handler tree (EHT), and the inner layer is a function call graph (FCG). Compared with the conventional methods, more source code information is used based on the two-layer model for prioritization. What is more, from a global perspective, centrality measure, a complex network viewpoint is used to highlight the importance of modified functions for specific version TCP. The experiment proved the effectiveness of this model and this method.},
  keywords={Graphical user interfaces;Software;Object oriented modeling;Complex networks;Software testing;Regression tree analysis;GUI Testing, Regression Testing, Test Case Prioritization, Event Handler Tree, Complex Network},
  doi={10.1109/COMPSAC.2018.10275},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{10958234,
  author={Ndlovu, Siqabukile and Mnkandla, Ernest},
  booktitle={2024 3rd Zimbabwe Conference of Information and Communication Technologies (ZCICT)}, 
  title={A Preliminary Framework for Optimising Test Case Selection Using Natural Language Processing and Test Case Prioritisation Using Deep Learning in Continuous Integration}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Regression testing, though crucial for software quality, is extremely time consuming especially in continuous integration environments. Test case prioritisation can however improve the efficiency of this process by re-ordering test execution. However, due to the growing volume of test cases in continuous integration, effective selection and prioritisation of test cases is a noteworthy challenge. This paper focusses on improving test case selection and test case prioritisation for regression testing in dynamic continuous integration environments. By applying natural language processing to semantically analyse test cases to include implicit test cases in testing, and deep learning to prioritise the most impactful test cases, this approach will reduce the time and resources required for regression testing while maintaining high fault detection and feedback transmission rates. This early stage research paper proposes a new conceptual framework for optimising regression testing in continuous integration environments using natural language processing and deep learning and outlines potential challenges and future research. The expected outcomes of this proposed framework include improved fault detection rates, reduced overall testing time, and improved resource utilisation. The effectiveness of the framework will be evaluated using metrics such as fault detection rate, testing cycle duration, and computational resource efficiency, providing a comprehensive assessment of its impact on software quality assurance.},
  keywords={Deep learning;Measurement;Fault detection;Semantics;Software quality;Continuous integration;Natural language processing;Information and communication technology;Resource management;Testing;Regression Testing;Continuous Integration;Natural Language Processing;Deep Learning;Test Case Selection;Test Case Prioritisation},
  doi={10.1109/ZCICT63770.2024.10958234},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6676952,
  author={Marijan, Dusica and Gotlieb, Arnaud and Sen, Sagar},
  booktitle={2013 IEEE International Conference on Software Maintenance}, 
  title={Test Case Prioritization for Continuous Regression Testing: An Industrial Case Study}, 
  year={2013},
  volume={},
  number={},
  pages={540-543},
  abstract={Regression testing in continuous integration environment is bounded by tight time constraints. To satisfy time constraints and achieve testing goals, test cases must be efficiently ordered in execution. Prioritization techniques are commonly used to order test cases to reflect their importance according to one or more criteria. Reduced time to test or high fault detection rate are such important criteria. In this paper, we present a case study of a test prioritization approach ROCKET (Prioritization for Continuous Regression Testing) to improve the efficiency of continuous regression testing of industrial video conferencing software. ROCKET orders test cases based on historical failure data, test execution time and domain-specific heuristics. It uses a weighted function to compute test priority. The weights are higher if tests uncover regression faults in recent iterations of software testing and reduce time to detection of faults. The results of the study show that the test cases prioritized using ROCKET (1) provide faster fault detection, and (2) increase regression fault detection rate, revealing 30% more faults for 20% of the test suite executed, comparing to manually prioritized test cases.},
  keywords={Testing;Rockets;Fault detection;Software;Manuals;Time factors;Linear programming;software testing;continuous integration;regression testing;test case prioritization;history-based prioritization},
  doi={10.1109/ICSM.2013.91},
  ISSN={1063-6773},
  month={Sep.},}@INPROCEEDINGS{7045344,
  author={Sharma, Neha and Sujata and Purohit, G.N.},
  booktitle={2014 International Conference on High Performance Computing and Applications (ICHPCA)}, 
  title={Test case prioritization techniques “an empirical study”}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Regression testing is an expensive process. A number of methodologies of regression testing are used to improve its effectiveness. These are retest all, test case selection, test case reduction and test case prioritization. Retest all technique involves re-execution of all available test suites, which are critical moreover cost effective. In order to increase efficiency, test case prioritization is being utilized for rearranging the test cases. A number of algorithms has been stated in the literature survey such as Greedy Algorithms and Metaheuristic search algorithms. A simple greedy algorithm focuses on test case prioritization but results in less efficient manner, due to which researches moved towards the additional greedy and 2-Optimal algorithms. Forthcoming metaheuristic search technique (Hill climbing and Genetic Algorithm) produces a much better solution to the test case prioritization problem. It implements stochastic optimization while dealing with problem concern. The genetic algorithm is an evolutionary algorithm which gives an exact mathematical fitness value for the test cases on which prioritization is done. This paper focuses on the comparison of metaheuristic genetic algorithm with other algorithms and proves the efficiency of genetic algorithm over the remaining ones.},
  keywords={Genetics;Computers;Genetic algorithms;Testing;regression testing;test case prioritization;genetic algorithm;greedy algorithm;APFD},
  doi={10.1109/ICHPCA.2014.7045344},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8343055,
  author={Mahmood, Md. Hasan and Hosain, Md. Shazzad},
  booktitle={2017 8th IEEE International Conference on Software Engineering and Service Science (ICSESS)}, 
  title={Improving test case prioritization based on practical priority factors}, 
  year={2017},
  volume={},
  number={},
  pages={899-902},
  abstract={Test case prioritization involves prioritized the test cases for regression testing which improve the effectiveness of the testing process. By improving test case scheduling we can optimize time and cost as well as can produce better tested products. There are a number of methods to do prioritized test cases but not that effective or practical for the real-life large commercial systems. Most of the technique deals with finding defects or covering more test cases. In this paper, we will extend the previous work to incorporate real life practical aspects to schedule test cases. This will cover most of the businesses functionally based on the practical aspects. This approach covers more business area and ensure more defects. By prioritized test cases with this technique we will cover most important business functionally with less number of test cases.},
  keywords={Complexity theory;Testing;Computer bugs;Business;Fault detection;Software systems;Test case;Test case prioritization;Test case prioritization methods;Regression Testing},
  doi={10.1109/ICSESS.2017.8343055},
  ISSN={2327-0594},
  month={Nov},}@INPROCEEDINGS{7079143,
  author={Sujata and Purohit, G.N.},
  booktitle={2015 Fifth International Conference on Advanced Computing & Communication Technologies}, 
  title={A Schema Support for Selection of Test Case Prioritization Techniques}, 
  year={2015},
  volume={},
  number={},
  pages={547-551},
  abstract={Regression testing is a vast field of research. It is very costly and time consuming process but on the other hand very important process in software testing. Retest all, Test case Selection, Hybrid and Test Case Prioritization are its various techniques which are used to reduce the efforts in maintenance phase. In technical literature several techniques are present with their different and vast number of goals which can be applied in software projects despite of that they have not proven their true efficiency in the testing process. The major problem in regression testing area is to select the test case prioritization technique/s that is effective in such a way that maximum project characteristics should be cover in a minimum time span. However, consideration of this decision be carefully done so that loss of resources can be avoided in a software project. Based on the above scenario, author proposes a selection schema to support the selection of TCP techniques for a given software project aiming at maximizing the coverage of software project characteristics considering aspect of prioritization of software project characteristics. At the end, preliminary results of an experimental evaluation are presented. The purpose of this research is decision should be based on the objective knowledge of the techniques rather than considering some perception and assumptions.},
  keywords={Software;Maintenance engineering;Software algorithms;Software testing;Reliability;Estimation;regression testing;project characteristics;selection schema;test case prioritization techniques},
  doi={10.1109/ACCT.2015.91},
  ISSN={2327-0659},
  month={Feb},}@INPROCEEDINGS{8711039,
  author={Dhiman, Riza and Chopra, Vinay},
  booktitle={2019 IEEE 2nd International Conference on Information and Computer Technologies (ICICT)}, 
  title={Novel Approach for Test Case Prioritization Using ACO Algorithm}, 
  year={2019},
  volume={},
  number={},
  pages={292-295},
  abstract={Regression testing is used to retest the component of a system that verifies that after modifications defects are removed from the in effected software. Automation tools are required for these types of testing. This work is based on manual slicing and automated slicing for test case prioritization to detect maximum number of faults from the project in which some changes are done for the new version release. The slicing is the technique which will divide the whole project function wise and detect associated functions. To test the performance of proposed and existing algorithm MATLAB is being used by considering the dataset of ten projects. Each project has seven functions and four numbers of changes are defined for the regression testing. In the simulation it is being analyzed that fault detection rate is increased and execution time is reduced with the implementation of automated test case prioritization as compared to manual test case prioritization in regression testing.},
  keywords={Testing;Manuals;Fault detection;Software;Optimization;Performance analysis;Software algorithms;test case prioritization;ACO;regression testing},
  doi={10.1109/INFOCT.2019.8711039},
  ISSN={},
  month={March},}@INPROCEEDINGS{7724418,
  author={Yadav, Dharmveer Kumar and Dutta, Sandip},
  booktitle={2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Test case prioritization technique based on early fault detection using fuzzy logic}, 
  year={2016},
  volume={},
  number={},
  pages={1033-1036},
  abstract={Regression testing is time consuming and expensive activity in software testing. In Regression testing when any changes made to already tested program it should not affect to other part of program. Regression testing is crucial activities in software testing and maintenance phases. If some part of code is altered then it is mandatory to validate the modified code. Throughout regression testing test case from test suite will be re-executed and re-execution of all the test case will be very expensive. In this paper we present regression test case prioritization for object oriented program. The most important research is how to select efficient and suitable test cases during regression testing from the test suite. To minimize the regression testing cost we have applied prioritization technique. In this paper prioritization is done based on fault detection rate of program, execution time and requirement coverage using fuzzy logic.},
  keywords={Testing;Measurement;Fault detection;Software;Conferences;Software engineering;Fuzzy logic;Regression testing;Test case prioritization;APFD metric;Fuzzy inference system (FIS)},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{9198020,
  author={Vats, Prashant and Gossain, Anjana and Mandot, Manju},
  booktitle={2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, 
  title={SARLA - A 3-Tier Architectural Framework Based on the ACO for the Probablistic Analysis of the Regression Test Case Selection and their Prioritization}, 
  year={2020},
  volume={},
  number={},
  pages={681-687},
  abstract={Software testing is a process of testing Software under Test (SUT) with the intent of finding errors in it & plays a major role in the software development process. Further the Maintenance phase of any software product needed to go through a series of Regression testing process. In Regression Testing, It is required to retest the existing software module whenever any modification is done to that module in order to see & check its functioning after the removal of errors in it. During the Regression Testing it is a necessary habit that we use to perform certain steps like Test case selection, their effective prioritization. To select and chose an effective set of prioritized test cases that ensures that all the faults are being covered quickly with the minimum execution time. So in other words, we can say that Regression test selection is a process of reducing the number of test suites by selecting the appropriate subsets from an original test suite to ensure the hundred percent code coverage of a SUT. In this paper, we have proposed a 3-tier Architectural framework called SARLA that provides us a cost effective method for the probabilistic analysis of the Regression test case selection and their prioritization based upon the Ant Colony Optimization (ACO) technique.},
  keywords={Testing;Software;Genetic algorithms;Probabilistic logic;Ant colony optimization;Fault detection;Measurement;Regression Testing;Test case selection;Test suite prioritization;ACO.},
  doi={10.1109/ICRITO48877.2020.9198020},
  ISSN={},
  month={June},}@INPROCEEDINGS{8776936,
  author={Padmnav, Pushkar and Pahwa, Gaurav and Singh, Dinesh and Bansal, Saurabh},
  booktitle={2019 9th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={Test Case Prioritization based on Historical Failure Patterns using ABC and GA}, 
  year={2019},
  volume={},
  number={},
  pages={293-298},
  abstract={Regression testing is defined as type of software testing carried out to ensure that no new bugs are introduced due to modifications to existing code or addition of new features. Prioritization techniques order the set of test cases for improved & effective testing. Test Case Prioritization (TCP) in corrective regression testing is an indispensable arsenal to help discover faults faster during the initial phase of testing. Many techniques have been proposed for Test Case Prioritization (TCP) based on requirement correlation, test coverage, information retrieval which are dependent on data which is not easily available. Our approach considers the historical execution of the regression cycles through use of Artificial Bee Colony Optimization (Swarm Intelligence) & Genetic Algorithm for fault detection with improved results.},
  keywords={Testing;Genetic algorithms;Optimization;Particle swarm optimization;Software;Measurement;Computer bugs;Test Case Prioritization;Regression Testing;APFD;Artificial Bee Colony Optimization;Genetic algorithm;Corrective Regression Testing;Swarm Intelligence},
  doi={10.1109/CONFLUENCE.2019.8776936},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10197719,
  author={Xiao, Zhengxinchao and Xiao, Lei},
  booktitle={2023 IEEE/ACIS 21st International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={A Systematic Literature Review on Test Case Prioritization and Regression Test Selection}, 
  year={2023},
  volume={},
  number={},
  pages={235-242},
  abstract={Regression testing is a crucial component of software testing and a crucial tool for ensuring the quality of software. An appropriate optimization method is essential for maximizing productivity and reducing expenses in regression testing. Test case prioritization (TCP) and regression test selection (RTS) are two popular methods in regression testing. This paper provides a qualitative analysis of 18 TCP and 17 RTS publications from the last five years. This paper presents four main issues. The first covers the most popular TCP techniques, the second covers the most popular RTS methods, the third covers the most popular metrics for measuring TCP and RTS, and the fourth covers data sources. Based on this study, we draw the following conclusions: (1) Defect prediction and machine learning-based TCP methods, machine learning, multi-objective, and model-based RTS methods will receive additional attention in future. (2) Defects4J is the most commonly used data set in TCP in the past five years. SIR and GitHub are the most commonly used datasets in RTS. (3) The most widely used measurement methods in TCP and RTS are APFD and cost, respectively. In future, researchers will use these two indicators to conduct a more comprehensive evaluation together with cost, fault detection capability, and test coverage.},
  keywords={Software testing;Productivity;Costs;Systematics;Bibliographies;Soft sensors;Optimization methods;Regression testing;Test case prioritization;Test case selection;Systematic literature review},
  doi={10.1109/SERA57763.2023.10197719},
  ISSN={2770-8209},
  month={May},}@INPROCEEDINGS{10633335,
  author={Ahmad, Azeem and Rentas, Dimistris and Hasselqvist, Daniel and Sandberg, Pontus and Sandahl, Kristian and Vulgarakis, Aneta},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Test Case Selection in Continuous Regression Testing Using Machine Learning: An Industrial Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={33-38},
  abstract={Continuous integration and delivery (CI/CD) have transformed software development by reducing delivery time, improving product quality, and giving enterprises a competitive advantage. However, large-scale projects confront difficulties in giving fast feedback to developers due to large test suites, resulting in longer testing cycles and lower productivity. Traditional regression testing methods struggle to find a balance between efficacy and efficiency, demanding advanced approaches. This study investigates the use of machine learning (ML), specifically Neural Network and Random Forest models, to choose test cases based on source code changes, commit messages, and change file path in order to offer developers with faster feedback. The study investigates the predicted accuracy of ML models using a large industrial dataset from a telecom company, which included 15 million test executions over 15 months. The results show that Random Forest outperforms Neural Network models in test case selection, with up to 97% accuracy achieved. Real-time evaluations conducted over a month show significant savings in test executions (88 % -90 %) and testing time (44 % -74%) across multiple regression testing activities, illustrating the potential of ML-driven techniques to optimize CI/CD pipelines and increase developer productivity.},
  keywords={Productivity;Accuracy;Source coding;Computational modeling;Neural networks;Predictive models;Real-time systems;Test Case Selection;Machine Learning Models;Test Case Selection on Code Changes;Multi-factor Test Case Selection},
  doi={10.1109/COMPSAC61105.2024.00015},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{8261011,
  author={Farooq, Faiza and Nadeem, Aamer},
  booktitle={2017 International Conference on Frontiers of Information Technology (FIT)}, 
  title={A Fault Based Approach to Test Case Prioritization}, 
  year={2017},
  volume={},
  number={},
  pages={52-57},
  abstract={Regression testing is performed to ensure that the no new faults have been introduced in the software after modification and the software continues to work correctly. Regression testing is an expensive process because the test suite might be too large to execute in full. Thus to reduce the cost of such testing, regression testing techniques are used. One such technique is test case prioritization. Software testers assign priority to each test case to make sure that the test cases with higher priorities are executed first, in case of not having enough resources to execute the whole test suite. Test case prioritization is mainly used to increase fault detection rate of test suite which is the measure of how early faults are detected. In this paper, we propose an approach which exploits mutation testing in order to assign priorities to test cases. Using mutation testing, we introduce different faults in original program thus creating a number of mutated copies of the program and test case that exposes maximum number of these faults is given the highest priority. We report the outcomes of our experiments in which we applied our technique to test suites and calculated the fault detection rates produced by the prioritized test suites, comparing those rates of fault detection to the rates achieved by existing prioritization technique. The resulting data shows that prioritization technique proposed improved the fault detection rate of test suites.},
  keywords={Testing;Fault detection;Software;Minimization;Computer science;History;Information technology;Regression testing;Test case prioritization;Mutation testing},
  doi={10.1109/FIT.2017.00017},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6630498,
  author={Larprattanakul, Adipat and Suwannasart, Taratip},
  booktitle={2013 5th International Conference on Intelligent Networking and Collaborative Systems}, 
  title={An Approach for Regression Test Case Selection Using Object Dependency Graph}, 
  year={2013},
  volume={},
  number={},
  pages={617-621},
  abstract={Regression testing is one important step in software development activities to ensure a new change does not have a negative impact to unchanged parts. Regression test case selection is an approach to reduce time and resource consumption in regression testing. We present a framework of regression test case selection by using object dependency graph as a change identifier and identifying the test cases which are worthwhile to be rerun in object-oriented software.},
  keywords={Testing;Object recognition;Databases;Software maintenance;Object oriented programming;Computers;object dependency graph;regression testing;regression test case selection},
  doi={10.1109/INCoS.2013.115},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9160217,
  author={Ashima and Shaheamlung, Golmei and Rote, Ketusezo},
  booktitle={2020 International Conference on Intelligent Engineering and Management (ICIEM)}, 
  title={A comprehensive review for test case prioritization in Software Engineering}, 
  year={2020},
  volume={},
  number={},
  pages={331-336},
  abstract={In the past years, test case prioritization has been improved in the regression testing by the use of effective test cases. The continuous improvement and attention have increased in terms of prioritization algorithm, coverage criteria, measurement, application scenario and the practice concerned. It has focused mainly on Prioritizing and scheduling the test cases. The main purpose of this paper is to study the different prioritization techniques used by various authors in previous years. Regression testing, a type of testing in which is being used as a tool for checking, testing, and up-gradation of software. The test cases of all scheduling and prioritizing are set in the ordered and proper method and as result, this case shows the detection and a maximum number of faults in the software in which the technical faults are traced and detected as the detected faults. Through the fault detection of the test case, it reduces the test case and minimizes the execution cost. As a result, this method shows the running of the test case at a higher priority in order to reduce and minimize the cost, time and effort of software testing.},
  keywords={Software;Optimization;Software testing;Computer science;Job shop scheduling;Fault detection;Regression Testing;Test case prioritization;Prioritization algorithm},
  doi={10.1109/ICIEM48762.2020.9160217},
  ISSN={},
  month={June},}@INPROCEEDINGS{10675906,
  author={Fariha, Asma and Azim, Akramul and Liscano, Ramiro},
  booktitle={2024 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Replay-Based Continual Learning for Test Case Prioritization}, 
  year={2024},
  volume={},
  number={},
  pages={106-107},
  abstract={In a large-scale Continuous Integration (CI) environment, regression testing can encounter high time and resource demands in ad hoc execution. Therefore, Test Case Prioritization (TCP) is crucial for enhancing the regression testing efficiency of CI. TCP methods aim to optimize regression testing by ordering test cases to effectively cover new code changes and their potential side effects and to maximize early fault detection. Traditional prioritization processes use diverse data sources, including code coverage analysis, test execution history, and domain-specific features. Heuristic-based or code-coverage-driven prioritization techniques may not be sufficient for accurate results in a rapidly changing environment. For this reason, there has been a significant shift towards employing Machine Learning (ML) techniques in TCP in recent years to harness the vast and complex datasets generated by CI practices. ML-based TCP approaches integrate multifaceted test case features from various sources to enhance the accuracy of test case prioritization. This trend reflects a broader movement towards data-driven decisionmaking in software testing, offering the potential to significantly reduce the regression testing burden by tailoring test suites more effectively to the needs of each software build, thereby saving time and resources while maintaining or improving the software quality. Recent studies have shown that the ML-based methods used in TCP can be categorized into four groups: Supervised Learning, Unsupervised Learning, Reinforcement Learning, and Natural Language Processing. Codebases for software projects can be changed rapidly by introducing new feature distributions into the CI systems. We analyzed a Java application’s CI and version control system (VCS) history data received from the International Business Machines Corporation (IBM) [1], [6], [7]. The frequent inclusion of new test suites introduced new patterns into the dataset properties. To keep up with these changes, ML models require frequent re-training on old and new datasets to maintain high accuracy on new data. The volume of the dataset tends to increase with time as more data becomes available. Frequent re-training of ML models on the entire dataset is computationally costly and requires extensive storage. Reinforcement Learning focuses on finding the best solution through reward maximization [2] and restricts the learning goal. Learning incrementally from new non-stationary data without requiring an old dataset to solve this TCP problem. Continual Learning (CL) or life-long learning/ incremental learning adapts to changes without needing old training samples. While CL has recently been studied in several works for different domains, we could not find effective research on implementing CL in the TCP domain. Given the dynamic environment of software testing, we apply CL in industrial test case prioritization is critical for maintaining the efficiency and effectiveness of software testing processes in dynamic environments. However, modifying ML models on new datasets may introduce other problems, such as catastrophic forgetting. This can occur when the model is trained on a new distribution, and the model weights change drastically. Different strategies have been suggested to solve the problem of catastrophic forgetting in CL. This abstract discusses the integration of pre-training and replay-based continual learning methods to enhance test case prioritization. Pre-trainingbased continual learning leverages the strong representation of pre-training models on a large dataset. This approach helps initialize the model with a broad understanding, which can be further incrementally trained to accommodate new tasks without significant performance loss on previous tasks. The dataset we obtained from IBM has a few years of test execution data for the CI and VCS. The model can be trained using a large volume of data for the pre-training method. Replay-based continual learning, however, involves retaining a small buffer of old training samples. This strategy includes a small fraction of old samples with a new dataset while incrementally training the model, enabling it to maintain its performance on older tasks by reinforcing the previous learning. Integrating pre-training and replay-based methods is most effective in the literature [3]. Pre-training provides a solid foundation for generic knowledge; replay-based methods complement this by continuously reinforcing past learning, ensuring that the adaptation to new tasks does not come at the expense of previously acquired knowledge. Several design choices leverage the benefits of this combined method. The frequency of incremental training on new datasets is an important design decision. This frequency can be timedriven or property-driven. Experimental work will guide the decision on incremental training frequency. Next, in replay-based approaches, the memory buffer size, number of old samples, and criteria for old sample selection are some of the decision parameters. In addition, a small buffer memory requires effective management in terms of data-retaining strategies. The empirical evidence supports the effectiveness of this integrated approach. Hu et al. [4] introduced prioritized experience replay in continual learning, emphasizing the selection of representative experiences to alleviate catastrophic forgetting. Similarly, Merlin et al. [5] provided practical recommendations for replay-based continual learning methods, highlighting the importance of memory size and data augmentation in enhancing the performance. We will conduct detailed investigations to determine the optimal values for these decision parameters. For time-based frequency, we will experiment at different intervals, such as weekly, every ten or 15 days, monthly, three months, and six months of incremental training. Property-based choices can be new test suite additions, significant changes in test suites, and an increase or decrease in the test case failure rate. Similarly, for the replay-based method, samples can be selected from each incremental training dataset; the selection can be random or property-based. For example, an even distribution of passed or failed samples could be selected to avoid overfitting. In conclusion, integrating pretraining and replay-based continual learning methods presents a promising research direction for enhancing large-scale test case prioritization in CI. Future research should explore different strategies to maximize the benefits of continual learning in test case prioritization.},
  keywords={Continuing education;Training;Software testing;Time-frequency analysis;Accuracy;Codes;Computational modeling;continual learning;test case prioritization;pretraining;experience replay;catastrophic forgetting},
  doi={10.1109/ICSTW60967.2024.00031},
  ISSN={2159-4848},
  month={May},}@INPROCEEDINGS{7339162,
  author={Wang, Yiting and Zhao, Xiaomin and Ding, Xiaoming},
  booktitle={2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)}, 
  title={An effective test case prioritization method based on fault severity}, 
  year={2015},
  volume={},
  number={},
  pages={737-741},
  abstract={In regression testing area, test case prioritization is one of the main techniques to improve the test validity and test effectiveness. However, when the test cases have the same maximum coverage rate, the random selection of the additional statement will influence the effect of sorting. For dealing with this problem, a new method is proposed to optimize test case prioritization based on fault severity, referred to as additional-statement-on-fault-severity. Facing those same maximum coverage rate, the new technique main consider a factor, fault severity, to sort test cases, it figures out the value of test case based on the algorithm of the new technique and order the sequence from high to low. Experiment results show that the improved technique of test case prioritizaftion can improve the efficiency of regression testing.},
  keywords={Software;Testing;Computers;Fault detection;Sorting;Minimization;Computer aided software engineering;regression testing;random selection;additional statement;test case prioritization;fault severities},
  doi={10.1109/ICSESS.2015.7339162},
  ISSN={2327-0594},
  month={Sep.},}@INPROCEEDINGS{8229925,
  author={Sujata and Purohit, G.N.},
  booktitle={2017 International Conference on Computing, Communication and Automation (ICCCA)}, 
  title={Classification model for test case prioritization techniques}, 
  year={2017},
  volume={},
  number={},
  pages={919-924},
  abstract={Regression Testing is mainly done in software maintenance aiming to assure that the changes made in the software have correctly been implemented and also to achieve the confidence that the modifications have not affected the other parts of the software. It is very costly and expensive technique. There are number of techniques present in literature that focus on achieving various testing objectives early in the process and hence reduces its cost. Despite of that, testers usually prefer only few already known techniques for test case prioritization. The main reason behind is the absence of guidelines for the selection of TCP techniques. Hence, this piece of research introduces a novel approach for classification of TCP techniques using fuzzy logic to support the efficient selection of test case prioritization techniques. This work is an extension of already proposed selection schema for test case prioritization techniques. To perform the validation of proposed approach results are compared with other classification techniques using Weka tool. The analysis clearly shows the effectiveness of proposed approach as compared to others in terms of its accuracy.},
  keywords={Testing;Complexity theory;Fuzzy logic;Software;Fault detection;Automation;Optimization;regression testing;test case prioritization;classification;fuzzy logic},
  doi={10.1109/CCAA.2017.8229925},
  ISSN={},
  month={May},}@INPROCEEDINGS{7207103,
  author={Konsaard, Patipat and Ramingwong, Lachana},
  booktitle={2015 12th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)}, 
  title={Total coverage based regression test case prioritization using genetic algorithm}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  abstract={Regression Testing is a test to ensure that a program that was changed is still working. Changes introduced to a software product often come with defects. Additional test cases are, this could reduce the main challenges of regression testing is test case prioritization. Time, effort and budget needed to retest the software. Former studies in test case prioritization confirm the benefits of prioritization techniques. Most prioritization techniques concern with choosing test cases based on their ability to cover more faults. Other techniques aim to maximize code coverage. Thus, the test cases selected should secure the total coverage to assure the adequacy of software testing. In this paper, we present an algorithm to prioritize test cases based on total coverage using a modified genetic algorithm. Its performance on the average percentage of condition covered and execution time are compared with five other approaches.},
  keywords={Genetic algorithms;Software;Software testing;Sociology;Statistics;Fault detection;Test case prioritization;Test suite;Regression testing;Genetic algorith;Code coverage;APCC;Software Testing;Software engineering},
  doi={10.1109/ECTICon.2015.7207103},
  ISSN={},
  month={June},}@INPROCEEDINGS{9978198,
  author={d’Aragona, Dario Amoroso and Pecorelli, Fabiano and Romano, Simone and Scanniello, Giuseppe and Baldassarre, Maria Teresa and Janes, Andrea and Lenarduzzi, Valentina},
  booktitle={2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={CATTO: Just-in-time Test Case Selection and Execution}, 
  year={2022},
  volume={},
  number={},
  pages={459-463},
  abstract={Regression testing wants to prevent that errors, which have already been corrected once, creep back into a system that has been updated. A naïve approach consists of re-running the entire test suite (TS) against the changed version of the software under test (SUT). However, this might result in a time-and resource-consuming process; e.g., when dealing with large and/or complex SUTs and TSs. To avoid this problem, Test Case Selection (TCS) approaches can be used. This kind of approaches build a temporary TS comprising only those test cases (TCs) that are relevant to the changes made to the SUT, so avoiding executing unnecessary TCs. In this paper, we introduce CATTO (Commit Adaptive Tool for Test suite Optimization), a tool implementing a TCS strategy for SUTs written in Java as well as a wrapper to allow developers to use CATTO within IntelliJ IDEA and to execute CATTO just-in-time before committing changes to the repository. We conducted a preliminary evaluation of CATTO on seven open-source Java projects to evaluate the reduction of the test-suite size, the loss of fault-revealing TCs, and the loss of fault-detection capability. The results suggest that CATTO can be of help to developers when performing TCS. The video demo and the documentation of the tool is available at: https://catto-tool.github.io/},
  keywords={Java;Software maintenance;Creep;Documentation;Optimization;Testing;Software testing;test case selection;regression testing},
  doi={10.1109/ICSME55016.2022.00059},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{9159097,
  author={Joo, Jeonghyun and Yoo, Seunghoon and Park, Myunghwan},
  booktitle={2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)}, 
  title={Poster: Test Case Prioritization Using Error Propagation Probability}, 
  year={2020},
  volume={},
  number={},
  pages={398-401},
  abstract={A software test is to execute the program using a test case to examine whether it produces the intended output. For successful regression testing, it is very important to choose a relatively small amount, but productive test cases to maximize testing efficiency. Test case prioritization is a suggested technique for this purpose. This technique arranges the test cases in such a way that higher-order test cases are expected to outperform those on lower-order test cases in fault-finding capability. In this paper, we suggest a new metric for test case prioritization based on the error propagation probability of the test cases. This metric arranges test cases in order by means of the probabilistic fault finding capability of the test cases. Since our metric is based on mathematical probability, it can show statistically consistent and constant results for the fault-finding capability of test cases. The experiment results show that there is a high correlation between the test cases aligned by our metric and their fault-finding capabilities.},
  keywords={Measurement;Software;Error probability;Testing;Manganese;Correlation;Test Case Prioritization;Error Propagation Probability;Lustre Language;Regression Testing},
  doi={10.1109/ICST46399.2020.00047},
  ISSN={2159-4848},
  month={Oct},}@INPROCEEDINGS{7515934,
  author={Ma, Tingting and Zeng, Hongwei and Wang, Xiaolin},
  booktitle={2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={Test case prioritization based on requirement correlations}, 
  year={2016},
  volume={},
  number={},
  pages={419-424},
  abstract={Test case prioritization technique aims to improve test efficiency rate by sorting test cases according to some specific criteria. Requirements play an important role throughout software testing. This paper proposes a test case prioritization method based on requirement correlations. Prioritization of requirements is defined by the users and the developers. This technique focuses on requirements with detected faults after the last regression testing. By readjusting prioritization of fault-related requirements, it can optimize the order of test cases. Experimental results show that this technique exactly contributes to achieving high testing efficiency.},
  keywords={Software;Correlation;Software testing;Heuristic algorithms;Complexity theory;Cognition;Test case prioritization;Requirement correlations;Fault detection rate;Regression Testing},
  doi={10.1109/SNPD.2016.7515934},
  ISSN={},
  month={May},}@INPROCEEDINGS{6888744,
  author={Wang, Xiaolin and Zeng, Hongwei},
  booktitle={15th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={Dynamic test case prioritization based on multi-objective}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Test case prioritization technology is to sort the test cases before the software testing designed to improve test efficiency. This paper presents a dynamic test case prioritization technique based on multi-objective. It integrates several traditional single-objective technologies so that makes it more flexible. This technology, from five dimensions, calculates prioritization values of test cases separately. Then a weighted sum is made to the values and it sorts the test cases according to the values. The results return to the storage in order to dynamically adjust the sort of test cases. This technology not only meets the high demands of regression testing, but also ensures the high efficiency of the test results.},
  keywords={History;Testing;Software;Fault detection;Databases;Measurement;Probability;Test case prioritization;Multi-objective;Dynamic;Regression testing},
  doi={10.1109/SNPD.2014.6888744},
  ISSN={},
  month={June},}@INPROCEEDINGS{10556478,
  author={Torbunova, Alina and Strandberg, Per Erik and Porres, Ivan},
  booktitle={2024 IEEE/ACM International Conference on Automation of Software Test (AST)}, 
  title={Dynamic Test Case Prioritization in Industrial Test Result Datasets}, 
  year={2024},
  volume={},
  number={},
  pages={154-158},
  abstract={Regression testing in software development checks if new software features affect existing ones. Regression testing is a key task in continuous development and integration, where software is built in small increments and new features are integrated as soon as possible. It is therefore important that developers are notified about possible faults quickly. In this article, we propose a test case prioritization schema that combines the use of a static and a dynamic prioritization algorithm. The dynamic prioritization algorithm rearranges the order of execution of tests on the fly, while the tests are being executed. We propose to use a conditional probability dynamic algorithm for this. We evaluate our solution on three industrial datasets and utilize Average Percentage of Fault Detection for that. The main findings are that our dynamic prioritization algorithm can: a) be applied with any static algorithm that assigns a priority score to each test case b) can improve the performance of the static algorithm if there are failure correlations between test cases c) can also reduce the performance of the static algorithm, but only when the static scheduling is performed at a near optimal level.},
  keywords={Job shop scheduling;Correlation;Heuristic algorithms;Fault detection;Software algorithms;Dynamic scheduling;Software;regression testing;Test Case Prioritization (TCP);dynamic prioritization},
  doi={},
  ISSN={2833-9061},
  month={April},}@INPROCEEDINGS{7899091,
  author={Zhou, Jianyi and Hao, Dan},
  booktitle={2017 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Impact of Static and Dynamic Coverage on Test-Case Prioritization: An Empirical Study}, 
  year={2017},
  volume={},
  number={},
  pages={392-394},
  abstract={Most of existing research in Test-Case Prioritization uses coverage information as the input during the process of prioritization and these coverage can be classified into two categories: static coverage and dynamic coverage. As these coverage information are collected in different ways, they have different influence on test-case prioritization. In this work, we present the first empirical study comparing the impact of static coverage and dynamic coverage with five typical techniques at different test-case granularities (e.g., test-method and test-class level) and different coverage criteria (e.g., method and statement coverage). This study is performed on 15 real-world Java projects (using 163 versions) and we find that the dynamic coverage performs better than static coverage in terms of the results of test-case prioritization.},
  keywords={Software;Software engineering;Conferences;Software testing;Java;Performance analysis;Test Case Prioritization;Empirical Study;Coverage Information;Regression Testing},
  doi={10.1109/ICSTW.2017.74},
  ISSN={},
  month={March},}@INPROCEEDINGS{7913140,
  author={Sharma, Sonia and Singh, Ajmer},
  booktitle={2016 Fourth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
  title={Model-based test case prioritization using ACO: A review}, 
  year={2016},
  volume={},
  number={},
  pages={177-181},
  abstract={Regression testing is very costly and inevitable activity of maintenance that is performed to ensure whether the modified software is valid or not. Running all the test cases of a test suit within given limited time and cost constraints is not possible. So, to cover the maximum number of faults in comparatively less time, it is necessary to prioritize the test cases. To solve the time constraint test case prioritization problems Ant Colony optimization (ACO) is a better approach. This paper presents a review on test case prioritization from a given test suite using ACO.},
  keywords={Decision support systems;Testing;Time factors;Ant colony optimization;Maintenance engineering;Software;Regression testing;Ant Colony Optimization;Test case Prioritization},
  doi={10.1109/PDGC.2016.7913140},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7100468,
  author={Kumar, Harish and Chauhan, Naresh},
  booktitle={2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={A coupling effect based test case prioritization technique}, 
  year={2015},
  volume={},
  number={},
  pages={1341-1345},
  abstract={Regression testing is a process that executes subset of tests that have already been conducted to ensure that changes have not propagated unintended side effects. Test case prioritization aims at reordering the regression test suit based on certain criteria, so that the test cases with higher priority can be executed first rather than those with lower priority. In this paper, a new approach for test case prioritization has been proposed which is based on a module-coupling effect that considers the module-coupling value for the purpose of prioritizing the modules in the software so that critical modules can be identified which in turn will find the prioritized set of test cases. In this way there will be high percentage of detecting critical errors that have been propagated to other modules due to any change in a module. The proposed approach has been evaluated with the case study of software consisting of ten modules.},
  keywords={Couplings;Testing;Software;Fault detection;Symmetric matrices;Computer science;Computer bugs;Regression Testing;Test Case Prioritization;Coupling & Cohesion},
  doi={},
  ISSN={},
  month={March},}@ARTICLE{9801672,
  author={Yaraghi, Ahmadreza Saboor and Bagherzadeh, Mojtaba and Kahani, Nafiseh and Briand, Lionel C.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Scalable and Accurate Test Case Prioritization in Continuous Integration Contexts}, 
  year={2023},
  volume={49},
  number={4},
  pages={1615-1639},
  abstract={Continuous Integration (CI) requires efficient regression testing to ensure software quality without significantly delaying its CI builds. This warrants the need for techniques to reduce regression testing time, such as Test Case Prioritization (TCP) techniques that prioritize the execution of test cases to detect faults as early as possible. Many recent TCP studies employ various Machine Learning (ML) techniques to deal with the dynamic and complex nature of CI. However, most of them use a limited number of features for training ML models and evaluate the models on subjects for which the application of TCP makes little practical sense, due to their small regression testing time and low number of failed builds. In this work, we first define, at a conceptual level, a data model that captures data sources and their relations in a typical CI environment. Second, based on this data model, we define a comprehensive set of features that covers all features previously used by related studies. Third, we develop methods and tools to collect the defined features for 25 open-source software systems with enough failed builds and whose regression testing takes at least five minutes. Fourth, relying on the collected dataset containing a comprehensive feature set, we answer four research questions concerning data collection time, the effectiveness of ML-based TCP, the impact of the features on effectiveness, the decay of ML-based TCP models over time, and the trade-off between data collection time and the effectiveness of ML-based TCP techniques.},
  keywords={Feature extraction;Codes;Testing;History;Training;Data collection;Computational modeling;Machine learning;software testing;test case prioritization;test case selection;continuous integration},
  doi={10.1109/TSE.2022.3184842},
  ISSN={1939-3520},
  month={April},}@INPROCEEDINGS{9240666,
  author={Vescan, Andreea and Şerban, Camelia},
  booktitle={2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Towards a new Test Case Prioritization Approach based on Fuzzy Clustering Analysis}, 
  year={2020},
  volume={},
  number={},
  pages={786-788},
  abstract={Regression testing is used every time a change is taking place in the source code, various approaching for the test cases to be executed focusing on different criteria: from the maximization of faults and/or code coverage to minimization of time execution. Test Case Prioritization is one of such approaches that aim to optimize the execution order of test cases according to various criteria. However, many regression testing approaches use only code coverage criteria, few considered requirements. This paper aims to propose a fuzzy clustering approach with various metrics of the considered test cases, considering several aspects: faults, execution time, requirements covered by the test cases, and requirements dependencies. An in-depth analysis will follow to determine what are the best metrics to be used in the TCP. This will have a positive impact on the research community by identifying new perspectives to be considered for the TCP.},
  keywords={Measurement;Software maintenance;Software algorithms;Focusing;Prediction algorithms;Minimization;Testing;Test Case Prioritization;Regression Testing;Defect Prediction;Average Percentage of Faults Detected (APFD)},
  doi={10.1109/ICSME46990.2020.00091},
  ISSN={2576-3148},
  month={Sep.},}@INPROCEEDINGS{7506447,
  author={Chaurasia, Geetanjali and Agarwal, Sonali and Gautam, Swarnima Singh},
  booktitle={2015 IEEE Students Conference on Engineering and Systems (SCES)}, 
  title={Clustering based novel test case prioritization technique}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={Regression testing is an activity during the maintenance phase to validate the changes made to the software and to ensure that these changes would not affect the previously verified code or functionality. Often, regression testing is performed with limited computing resources and time budget. So in this phase, it is infeasible to run the complete test suite Thus, test-case prioritization approaches are applied to ensure the execution of test cases in some prioritized order and to achieve some specific goals like, increasing the rate of bug detection, identifying the most critical bugs as early as possible etc. In this research work, we are going to propose a new and more effective clustering based prioritization technique that uses various metrics and execution time of test cases to reorder them. The results of implementation will prove that the suggested approach is more productive than the existing coverage and clustering based prioritization techniques.},
  keywords={Measurement;Complexity theory;Fault detection;Testing;Information technology;History;Clustering algorithms;Clustering;Regression testing;test case prioritization;test suite},
  doi={10.1109/SCES.2015.7506447},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6601820,
  author={Lin, Chu-Ti and Chen, Cheng-Ding and Tsai, Chang-Shi and Kapfhammer, Gregory M.},
  booktitle={2013 18th International Conference on Engineering of Complex Computer Systems}, 
  title={History-Based Test Case Prioritization with Software Version Awareness}, 
  year={2013},
  volume={},
  number={},
  pages={171-172},
  abstract={Test case prioritization techniques schedule the test cases in an order based on some specific criteria so that the tests with better fault detection capability are executed at an early position in the regression test suite. Many existing test case prioritization approaches are code-based, in which the testing of each software version is considered as an independent process. Actually, the test results of the preceding software versions may be useful for scheduling the test cases of the later software versions. Some researchers have proposed history-based approaches to address this issue, but they assumed that the immediately preceding test result provides the same reference value for prioritizing the test cases of the successive software version across the entire lifetime of the software development process. Thus, this paper describes ongoing research that studies whether the reference value of the immediately preceding test results is version-aware and proposes a test case prioritization approach based on our observations. The experimental results indicate that, in comparison to existing approaches, the presented one can schedule test cases more effectively.},
  keywords={Software;Testing;Fault detection;Schedules;Software engineering;Computers;Educational institutions;Regression Testing;Test Case Prioritization},
  doi={10.1109/ICECCS.2013.33},
  ISSN={},
  month={July},}@INPROCEEDINGS{9609187,
  author={Sharif, Aizaz and Marijan, Dusica and Liaaen, Marius},
  booktitle={2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={DeepOrder: Deep Learning for Test Case Prioritization in Continuous Integration Testing}, 
  year={2021},
  volume={},
  number={},
  pages={525-534},
  abstract={Continuous integration testing is an important step in the modern software engineering life cycle. Test prioritization is a method that can improve the efficiency of continuous integration testing by selecting test cases that can detect faults in the early stage of each cycle. As continuous integration testing produces voluminous test execution data, test history is a commonly used artifact in test prioritization. However, existing test prioritization techniques for continuous integration either cannot handle large test history or are optimized for using a limited number of historical test cycles. We show that such a limitation can decrease fault detection effectiveness of prioritized test suites. This work introduces DeepOrder, a deep learning-based model that works on the basis of regression machine learning. DeepOrder ranks test cases based on the historical record of test executions from any number of previous test cycles. DeepOrder learns failed test cases based on multiple factors including the duration and execution status of test cases. We experimentally show that deep neural networks, as a simple regression model, can be efficiently used for test case prioritization in continuous integration testing. DeepOrder is evaluated with respect to time-effectiveness and fault detection effectiveness in comparison with an industry practice and the state of the art approaches. The results show that DeepOrder outperforms the industry practice and state-of-the-art test prioritization approaches in terms of these two metrics.},
  keywords={Industries;Deep learning;Measurement;Software maintenance;Fault detection;Conferences;History;Regression testing;Test case prioritization;Test case selection;Deep Learning;Machine Learning;Continuous Integration},
  doi={10.1109/ICSME52107.2021.00053},
  ISSN={2576-3148},
  month={Sep.},}@INPROCEEDINGS{7019794,
  author={Vedpal and Chauhan, Naresh and Kumar, Harish},
  booktitle={2014 International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={A hierarchical test case prioritization technique for object oriented software}, 
  year={2014},
  volume={},
  number={},
  pages={249-254},
  abstract={Software reuse is the use of existing artifacts to create new software. Inheritance is the foremost technique of reuse. But the inherent complexity due to inheritance hierarchy found in object - oriented paradigm also affect testing. Every time any change occurs in the software, new test cases are added in addition to the existing test suite. So there is need to conduct effective regression testing having less number of test cases to reduce cost and time. In this paper a hierarchical test case prioritization technique is proposed wherein various factors have been considered that affect error propagation in the inheritance. In this paper prioritization of test cases take place at two levels. In the first level the classes are prioritized and in the second level the test cases of prioritized classes are ordered. To show the effectiveness of proposed technique it was applied and analyze on a C++ program.},
  keywords={Testing;Software;Fault detection;Measurement;Unified modeling language;Informatics;Object oriented modeling;object oriented testing;test case prioritization;regression testing},
  doi={10.1109/IC3I.2014.7019794},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7155012,
  author={Nagar, Reetika and Kumar, Arvind and Singh, Gaurav Pratap and Kumar, Sachin},
  booktitle={2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE)}, 
  title={Test case selection and prioritization using cuckoos search algorithm}, 
  year={2015},
  volume={},
  number={},
  pages={283-288},
  abstract={Regression Testing is an inevitable and very costly activity that is implemented to ensure the validity of new version of software in a time and resource constrained environment. Execution of entire test suite is not possible so it is necessary to apply techniques like Test Case Selection and Test Case Prioritization for proper selection and schedule of test cases in a specific sequence, fulfilling some chosen criteria. Cuckoo search (CS) algorithm is an optimization algorithm proposed by Yang and Deb [13]. It is inspired by the obligate brood parasitism of some cuckoo species by laying their eggs in the nests of other host birds. Cuckoo Search is very easy to implement as it depends on single parameter only unlike other optimization algorithms. In this paper a test case selection and prioritization algorithm has been proposed using Cuckoo Search. This algorithm selects and prioritizes the test cases based on the number of faults covered in minimum time. The proposed algorithm is an optimistic approach which provides optimum best results in minimum time.},
  keywords={Testing;Algorithm design and analysis;Optimization;Software algorithms;Software;Sociology;Statistics;Cuckoos Search;Levy Flight;Regression Test Selection;Test Case Prioritization;Artificial Intelligence},
  doi={10.1109/ABLAZE.2015.7155012},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9712155,
  author={Lin, Chu-Ti and Yuan, Sheng-Hsiang and Intasara, Jutarporn},
  booktitle={2021 28th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={A Learning-to-Rank Based Approach for Improving Regression Test Case Prioritization}, 
  year={2021},
  volume={},
  number={},
  pages={576-577},
  abstract={Many prior studies with attempt to improve regression testing adopt test case prioritization (TCP). TCP generally arranges the execution of regression test cases according to specific rules with the goal of revealing faults as early as possible. It is noted that different TCP algorithms adopt different metrics to evaluate test cases' priority so that they may be effect at revealing faults early in different faulty programs. Adopting a single metric may not generally work well. In this decade, learning-to-rank (LTR) strategies have been adopted to address some software engineering problems. This study also uses a pairwise LTR strategy XGBoost to combine several existing metrics so as to improve TCP effectiveness. More specifically, we regard the metrics adopted by TCP techniques to evaluate test cases' priority as the features of the training data and adopt XGBoost to learn the weights of the combined metrics. Additionally, in order to avoid overfitting, we use a fuzzy inference system to generate additional features for data augmentation. The experimental results show that our approach achieves more excellent effectiveness than the existing TCP techniques with respect to the selected subject programs.},
  keywords={Measurement;Fuzzy logic;Software algorithms;Training data;Software engineering;Testing;regression testing;test case prioritization;machine learning;learning-to-rank;fuzzy inference system},
  doi={10.1109/APSEC53868.2021.00075},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{7380585,
  author={Dhareula, Priyanka and Ganpati, Anita},
  booktitle={2015 International Conference on Green Computing and Internet of Things (ICGCIoT)}, 
  title={Prevalent criteria's in regression test case selection techniques: An exploratory study}, 
  year={2015},
  volume={},
  number={},
  pages={871-876},
  abstract={Regression testing is done after needful changes, ensuring that changes are working as required and does not produce unexpected results for a system under test. Note worthy difficulty in regression testing is selection of significant subgroup of test cases. This paper has analyzed techniques of regression test selection (RTS) for test case optimization in various domains. The study identified most prevalent criteria's used by various researchers. This study analyzed two broad groups of techniques under which test cases are optimized i.e. code-based and requirement-based techniques. Further most prevalent criteria's were identified and techniques were grouped under them. The study is also focused on the level of test granularity used by different researchers. Two main granularity levels were identified for code based testing i.e. fine granularity and coarse granularity. From this study it is also concluded that no such technique could be generalized because they are proposed for different domains of interest.},
  keywords={Testing;Software;Unified modeling language;Optimization;Fault diagnosis;Flow graphs;Databases;Regression testing;maintenance;test case selection;selection techniques},
  doi={10.1109/ICGCIoT.2015.7380585},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6949377,
  author={Nagar, Reetika and Kumar, Arvind and Kumar, Sachin and Baghel, Anurag Singh},
  booktitle={2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)}, 
  title={Implementing test case selection and reduction techniques using meta-heuristics}, 
  year={2014},
  volume={},
  number={},
  pages={837-842},
  abstract={Regression Testing is an inevitable and very costly maintenance activity that is implemented to make sure the validity of modified software in a time and resource constrained environment. Execution of entire test suite is not possible so it is necessary to apply techniques like Test Case Selection and Test Case Prioritization to select and prioritize a minimum set of test cases, fulfilling some chosen criteria, that is, covering all possible faults in minimum time and other. In this paper a test case reduction hybrid Particle Swarm Optimization (PSO) algorithm has been proposed. This PSO algorithm uses GA mutation operator while processing. PSO is a swarm intelligence algorithm based on particles behavior. GA is an evolutionary algorithm (EA). The proposed algorithm is an optimistic approach which provides optimum best results in minimum time.},
  keywords={Testing;Genetic algorithms;Software algorithms;Software;Particle swarm optimization;Sociology;Statistics;Particle Swarm Optimization;Genetic Algorithm;Regression Test Selection;Test Case Prioritization},
  doi={10.1109/CONFLUENCE.2014.6949377},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7975319,
  author={Saraswat, Pavi and Singhal, Abhishek},
  booktitle={2016 1st India International Conference on Information Processing (IICIP)}, 
  title={A hybrid approach for test case prioritization and optimization using meta-heuristics techniques}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Software testing is a very crucial and important phase for (SDLC) software development life cycle. Software is being tested on its effectiveness for generating good quality software. Regression testing is done by considering the constraints of resources and in this phase optimization of test suite is very important and crucial. This paper mainly aims to make use of hybrid approach of meta-heuristics, It comprises of two algorithms first is genetic algorithm and second is particle swarm optimization. In addition to algorithm the comparison of proposed algorithm hybrid GA_PSO with other optimization algorithms are been done. To validate the research Average Percentage Fault Detection (APFD) metric is used for comparison and fitness evaluation of the proposed algorithm.},
  keywords={Genetic algorithms;Testing;Sociology;Statistics;Fault detection;Software;Optimization;Software testing;regression testing;test case prioritization;test case optimization;genetic algorithm;partucle swarm optimization},
  doi={10.1109/IICIP.2016.7975319},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9200083,
  author={Chaudhary, Sarika and Jatain, Aman},
  booktitle={2020 International Conference on Computational Performance Evaluation (ComPE)}, 
  title={Performance Evaluation of Clustering Techniques in Test Case Prioritization}, 
  year={2020},
  volume={},
  number={},
  pages={699-703},
  abstract={Regression testing plays a crucial role in maintaining quality of a software, yet accounts for a huge percentage of cost from overall development cost. Selection of regression testing technique directly impacts the software quality, where at first step relevant test cases are selected, then redundant test case are removed during minimization step and at final step test cases are prioritized to execute the most relevant test cases first and so on. The test case prioritization is one of the broadly used approach to reduce cost and time of regression testing. In literature researchers have proposed various methods to prioritize test cases, and clustering is one of the popular and suggested techniques among them. It is an unsupervised method of putting similar data into one cluster and dissimilar data into different cluster and considered to be an important tool for exploratory data analysis. This paper analyses various clustering techniques used for test case prioritization and presents a performance analysis on different hard clustering algorithm and then the test case prioritization techniques are also evaluated using APFD.},
  keywords={Clustering algorithms;Classification algorithms;Fault detection;Testing;Schedules;Software;Software algorithms;APFD;clustering;DBSCAN;DBK-mean;K-mean;test case prioritization},
  doi={10.1109/ComPE49325.2020.9200083},
  ISSN={},
  month={July},}@INPROCEEDINGS{6986033,
  author={Nejad Dobuneh, Mojtaba Raeisi and Jawawi, Dayang N. A. and Ghazali, Masitah and Malakooti, Mohammad V.},
  booktitle={2014 8th. Malaysian Software Engineering Conference (MySEC)}, 
  title={Development test case prioritization technique in regression testing based on hybrid criteria}, 
  year={2014},
  volume={},
  number={},
  pages={301-305},
  abstract={Test case prioritization techniques improve the performance of regression testing, and arrange test cases in order to obtain maximum available fault that is going to be detected in a shorter time. In this research the priority is given to test cases that are performed based on multiple criteria and hybrid criteria to enhance the effectiveness of time and cost for proposed technique. This paper shows that our prioritization technique is appropriate for regression testing environment and show that our prioritization approach frequently produces a higher average percentage of fault detection rate value, for web application. The experiments also reveal fundamental tradeoffs in the performance of time aware prioritization. In this technique some fault will be seeded in subject application, then applying the prioritization criteria on test cases to obtain the effective time of average percentage fault detection rate.},
  keywords={Fault detection;Software;Software engineering;Schedules;Organizations;Software testing;web application;regression testing;prioritization criteria},
  doi={10.1109/MySec.2014.6986033},
  ISSN={},
  month={Sep.},}@ARTICLE{8920054,
  author={Ji, Shunhui and Li, Bixin and Zhang, Pengcheng},
  journal={IEEE Access}, 
  title={Test Case Selection for All-Uses Criterion-Based Regression Testing of Composite Service}, 
  year={2019},
  volume={7},
  number={},
  pages={174438-174464},
  abstract={Composite services evolve for various reasons. Test case selection in the regression testing is an effective technique to ensure the correctness of modified versions meanwhile to reduce the cost of testing. However, few work has studied the test case selection problem based on the data flow testing criteria. In addition, there are three observable kinds of changes during the evolution, including Process change, Binding change and Interface change, which all bring impact to the data flow. To address these issues, a test case selection approach is proposed for regression testing of BPEL (Business Process Execution Language) composite service where all-uses criterion is satisfied and all the three change types are involved. BPEL composite service is modeled with a two-level model in which XCFG (eXtended Control Flow Graph) describes the behavior of BPEL process in the first level and WSDM (Web Service Description Model) depicts the interface information of composite service and partner services in the second level. Change impact analysis is performed to identify the affected definition-use pairs by comparing and analyzing two-level models of the baseline and evolved versions. And testing paths are generated to cover the affected definition-use pairs and select test cases based on the path condition analysis. Empirical result shows that the proposed approach is effective.},
  keywords={Testing;Payloads;Web services;Flow graphs;Process control;Regression testing;data flow testing;composite service;test case selection},
  doi={10.1109/ACCESS.2019.2957220},
  ISSN={2169-3536},
  month={},}@ARTICLE{10614590,
  author={Ghani, Israr and Wan Kadir, Wan Mohd Nasir and Arbain, Adila Firdaus and Ghani, Imran},
  journal={IEEE Access}, 
  title={A Detection-Based Multi-Objective Test Case Selection Algorithm to Improve Time and Efficiency in Regression Testing}, 
  year={2024},
  volume={12},
  number={},
  pages={114974-114994},
  abstract={Regression testing is carried out to ensure that changes or enhancements are not impacting previous working software. Deciding how much retesting is required after modifications, bug fixes or before product deployments are difficult. Therefore, Test Case Selection (TCS) select the satisfactory subset of modified test cases from already executed test suites. The testing primary concerns in TCS for regression testing are efficiency (i.e., coverage, fault detection ability, redundancy) and time. The first challenge in TCS concerns the efficiency of multi-objective test case selection. The second challenge is to improve the execution time to detect the changes in a test suite, which makes it impractical to use these efficiency measures as a single goal for TCS. To overcome these challenges, there is a need to introduce an efficient detection-based multi-objective framework to improve the Time and efficiency of TCS. A multi-objective advanced and efficient regression test case selection (ARTeCS) framework is devised to improve the time performance and efficiency of a given TCS objective relative to the other TCS approaches. An algorithm to detect the changes in test cases using multiple TCS objectives. This comparison found that the enhanced ARTeCS algorithm improves redundancy efficiency by 44.02%. The selection technique showed ARTeCS improved the modified change detection by 43.00%, whereas the Hybrid Whale Optimization Algorithm (HWOA) stated 23% and ACO showed 33% only for selected test cases. Regarding average for fault detection, ACO scores 21%, HWOA scores 11%, and ARTeCS scores 31.08% with total execution times of 12, 21 and 09 seconds, respectively. In conclusion, the multiple-objective ARTeCS framework with four test suite selection parameters is more efficient than the existing multi-objective selection framework.},
  keywords={Redundancy;Software algorithms;Software testing;Fault detection;Codes;History;Regression analysis;Software testing;regression testing;test case selection;TCS algorithm;TCS framework;multi-objective approach in TCS},
  doi={10.1109/ACCESS.2024.3435678},
  ISSN={2169-3536},
  month={},}@ARTICLE{6936894,
  author={Panichella, Annibale and Oliveto, Rocco and Penta, Massimiliano Di and De Lucia, Andrea},
  journal={IEEE Transactions on Software Engineering}, 
  title={Improving Multi-Objective Test Case Selection by Injecting Diversity in Genetic Algorithms}, 
  year={2015},
  volume={41},
  number={4},
  pages={358-383},
  abstract={A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem. However, previous studies have shown that there is no clear winner between greedy and MOGAs, and that their combination does not necessarily produce better results. In this paper we show that the optimality of MOGAs can be significantly improved by diversifying the solutions (sub-sets of the test suite) generated during the search process. Specifically, we introduce a new MOGA, coined as DIversity based Genetic Algorithm (DIV-GA), based on the mechanisms of orthogonal design and orthogonal evolution that increase diversity by injecting new orthogonal individuals during the search process. Results of an empirical study conducted on eleven programs show that DIV-GA outperforms both greedy algorithms and the traditional MOGAs from the optimality point of view. Moreover, the solutions (sub-sets of the test suite) provided by DIV-GA are able to detect more faults than the other algorithms, while keeping the same test execution cost.},
  keywords={Optimization;Greedy algorithms;Testing;Linear programming;Genetic algorithms;Genetics;Sociology;Test Case Selection;Regression Testing;Orthogonal Design;Singular Value Decomposition;Genetic Algorithms;Empirical Studies;Test case selection;regression testing;orthogonal design;singular value decomposition;genetic algorithms;empirical studies},
  doi={10.1109/TSE.2014.2364175},
  ISSN={1939-3520},
  month={April},}@INPROCEEDINGS{7809434,
  author={Wang, Xiaolin and Zeng, Hongwei},
  booktitle={2016 IEEE/ACM International Workshop on Continuous Software Evolution and Delivery (CSED)}, 
  title={History-Based Dynamic Test Case Prioritization for Requirement Properties in Regression Testing}, 
  year={2016},
  volume={},
  number={},
  pages={41-47},
  abstract={Regression testing is an important but extremely costly and time-consuming process. Because of limited resources in practice, test case prioritization focuses on the improvement of testing efficiency. However, traditional test case prioritization techniques emphasize only one-time testing without considering huge historical data generated in regression testing. This paper proposes an approach to prioritizing test cases based on historical data. Requirements are a significant factor in the testing process, the priorities of test cases are initialized based on requirement priorities in our history-based approach, and then are calculated dynamically according to historical data in regression testing. To evaluate our approach, an empirical study on an industrial system is conducted. Experimental results show an improved performance for our proposed method using measurements of Average Percentage of Faults Detected and Fault Detection Rate.},
  keywords={Software;History;Fault detection;Complexity theory;Software testing;Time factors;Test Case Prioritization; Requirement Property; History Data; Regression Testing},
  doi={10.1145/2896941.2896949},
  ISSN={},
  month={May},}@INPROCEEDINGS{7475187,
  author={Tumeng, Rooster and Jawawi, Dayang Norhayati Abang and Isa, Mohd Adham},
  booktitle={2015 9th Malaysian Software Engineering Conference (MySEC)}, 
  title={Test case prioritization with textual comparison metrics}, 
  year={2015},
  volume={},
  number={},
  pages={7-12},
  abstract={Regression testing of a large test pool consistently needs a prioritization technique that caters requirements changes. Conventional prioritization techniques cover only the methods to find the ideal ordering of test cases neglecting requirement changes. In this paper, we propose string dissimilarity-based priority assignment to test cases through the combination of classical and non-classical textual comparison metrics and elaborate a prioritization algorithm considering requirement changes. The proposed technique is suitable to be used as a preliminary testing when the information of the entire program is not in possession. We performed evaluation on random permutations and three textual comparison metrics and concluded the findings of the experiment.},
  keywords={Measurement;Testing;Silicon;Software;Context;Software engineering;Programming;textual comparison;test case prioritization;regression testing},
  doi={10.1109/MySEC.2015.7475187},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8991645,
  author={Ali, Sadia and Hafeez, Yaser},
  booktitle={2019 International Conference on Frontiers of Information Technology (FIT)}, 
  title={Enabling Test Case Prioritization For Component Based Software Development}, 
  year={2019},
  volume={},
  number={},
  pages={105-1054},
  abstract={Frequent evolution of modern software systems increases complexity and system failure. Therefore, to overcome these issues the component-based system was developed that consists of integrated reuse components that work together to perform specific tasks or new application development. Mostly component based systems use configuration capabilities to adopt the changes and external uncertainties. Quality of these systems can be assessed through customer satisfaction after modification to verify the performance during maintenance activities. Software engineers for high-reliability, overall requirements functionality needs to verify before release of new product. One of the common ways to evaluate system quality in a sequence of releases is regression testing. Software quality engineers use to ensure that no faults introduced after changes. The purpose of this research work to identify the limitations in existing studies that create complexity and increase efforts during testing component based software and eliminate those factors through the proposed approach. The mixed research methodology will be followed in this context comprising qualitative and quantitative methods. To investigate the potential benefits of the proposed approach; will be performed a case study and experiment. Preliminary results indicated that the proposed approach significantly improve faults detection rate after changes alongwith less effort and cost in component based system development.},
  keywords={Component Based Software, Regression Testing, Test Case Prioritization},
  doi={10.1109/FIT47737.2019.00029},
  ISSN={2334-3141},
  month={Dec},}@INPROCEEDINGS{7148505,
  author={Singal, Prerna and Mishra, Anil K and Singh, Latika},
  booktitle={International Conference on Computing, Communication & Automation}, 
  title={Test case selection for regression testing of applications using web services based on WSDL specification changes}, 
  year={2015},
  volume={},
  number={},
  pages={908-913},
  abstract={There is much enthusiasm around web services in today's world. Web Services take the advantage of internet to communicate between two electronic devices connected via a network. Testing a Web Service is a challenge as the Service Requester does not have the source code and somehow needs to fully test the impact of changes on his application. Regression testing verifies the integrity of the application and makes sure that the changes have not introduced new software errors. Our approach involves the parsing of the WSDL XML file to extract information regarding the operation name, input message and output message. Both the original and changed XML files for the web service are parsed to extract their respective information from the port type and message element of WSDL. Then, we generate a hash table form the extracted information for both the original and delta WSDL. We pass the hash tables to a Comparator as input, which then compares the hash tables and generates the operation changes as output. In the last step test cases are selected for regressing testing of the changed web service based upon the changes in operations provided by the comparator.},
  keywords={Web services;Testing;XML;Ports (Computers);Unified modeling language;Data mining;Automation;Web Services;Regression Testing;Hash Table;WSDL},
  doi={10.1109/CCAA.2015.7148505},
  ISSN={},
  month={May},}@INPROCEEDINGS{10174146,
  author={Greca, Renan and Miranda, Breno and Bertolino, Antonia},
  booktitle={2023 IEEE/ACM International Conference on Automation of Software Test (AST)}, 
  title={Orchestration Strategies for Regression Test Suites}, 
  year={2023},
  volume={},
  number={},
  pages={163-167},
  abstract={Regression testing is widely studied in the literature, although most research on the topic is concerned with improving specific sub-challenges of a wider goal. Test suite orchestration proposes a more comprehensive view of the challenge of regression testing, by merging and combining different techniques with a variety of objectives, including prioritizing, selecting, reducing and amplifying tests, detecting flaky tests and potentially more. This paper presents the key approaches and techniques that form test suite orchestration, along with common evaluation metrics, and discusses how they can be used together to ultimately provide an efficient and effective regression testing strategy. To illustrate the benefits of orchestration, we provide some examples of existing papers that take steps towards this goal, even if the specific terminology is not yet used. Orchestrated strategies utilizing existing regression testing techniques provide a pathway to practicality and real-world usage of the academic literature.},
  keywords={Software testing;Measurement;Automation;Terminology;Merging;Software;software testing;regression testing;test case selection;test case prioritization;test suite reduction;test suite amplification;flaky test detection;test suite orchestration},
  doi={10.1109/AST58925.2023.00020},
  ISSN={2833-9061},
  month={May},}@ARTICLE{7314957,
  author={Hao, Dan and Zhang, Lu and Zang, Lei and Wang, Yanbo and Wu, Xingxia and Xie, Tao},
  journal={IEEE Transactions on Software Engineering}, 
  title={To Be Optimal or Not in Test-Case Prioritization}, 
  year={2016},
  volume={42},
  number={5},
  pages={490-505},
  abstract={Software testing aims to assure the quality of software under test. To improve the efficiency of software testing, especially regression testing, test-case prioritization is proposed to schedule the execution order of test cases in software testing. Among various test-case prioritization techniques, the simple additional coverage-based technique, which is a greedy strategy, achieves surprisingly competitive empirical results. To investigate how much difference there is between the order produced by the additional technique and the optimal order in terms of coverage, we conduct a study on various empirical properties of optimal coverage-based test-case prioritization. To enable us to achieve the optimal order in acceptable time for our object programs, we formulate optimal coverage-based test-case prioritization as an integer linear programming (ILP) problem. Then we conduct an empirical study for comparing the optimal technique with the simple additional coverage-based technique. From this empirical study, the optimal technique can only slightly outperform the additional coverage-based technique with no statistically significant difference in terms of coverage, and the latter significantly outperforms the former in terms of either fault detection or execution time. As the optimal technique schedules the execution order of test cases based on their structural coverage rather than detected faults, we further implement the ideal optimal test-case prioritization technique, which schedules the execution order of test cases based on their detected faults. Taking this ideal technique as the upper bound of test-case prioritization, we conduct another empirical study for comparing the optimal technique and the simple additional technique with this ideal technique. From this empirical study, both the optimal technique and the additional technique significantly outperform the ideal technique in terms of coverage, but the latter significantly outperforms the former two techniques in terms of fault detection. Our findings indicate that researchers may need take cautions in pursuing the optimal techniques in test-case prioritization with intermediate goals.},
  keywords={Software;Measurement;Schedules;Fault detection;Integer linear programming;Software testing;Test-Case Prioritization;Integer Linear Programming;Greedy Algorithm;Empirical Study;Test-case prioritization;integer linear programming;greedy algorithm;empirical study},
  doi={10.1109/TSE.2015.2496939},
  ISSN={1939-3520},
  month={May},}@INPROCEEDINGS{7176241,
  author={Akimoto, Shun and Yaegashi, Rihito and Takagi, Tomohiko},
  booktitle={2015 IEEE/ACIS 16th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={Test case selection technique for regression testing using differential control flow graphs}, 
  year={2015},
  volume={},
  number={},
  pages={1-3},
  abstract={This paper shows a new technique to select effective test cases for regression testing of software. In the technique, an UCN (update complexity number) of each module of software under test is calculated based on a differential control flow graph, and then test cases that execute modules with larger UCNs are selected automatically.},
  keywords={Flow graphs;Software;Complexity theory;Measurement;Software testing;Merging;software testing;regression testing;test case;structured chart;control flow graph},
  doi={10.1109/SNPD.2015.7176241},
  ISSN={},
  month={June},}@INPROCEEDINGS{6571611,
  author={Buchgeher, Georg and Ernstbrunner, Christian and Ramler, Rudolf and Lusser, Michael},
  booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation Workshops}, 
  title={Towards Tool-Support for Test Case Selection in Manual Regression Testing}, 
  year={2013},
  volume={},
  number={},
  pages={74-79},
  abstract={Manual regression testing can be a time-intensive and costly activity. Required efforts can be reduced by selecting only the tests for re-testing that verify actually modified system parts. However, if testers are not familiar with the system implementation the selection of relevant test cases may become difficult. In this paper we report on our experiences with the development of a tool-based approach supporting the selection of manual regression tests. The presented approach is developed together with the software testing department of an international company. Test cases are selected by analyzing different kinds of information resources, i.e., code coverage information and data provided by versioning systems. Experience shows that code coverage information can assist in selecting candidate test cases for regression testing. However, we also encountered some principal challenges in implementing test case selection in practice: Relying solely on code coverage often leads to a large set of test cases, available versioning systems lack the necessary details to map code changes to relevant structural elements, and collecting and keeping coverage data for manual regressing testing up-to-date involves additional costs and effort.},
  keywords={Testing;Manuals;User interfaces;Software systems;Hardware;Context;regression testing;test suite reduction;test case selection;manual testing},
  doi={10.1109/ICSTW.2013.16},
  ISSN={},
  month={March},}@INPROCEEDINGS{10393597,
  author={Han, Kangwei and Song, Yinglei and Zhang, Yaying},
  booktitle={2023 IEEE 11th International Conference on Information, Communication and Networks (ICICN)}, 
  title={Regression Test Case Selection Based on multi-objective Optimization and Improved Harmonic Search Algorithms}, 
  year={2023},
  volume={},
  number={},
  pages={830-834},
  abstract={Regression testing is a method for catching errors generated during version updates of a product. Retesting all existing test cases is its most reliable strategy, but the resulting testing costs are significant. This paper proposes a regression test case selection method based on multi-objective optimization and an improved harmonic search algorithm. Regression test cases are selected from the set of existing test cases to meet the test adequacy criteria and the coverage of faults, unique coverage and algorithm execution time are used as performance metrics to achieve the optimization criteria. The performance of the proposed approach was evaluated by comparing it with the Particle swarm algorithm. The results of the statistical tests show a more significant improvement compared to existing methods.},
  keywords={Measurement;Costs;Redundancy;Harmonic analysis;Reliability;Particle swarm optimization;Optimization;regression test;test case selection;multi-target search;harmony search},
  doi={10.1109/ICICN59530.2023.10393597},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10301343,
  author={Yu, Xiaolei and Jia, Kai and Hu, Wenhua and Tian, Jing and Xiang, Jianwen},
  booktitle={2023 IEEE 34th International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Black-Box Test Case Prioritization Using Log Analysis and Test Case Diversity}, 
  year={2023},
  volume={},
  number={},
  pages={186-191},
  abstract={Regression testing is a software testing type that examines whether updates made in the software impact the existing functionality of the application. Depressingly, the long testing time and high testing costs make regression testing very expensive. Test case prioritization (TCP) stands out as one of the extensively researched regression testing techniques. It prioritizes test cases to optimize their execution order, aiming to maximize the prioritization goals and reveal faults earlier to provide feedback to testers. The TCP technique based on log analysis (LogTCP) designs the prioritization strategy using logs generated during test case execution. However, LogTCP’s performance is limited by its inability to incorporate the diversity of test cases for sorting. To overcome these concerns, we propose a method to implement TCP using k-means clustering and log analysis(called KL-TCP), that takes into account both log information and test case diversity. We examine the effectiveness of this strategy in ten open source Java projects on GitHub. The experimental results show that our proposed method outperforms LogTCP method by detecting a higher average percentage of faults. The best average performance of the ten project experiments reached 0.77(APFD).},
  keywords={Software testing;Java;Fault detection;Semantics;Feature extraction;Software reliability;History;test case prioritization;test case diversity;log parsing},
  doi={10.1109/ISSREW60843.2023.00072},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8991616,
  author={Afzal, Tehseen and Nadeem, Aamer and Sindhu, Muddassar and uz Zaman, Qamar},
  booktitle={2019 International Conference on Frontiers of Information Technology (FIT)}, 
  title={Test Case Prioritization Based on Path Complexity}, 
  year={2019},
  volume={},
  number={},
  pages={363-3635},
  abstract={Software undergoes many modifications after its release. Regression testing is performed to ensure that the modification has not introduced any errors in the software and the software continues to work correctly. Regression testing is an expensive process. Three types of cost reduction techniques are used in regression testing. These techniques i.e., test case selection, test suite minimization and test case prioritization are used to reduce the cost of regression testing and improve the rate of fault detection. The focus of our research is on test case prioritization. Instead of minimizing test suite or selecting fewer test cases, test case prioritization orders test cases in such a way that the test cases detecting more faults are executed earlier. In case of limited resources, only top priority test cases are executed to ensure the reliability of the software. In this research, we have proposed an approach which uses path complexity and branch coverage to prioritize test cases based on assumption that the complex code is more likely to contain faults. Halstead's metric has been used to calculate the path complexity of the test cases. Proposed approach is compared with branch coverage based prioritization technique using some example programs. The results show that proposed approach outperforms existing branch coverage based approach in terms of APFD (Average Percentage of Faults Detected) up to 18% on average.},
  keywords={regression testing;test case prioritization},
  doi={10.1109/FIT47737.2019.00074},
  ISSN={2334-3141},
  month={Dec},}@INPROCEEDINGS{7058806,
  author={Hsu, Yen-Ching and Peng, Kuan-Li and Huang, Chin-Yu},
  booktitle={2014 IEEE International Conference on Industrial Engineering and Engineering Management}, 
  title={A study of applying severity-weighted greedy algorithm to software test case prioritization during testing}, 
  year={2014},
  volume={},
  number={},
  pages={1086-1090},
  abstract={Regression testing is a very useful technique for software testing. Traditionally, there are several techniques for test case prioritization; two of the most used techniques are Greedy and Additional Greedy Algorithm (GA and AGA). However, it can be found that they may not consider the severity while prioritizing test cases. In this paper, an Enhanced Additional Greedy Algorithm (EAGA) is proposed for test case prioritization. Experiments with eight subject programs are performed to investigate the effects of different techniques under different criteria and fault severity. Experimental results show that proposed EAGA perform well than other techniques.},
  keywords={Greedy algorithms;Software testing;Fault detection;Software engineering;Software;Schedules;Test case prioritization;code coverage;search algorithm;APFD;APFDc},
  doi={10.1109/IEEM.2014.7058806},
  ISSN={2157-362X},
  month={Dec},}@INPROCEEDINGS{9440156,
  author={Azizi, Maral},
  booktitle={2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={A Tag-based Recommender System for Regression Test Case Prioritization}, 
  year={2021},
  volume={},
  number={},
  pages={146-157},
  abstract={In continuous integration development environments (CI), the software undergoes frequent changes due to bug fixes or new feature requests. Some of these changes may accidentally cause regression issues to the newly released software version. To ensure the correctness of the newly released software, it is important to perform enough testing prior to code submission to avoid breaking builds. Regression testing is one of the important maintenance activities that can control the quality and reliability of modified software, but it can also be very expensive. Test case prioritization can reduce the costs of regression testing by reordering test cases to meet testing objectives better. To date, various test prioritization techniques have been developed, however, the majority of the proposed approaches utilize static or dynamic analyses to decide which test cases should be selected. These analyses often have significant cost overhead and are time consuming. This paper introduces a new method for automatic test case prioritization in a CI environment intending to minimize the testing cost. Our proposed approach uses information retrieval to automatically select test cases based on their textual similarity to the portion of the code that has been changed. Our technique not only helps developers to organize and manage the software repository but also helps them to find the relevant resources quickly. To evaluate our approach, we performed an empirical study using 37 versions of 6 open source applications. The results of our empirical study indicate that our proposed method can improve the effectiveness and efficiency of test case prioritization technique.},
  keywords={Software testing;Conferences;Computer bugs;Maintenance engineering;Information retrieval;Software;Software reliability;Regression Testing;Test Case Prioritization;IR-based Regression Testing;Recommender Systems;Continuous Integration;Tag-based Recommender System},
  doi={10.1109/ICSTW52544.2021.00035},
  ISSN={},
  month={April},}@INPROCEEDINGS{6830456,
  author={Cingiz, M. Özgür and Temei, Şefik and Kahpsız, Oya},
  booktitle={2014 22nd Signal Processing and Communications Applications Conference (SIU)}, 
  title={Test case prioritization with improved genetic algorithm}, 
  year={2014},
  volume={},
  number={},
  pages={1223-1226},
  abstract={In software development, the most time consuming phase is maintenance. Regression testing, which is a part of maintenance, deals with test case prioritization that aims to increase rate of fault detection with less number of tests. In our study, we used 100 tests and 1000 faults; however, faults are detected by tests using genetic algorithm and improved genetic algorithm. After test case prioritization, we may detect all faults with less number of tests so there'll no need to apply all 100 tests (re-test).},
  keywords={Software engineering;Signal processing;Conferences;Genetic algorithms;Software;Maintenance engineering;Testing;Anahtar Kelimeler;regression test;test case prioritization;genetic algorithms;hybrid algorithms},
  doi={10.1109/SIU.2014.6830456},
  ISSN={2165-0608},
  month={April},}@INPROCEEDINGS{7557497,
  author={Ji, Shunhui and Li, Bixin and Zhang, Pengcheng},
  booktitle={2016 IEEE International Conference on Services Computing (SCC)}, 
  title={Test Case Selection for Data Flow Based Regression Testing of BPEL Composite Services}, 
  year={2016},
  volume={},
  number={},
  pages={547-554},
  abstract={BPEL(Business Process Execution Language) composite service evolves a lot in its lifetime. Regression testing must be performed to ensure the correctness of each evolved version. In this article, an approach is proposed to select test cases for regression testing based on data flow testing criterion. With XCFG(eXtended Control Flow Graph) modeling BPEL composite service, the approach improves the traditional data flow analysis to compute the def-use pairs in BPEL process, and then identifies the affected def-use pairs by comparing the def-use pairs and XCFG model in the evolved version with those in the baseline version, where related WSDL(Web Service Description Language) documents are incorporated for comparison. The data flow paths covering the affected def-use pairs are calculated for regression testing, and some of them can reuse the test cases in the baseline version, which are determined by analyzing the path condition of data flow paths between two versions. The proposed approach can detect three kinds of changes, including process change, binding change and interface change. Experimental study shows the effectiveness.},
  keywords={Testing;Data models;Analytical models;Computational modeling;Concurrent computing;Nanoelectromechanical systems;Concrete;Web composite service;regression testing;data flow testing;test case selection},
  doi={10.1109/SCC.2016.77},
  ISSN={},
  month={June},}@INPROCEEDINGS{7724438,
  author={Priyanka and Kumar, Harish and Chauhan, Naresh},
  booktitle={2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={A novel approach for selecting an effective regression testing technique}, 
  year={2016},
  volume={},
  number={},
  pages={1122-1125},
  abstract={All software systems need modifications with time, these modifications involve different types or amounts of code modifications in different versions. To validate these modifications many regression testing sessions are needed. But researchers do not have a single regression testing technique that can be used on every version. The objective of this scrutiny is to evolve a methodology that attempts to determine the re-testing technique that would be effective for every re-testing period accounting testing domain and conditions. This methodology is based on Revised Analytical Hierarchy Process (Revised AHP). There are numerous regression testing techniques. But this investigation is limited to test case prioritization techniques only. The result showed that prioritization techniques selected by proposed technique are more efficacious than those used by the forgoing techniques.},
  keywords={Decision making;Matrices;Software testing;Electronic mail;Software systems;multiple criteria decision making approach;Regression testing;Revised Analytical Hierarchy process;Test case prioritization techniques},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{8281742,
  author={Abid, Robeala and Nadeem, Aamer},
  booktitle={2017 13th International Conference on Emerging Technologies (ICET)}, 
  title={A novel approach to multiple criteria based test case prioritization}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={When software is modified, it is retested to ensure that no new faults have been introduced in the previously tested code and it still works correctly. Such testing is known as regression testing. The cost of regression testing is high because the original program has large number of test cases. It is not feasible to execute all test cases for regression testing. Test suite minimization, test case selection and test case prioritization are cost commonly used techniques in regression testing to reduce the cost of regression testing. While test suite minimization and test case selection techniques select a subset of test cases, test case prioritization does not eliminate any test case, it only orders the test cases with the objective of increasing the fault detection rate. Prioritization is usually preferred over other two approaches because it does not involve the risk of losing useful test cases. Prioritization techniques assign priority to each test case on the basis of some coverage criteria. A number of different single criterion and multiple criteria based prioritization techniques have been proposed in the literature. Multiple criteria based prioritization techniques perform better than single criterion based prioritization techniques. The existing multiple criteria based prioritization techniques combine the criteria in such a way that “Additional” strategy cannot be applied on them. In this paper, we propose a new multiple criteria based test case prioritization algorithm that considers two criteria to prioritize test cases using “Additional” strategy. One criterion is considered as primary and other is considered as secondary. Primary criterion is used to prioritize the test cases whereas secondary criterion is used to break the tie among test cases when two or more test cases provide equal coverage of entities of first criterion. Our proposed multiple criteria based prioritization algorithm performs better than the existing prioritization techniques.},
  keywords={Software;Minimization;Fault detection;Software algorithms;History;Software testing},
  doi={10.1109/ICET.2017.8281742},
  ISSN={},
  month={Dec},}@ARTICLE{8819910,
  author={Bajaj, Anu and Sangwan, Om Prakash},
  journal={IEEE Access}, 
  title={A Systematic Literature Review of Test Case Prioritization Using Genetic Algorithms}, 
  year={2019},
  volume={7},
  number={},
  pages={126355-126375},
  abstract={Regression testing is the essential process of software maintenance and evolution phase of the software development life cycle for assuring the quality and reliability of updated software. Test case prioritization is the technique of regression testing to reduce the time and effort required for regression testing. Search-based algorithms are used to enhance the efficiency and effectiveness of the method. Among these search-based optimization algorithms, genetic algorithms are becoming more popular among researchers since the last decade. In this paper, we are doing a systematic literature review, i.e., a secondary study of test case prioritization using genetic algorithms. The objective of this review is to examine and classify the current state of use of the genetic algorithm in test case prioritization. In other words, to give a base for the advancement of test case prioritization research using genetic algorithms. With the use of the systematic literature review protocol, we selected the most relevant studies (20 out of 384) from the appropriate repositories by using a set of search keywords, inclusion/exclusion criteria and the quality assessment of studies. The data extraction and synthesis process and the taxonomic classification are used to answer the research questions. We also performed a rigorous analysis of the techniques by comparing them on research methodology, the prioritization method, dataset specification, test suite size, types of genetic algorithms used, performance metrics, and the validation criteria. The whole process took four months for comprehensive analysis and classification of primary studies. We observed that the parameter settings, the type of operators, the probabilistic rate of operators, and fitness function design have a significant impact on the quality of the solutions obtained. This systematic literature review yields that genetic algorithms have great potential in solving test case prioritization problems, and the area is open for further improvements. Future researchers can fill the research gaps by following the suggestions given in the review. From this review, we found that the use of the appropriate approach can make a genetic algorithm based test case prioritization one of the effective methods in regression testing.},
  keywords={Genetic algorithms;Software;Systematics;Testing;Sociology;Statistics;Bibliographies;Genetic algorithm;NSGA-II;regression testing;systematic review;test case prioritization},
  doi={10.1109/ACCESS.2019.2938260},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8117002,
  author={Vescan, Andreea and Şerban, Camelia and Chisăliţă-Cretu, Camelia and Dioşan, Laura},
  booktitle={2017 13th IEEE International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
  title={Requirement dependencies-based formal approach for test case prioritization in regression testing}, 
  year={2017},
  volume={},
  number={},
  pages={181-188},
  abstract={Regression testing is the testing activity performed after changes occurred on software. Its aim is to increase confidence that achieved software adjustments have no negative impact on the already functional parts of the software. Test case prioritization is one technique that could be applied in regression testing with the aim to find faults early, resulting in reduced cost and shorten time of testing activities. Thus, prioritizing in the context of regression testing means to re-order test cases such that high priority ones are run first. The current paper addresses the test case prioritization as a consistent part of a larger approach on regression testing, which combines both test case prioritization and test case selection in order to overcome the limitations of each of them. A comprehensive formalization of test case prioritization is provided, incorporating beside the well known ingredients (test case, test requirement, fault, cost) also elements relating to the functional requirements and dependencies between requirements. An evolutionary algorithm is used to construct the re-ordering of test cases, considering as optimization objectives fault detection and cost. A synthetic case study was used to empirically prove our perspective for test case prioritization approach.},
  keywords={Testing;Software;Evolutionary computation;Fault detection;Optimization;Measurement;Search problems},
  doi={10.1109/ICCP.2017.8117002},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10499739,
  author={Puviskar, S. Prabath and Wasalthilaka, W.V.S.K. and Kumara, B.T.G.S},
  booktitle={2024 4th International Conference on Advanced Research in Computing (ICARC)}, 
  title={Performance Evaluation of Clustering Algorithms for Enhancing Test Case Prioritization in Regression Testing}, 
  year={2024},
  volume={},
  number={},
  pages={300-305},
  abstract={Regression testing plays a crucial role in maintain software quality as applications evolving and getting more complex. Selection of a regression testing technique significantly influences overall software quality. In initial stages, this involves picking relevant test cases and remove unnecessary redundancies during minimization phase. Finally, prioritization of test cases phases most important ones is executed first which continue process iteratively or whole testing carried out which effect time and cost intensively. Test Case Prioritization method effective way to address the issue. In this study, we proposed approach to enhance Test Case Prioritization by integrating fault based methods and time of execution analysis. The study also evaluates the efficiency in proposed methodology through, employing APFD metric. The study aims to improve the precision and effectiveness of test case prioritization methods, advancing overall quality and reliability in dynamic software development environments. Notably, AHC outperforms in comparisons, showcasing its efficacy in improving outcomes.},
  keywords={Software testing;Performance evaluation;Heuristic algorithms;Scalability;Software algorithms;Clustering algorithms;Termination of employment;Test Case Prioritization;K-Mean;Expectation Maximization;Agglomerative Hierarchical Clustering;Spectral Clustering},
  doi={10.1109/ICARC61713.2024.10499739},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{7962333,
  author={Sun, Chang-Ai and Fan, Cuiyang and Wang, Zhen and Liu, Huai},
  booktitle={2017 IEEE/ACM 12th International Workshop on Automation of Software Testing (AST)}, 
  title={d(mu)Reg: A Path-Aware Mutation Analysis Guided Approach to Regression Testing}, 
  year={2017},
  volume={},
  number={},
  pages={59-64},
  abstract={Regression testing re-runs some previously executed test cases, with the purpose of checking whether previously fixed faults have re-emerged and ensuring that the changes do not negatively affect the existing behaviors of the software under development. Today's software is rapidly developed and evolved, and thus it is critical to implement regression testing quickly and effectively. In this paper, we propose a novel technique for regression testing, based on a family of mutant selection strategies. The preliminary results show that the proposed technique can significantly improve the efficiency of different regression testing activities, including test case reduction and prioritization. Our work also makes it possible to develop a unified framework that effectively implements various activities in regression testing.},
  keywords={Software testing;Schedules;History;Sun;Software systems;regression testing;test case reduction;test case prioritization;mutation analysis;path depth},
  doi={10.1109/AST.2017.8},
  ISSN={},
  month={May},}@INPROCEEDINGS{10199547,
  author={Nithya, B. and Prasanthi, B.G.},
  booktitle={2023 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)}, 
  title={Fuzzy and ANN based model for Test case prioritization for Regression testing}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={This research article performs the prioritization of the test case to test the software system after the occurrence of changes for Regression testing. The test expert here will categorize the sets as Optimistic test cases and Pessimistic test cases as formatted data for preprocessing by the Fuzzy rules. The optimistic test cases ensure that they are considered for regression testing by the tester. They are allowed to go into the next phase for deciding the prioritization. The test case is expected to have the details of case_id, case_name, case_details, predicted_result, obtained_result, seconds_time, and status. The ANN model deployed, gives the ranking to only Optimistic test cases by ensuring its capability to a dynamic environment. The efficiency of the regression testing on the proposed ANN model is evaluated by representing the faults, statements, and paths using the average percentage. The results provide a superior value above 95% when compared to the other methods taken in literature survey. The future scope of this ANN-based model can be used for prioritizing, selecting, and categorizing every cycle using reinforcement learning methods.},
  keywords={Surveys;Computational modeling;Reinforcement learning;Software systems;Informatics;Testing;Software testing;Test case prioritization;Regression testing;Fuzzy;ANN;APF;APS;APP},
  doi={10.1109/ACCAI58221.2023.10199547},
  ISSN={},
  month={May},}@INPROCEEDINGS{7273631,
  author={Wang, Hongda and Xing, Jianchun and Yang, Qiliang and Han, Deshuai and Zhang, Xuewei},
  booktitle={2015 IEEE 39th Annual Computer Software and Applications Conference}, 
  title={Modification Impact Analysis Based Test Case Prioritization for Regression Testing of Service-Oriented Workflow Applications}, 
  year={2015},
  volume={2},
  number={},
  pages={288-297},
  abstract={Test case prioritization for regression testing is an approach that schedules test cases to improve the efficiency of service-oriented workflow application testing. Most of existing prioritization approaches range test cases according to various metrics (e.g., Statement coverage, path coverage) in different application context. Service-oriented workflow applications orchestrate web services to provide value-added service and typically are long-running and time-consuming processes. Therefore, these applications need more precise prioritization to execute earlier those test cases that may detect failures. Surprisingly, most of current regression test case prioritization researches neglect to use internal structure information of software, which is a significant factor influencing the prioritization of test cases. Considering the internal structure information and fault propagation behavior of modifications respect to modified version for service-oriented workflow applications, we present in this paper a new regression test case prioritization approach. Our prioritization approach schedules test cases based on dependence analysis of internal activities in service-oriented workflow applications. Experimental results show that test case prioritization using our approach is more effective than conventional coverage-based techniques.},
  keywords={Testing;Correlation;Software;Synchronization;Schedules;Fault detection;Programmable logic arrays;test case prioritization;dependence analysis;service-oriented workflow applications;modification impact},
  doi={10.1109/COMPSAC.2015.11},
  ISSN={0730-3157},
  month={July},}@ARTICLE{10223041,
  author={Nazir, Muhammad and Mehmood, Arif and Aslam, Waqar and Park, Yongwan and Choi, Gyu Sang and Ashraf, Imran},
  journal={IEEE Access}, 
  title={A Multi-Goal Particle Swarm Optimizer for Test Case Prioritization}, 
  year={2023},
  volume={11},
  number={},
  pages={90683-90697},
  abstract={Regression testing is carried out to test the updated supply code within the constraints of time and sources. Since it is very difficult to run all the updated source code every time, test case prioritization is needed to decrease the fee of regression testing. Various methodologies including extensions of white box and black box prioritization, have been presented considering the prioritization of test instances. In this context, the employment of particle swarm optimization (PSO) is usually recommended for test case prioritization. Single test case prioritization focuses to order test cases to maximize objectives like fault detection rate, execution time, etc. Regression testing for single-objective test suite prioritization can become challenging due to its longer execution time. However, test case prioritization for multi-objective functions is a complex and time-consuming task. A check suite may be organized in a certain order by an appropriate technique, subsequently permitting the detection of flaws as early as possible. Multi-goal particle swarm optimization (MOPSO) is used for case prioritization in regression testing. The purpose of MOPSO in this context is to organize the test suite in a specific order that maximizes fault coverage, provides sufficient coverage of test cases, and minimizes execution time. This study proposes an approach based on MOPSO that focuses on maximum fault coverage, most circumstance insurance, and minimal execution time. Experiments are performed using the average percentage of faults detected (APFD) to evaluate its performance. Performance analysis using APFD consisting of no order, opposite order, and random order indicates that the MOPSO surpasses all the previous techniques and obtains an 85% fault coverage. Moreover, MOPSO is better in terms of execution time, fault detection fee, and early detection capabilities.},
  keywords={Testing;Particle swarm optimization;Software algorithms;Costs;Software testing;Genetic algorithms;Fault detection;Test case prioritization;regression testing;particle swarm optimization genetic algorithm;fault detection},
  doi={10.1109/ACCESS.2023.3305973},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7885851,
  author={Ammar, Asmaa and Baharom, Salmi and Ghani, Abdul Azim Abd and Din, Jamilah},
  booktitle={2016 International Conference on Information Science and Security (ICISS)}, 
  title={Enhanced Weighted Method for Test Case Prioritization in Regression Testing Using Unique Priority Value}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Regression testing is an integral and expensive part in software testing. To reduce its effort, test case prioritization approaches were proposed. The problem with most of the existing approaches is the random ranking of test cases with equal weight. In this paper, an enhanced weighted method to prioritize the full test suite without using random ranking is presented. In addition, a controlled experiment was executed to evaluate the effectiveness of the proposed method. The results show an improved performance in terms of prioritizing test cases and recording higher APFD values over the original weighted method. In future, a larger experiment would be executed to generalize the results.},
  keywords={Software;Software testing;Minimization;Sorting;Computer science;Information technology},
  doi={10.1109/ICISSEC.2016.7885851},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10507913,
  author={Behera, Aishwaryarani and Acharya, Arup Abhinna and Mohanty, Sanjukta and Panda, Namita},
  booktitle={2024 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)}, 
  title={Designing a Multi-Class Classification Optimized Model for Requirement based Test Case Prioritization}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Most of the times we have to test out the entire application functionality, for any code modification done to cater the need of the larger audiences or any bug fixes. This results to consumption of time and the effort to retest the application by executing all of the test suites. In such cases more often regression testing comes to the rescue, where prioritization techniques are being used to overcome the limitations of regression testing. Test Case Prioritization (TCP) usually means categorically ranking some test cases higher than others. The main goal of the TCP is to find the fault early in the testing process by scheduling the test cases with the help of Requirement based Test Case Prioritization Technique (RTCP) in order to increase effectiveness of regression testing. In this research study, we have developed a supervised machine learning based RTCP mechanism where the significant business requirement based relevant feature are considered for scheduling test cases according to their priority label as high, medium and low multi classes. The proposed model is validated with the two datasets collected from internet sources. The machine learning classifier k-Nearest Neighbor (K-NN), Decision Tree (DT), Random Forest (RF) Bagging and Boosting algorithm are utilized to evaluate the features for the test case prioritization. To enhance the performance of the model some hyper parameter settings are altered and found a drastic change in the results. To achieve the low cost and high fault detection rate in RTCP, an optimized model is designed which is validated by datasets and altered parameter settings. The experimental result demonstrates that RF classifier achieved the best performance among the other classifiers for predicting the prioritized test cases early to reduce the cost and time required for regression testing.},
  keywords={Costs;Machine learning algorithms;Codes;Fault detection;Computational modeling;Computer bugs;Tuning;Machine Learning;multi-class classification;Test case prioritization;Regression testing;Requirement based testing;Hyper-Parameter Tuning},
  doi={10.1109/ASSIC60049.2024.10507913},
  ISSN={},
  month={Jan},}@ARTICLE{9269420,
  author={Medhat, Noha and Moussa, Sherin M. and Badr, Nagwa Lotfy and Tolba, Mohamed F.},
  journal={IEEE Access}, 
  title={A Framework for Continuous Regression and Integration Testing in IoT Systems Based on Deep Learning and Search-Based Techniques}, 
  year={2020},
  volume={8},
  number={},
  pages={215716-215726},
  abstract={Tremendous systems are rapidly evolving based on the trendy Internet of Things (IoT) in various domains. Different technologies are used for communication between the massive connected devices through all layers of the IoT system, causing many security and performance issues. Regression and integration testing are considered repeatedly, in which the vast costs and efforts associated with the frequent execution of these inflated test suites hinder the adequate testing of such systems. This necessitates the focus on exploring innovative scalable testing approaches for large test suites in IoT-based systems. In this paper, a scalable framework for continuous integration and regression testing in IoT-based systems (IoT-CIRTF) is proposed, based on IoT-related criteria for test case prioritization and selection. The framework utilizes search-based techniques to provide an optimized prioritized set of test cases to select from. The selection is based on a trained prediction model for IoT standard components using supervised deep learning algorithms to continuously ensure the overall reliability of IoT-based systems. The experiments are held on two GSM datasets. The experimental results achieved prioritization accuracy up to 90% and 92% for regression testing and integration testing respectively. This provides an enhanced and efficient framework for continuous testing of IoT-based systems, as per IoT-related criteria for the prioritization and selection purposes.},
  keywords={Testing;Feature extraction;Deep learning;Protocols;Classification algorithms;Unified modeling language;Tools;Deep learning;integration testing;IoT;regression testing;test case prioritization;test case selection;search-based techniques},
  doi={10.1109/ACCESS.2020.3039931},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8305939,
  author={Fu, Wenhao and Yu, Huiqun and Fan, Guisheng and Ji, Xiang and Pei, Xin},
  booktitle={2017 24th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={A Regression Test Case Prioritization Algorithm Based on Program Changes and Method Invocation Relationship}, 
  year={2017},
  volume={},
  number={},
  pages={169-178},
  abstract={Regression testing is essential for assuring the quality of a software product. Because rerunning all test cases in regression testing may be impractical under limited resources, test case prioritization is a feasible solution to optimize regression testing by reordering test cases for the current testing version. In this paper, we propose a new test case prioritization algorithm based on program changes and method (function) invocation relationship. Combining the estimated risk value of each program method (function) and the method (function) coverage information, the fault detection capability of each test case can be calculated. The algorithm reduces the prioritization problem to an integer linear programming (ILP) problem, and finally prioritizes test cases according to their fault detection capabilities. Experiments are conducted on 11 programs to validate the effectiveness of our proposed algorithm. Experimental results show that our approach is more effective than some well studied test case prioritization techniques in terms of average percentage of fault detected (APFD) values.},
  keywords={Fault detection;Testing;Greedy algorithms;Software;Software algorithms;Complexity theory;Heuristic algorithms;regression testing;test case prioritization;program changes;method invocation},
  doi={10.1109/APSEC.2017.23},
  ISSN={},
  month={Dec},}@ARTICLE{8705674,
  author={Huang, Rubing and Sun, Weifeng and Chen, Tsong Yueh and Towey, Dave and Chen, Jinfu and Zong, Weiwen and Zhou, Yunan},
  journal={IEEE Transactions on Reliability}, 
  title={Abstract Test Case Prioritization Using Repeated Small-Strength Level-Combination Coverage}, 
  year={2020},
  volume={69},
  number={1},
  pages={349-372},
  abstract={Abstract test cases (ATCs) have been widely used in practice, including in combinatorial testing and in software product line testing. When constructing a set of ATCs, due to limited testing resources in practice (e.g., in regression testing), test case prioritization (TCP) has been proposed to improve the testing quality, aiming at ordering test cases to increase the speed with which faults are detected. One intuitive and extensively studied TCP technique for ATCs is λ-wise Level-combination Coverage based Prioritization (λLCP), a static, black-box prioritization technique that only uses the ATC information to guide the prioritization process. A challenge facing λLCP, however, is the necessity for the selection of the fixed prioritization strength λ before testing-testers need to choose an appropriate λ value before testing begins. Choosing higher λ values may improve the testing effectiveness of λLCP (e.g., by finding faults faster), but may reduce the testing efficiency (by incurring additional prioritization costs). Conversely, choosing lower λ values may improve the efficiency, but may also reduce the effectiveness. In this paper, we propose a new family of λLCP techniques, Repeated Small-strength Level-combination Coverage-based Prioritization (RSLCP), that repeatedly achieves the full combination coverage at lower strengths. RSLCP maintains λLCP's advantages of being static and black box, but avoids the challenge of prioritization strength selection. We have performed an empirical study involving five different versions of each of five C programs. Compared with λLCP, and Incremental-strength LCP (ILCP), our results show that RSLCP could provide a good tradeoff between testing effectiveness and efficiency. Our results also show that RSLCP is more effective and efficient than two popular techniques of Similarity-based Prioritization (SP). In addition, the results of empirical studies also show that RSLCP can remain robust over multiple system releases.},
  keywords={Software testing;Fault detection;Regression analysis;Level set;Abstract test case;level-combination coverage;regression testing;software testing;test case prioritization},
  doi={10.1109/TR.2019.2908068},
  ISSN={1558-1721},
  month={March},}@INPROCEEDINGS{9440161,
  author={Azizi, Maral},
  booktitle={2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={QRTest: Automatic Query Reformulation for Information Retrieval Based Regression Test Case Prioritization}, 
  year={2021},
  volume={},
  number={},
  pages={254-262},
  abstract={The most effective regression testing algorithms have long running times and often require dynamic or static code analysis, making them unsuitable for the modern software development environment where the rate of software delivery could be less than a minute. More recently, some researchers have developed information retrieval-based (IR-based) techniques for prioritizing tests such that the higher similar tests to the code changes have a higher likelihood of finding bugs. A vast majority of these techniques are based on standard term similarity calculation, which can be imprecise. One reason for the low accuracy of these techniques is that the original query often is short, therefore, it does not return the relevant test cases. In such cases, the query needs reformulation. The current state of research lacks methods to increase the quality of the query in the regression testing domain. Our research aims at addressing this problem and we conjecture that enhancing the quality of the queries can improve the performance of IR-based regression test case prioritization (RTP). Our empirical evaluation with six open source programs shows that our approach improves the accuracy of IR-based RTP and increases regression fault detection rate, compared to the common prioritization techniques.},
  keywords={Software testing;Heuristic algorithms;Conferences;Fault detection;Software algorithms;Computer bugs;Information retrieval;Regression Testing;Test Case Prioritization;Software Repository;IR-based Regression Testing;Query Reformulation},
  doi={10.1109/ICSTW52544.2021.00050},
  ISSN={},
  month={April},}@INPROCEEDINGS{9796413,
  author={Greca, Renan and Miranda, Breno and Gligoric, Milos and Bertolino, Antonia},
  booktitle={2022 IEEE/ACM International Conference on Automation of Software Test (AST)}, 
  title={Comparing and Combining File-based Selection and Similarity-based Prioritization towards Regression Test Orchestration}, 
  year={2022},
  volume={},
  number={},
  pages={115-125},
  abstract={Test case selection (TCS) and test case prioritization (TCP) techniques can reduce time to detect the first test failure. Although these techniques have been extensively studied in combination and isolation, they have not been compared one against the other. In this paper, we perform an empirical study directly comparing TCS and TCP approaches, represented by the tools Ekstazi and FAST, respectively. Furthermore, we develop the first combination, named Fastazi, of file-based TCS and similarity-based TCP and evaluate its benefit and cost against each individual technique. We performed our experiments using 12 Java-based open-source projects. Our results show that, in the median case, the combined approach detects the first failure nearly two times faster than either Ekstazi alone (with random test ordering) or FAST alone (without TCS). Statistical analysis shows that the effectiveness of Fastazi is higher than that of Ekstazi, which in turn is higher than that of FAST. On the other hand, FAST adds the least overhead to testing time, while the difference between the additional time needed by Ekstazi and Fastazi is negligible. Fastazi can also improve failure detection in scenarios where the time available for testing is restricted. CCS CONCEPTS • Software and its engineering →Software testing and debugging.},
  keywords={Costs;Automation;Statistical analysis;Diversity reception;Debugging;Open source software;Testing;regression testing;test case selection;test case prioritization;test orchestration;Fastazi},
  doi={10.1145/3524481.3527223},
  ISSN={},
  month={May},}@INPROCEEDINGS{6844270,
  author={Rai, Deepak and Tyagi, Kirti},
  booktitle={2013 International Conference on Recent Trends in Information Technology (ICRTIT)}, 
  title={Estimating the regression test case selection probability using fuzzy rules}, 
  year={2013},
  volume={},
  number={},
  pages={603-611},
  abstract={Software maintenance is performed regularly for enhancing and adapting the functionalities of the existing software, which modifies the software and breaks the previously verified functionalities. This sets a requirement for software regression testing, making it a necessary maintenance activity. As the evolution of software takes place the size of the test suite tends to grow, which makes it difficult to execute the entire test suite in a time constrained environment. There are many existing techniques for regression test case selection. Some are based on dataflow analysis technique, slicing-based technique, bio-inspired techniques, and genetic algorithm based techniques. This paper gives a regression test case selection technique based on fuzzy model, which reduces the size of the test suite by selecting test cases from existing test suite. The test cases, which are necessary for validating the recent changes in the software and have the ability to find the faults and cover maximum coding under testing in minimum time, are selected. A fuzzy model is designed which takes three parameters namely code covered, execution time and faults covered as input and produces the estimation for the test case selection probability as very low, low, medium, high and very high.},
  keywords={Testing;Fuzzy logic;Maintenance engineering;Software maintenance;Market research;Information technology;Regression testing;Test case selection;Fuzzy logic;Selection probability},
  doi={10.1109/ICRTIT.2013.6844270},
  ISSN={},
  month={July},}@INPROCEEDINGS{7375627,
  author={Solanki, Kamna and Singh, Yudhvir and Dalal, Sandeep},
  booktitle={2015 International Conference on Computer, Communication and Control (IC4)}, 
  title={Test case prioritization: An approach based on modified ant colony optimization (m-ACO)}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  abstract={Intense and widespread usage of software in every field of life has attracted the researchers to focus their attention on developing the methods to improve the efficiency of software testing; which is the most crucial and cost intensive phase of software development. Software testing aims to uncover the potential faults in Application Under Test by running the test cases on software code. Software code keeps on changing as the uncovered faults during testing are fixed by the developers. Regression testing is concerned with verifying the modified software code to ensure that changes in software code does not induce any undesired effect on rest of the code. Test Case Prioritization is a regression testing technique which re-schedule the execution sequence of test cases to improve the fault detection rate and enhance the performance of regression test suite. This paper focuses on proposing a novel method "m-ACO" for test case prioritization and the performance evaluation of the proposed method using Average Percentage of faults Detected.},
  keywords={Software;Software testing;Ant colony optimization;Optimization;Algorithm design and analysis;Fault detection;Software Testing;Regression Testing;Test Case Prioritization;APFD},
  doi={10.1109/IC4.2015.7375627},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8452804,
  author={Choudhary, Ankur and Agrawal, Arun Prakash and Kaur, Arvinder},
  booktitle={2018 IEEE/ACM 11th International Workshop on Search-Based Software Testing (SBST)}, 
  title={An Effective Approach for Regression Test Case Selection Using Pareto Based Multi-Objective Harmony Search}, 
  year={2018},
  volume={},
  number={},
  pages={13-20},
  abstract={Regression testing is a way of catching bugs in new builds and releases to avoid the product risks. Corrective, progressive, retest all and selective regression testing are strategies to perform regression testing. Retesting all existing test cases is one of the most reliable approaches but it is costly in terms of time and effort. This limitation opened a scope to optimize regression testing cost by selecting only a subset of test cases that can detect faults in optimal time and effort. This paper proposes Pareto based Multi-Objective Harmony Search approach for regression test case selection from an existing test suite to achieve some test adequacy criteria. Fault coverage, unique faults covered and algorithm execution time are utilised as performance measures to achieve optimization criteria. The performance evaluation of proposed approach is performed against Bat Search and Cuckoo Search optimization. The results of statistical tests indicate significant improvement over existing approaches.},
  keywords={Optimization;Search problems;Software;Genetic algorithms;Software testing;Software algorithms;Software testing;Regression testing;Optimization;Harmony Search;Bat Search Optimization;Cuckoo Search Optimization;Test case selection},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{10932075,
  author={Garg, Kamal and Agarwal, Rohit and Shekhar, Shashi},
  booktitle={2024 International Conference on Communication, Control, and Intelligent Systems (CCIS)}, 
  title={Explainable Test Case Prioritization in Continuous Integration through Incremental Learning Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In Continuous Integration (CI) environments, where software undergoes frequent updates, regression testing is vital in ensuring software quality. However, rerunning every test case becomes impractical with the constant changes. Test Case Prioritization (TCP) addresses this issue, and Machine Learning (ML) is increasingly used to manage regression testing. However, many ML models struggle to adapt to new features or changes in CI and lack transparency, complicating the regression process. To address these issues, we propose an incremental learning-based explainable ML model for TCP in CI environments, which adaptively incorporates new changes. We use SHapley Additive exPlanations (SHAP) to evaluate feature contributions and help testers understand the model's functionality. Our model is trained and tested on 20 open-source software projects. Its performance is assessed using Accuracy and F1 Score, while test case prioritization is evaluated with the Average Percentage of Faults Detected (APFD) and a new metric, the Failed Test Ranking Score (FTRS).},
  keywords={Software testing;Measurement;Adaptation models;Logistic regression;Transfer learning;Refining;Software quality;Continuous integration;Intelligent systems;Open source software;Continuous Integration;Deep Learning Model;Regression Testing;Software Testing;Test case Prioritization},
  doi={10.1109/CCIS63231.2024.10932075},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7273420,
  author={Zhao, Xiaobin and Wang, Zan and Fan, Xiangyu and Wang, Zhenhua},
  booktitle={2015 IEEE 39th Annual Computer Software and Applications Conference}, 
  title={A Clustering-Bayesian Network Based Approach for Test Case Prioritization}, 
  year={2015},
  volume={3},
  number={},
  pages={542-547},
  abstract={Test case prioritization can effectively reduce the cost of regression testing by executing test cases with respect to their contributions to testing goals. Previous research has proved that the Bayesian Networks based technique which uses source code change information, software quality metrics and test coverage data has better performance than those methods merely depending on only one of the items above. Although the former Bayesian Networks based Test Case Prioritization (BNTCP) focusing on assessing the fault detection capability of each test case can utilize all three items above, it still has a deficiency that ignores the similarity between test cases. For mitigating this problem, this paper proposes a hybrid regression test case prioritization technique which aims to achieve better prioritization by incorporating code coverage based clustering approach with BNTCP to depress the impact of those similar test cases having common code coverage. Experiments on two Java projects with mutation faults and one Java project with hand-seeded faults have been conducted to evaluate the fault detection performance of the proposed approach against Additional Greedy approach, Bayesian Networks based approach (BNTCP), Bayesian Networks based approach with feedback (BNA) and code coverage based clustering approach. The experimental results showed that the proposed approach is promising.},
  keywords={Fault detection;Measurement;Testing;Bayes methods;Software quality;Java;Clustering algorithms;Regression testing; Test case prioritization (TCP); Clustering; Bayesian Network (BN)},
  doi={10.1109/COMPSAC.2015.154},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{10298744,
  author={Rotaru, Ioana-Claudia and Vescan, Andreea},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW)}, 
  title={Test Case Prioritization Based on Neural Network Classification with Artifacts Traceability}, 
  year={2023},
  volume={},
  number={},
  pages={78-87},
  abstract={Regression testing is an important factor in ensuring software system reliability once new changes are introduced, but maintaining complex testing suites in continuous integration environments is challenging. Test case prioritization techniques are a potential solution to this problem by computing a reordered testing suite that can provide better fault detection capabilities. However, current methods rely on manually providing artifact dependencies (requirements to code, code to test cases, test cases to faults) as input. The purpose of this paper is to minimize the gap between automatic dependency computation and test case prioritization by analyzing how Behavior-Driven Development (BDD) practices affect the two tasks. Thus, the first contribution of this paper is related to the design and implementation of an automatic traceability component to retrieve dependencies based on BDD artifacts (requirements, source code, test cases, and faults). The second contribution refers to the integration of the discovered traces as features in a neural network classification model for test cases for further prioritization. Various architectures were used for the neural network classification model. Two real-world BDD projects were used for the validation of the models, comparing the best-performing models with a baseline test case prioritization technique to assess their fault-detection capabilities. Our approach achieved promising fault detection rates that demonstrate the efficiency of automatic traceability and may lead to future applicability to large-scale projects.},
  keywords={Measurement;Codes;Fault detection;Source coding;Neural networks;Training data;Computer architecture;Regression Testing;Test Case Prioritization;Artifact Traceability;Behavior-Driven Development},
  doi={10.1109/ASEW60602.2023.00015},
  ISSN={2151-0849},
  month={Sep.},}@ARTICLE{9328763,
  author={Huang, Yechao and Shu, Ting and Ding, Zuohua},
  journal={IEEE Access}, 
  title={A Learn-to-Rank Method for Model-Based Regression Test Case Prioritization}, 
  year={2021},
  volume={9},
  number={},
  pages={16365-16382},
  abstract={Regression testing plays an indispensable role in software maintenance, which refers to retest the software following modifications to determine whether the changes have introduced new faults. However, regression testing requires massive amounts of effort to achieve a high fault detection rate. To address this issue, the test case prioritization technique is used to improve the fault detection rate by adjusting the execution order of test cases. For model-based regression test case prioritization, existing approaches have been developed using the single aspect of model-related information extracted from the previous executed test cases. In this paper, a novel learn-to-rank technique is proposed to prioritize test cases by combining the multidimensional features of Extended Finite State Machine (EFSM) under test to improve fault detection rate. Specifically, our method utilizes the random forest algorithm to combine multiple existing heuristic prioritization methods. Detailed experiments are conducted to evaluate the proposed method's performance in terms of Average Percentage Fault Detected (APFD). The experimental results show that the mean APFD value of our method reaches 0.884 for five subject EFSMs, which is 33.9% higher than the compared methods.},
  keywords={Testing;Unified modeling language;Software;Fault detection;Software algorithms;Monitoring;Heuristic algorithms;Regression testing;model based testing;EFSM;test case prioritization;learn to rank},
  doi={10.1109/ACCESS.2021.3053163},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9787970,
  author={Abdelkarim, Mohamed and ElAdawi, Reem},
  booktitle={2022 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={TCP-Net: Test Case Prioritization using End-to-End Deep Neural Networks}, 
  year={2022},
  volume={},
  number={},
  pages={122-129},
  abstract={Regression testing is facing a bottleneck due to the growing number of test cases and the wide adoption of continuous integration (CI) in software projects, which increases the frequency of running software builds, making it challenging to run all the regression test cases. Machine learning (ML) techniques can be used to save time and hardware resources without compromising quality. In this work, we introduce a novel end-to-end, self-configurable, and incremental learning deep neural network (DNN) tool for test case prioritization (TCP-Net). TCP-Net is fed with source code-related features, test case metadata, test case coverage information, and test case failure history, to learn a high dimensional correlation between source files and test cases. We experimentally show that TCP-Net can be efficiently used for test case prioritization by evaluating it on three different real-life industrial software packages.},
  keywords={Deep learning;Software testing;Correlation;Software packages;Conferences;Neural networks;Metadata;regression testing;test case prioritization;neural networks;deep learning;fusion network;incremental learning;hyperparameter optimization},
  doi={10.1109/ICSTW55395.2022.00034},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{8855691,
  author={Zhang, Weixiang and Qi, Yuhua and Zhang, Xuebo and Wei, Bo and Zhang, Min and Dou, Zhaohui},
  booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={On Test Case Prioritization Using Ant Colony Optimization Algorithm}, 
  year={2019},
  volume={},
  number={},
  pages={2767-2773},
  abstract={Test case prioritization technology improves the efficiency of software testing by optimizing the execution order of test cases, which is an important research topic of software regression testing. In order to solve the problem of requirement-based test case prioritization, this paper proposed a solution based on ant colony optimization algorithm and gave its two different implementation methods: distance-based and index-based implementation. Firstly, a general indicator based on requirements was designed to evaluate the test cases. Secondly, the concept of test case attractivity was proposed, and the definition of the distance between test cases was given based on it. Finally, the main design strategies such as the pheromone update strategy, the optimal solution update strategy, and the local optimal mutation strategy were given. The experimental results show that the method has good global optimization ability, and its overall effect is better than particle swarm optimization algorithm, genetic algorithm and random testing.},
  keywords={Testing;Optimization;Urban areas;Software;Sorting;Software algorithms;Indexes;Software Testing, Test Case Prioritization, Ant Colony Algorithm, Black Box Testing, Regression Testing},
  doi={10.1109/HPCC/SmartCity/DSS.2019.00388},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8029584,
  author={Huang, Rubing and Zhou, Yunan and Zong, Weiwen and Towey, Dave and Chen, Jinfu},
  booktitle={2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={An Empirical Comparison of Similarity Measures for Abstract Test Case Prioritization}, 
  year={2017},
  volume={1},
  number={},
  pages={3-12},
  abstract={Test case prioritization (TCP) attempts to order test cases such that those which are more important, according to some criterion or measurement, are executed earlier. TCP has been applied in many testing situations, including, for example, regression testing. An abstract test case (also called a model input) is an important type of test case, and has been widely used in practice, such as in configurable systems and software product lines. Similarity-based test case prioritization (STCP) has been proven to be cost-effective for abstract test cases (ATCs), but because there are many similarity measures which could be used to evaluate ATCs and to support STCP, we face the following question: How can we choose the similarity measure(s) for prioritizing ATCs that will deliver the most effective results? To address this, we studied fourteen measures and two popular STCP algorithms - local STCP (LSTCP), and global STCP (GSTCP). We also conducted an empirical study of five realworld programs, and investigated the efficacy of each similarity measure, according to the interaction coverage rate and fault detection rate. The results of these studies show that GSTCP outperforms LSTCP - in 61% to 84% of the cases, in terms of interaction coverage rates; and in 76% to 78% of the cases with respect to fault detection rates. Our studies also show that Overlap, the simplest similarity measure examined in this study, could obtain the overall best performance for LSTCP; and that Goodall3 has the best performance for GSTCP.},
  keywords={Testing;Fault detection;Software;Computer science;Software product lines;Fault diagnosis;Algorithm design and analysis;Software testing;test case prioritization;abstract test case;similarity},
  doi={10.1109/COMPSAC.2017.271},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{7838169,
  author={Lachmann, Remo and Schulze, Sandro and Nieke, Manuel and Seidl, Christoph and Schaefer, Ina},
  booktitle={2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
  title={System-Level Test Case Prioritization Using Machine Learning}, 
  year={2016},
  volume={},
  number={},
  pages={361-368},
  abstract={Regression testing is the common task of retesting software that has been changed or extended (e.g., by new features) during software evolution. As retesting the whole program is not feasible with reasonable time and cost, usually only a subset of all test cases is executed for regression testing, e.g., by executing test cases according to test case prioritization. Although a vast amount of methods for test case prioritization exist, they mostly require access to source code (i.e., white-box). However, in industrial practice, system-level testing is an important task that usually grants no access to source code (i.e., black-box). Hence, for an effective regression testing process, other information has to be employed. In this paper, we introduce a novel technique for test case prioritization for manual system-level regression testing based on supervised machine learning. Our approach considers black-box meta-data, such as test case history, as well as natural language test case descriptions for prioritization. We use the machine learning algorithm SVM Rank to evaluate our approach by means of two subject systems and measure the prioritization quality. Our results imply that our technique improves the failure detection rate significantly compared to a random order. In addition, we are able to outperform a test case order given by a test expert. Moreover, using natural language descriptions improves the failure finding rate.},
  keywords={Testing;Support vector machines;Software;Training data;Natural languages;Dictionaries;Training;System-Level Testing;Black-Box Testing;Test Case Prioritization;Supervised Machine Learning},
  doi={10.1109/ICMLA.2016.0065},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6569743,
  author={Arafeen, Md. Junaid and Do, Hyunsook},
  booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation}, 
  title={Test Case Prioritization Using Requirements-Based Clustering}, 
  year={2013},
  volume={},
  number={},
  pages={312-321},
  abstract={The importance of using requirements information in the testing phase has been well recognized by the requirements engineering community, but to date, a vast majority of regression testing techniques have primarily relied on software code information. Incorporating requirements information into the current testing practice could help software engineers identify the source of defects more easily, validate the product against requirements, and maintain software products in a holistic way. In this paper, we investigate whether the requirements-based clustering approach that incorporates traditional code analysis information can improve the effectiveness of test case prioritization techniques. To investigate the effectiveness of our approach, we performed an empirical study using two Java programs with multiple versions and requirements documents. Our results indicate that the use of requirements information during the test case prioritization process can be beneficial.},
  keywords={Testing;Software;Measurement;Complexity theory;Fault detection;Educational institutions;Java;regression testing;test case prioritization;requirements-based clustering;empirical study},
  doi={10.1109/ICST.2013.12},
  ISSN={2159-4848},
  month={March},}@INPROCEEDINGS{9870238,
  author={Bajaj, Anu and Abraham, Ajith},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Test Case Prioritization and Reduction Using Hybrid Quantum-behaved Particle Swarm Optimization}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Regression testing is an integral part of the software evolution and maintenance phase as it ensures that the modified software is working correctly after any upgrades. Test case prioritization and reduction minimize cost and effort needed for retesting by scheduling critical test cases before the less critical ones and removing redundant test cases. The criticality and redundancy of the test cases depend on several testing criteria. This paper empirically analyzed the effect of different testing criteria like code and fault coverage on the techniques' performance. This paper proposed a discrete Quantum-behaved particle swarm optimization (QPSO) for enhancing efficiency of test case prioritization. The algorithm is improved by replacing the random distribution with Gaussian probability to escape from the local optima. The evolution stagnation issue is further resolved by hybridizing it with genetic algorithm (QPSO-GA). In addition to prioritizing the test cases, the algorithm also reduces the test suite size through the test suite reduction approach. The experiments are conducted on different versions of three pro-grams from the open-source software infrastructure repository. The performance is compared with the average percentage of statement coverage, fault detection, and their combinations with the cost. Consequently, suite reduction, fault detection capability losses, and coverage loss percentage are also drawn for test suite reduction. The proposed algorithms outperformed the random search, ant colony optimization, differential evolution, GA, PSO, and adaptive PSO for all the evaluation metrics.},
  keywords={Costs;Fault detection;Software algorithms;Redundancy;Software quality;Proposals;Particle swarm optimization;regression testing;nature-inspired algorithms;test case prioritization;test suite reduction;particle swarm optimization;QPSO},
  doi={10.1109/CEC55065.2022.9870238},
  ISSN={},
  month={July},}@INPROCEEDINGS{9700308,
  author={Chen, Jinfu and Gu, Yuechao and Cai, Saihua and Chen, Haibo and Chen, Jingyi},
  booktitle={2021 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={KS-TCP: An Efficient Test Case Prioritization Approach based on K-medoids and Similarity}, 
  year={2021},
  volume={},
  number={},
  pages={105-110},
  abstract={Test case prioritization (TCP) tries to find an optimal execution sequence by adjusting test cases that need to be executed. Traditional techniques rely on code coverage information to achieve effective results, but they need access to historical execution information. The string distance-based test case prioritization (SD-TCP) can avoid these limitations through only using the test cases themselves for sorting, but it is sensitive to extreme test cases and inefficient. To overcome these problems, we propose a test case prioritization method based on K-medoids and Similarity (KS-TCP). The proposed KS-TCP approach considers sorting a set of test cases rather than individual test case to effectively avoid the effect of extreme test cases, it uses cluster analysis and greedy strategy to divide the subsets and compose the final execution sequence by polling. Extensive experimental results show that the proposed KS-TCP approach has a higher APFD value compared to Random Prioritization (RP) and SD-TCP, and it also outperforms SD-TCP in terms of better time efficiency on test case prioritization.},
  keywords={Greedy algorithms;Codes;Conferences;Clustering methods;Software algorithms;Software reliability;Sorting;Regression testing;Test case prioritization;Cluster analysis;Greedy algorithm},
  doi={10.1109/ISSREW53611.2021.00051},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7219790,
  author={Klindee, Piyakarn and Prompoon, Nakornthip},
  booktitle={2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)}, 
  title={Test cases prioritization for software regression testing using analytic hierarchy process}, 
  year={2015},
  volume={},
  number={},
  pages={168-173},
  abstract={Test cases are considered an important asset in the software testing process since they are used to detect defects in the software. In order to produce quality software covering all of the requirements, the test case designer requires much time and effort in designing test cases to cover all requirements and conditions according to the test case structure. This research proposes a method for storing and retrieving of test cases affected by software requirements changes, as well as ranking the retrieved test cases using the AHP method to improve the quality of the ranking. There are to assist system testers in identifying test cases for complete regression testing. An example application of the proposed method will also be presented.},
  keywords={Software;Indexes;Complexity theory;Analytic hierarchy process;Software testing;Computer aided software engineering;Analytical Hierarchy Process;AHP;Information Retrieval;Prioritization Technique;Regression Testing;Test Case Prioritization},
  doi={10.1109/JCSSE.2015.7219790},
  ISSN={},
  month={July},}

@ARTICLE{10144307,
  author={Ufuktepe, Ekincan and Tuglular, Tugkan},
  journal={IEEE Access}, 
  title={Application of the Law of Minimum and Dissimilarity Analysis to Regression Test Case Prioritization}, 
  year={2023},
  volume={11},
  number={},
  pages={57137-57157},
  abstract={Regression testing is one of the most expensive processes in testing. Prioritizing test cases in regression testing is critical for the goal of detecting the faults sooner within a large set of test cases. We propose a test case prioritization (TCP) technique for regression testing called LoM-Score inspired by the Law of Minimum (LoM) from biology. This technique calculates the impact probabilities of methods calculated by change impact analysis with forward slicing and orders test cases according to LoM. However, this ordering doesn’t consider the possibility that consecutive test cases may be covering the same methods repeatedly. Thereby, such ordering can delay the time of revealing faults that exist in other methods. To solve this problem, we enhance the LoM-Score TCP technique with an adaptive approach, namely with a dissimilarity-based coordinate analysis approach. The dissimilarity-based coordinate analysis uses Jaccard Similarity for calculating the similarity coefficients between test cases in terms of covered methods and the enhanced technique called Dissimilarity-LoM-Score (Dis-LoM-Score) applies a penalty with respective on the ordered test cases. We performed our case study on 10 open-source Java projects from Defects4J, which is a dataset of real bugs and an infrastructure for controlled experiments provided for software engineering researchers. Then, we hand-seeded multiple mutants generated by Major, which is a mutation testing tool. Then we compared our TCP techniques LoM-Score and Dis-LoM-Score with the four traditional TCP techniques based on their Average Percentage of Faults Detected (APFD) results.},
  keywords={Software testing;Probabilistic logic;Codes;Fault detection;Computer bugs;Probability;Change impact analysis;regression testing;software testing;test case prioritization},
  doi={10.1109/ACCESS.2023.3283212},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7783254,
  author={Joseph, Abraham Kiran and Radhamani, G. and Kallimani, Vish},
  booktitle={2016 3rd International Conference on Computer and Information Sciences (ICCOINS)}, 
  title={Improving test efficiency through multiple criteria coverage based test case prioritization using Modified heuristic algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={430-435},
  abstract={Test case prioritization involves reordering the test cases in an order that helps in attaining certain performance goals. The rate of fault detection is one of the prime goals that we tend to achieve while doing prioritization. Test cases should run in an order to increase the possibility of fault detection and it should be achieved early during the test life cycle. To reduce the cost and time of regression testing, test case prioritization should be done with the intention of periodically modifying the test suite. The humongous set of test cases makes it redundant and cumbersome for the testers who ensure quality for an end application. The fault detection capability of a prioritized test suite is improved up to 15% using Modified PSO which forms the base algorithms for prioritization. The algorithm illustrated detects serious errors at earlier phases of testing process and effectiveness between prioritized and unprioritized test cases.},
  keywords={Testing;Complexity theory;Software;Fault detection;Electric breakdown;Computers;Software algorithms;Test case prioritization;Heuristic Algorithm;Modified Particle Swarm Optimization;Regression testing},
  doi={10.1109/ICCOINS.2016.7783254},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8854718,
  author={Hettiarachchi, Charitha and Do, Hyunsook},
  booktitle={2019 IEEE 19th International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={A Systematic Requirements and Risks-Based Test Case Prioritization Using a Fuzzy Expert System}, 
  year={2019},
  volume={},
  number={},
  pages={374-385},
  abstract={The use of risk information can help software engineers identify software components that are likely vulnerable or require extra attention when testing. Some studies have shown that the requirements risk-based approaches can be effective in improving the effectiveness of regression testing techniques. However, the risk estimation processes used in such approaches can be subjective, time-consuming, and costly. In this research, we introduce a fuzzy expert system that emulates human thinking to address the subjectivity related issues in the risk estimation process in a systematic and an efficient way and thus further improve the effectiveness of test case prioritization. Further, the required data for our approach was gathered by employing a semi-automated process that made the risk estimation process less subjective. The empirical results indicate that the new prioritization approach can improve the rate of fault detection over several existing test case prioritization techniques, while reducing threats to subjective risk estimation.},
  keywords={Expert systems;Iron;Security;Software;Testing;Estimation;Complexity theory;Regression testing, requirements risks-based testing, fuzzy expert systems, test case prioritization, software requirements},
  doi={10.1109/QRS.2019.00054},
  ISSN={},
  month={July},}@INPROCEEDINGS{8536351,
  author={Paterson, David and Kapfhammer, Gregory and Fraser, Gordon and McMinn, Phil},
  booktitle={2018 IEEE/ACM 13th International Workshop on Automation of Software Test (AST)}, 
  title={Using Controlled Numbers of Real Faults and Mutants to Empirically Evaluate Coverage-Based Test Case Prioritization}, 
  year={2018},
  volume={},
  number={},
  pages={57-63},
  abstract={Used to establish confidence in the correctness of evolving software, regression testing is an important, yet costly, task. Test case prioritization enables the rapid detection of faults during regression testing by reordering the test suite so that effective tests are run as early as is possible. However, a distinct lack of information about the regression faults found in complex real-world software forced prior experimental studies of these methods to use artificial faults called mutants. Using the Defects4J database of real faults, this paper presents the results of experiments evaluating the effectiveness of four representative test prioritization techniques. Since this paper's results show that prioritization is susceptible to high amounts of variance when only one fault is present, our experiments also control the number of real faults and mutants in the program subject to regression testing. Our overall findings are that, in comparison to mutants, real faults are harder for reordered test suites to quickly detect, suggesting that mutants are not a surrogate for real faults.},
  keywords={Software;Tools;Testing;Fault detection;Measurement;Conferences;Automation;test case prioritization;regression testing;real faults;defects4j},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{8730206,
  author={Paterson, David and Campos, Jose and Abreu, Rui and Kapfhammer, Gregory M. and Fraser, Gordon and McMinn, Phil},
  booktitle={2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)}, 
  title={An Empirical Study on the Use of Defect Prediction for Test Case Prioritization}, 
  year={2019},
  volume={},
  number={},
  pages={346-357},
  abstract={Test case prioritization has been extensively re-searched as a means for reducing the time taken to discover regressions in software. While many different strategies have been developed and evaluated, prior experiments have shown them to not be effective at prioritizing test suites to find real faults. This paper presents a test case prioritization strategy based on defect prediction, a technique that analyzes code features - such as the number of revisions and authors - to estimate the likelihood that any given Java class will contain a bug. Intuitively, if defect prediction can accurately predict the class that is most likely to be buggy, a tool can prioritize tests to rapidly detect the defects in that class. We investigated how to configure a defect prediction tool, called Schwa, to maximize the likelihood of an accurate prediction, surfacing the link between perfect defect prediction and test case prioritization effectiveness. Using 6 real-world Java programs containing 395 real faults, we conducted an empirical evaluation comparing this paper's strategy, called G-clef, against eight existing test case prioritization strategies. The experiments reveal that using defect prediction to prioritize test cases reduces the number of test cases required to find a fault by on average 9.48% when compared with existing coverage-based strategies, and 10.4% when compared with existing history-based strategies.},
  keywords={Computer bugs;History;Software;Java;Testing;Fault detection;Genetic algorithms;Regression Testing;Test Case Prioritization;Defect Prediction;Continuous Testing;Empirical Studies},
  doi={10.1109/ICST.2019.00041},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{6918806,
  author={Mohapatra, Sudhir Kumar and Prasad, Srinivas},
  booktitle={2013 International Conference on Machine Intelligence and Research Advancement}, 
  title={Evolutionary Search Algorithms for Test Case Prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={115-119},
  abstract={To improve the effectiveness of certain performance goals, test case prioritization techniques are used. These technique schedule the test cases in particular order for execution so as to increase the efficacy in meeting the performance goals. For every change in the program it is considered inefficient to re-execute each and every test case. Test case prioritization techniques arrange the test cases within a test suite in such a way that the most important test case is executed first. This process enhances the effectiveness of testing. This algorithm during time constraint execution has been shown to have detected maximum number fault while including the sever test cases.},
  keywords={Genetic algorithms;Testing;Software;Sociology;Statistics;Algorithm design and analysis;Fault detection;Regression testing;Test case;Genetic algorithm;prioritization},
  doi={10.1109/ICMIRA.2013.29},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6649820,
  author={Jiang, Bo and Chan, W.K.},
  booktitle={2013 IEEE 37th Annual Computer Software and Applications Conference}, 
  title={Bypassing Code Coverage Approximation Limitations via Effective Input-Based Randomized Test Case Prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={190-199},
  abstract={Test case prioritization assigns the execution priorities of the test cases in a given test suite with the aim of achieving certain goals. Many existing test case prioritization techniques however assume the full-fledged availability of code coverage data, fault history, or test specification, which are seldom well-maintained in many software development projects. This paper proposes a novel family of LBS techniques. They make adaptive tree-based randomized explorations with an adaptive randomized candidate test set strategy to diversify the explorations among the branches of the exploration trees constructed by the test inputs in the test suite. They get rid of the assumption on the historical correlation of code coverage between program versions. Our techniques can be applied to programs with or without any previous versions, and hence are more general than many existing test case prioritization techniques. The empirical study on four popular UNIX utility benchmarks shows that, in terms of APFD, our LBS techniques can be as effective as some of the best code coverage-based greedy prioritization techniques ever proposed. We also show that they are significantly more efficient and scalable than the latter techniques.},
  keywords={Testing;Subspace constraints;Silicon;Software;Approximation methods;History;Equations;regression testing;adaptive test case prioritization},
  doi={10.1109/COMPSAC.2013.33},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{7272924,
  author={Jiang, Bo and Chan, W.K. and Tse, T.H.},
  booktitle={2015 IEEE International Conference on Software Quality, Reliability and Security}, 
  title={PORA: Proportion-Oriented Randomized Algorithm for Test Case Prioritization}, 
  year={2015},
  volume={},
  number={},
  pages={131-140},
  abstract={Effective testing is essential for assuring software quality. While regression testing is time-consuming, the fault detection capability may be compromised if some test cases are discarded. Test case prioritization is a viable solution. To the best of our knowledge, the most effective test case prioritization approach is still the additional greedy algorithm, and existing search-based algorithms have been shown to be visually less effective than the former algorithms in previous empirical studies. This paper proposes a novel Proportion-Oriented Randomized Algorithm (PORA) for test case prioritization. PORA guides test case prioritization by optimizing the distance between the prioritized test suite and a hierarchy of distributions of test input data. Our experiment shows that PORA test case prioritization techniques are as effective as, if not more effective than, the total greedy, additional greedy, and ART techniques, which use code coverage information. Moreover, the experiment shows that PORA techniques are more stable in effectiveness than the others.},
  keywords={Testing;Subspace constraints;Fault detection;Greedy algorithms;Resource management;Clustering algorithms;Genetic algorithms;Test case prioritization;randomized algorithm;proportional sampling strategy;multi-objective optimization},
  doi={10.1109/QRS.2015.28},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9741963,
  author={Hu, Peng and Chaowen, Chang and Ma, Yingying and Wang, Xiaolin},
  booktitle={2021 2nd International Conference on Electronics, Communications and Information Technology (CECIT)}, 
  title={Acceptance Testing Optimization Method for Continuous Delivery}, 
  year={2021},
  volume={},
  number={},
  pages={168-173},
  abstract={From agile to DevOps, development methods have been extended from continuous integration to continuous delivery. In the acceptance testing before software delivery, the constantly changing software configuration, real user environment, and user-led testing, all of these extend the delivery time and increase the risk of testing. How to further optimize the test and shorten the delivery cycle are problem that must be considered to realize the end-to-end value flow in DevOps. In the testing optimization research, the methods are mainly for regression testing. There are few researches on acceptance testing, and the methods for the acceptance testing mainly focus on specific scenario, that almost none research consider how to shorten the continuous delivery cycle. Aiming at the characteristics of acceptance testing, this paper proposes an acceptance testing optimization method for continuous delivery. For different levels of test cases, test case selection and prioritization are used to optimize test cases. Firstly, the test suite related to requirements is constructed, and the test cases are selected according to the requirements. Then, the test suites are divided into two levels to prioritize. During the test execution, the use case execution actions are streamlined to shorten execution time of the acceptance testing, meet user needs as soon as possible and achieve rapid value delivery. Finally, the method is applied to actual industrial projects for experiments. The results show that the method can reduce the scale of test cases, shorten the test execution times and improve the efficiency of demand satisfaction.},
  keywords={Diversity reception;Optimization methods;Software;Information and communication technology;Testing;testing optimization;acceptance testing;test case selection;test case prioritization},
  doi={10.1109/CECIT53797.2021.00037},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8367035,
  author={Pradhan, Dipesh and Wang, Shuai and Ali, Shaukat and Yue, Tao and Liaaen, Marius},
  booktitle={2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)}, 
  title={REMAP: Using Rule Mining and Multi-objective Search for Dynamic Test Case Prioritization}, 
  year={2018},
  volume={},
  number={},
  pages={46-57},
  abstract={Test case prioritization (TP) prioritizes test cases into an optimal order for achieving specific criteria (e.g., higher fault detection capability) as early as possible. However, the existing TP techniques usually only produce a static test case order before the execution without taking runtime test case execution results into account. In this paper, we propose an approach for black-box dynamic TP using rule mining and multi-objective search (named as REMAP). REMAP has three key components: 1) Rule Miner, which mines execution relations among test cases from historical execution data; 2) Static Prioritizer, which defines two objectives (i.e., fault detection capability (FDC) and test case reliance score (TRS)) and applies multi-objective search to prioritize test cases statically; and 3) Dynamic Executor and Prioritizer, which executes statically-prioritized test cases and dynamically updates the test case order based on the runtime test case execution results. We empirically evaluated REMAP with random search, greedy based on FDC, greedy based on FDC and TRS, static search-based prioritization, and rule-based prioritization using two industrial and three open source case studies. Results showed that REMAP significantly outperformed the other approaches for 96% of the case studies and managed to achieve on average 18% higher Average Percentage of Faults Detected (APFD).},
  keywords={Testing;Fault detection;Runtime;Data mining;Search problems;Software;Conferences;dynamic test case prioritization;black-box regression testing;multi-objective optimization;rule-mining;search},
  doi={10.1109/ICST.2018.00015},
  ISSN={},
  month={April},}@ARTICLE{7456343,
  author={Eghbali, Sepehr and Tahvildari, Ladan},
  journal={IEEE Transactions on Software Engineering}, 
  title={Test Case Prioritization Using Lexicographical Ordering}, 
  year={2016},
  volume={42},
  number={12},
  pages={1178-1195},
  abstract={Test case prioritization aims at ordering test cases to increase the rate of fault detection, which quantifies how fast faults are detected during the testing phase. A common approach for test case prioritization is to use the information of previously executed test cases, such as coverage information, resulting in an iterative (greedy) prioritization algorithm. Current research in this area validates the fact that using coverage information can improve the rate of fault detection in prioritization algorithms. The performance of such iterative prioritization schemes degrade as the number of ties encountered in prioritization steps increases. In this paper, using the notion of lexicographical ordering, we propose a new heuristic for breaking ties in coverage based techniques. Performance of the proposed technique in terms of the rate of fault detection is empirically evaluated using a wide range of programs. Results indicate that the proposed technique can resolve ties and in turn noticeably increases the rate of fault detection.},
  keywords={Software testing;Fault detection;Feature extraction;Regression analysis;Fault diagnosis;Regression testing;test case prioritization;lexicographical ordering},
  doi={10.1109/TSE.2016.2550441},
  ISSN={1939-3520},
  month={Dec},}@INPROCEEDINGS{9990713,
  author={A, Mugilan and Totla, Tushar and Renwa, Yash and R, Charanya and Subbiah, Stalin and Dharmaraj, T. B. and Prakash, S. Om},
  booktitle={2022 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)}, 
  title={Comparative Analysis of Ant Colony Optimization and Particle Swarm Optimization for Test Case Prioritization}, 
  year={2022},
  volume={},
  number={},
  pages={680-686},
  abstract={To boost the efficiency of testing and save time and money in the construction of the testing program, the test case prioritization technique prioritizes a subset of the full test suite and optimizes the execution order of the test cases. The goal of this paper is to classify and compare the performance of two nature-based test case prioritization techniques: To overcome the problem of needing to perform the whole test suite at some point, resulting in time and expense limits, we used Ant Colony Optimization and Particle Swarm Optimization. We chose a sample test suite and prioritized the test cases for our research. An experimental investigation of the acquired data will be useful in selecting the best prioritizing technique under various environmental constraints. For our analysis, we selected a sample test suite and prioritized the test cases. In various environmental restrictions, an experimental study of the findings collected will be valuable in determining the optimum prioritization strategy. The findings of both algorithms showed high global optimization abilities, with the ant colony strategy outperforming the particle swarm optimization approach.},
  keywords={Ant colony optimization;Technological innovation;Particle swarm optimization;Informatics;Optimization;Testing;Particle Swarm Optimization;Ant Colony Algorithm;Test Case Prioritization;Regression Testing;Software Testing},
  doi={10.1109/3ICT56508.2022.9990713},
  ISSN={2770-7466},
  month={Nov},}@ARTICLE{8329518,
  author={Luo, Qi and Moran, Kevin and Zhang, Lingming and Poshyvanyk, Denys},
  journal={IEEE Transactions on Software Engineering}, 
  title={How Do Static and Dynamic Test Case Prioritization Techniques Perform on Modern Software Systems? An Extensive Study on GitHub Projects}, 
  year={2019},
  volume={45},
  number={11},
  pages={1054-1080},
  abstract={Test Case Prioritization (TCP) is an increasingly important regression testing technique for reordering test cases according to a pre-defined goal, particularly as agile practices gain adoption. To better understand these techniques, we perform the first extensive study aimed at empirically evaluating four static TCP techniques, comparing them with state-of-research dynamic TCP techniques across several quality metrics. This study was performed on 58 real-word Java programs encompassing 714 KLoC and results in several notable observations. First, our results across two effectiveness metrics (the Average Percentage of Faults Detected APFD and the cost cognizant APFDc) illustrate that at test-class granularity, these metrics tend to correlate, but this correlation does not hold at test-method granularity. Second, our analysis shows that static techniques can be surprisingly effective, particularly when measured by APFDc. Third, we found that TCP techniques tend to perform better on larger programs, but that program size does not affect comparative performance measures between techniques. Fourth, software evolution does not significantly impact comparative performance results between TCP techniques. Fifth, neither the number nor type of mutants utilized dramatically impact measures of TCP effectiveness under typical experimental settings. Finally, our similarity analysis illustrates that highly prioritized test cases tend to uncover dissimilar faults.},
  keywords={Testing;Measurement;Computer bugs;Software systems;Java;Fault detection;Regression testing;test case prioritization;static;dynamic;mutation analysis},
  doi={10.1109/TSE.2018.2822270},
  ISSN={1939-3520},
  month={Nov},}@ARTICLE{8793223,
  author={Lu, Chengyu and Zhong, Jinghui and Xue, Yinxing and Feng, Liang and Zhang, Jun},
  journal={IEEE Transactions on Reliability}, 
  title={Ant Colony System With Sorting-Based Local Search for Coverage-Based Test Case Prioritization}, 
  year={2020},
  volume={69},
  number={3},
  pages={1004-1020},
  abstract={Test case prioritization (TCP) is a popular regression testing technique in software engineering field. The task of TCP is to schedule the execution order of test cases so that certain objective (e.g., code coverage) can be achieved quickly. In this article, we propose an efficient ant colony system framework for the TCP problem, with the aim of maximizing the code coverage as soon as possible. In the proposed framework, an effective heuristic function is proposed to guide the ants to construct solutions based on additional statement coverage among remaining test cases. Besides, a sorting-based local search mechanism is proposed to further accelerate the convergence speed of the algorithm. Experimental results on different benchmark problems, and a real-world application, have shown that the proposed framework can outperform several state-of-the-art methods, in terms of solution quality and search efficiency.},
  keywords={Search problems;Testing;Software engineering;Computer science;Stochastic processes;Graphics processing units;Ant colony system (ACS);regression testing,statement coverage;test case prioritization (TCP)},
  doi={10.1109/TR.2019.2930358},
  ISSN={1558-1721},
  month={Sep.},}@INPROCEEDINGS{10675922,
  author={Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Seferi, Gkerta and Tauseef, Qasim},
  booktitle={2024 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={An End-to-End Test Case Prioritization Framework using Optimized Machine Learning Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Regression testing in software development is challenging due to the large number of test cases and continuous integration (CI) practices. Recently, test case prioritization (TCP) using machine learning (ML) has been shown to efficiently execute regression tests. This study introduces an automated, endto-end, self-contained ML-based framework, TCP-Tune, tailored exclusively for TCP. The framework utilizes open-source version control system data to combine code-change-related features with test execution results. This integration allows the automated optimization of hyperparameters across different ML models to improve the TCP. The framework also effectively visualizes and utilizes multiple evaluation metrics to evaluate the performance of the model over several builds. Unlike existing implementations, which rely on various frameworks, TCP-Tune enables the effortless incorporation of features from multiple sources and fine-tuned models, thereby providing optimum test prioritization in the ever-changing field of software development. Our approach has helped to provide efficient TCP through experimental assessments of a real-life, large-scale CI system.},
  keywords={Software testing;Radio frequency;Measurement;Machine learning;Production;Continuous integration;Market research;test case prioritization;hyperparameter tuning;regression testing;machine learning},
  doi={10.1109/ICSTW60967.2024.00014},
  ISSN={2159-4848},
  month={May},}@INPROCEEDINGS{10229439,
  author={Abdelkarim, Mohamed and ElAdawi, Reem},
  booktitle={2023 IEEE International Conference On Artificial Intelligence Testing (AITest)}, 
  title={TCP-Net++: Test Case Prioritization Using End-to-End Deep Neural Networks - Deployment Analysis and Enhancements}, 
  year={2023},
  volume={},
  number={},
  pages={99-106},
  abstract={The increasing number of test cases and frequency of continuous integration in software projects has created a bottleneck in regression testing. To save time and hardware resources, machine learning techniques can be applied without compromising quality. In this work, we present a case study for deployment analysis and results of using our previous work: TCP-Net: Test Case Prioritization using End-to-End Deep Neural Networks [1] in a real-life industrial environment, showing roadblocks, challenges, and enhancements done to improve its performance and usability, achieving 90% to 100% failure coverage by running an average of 23% to 39% of the test cases.},
  keywords={Software testing;Deep learning;Artificial neural networks;Software;Hardware;Usability;software testing;regression testing;test case prioritization;neural networks;deep learning;AI},
  doi={10.1109/AITest58265.2023.00024},
  ISSN={2835-3560},
  month={July},}@INPROCEEDINGS{8625203,
  author={Carballo, Pablo and Perera, Pablo and Rama, Santiago and Pedemonte, Martín},
  booktitle={2018 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, 
  title={A Biased Random-Key Genetic Algorithm for Regression Test Case Prioritization}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={The Test Case Prioritization Problem (TCPP) is a real-world problem that arises in regression testing. It lies in finding an ordering of the test cases of a test suite, such that test cases ordered first should be run first. The classical approach to solve this problem employing GAs is to use permutational encoding, but it requires specific operators to keep the feasibility of the solutions. The Biased Random-Key Genetic Algorithm (BRKGA) follows a different philosophy for dealing with permutations, using a string of real numbers and a decoder for computing the permutation. In this paper, we propose a BRKGA for solving the TCPP. The experimental evaluation on eleven instances of seven real-world programs shows that BRKGA is able to outperform two different permutational encoding based GAs (with order and cycle crossover operators), and that it has at least a similar performance than another permutational encoding based GA (with partially-mapped crossover) and a GA from a previous work specially conceived for tackling the TCPP.},
  keywords={Genetic algorithms;Encoding;Testing;Software;Springs;Fault detection;Decoding;Regression testing;Search-based software engineering;Biased random-key genetic algorithm;Test case prioritization problem},
  doi={10.1109/LA-CCI.2018.8625203},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10301223,
  author={Querejeta, Miriam Ugarte and Jee, Eunkyoung and Liu, Lingjun and Valle, Pablo and Arrieta, Aitor and Rezabal, Miren Illarramendi},
  booktitle={2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Search-based Test Case Selection for PLC Systems using Functional Block Diagram Programs}, 
  year={2023},
  volume={},
  number={},
  pages={228-239},
  abstract={Programmable Logic Controllers (PLCs) are the core unit of the production system, which frequently need to implement new processes to address customer needs. These changes must be fully tested to ensure the reliability of the PLC code, which is commonly programmed through Functional Block Diagrams (FBDs). This is a tedious task that requires considerable time and effort given the manual nature of the process involved in PLC testing. Hence, we present a cost-effective test selection approach to test FBD programs in dynamic environments. The proposed method uses a search-based multi-objective test case selection algorithm as a regression technique to test recently modified FBD programs. Specifically, we derived a total of 7 fitness function combinations, by combining different cost and quality-based fitness functions. We carried out an empirical evaluation, by employing fitness metrics in the wellknown NSGA-II algorithm to determine the best configuration setup for testing FBD programs. Furthermore, we benchmarked the performance of the NSGA-II with the baseline Random Search (RS). The study was carried out with three case studies of a reactor protection system, and evaluated with two sets of mutants. The results demonstrated that the proposed approach significantly reduces time, while keeping high the overall fault detection capability.},
  keywords={Measurement;Production systems;Programmable logic devices;Process control;Programming;Software;Software reliability;programmable logic controller;functional block diagram;test case selection;regression testing;search-based testing},
  doi={10.1109/ISSRE59848.2023.00040},
  ISSN={2332-6549},
  month={Oct},}@ARTICLE{9900114,
  author={Biswas, Sourav and Bansal, Aman and Mitra, Pabitra and Mall, Rajib},
  journal={IEEE Transactions on Reliability}, 
  title={Fault-Based Regression Test Case Prioritization}, 
  year={2023},
  volume={72},
  number={3},
  pages={1176-1190},
  abstract={We propose a set of four novel fault-based regression test case prioritization (TCP) techniques for object-oriented programs. We seed bugs into a program to create large number of mutants. We execute each mutant with the originally designed test suite. From this, we record the number of mutants for which a test case fails. Based on this, we prioritize the test cases using four base fault-based prioritization techniques that we have proposed. Finally, we combine the results of our four base prioritizers using three ensemble methods. We have conducted experimental studies to determine the effectiveness of our proposed approaches. Our experimental results show that our proposed TCP techniques exhibit superior performance over related techniques.},
  keywords={Computer bugs;Frequency modulation;Codes;Measurement;Fault detection;Java;Bayes methods;Mutation testing;object-oriented (OO) programs;regression test case prioritization (TCP);regression testing},
  doi={10.1109/TR.2022.3205483},
  ISSN={1558-1721},
  month={Sep.},}@ARTICLE{8453036,
  author={Di Nucci, Dario and Panichella, Annibale and Zaidman, Andy and De Lucia, Andrea},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Test Case Prioritization Genetic Algorithm Guided by the Hypervolume Indicator}, 
  year={2020},
  volume={46},
  number={6},
  pages={674-696},
  abstract={Regression testing is performed during maintenance activities to assess whether the unchanged parts of a software behave as intended. To reduce its cost, test case prioritization techniques can be used to schedule the execution of the available test cases to increase their ability to reveal regression faults earlier. Optimal test ordering can be determined using various techniques, such as greedy algorithms and meta-heuristics, and optimizing multiple fitness functions, such as the average percentage of statement and branch coverage. These fitness functions condense the cumulative coverage scores achieved when incrementally running test cases in a given ordering using Area Under Curve (AUC) metrics. In this paper, we notice that AUC metrics represent a bi-dimensional (simplified) version of the hypervolume metric, which is widely used in many-objective optimization. Thus, we propose a Hypervolume-based Genetic Algorithm, namely HGA, to solve the Test Case Prioritization problem when using multiple test coverage criteria. An empirical study conducted with respect to five state-of-the-art techniques shows that (i) HGA is more cost-effective, (ii) HGA improves the efficiency of Test Case Prioritization, (iii) HGA has a stronger selective pressure when dealing with more than three criteria.},
  keywords={Measurement;Greedy algorithms;Genetic algorithms;Testing;Software systems;Fault detection;Test case prioritization;genetic algorithm;hypervolume},
  doi={10.1109/TSE.2018.2868082},
  ISSN={1939-3520},
  month={June},}@ARTICLE{6839018,
  author={Mei, Lijun and Cai, Yan and Jia, Changjiang and Jiang, Bo and Chan, W.K. and Zhang, Zhenyu and Tse, T.H.},
  journal={IEEE Transactions on Services Computing}, 
  title={A Subsumption Hierarchy of Test Case Prioritization for Composite Services}, 
  year={2015},
  volume={8},
  number={5},
  pages={658-673},
  abstract={Many composite workflow services utilize non-imperative XML technologies such as WSDL, XPath, XML schema, and XML messages. Regression testing should assure the services against regression faults that appear in both the workflows and these artifacts. In this paper, we propose a refinement-oriented level-exploration strategy and a multilevel coverage model that captures progressively the coverage of different types of artifacts by the test cases. We show that by using them, the test case prioritization techniques initialized on top of existing greedy-based test case prioritization strategy form a subsumption hierarchy such that a technique can produce more test suite permutations than a technique that subsumes it. Our experimental study of a model instance shows that a technique generally achieves a higher fault detection rate than a subsumed technique, which validates that the proposed hierarchy and model have the potential to improve the cost-effectiveness of test case prioritization techniques.},
  keywords={XML;Fault detection;Semantics;Testing;Business;Educational institutions;Test case prioritization;service orientation;XPath;WSDL;XML messages},
  doi={10.1109/TSC.2014.2331683},
  ISSN={1939-1374},
  month={Sep.},}@INPROCEEDINGS{6676871,
  author={Schwartz, Amanda and Do, Hyunsook},
  booktitle={2013 IEEE International Conference on Software Maintenance}, 
  title={A Fuzzy Expert System for Cost-Effective Regression Testing Strategies}, 
  year={2013},
  volume={},
  number={},
  pages={1-10},
  abstract={Different testing environments and software change characteristics can affect the choice of regression testing techniques. In our prior work, we developed adaptive regression testing (ART) strategies to investigate this problem. While the ART strategies showed promising results, we also found that the multiple criteria decision making processes required for the ART strategies are time-consuming, often inaccurate and inconsistent, and limited in their scalability. To address these issues, in this research, we develop and empirically study a fuzzy expert system (FESART) to aid decision makers in choosing the most cost-effective technique for a particular software version. The results of our study show that FESART is consistently more cost-effective than the previously proposed ART strategies. One of the biggest contributors to FESART being more cost-effective is the reduced time required to apply the strategy. This contribution has significant impact because a strategy that is less time-consuming will be easier for researchers and practitioners to adopt, and will provide even greater cost-savings for regression testing sessions.},
  keywords={Expert systems;Testing;Subspace constraints;Fuzzy logic;Software;Decision making;Fuzzy sets;Regression testing;test case prioritization;adaptive regression testing strategy;AHP;fuzzy AHP;empirical studies},
  doi={10.1109/ICSM.2013.11},
  ISSN={1063-6773},
  month={Sep.},}@ARTICLE{9367020,
  author={Ling, Xiao and Agrawal, Rishabh and Menzies, Tim},
  journal={IEEE Transactions on Software Engineering}, 
  title={How Different is Test Case Prioritization for Open and Closed Source Projects?}, 
  year={2022},
  volume={48},
  number={7},
  pages={2526-2540},
  abstract={Improved test case prioritization means that software developers can detect and fix more software faults sooner than usual. But is there one “best” prioritization algorithm? Or do different kinds of projects deserve special kinds of prioritization? To answer these questions, this article applies nine prioritization schemes to 31 projects that range from (a) highly rated open-source Github projects to (b) computational science software to (c) a closed-source project. We find that prioritization approaches that work best for open-source projects can work worst for the closed-source project (and vice versa). From these experiments, we conclude that (a) it is ill-advised to always apply one prioritization scheme to all projects since (b) prioritization requires tuning to different project types.},
  keywords={Testing;Software;Open source software;Software development management;Measurement;Software algorithms;History;Software testing;regression testing;test case prioritization;open-source software},
  doi={10.1109/TSE.2021.3063220},
  ISSN={1939-3520},
  month={July},}@INPROCEEDINGS{6649891,
  author={Lv, Junpeng and Yin, Beibei and Cai, Kai-Yuan},
  booktitle={2013 IEEE 37th Annual Computer Software and Applications Conference}, 
  title={On the Gain of Measuring Test Case Prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={627-632},
  abstract={Test case prioritization (TCP) techniques aim to schedule the order of regression test suite to maximize some properties, such as early fault detection. In order to measure the abilities of different TCP techniques for early fault detection, a metric named average percentage of faults detected (APFD) is widely adopted. In this paper, we analyze the metric APFD and explore the gain of measuring TCP techniques from a control theory viewpoint. Based on that, we propose a generalized metric for TCP. This new metric focuses on the gain of defining early fault detection and measuring TCP techniques for various needs in different evaluation scenarios. By adopting this new metric, not only flexibility can be guaranteed, but also explicit physical significance for the metric will be provided before evaluation.},
  keywords={Fault detection;Testing;Gain measurement;Software;Weight measurement;Approximation methods;regression testing;test case prioritization;software metric;software cybernetics},
  doi={10.1109/COMPSAC.2013.101},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{10911525,
  author={Pilley, Kunal and Mall, Rajib and Biswas, Sourav and Mamgain, Vishal and Verma, Rajesh and Vishvakarma, S K},
  booktitle={2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={A Regression Test Case Prioritization Technique for Web Application Using User Session Data}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={We propose a novel regression test case prioritization technique (RTCP) for web applications exploiting user session data and hamming code distance. The proposed technique utilises user session data to reorder test cases such that test cases which cover the ‘most frequently accessed subset of pages together’ are given higher priority. The coverage information of user session data along with its frequency appearance and test cases are converted to hamming code. These hamming codes are used to calculate the coverage similarity between user access pattern and the test cases. Further, the hamming code distance is incorporated with frequency of appearance to calculate a weighted average distance among user session data and test cases. Finally, the test cases with a lesser weighted average distance are given higher priority.},
  keywords={Measurement;Codes;Government;Frequency conversion;Testing;Regression Testing;Regression Test Case Prioritization;Web Application;Hamming Code Distance},
  doi={10.1109/ICTBIG64922.2024.10911525},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10196878,
  author={Yang, Yu and Wang, Lu and Cha, Na and Li, Hua},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={A Test Case Prioritization Based on Genetic Algorithm With Ant Colony and Reinforcement Learning Improvement}, 
  year={2023},
  volume={},
  number={},
  pages={1588-1593},
  abstract={In order to improve the efficiency of regression testing in the cloud-network convergence platform, a test case prioritization method based on reinforcement learning and a genetic algorithm is proposed. The classical genetic algorithm of initial population and selection operations are improved by incorporating an ant colony algorithm of solutions to form a part of the starting population in the genetic algorithm. The selection process employs an "elite retention strategy" to avoid the classical genetic algorithm of the problem of getting trapped in locally optimal solutions. The improved algorithm is applied to test the cloud-network convergence platform, and the optimization-seeking abilities of the classical genetic algorithm, the ant colony genetic algorithm, and the reinforcement learning-based ant colony genetic algorithm are compared and analyzed. The findings reveal that the reinforcement learning-based ant colony genetic algorithm outperforms the other two algorithms by finding the best test case for the test case prioritization problem.},
  keywords={Q-learning;Software algorithms;Sociology;Genetics;Software;Statistics;Genetic algorithms;test case prioritization;reinforcement learning;genetic algorithm;ant colony algorithm},
  doi={10.1109/COMPSAC57700.2023.00245},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{7102622,
  author={Noguchi, Tadahiro and Washizaki, Hironori and Fukazawa, Yoshiaki and Sato, Atsutoshi and Ota, Kenichiro},
  booktitle={2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)}, 
  title={History-Based Test Case Prioritization for Black Box Testing Using Ant Colony Optimization}, 
  year={2015},
  volume={},
  number={},
  pages={1-2},
  abstract={Test case prioritization is a technique to improve software testing. Although a lot of work has investigated test case prioritization, they focus on white box testing or regression testing. However, software testing is often outsourced to a software testing company, in which testers are rarely able to access to source code due to a contract. Herein a framework is proposed to prioritize test cases for black box testing on a new product using the test execution history collected from a similar prior product and the Ant Colony Optimization. A simulation using two actual products shows the effectiveness and practicality of our proposed framework.},
  keywords={Software testing;Software;Ant colony optimization;Companies;History;Fault detection},
  doi={10.1109/ICST.2015.7102622},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{7507373,
  author={Banias, Ovidiu},
  booktitle={2016 IEEE 11th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={The drawbacks of statement code coverage test case prioritization related to domain testing}, 
  year={2016},
  volume={},
  number={},
  pages={221-224},
  abstract={In this paper we study the weaknesses of the test case prioritization algorithms based on statement code coverage and applied to the domain test cases. We present the inconsistency between the principles of domain testing and the selection and prioritization practices over domain test cases on criteria unrelated to the scope of the domain testing. We continue the study by discussing the impact of 100% statement code coverage over the suites of domain test cases, studying why this type of code coverage should not produce effects over the domain test cases. Statement code coverage prioritization techniques related to unit testing, integration testing and regression testing phases are discussed, emphasizing the incompatibility between statement code coverage, domain testing and test case prioritization all at once.},
  keywords={Software testing;Software;Computational intelligence;Informatics;Fault detection;Computer aided software engineering},
  doi={10.1109/SACI.2016.7507373},
  ISSN={},
  month={May},}@INPROCEEDINGS{10366665,
  author={Jabbar, Emad and Hemmati, Hadi and Feldt, Robert},
  booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)}, 
  title={Investigating Execution Trace Embedding for Test Case Prioritization}, 
  year={2023},
  volume={},
  number={},
  pages={279-290},
  abstract={Most automated software testing tasks, such as test case generation, selection, and prioritization, can benefit from an abstract representation of test cases. Although test case representation usually is not explicitly discussed in software literature, but traditionally test cases are mostly represented based on what they cover in source code (e.g., which statements or branches), which is in fact an abstract representation. In this paper, we hypothesize that execution traces of test cases, as representations of their behaviour, can be leveraged to better encode test cases compared to code-based coverage information, for automated testing tasks. To validate this hypothesis, we propose an embedding approach, Test2Vec, based on an state-of-the-art neural program embedding (CodeBert), where the encoder maps test execution traces, i.e. sequences of method calls with their inputs and return values, to fixed-length, numerical vectors. We evaluate this representation in automated test case prioritization (TP) task. Our TP method is a classifier trained on the passing and failing vectors of historical test cases, in regression testing. We compare our embedding with multiple baselines and related work including CodeBert itself. The empirical study is based on 250 real faults and 703,353 seeded faults (mutants) over 250 revisions of 10 open-source Java projects from Defects4J, with a total of over 1,407,206 execution traces. Results show that our approach improves all alternatives, significantly, with respect to studied metrics. We also show that both inputs and outputs of a method are important elements of the execution-based embedding.},
  keywords={Software testing;Measurement;Java;Source coding;Software quality;Software reliability;Security;Test Case Prioritization;Transformers;Software Testing;Embedding},
  doi={10.1109/QRS60937.2023.00036},
  ISSN={2693-9177},
  month={Oct},}@INPROCEEDINGS{7589817,
  author={Zhang, Xiaofang and Xie, Xiaoyuan and Chen, Tsong Yueh},
  booktitle={2016 IEEE International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Test Case Prioritization Using Adaptive Random Sequence with Category-Partition-Based Distance}, 
  year={2016},
  volume={},
  number={},
  pages={374-385},
  abstract={Test case prioritization schedules test cases in a certain order aiming to improve the effectiveness of regression testing. Random sequence is a basic and simple prioritization technique, while Adaptive Random Sequence (ARS) makes use of extra information to improve the diversity of random sequence. Some researchers have proposed prioritization techniques using ARS with white-box information, such as code coverage information, or with black-box information, such as string distances of the input data. In this paper, we propose new black-box test case prioritization techniques using ARS, and the diversity of test cases is assessed by category-partition-based distance. Our experimental studies show that these new techniques deliver higher fault-detection effectiveness than random prioritization, especially in the case of smaller ratio of failed test cases. In addition, in the comparison of different distance metrics, techniques with category-partition-based distance generally deliver better fault-detection effectiveness and efficiency, meanwhile in the comparison of different ordering algorithms, our ARS-based ordering algorithms usually have comparable fault-detection effectiveness but much lower computation overhead, and thus are much more cost-effective.},
  keywords={Random sequences;Measurement;Testing;Subspace constraints;Fault detection;Algorithm design and analysis;Semantics;test case prioritization;adaptive random sequence;random sequence;catergory partition;string distance},
  doi={10.1109/QRS.2016.49},
  ISSN={},
  month={Aug},}@ARTICLE{9086053,
  author={Lima, Jackson A. Prado and Vergilio, Silvia Regina},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Multi-Armed Bandit Approach for Test Case Prioritization in Continuous Integration Environments}, 
  year={2022},
  volume={48},
  number={2},
  pages={453-465},
  abstract={Continuous Integration (CI) environments have been increasingly adopted in the industry to allow frequent integration of software changes, making software evolution faster and cost-effective. In such environments, Test Case Prioritization (TCP) techniques play an important role to reduce regression testing costs, establishing a test case execution order that usually maximizes early fault detection. Existing works on TCP in CI environments (TCPCI) present some limitations. Few pieces of work consider CI particularities, such as the test case volatility, that is, they do not consider the dynamic environment of the software life-cycle in which new test cases can be added or removed (discontinued), characteristic related to the Exploration versus Exploitation (EvE) dilemma. To solve such a dilemma an approach needs to balance: i) the diversity of test suite; and ii) the quantity of new test cases and test cases that are error-prone or that comprise high fault-detection capabilities. To deal with this, most approaches use, besides the failure-history, other measures that rely on code instrumentation or require additional information, such as testing coverage. However, to maintain the information updated can be difficult and time-consuming, not scalable due to the test budget of CI environments. In this context, and to properly deal with the TCPCI problem, this work presents an approach based on Multi-Armed Bandit (MAB) called COLEMAN (Combinatorial VOlatiLE Multi-Armed BANdit). The TCPCI problem falls into the category of volatile and combinatorial MAB, because multiple arms (test cases) need to be selected, and they are added or removed over the cycles. We conducted an evaluation considering three time budgets and eleven systems. The results show the applicability of our approach and that COLEMAN outperforms the most similar approach from literature in terms of early fault detection and performance.},
  keywords={Testing;Fault detection;Software;Instruments;Google;Industries;Companies;Test case prioritization;continuous integration;multi-armed bandit},
  doi={10.1109/TSE.2020.2992428},
  ISSN={1939-3520},
  month={Feb},}@INPROCEEDINGS{7381799,
  author={Noor, Tanzeem Bin and Hemmati, Hadi},
  booktitle={2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={A similarity-based approach for test case prioritization using historical failure data}, 
  year={2015},
  volume={},
  number={},
  pages={58-68},
  abstract={Test case prioritization is a crucial element in software quality assurance in practice, specially, in the context of regression testing. Typically, test cases are prioritized in a way that they detect the potential faults earlier. The effectiveness of test cases, in terms of fault detection, is estimated using quality metrics, such as code coverage, size, and historical fault detection. Prior studies have shown that previously failing test cases are highly likely to fail again in the next releases, therefore, they are highly ranked, while prioritizing. However, in practice, a failing test case may not be exactly the same as a previously failed test case, but quite similar, e.g., when the new failing test is a slightly modified version of an old failing one to catch an undetected fault. In this paper, we define a class of metrics that estimate the test cases quality using their similarity to the previously failing test cases. We have conducted several experiments with five real world open source software systems, with real faults, to evaluate the effectiveness of these quality metrics. The results of our study show that our proposed similarity-based quality measure is significantly more effective for prioritizing test cases compared to existing test case quality measures.},
  keywords={Measurement;Testing;Fault detection;History;Context;Software quality;Test case prioritization;Test quality metric;Similarity;Execution trace;Distance function;Historical data;Code coverage;Test size},
  doi={10.1109/ISSRE.2015.7381799},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9103716,
  author={Su, Wenjun and Li, Zhao and Wang, Zhihui and Yang, Dengxin},
  booktitle={2020 International Conference on Computer Engineering and Application (ICCEA)}, 
  title={A Meta-heuristic Test Case Prioritization Method Based on Hybrid Model}, 
  year={2020},
  volume={},
  number={},
  pages={430-435},
  abstract={Software testing is an important and complex part of the software development life cycle. Along with version changes and defect repairs of the software system under test, regression testing is required to ensure that the modified parts have no impact on the unmodified parts. In a resource-constrained environment, it is necessary to select a more valuable test case from the test case library to execute first. However, the existing prioritization methods of test cases are still insufficient in terms of Average Percentage of Faults Detected (APFD) and time execution performance, and there is a problem of large search space. Aiming at the test case priority ranking problem, this paper proposes a meta-heuristic test case prioritization method based on a hybrid model to reduce test cost. This method first establishes a hybrid model by using the correlation between test cases and the importance of test data, and then uses an improved firefly algorithm based on the hybrid model to find an optimal test sequence. This article has carried out experiments on three benchmark test programs. The test suite is from Software-artifact Infrastructure Repository (1SIR). The experimental results show that the method proposed in this paper has better performance in terms of APFD and time execution compared with existing methods, such as Greedy, Particle Swarm Optimization (PSO) and Firefly Algorithm (FA).},
  keywords={Software;Measurement;Brightness;Linear programming;Automation;Telecommunications;Software testing;component;Software testing;test case priority;hybrid model;firefly algorithm},
  doi={10.1109/ICCEA50009.2020.00099},
  ISSN={},
  month={March},}@INPROCEEDINGS{10621714,
  author={Găceanu, Radu and Szederjesi-Dragomir, Arnold and Vescan, Andreea},
  booktitle={2024 IEEE International Conference on Software Analysis, Evolution and Reengineering - Companion (SANER-C)}, 
  title={Leveraging Rough Sets for Enhanced Test Case Prioritization in a Continuous Integration Context}, 
  year={2024},
  volume={},
  number={},
  pages={175-182},
  abstract={In the rapidly evolving landscape of Continuous Integration (CI), test case execution becomes pivotal with every code modification, rendering regression testing strategies essential. Among these, Test Case Prioritization (TCP) has become a popular way to improve the efficiency and effectiveness of software testing. Recently, researchers have been mostly looking at supervised learning methods and reinforcement learning to deal with TCP in CI. However, because of the dynamic nature of these environments, it might be worth exploring unsupervised approaches that can adapt to the inherent uncertainties without labeled data. This paper proposes RoughTCP, a novel approach utilizing a rough sets-based agglomerative clustering algorithm, to prioritize test cases. RoughTCP automatically groups and ranks tests based on their intrinsic patterns and correlations (e.g., faults, tests duration, cycles count, and total runs count) without a predefined model. This improves fault detection without the need for constant supervision and provides a more comprehensive understanding of the results by incorporating rough sets. Three sets of experiments were performed, considering data from continuous integration contexts in industrial projects. Compared to recent related work, our experiments show that the RoughTCP approach yields better results for budgets higher than or equal to 75% on all datasets, while sometimes also outperforming all other methods on lower budgets. This underlines the potential of unsupervised methods and, in particular, the strength of RoughTCP in reshaping the TCP landscape in CI environments.},
  keywords={Software testing;Uncertainty;Heuristic algorithms;Supervised learning;Rough sets;Clustering algorithms;Reinforcement learning;Test Case Prioritization;Continuous Integration;Rough Sets;Clustering;Faults;Duration;Cycles},
  doi={10.1109/SANER-C62648.2024.00030},
  ISSN={},
  month={March},}@INPROCEEDINGS{6598153,
  author={Fuzhen Sun and Yan Li},
  booktitle={2013 Fourth International Conference on Digital Manufacturing & Automation}, 
  title={Regression Testing Prioritization Based on Model Checking for Safety-Crucial Embedded Systems}, 
  year={2013},
  volume={},
  number={},
  pages={979-983},
  abstract={The order in which test-cases are executed has an influence on the rate at which faults can be detected. In this paper we demonstrate how test-case prioritization can be performed with the use of model-checkers. For this, different well known prioritization techniques are adapted for modelbased use. New property based prioritization techniques are introduced. In addition it is shown that prioritization can be done at test-case generation time, thus removing the need for test-suite post-processing. Several experiments for safetycrucial embedded systems are used to show the validity of these ideas.},
  keywords={Manufacturing;Automation;Test Case Prioritization;Software Testing;Model Checking;Property Testing},
  doi={10.1109/ICDMA.2013.229},
  ISSN={},
  month={June},}@INPROCEEDINGS{10216597,
  author={Abdalla, Zeinab and Haring, Kerstin and Andrews, Anneliese},
  booktitle={2022 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Test Case Prioritization for Mobile Apps}, 
  year={2022},
  volume={},
  number={},
  pages={1843-1848},
  abstract={Like for any software, Mobile Applications (Apps) are modified during their specification, implementation, and maintenance phases with the goal to satisfy new requirements, fix defects, and change or add functionality. There is a need to regression test for and detect faults in every phase. However, resource and time constraints may lead to Mobile Apps not being tested. In this paper we present a model-based test approach to prioritize test cases based on the input complexity for each test path of the Mobile App. We argue that this novel approach will significantly improve the efficiency and effectiveness of current techniques.},
  keywords={Scientific computing;Fault detection;Computational modeling;Closed box;Maintenance engineering;Mobile applications;Complexity theory;Model-Based Regression Testing;Test Case Pri-oritization;Mobile Apps},
  doi={10.1109/CSCI58124.2022.00332},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{7943143,
  author={Kaur, Arvinder and Agrawal, Arun Prakash},
  booktitle={2017 7th International Conference on Cloud Computing, Data Science & Engineering - Confluence}, 
  title={A comparative study of Bat and Cuckoo search algorithm for regression test case selection}, 
  year={2017},
  volume={},
  number={},
  pages={164-170},
  abstract={Enhancing the software by either adding new functionality or deleting some obsolete capability or fixing the errors is called software maintenance. As a result, the software may function improperly or unchanged parts of the software may be adversely affected. Testing carried out to validate that no new errors have been introduced during maintenance activity is called Regression Testing. It is acknowledged to be an expensive activity and may account for around 60-70% of the total software life cycle cost. Reducing the cost of regression testing is therefore of vital importance and has the caliber to reduce the cost of maintenance also. This paper evaluates the performance of two metaheuristic algorithms-Bat Algorithm and Cuckoo Search Algorithm for selecting test cases. Factors that we have considered for performance evaluation are the number of faults detected and the execution time. The domain of study is the flex object from the Benchmark repository - Software Artifact and Infrastructure Repository. Extensive experiments have been conducted to collect and analyze the results. A Statistical test, F-test has also been conducted to validate the research hypothesis. Results indicate that the Cuckoo Search Algorithms perform a little better than Bat Algorithm.},
  keywords={Software algorithms;Software;Testing;Optimization;Search problems;Algorithm design and analysis;Estimation;Software Maintenance;Regression Test Case Selection;Bat Algorithm;Cuckoo Search Algorithm},
  doi={10.1109/CONFLUENCE.2017.7943143},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9142966,
  author={Gokilavani, N. and Bharathi, B.},
  booktitle={2020 4th International Conference on Trends in Electronics and Informatics (ICOEI)(48184)}, 
  title={An Enhanced Adaptive Random Sequence (EARS) Based Test Case Prioritization Using K-Mediods Based Fuzzy Clustering}, 
  year={2020},
  volume={},
  number={},
  pages={567-572},
  abstract={The efforts of prioritization method is to maximize the detection of fault rate by organizing the significant test cases which is operated in a sequence of regression tests. Generally, it is implemented to sort down the test cases based on the priorities former than those with minimum priority imparting to an estimated criteria. The faults which gives maximum impacts should be detected at earlier stages in testing practices. The adaptive random testing is implemented to execute arbitrary testing through input triggering clustering errors. It improves the detection ratio of regression testing in software based on object-oriented. In this proposal, an adaptive techniques of test case prioritization relied on fuzzy clustering is implemented. The adjacent matrices is generated and cluster head is chosen within the test cases. It is made by identity precise pairing. Then Enhanced Adaptive random sequence depending on prioritization of test cases detects the flaws which operates to categorize neighboring test cases as varied as possible. Hence the outcomes proved increased efficacy in earlier fault detection rate.},
  keywords={Testing;Random sequences;Software;Fault detection;Ear;Programming;Conferences;Adjacency Matrix;Fuzzy k-medoid;Adaptive Random Sequence (ARS);Average Percentage of Fault Detected},
  doi={10.1109/ICOEI48184.2020.9142966},
  ISSN={},
  month={June},}@INPROCEEDINGS{8530033,
  author={Luo, Qi and Moran, Kevin and Poshyvanyk, Denys and Di Penta, Massimiliano},
  booktitle={2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Assessing Test Case Prioritization on Real Faults and Mutants}, 
  year={2018},
  volume={},
  number={},
  pages={240-251},
  abstract={Test Case Prioritization (TCP) is an important component of regression testing, allowing for earlier detection of faults or helping to reduce testing time and cost. While several TCP approaches exist in the research literature, a growing number of studies have evaluated them against synthetic software defects, called mutants. Hence, it is currently unclear to what extent TCP performance on mutants would be representative of the performance achieved on real faults. To answer this fundamental question, we conduct the first empirical study comparing the performance of TCP techniques applied to both real-world and mutation faults. The context of our study includes eight well-studied TCP approaches, 35k+ mutation faults, and 357 real-world faults from five Java systems in the Defects4J dataset. Our results indicate that the relative performance of the studied TCP techniques on mutants may not strongly correlate with performance on real faults, depending upon attributes of the subject programs. This suggests that, in certain contexts, the best performing technique on a set of mutants may not be the best technique in practice when applied to real faults. We also illustrate that these correlations vary for mutants generated by different operators depending on whether chosen operators reflect typical faults of a subject program. This highlights the importance, particularly for TCP, of developing mutation operators tailored for specific program domains.},
  keywords={Testing;Software;Fault detection;Genetic algorithms;Correlation;Measurement;Data mining;Test Case Prioritization;Empirical Study;TCP;Mutation Analysis;Mutation Testing;Mutants},
  doi={10.1109/ICSME.2018.00033},
  ISSN={2576-3148},
  month={Sep.},}@INPROCEEDINGS{10298714,
  author={Vescan, Andreea and Găceanu, Radu and Szederjesi-Dragomir, Arnold},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW)}, 
  title={Neural Network-Based Test Case Prioritization in Continuous Integration}, 
  year={2023},
  volume={},
  number={},
  pages={68-77},
  abstract={In continuous integration environments, the execution of test cases is performed for every newly added feature or when a bug fix occurs. Therefore, regression testing is performed considering various testing strategies. The Test Case Prioritization (TCP) approach considers reordering test cases so that faults are found earlier with a minimum execution cost. The purpose of the paper is to investigate the impact of neural network-based classification models to assist in the prioritization of test cases. Three different models are employed with various features (duration, fault rate, cycles count, total runs count) and considering information at every 30 cycles or at every 100 cycles. The results obtained emphasize that the NEUTRON approach finds a better prioritization with respect to NAPFD (normalized average percent of the detected fault) than random permutation and is comparable with the solutions that used either duration or faults, considering that it combines both values. Compared to other existing approaches, NEUTRON obtains similar com-petitive results when considering a budget of 50% and the best results when considering budgets of 75% and 100%.},
  keywords={Source coding;Conferences;Computer bugs;Neutrons;Feature extraction;Testing;Software engineering;Test Case Prioritization;Continuous Integration;Neural Network;Faults;Duration;Cycles},
  doi={10.1109/ASEW60602.2023.00014},
  ISSN={2151-0849},
  month={Sep.},}@ARTICLE{6375700,
  author={Zhai, Ke and Jiang, Bo and Chan, W.K.},
  journal={IEEE Transactions on Services Computing}, 
  title={Prioritizing Test Cases for Regression Testing of Location-Based Services: Metrics, Techniques, and Case Study}, 
  year={2014},
  volume={7},
  number={1},
  pages={54-67},
  abstract={Location-based services (LBS) are widely deployed. When the implementation of an LBS-enabled service has evolved, regression testing can be employed to assure the previously established behaviors not having been adversely affected. Proper test case prioritization helps reveal service anomalies efficiently so that fixes can be scheduled earlier to minimize the nuisance to service consumers. A key observation is that locations captured in the inputs and the expected outputs of test cases are physically correlated by the LBS-enabled service, and these services heuristically use estimated and imprecise locations for their computations, making these services tend to treat locations in close proximity homogenously. This paper exploits this observation. It proposes a suite of metrics and initializes them to demonstrate input-guided techniques and point-of-interest (POI) aware test case prioritization techniques, differing by whether the location information in the expected outputs of test cases is used. It reports a case study on a stateful LBS-enabled service. The case study shows that the POI-aware techniques can be more effective and more stable than the baseline, which reorders test cases randomly, and the input-guided techniques. We also find that one of the POI-aware techniques, cdist, is either the most effective or the second most effective technique among all the studied techniques in our evaluated aspects, although no technique excels in all studied SOA fault classes.},
  keywords={Measurement;Entropy;Testing;Semiconductor optical amplifiers;Global Positioning System;Earth;Google;Regression testing;location-based services;black-box metrics;test case prioritization;point-of-interest},
  doi={10.1109/TSC.2012.40},
  ISSN={1939-1374},
  month={Jan},}@INPROCEEDINGS{8300829,
  author={Indumathi, C. P. and Madhumathi, S.},
  booktitle={2017 International Conference on Trends in Electronics and Informatics (ICEI)}, 
  title={Cost aware test suite reduction algorithm for regression testing}, 
  year={2017},
  volume={},
  number={},
  pages={869-874},
  abstract={Regression testing is the process that a recent code change has not adversely affect the existing features. The re-running of all the test cases during regression testing is very expensive as it requires huge time and resources. Test case prioritization techniques are to schedule the test cases in accordance with some criteria such that important test cases are executed with that given period. This study presents test case prioritization using genetic algorithm and their effectiveness is measured using APFD. Then the prioritized test cases are reduced. Test suite reduction techniques aim at identifying and eliminating redundant test cases from test suites in order to reduce the total number of test cases to execute, thereby improving the efficiency of the software testing activity. Our aim is to reduce the cost by reducing the number of test suite after prioritization. MFTS algorithm is used to reduce the given test suite with maximum coverage and it improves the rate of fault detection effectiveness.},
  keywords={Testing;Genetic algorithms;Fault detection;Software;Market research;Informatics;Heuristic algorithms;Regression testing;Genetic Algorithm;APFD;MFTS algorithm},
  doi={10.1109/ICOEI.2017.8300829},
  ISSN={},
  month={May},}@INPROCEEDINGS{9058244,
  author={Kaur, Amandeep},
  booktitle={2020 10th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={An Approach To Extract Optimal Test Cases Using AI}, 
  year={2020},
  volume={},
  number={},
  pages={649-654},
  abstract={Regression testing is the backbone of the functional Software Testing. Unlike any other testing; regression validation evolves the whole suite of code which incorporates the existing code as well as new code or the change request. Validating all the possible scenarios is not effective as it increases the expenditure. This gains the outlook for the researchers to analyze a more efficient way for regression testing by electing a subset from the test suite to spot the defects. Ample research has crop up for this NP-Hard problem and folks are implementing the metaheuristic techniques and dominantly the nature-inspired ones. In this paper, to extract the optimal test cases we have utilized Harris Hawks Optimization (HHO) which is a nature-inspired technique and portrays chasing drive away style of Harris' hawks termed as Surprise Pounce. In this tactic, assorted hawks combine together to pounce a prey through the offbeat directions to surprise the prey. This paper focuses on the Harris Hawks Optimization algorithm and its applications in the domain of software testing.},
  keywords={Optimization;Sociology;Statistics;Rabbits;Software testing;Genetic algorithms;Software testing;Regression testing;Optimization;Harris Hawks Optimization;Test case selection},
  doi={10.1109/Confluence47617.2020.9058244},
  ISSN={},
  month={Jan},}@ARTICLE{9394799,
  author={Bagherzadeh, Mojtaba and Kahani, Nafiseh and Briand, Lionel},
  journal={IEEE Transactions on Software Engineering}, 
  title={Reinforcement Learning for Test Case Prioritization}, 
  year={2022},
  volume={48},
  number={8},
  pages={2836-2856},
  abstract={Continuous Integration (CI) significantly reduces integration problems, speeds up development time, and shortens release time. However, it also introduces new challenges for quality assurance activities, including regression testing, which is the focus of this work. Though various approaches for test case prioritization have shown to be very promising in the context of regression testing, specific techniques must be designed to deal with the dynamic nature and timing constraints of CI. Recently, Reinforcement Learning (RL) has shown great potential in various challenging scenarios that require continuous adaptation, such as game playing, real-time ads bidding, and recommender systems. Inspired by this line of work and building on initial efforts in supporting test case prioritization with RL techniques, we perform here a comprehensive investigation of RL-based test case prioritization in a CI context. To this end, taking test case prioritization as a ranking problem, we model the sequential interactions between the CI environment and a test case prioritization agent as an RL problem, using three alternative ranking models. We then rely on carefully selected and tailored state-of-the-art RL techniques to automatically and continuously learn a test case prioritization strategy, whose objective is to be as close as possible to the optimal one. Our extensive experimental analysis shows that the best RL solutions provide a significant accuracy improvement over previous RL-based work, with prioritization strategies getting close to being optimal, thus paving the way for using RL to prioritize test cases in a CI context.},
  keywords={Testing;History;Training;Reinforcement learning;Software systems;Adaptation models;Software algorithms;Continuous integration;CI;reinforcement learning;test prioritization},
  doi={10.1109/TSE.2021.3070549},
  ISSN={1939-3520},
  month={Aug},}@ARTICLE{10872897,
  author={Rothermel, Gregg and Untch, Roland},
  journal={IEEE Transactions on Software Engineering}, 
  title={On “Prioritizing Test Cases for Regression Testing”}, 
  year={2025},
  volume={51},
  number={3},
  pages={802-807},
  abstract={The paper “Prioritizing Test Cases for Regression Testing”, by Rothermel, Untch, Chu and Harrold, appeared in IEEE Transactions on Software Engineering in 2001. This paper was a seminal paper in the area of test case prioritization, and it set the stage for research on many different topics related to prioritization. In this retrospective, we recount the work presented in the paper, and then reflect on how it has influenced subsequent research and practice.},
  keywords={Testing;Fault detection;Software;Codes;Minimization;Training;Surges;Software measurement;Software engineering;Electronic mail;Test case prioritization; regression testing},
  doi={10.1109/TSE.2025.3538490},
  ISSN={1939-3520},
  month={March},}@INPROCEEDINGS{7819324,
  author={Abele, Sebastian and Weyrich, Michael},
  booktitle={2016 IEEE 14th International Conference on Industrial Informatics (INDIN)}, 
  title={A combined fault diagnosis and test case selection assistant for automotive end-of-line test systems}, 
  year={2016},
  volume={},
  number={},
  pages={1072-1077},
  abstract={With growing complexity of premium cars, the end-of-line test systems also increase in complexity. The test systems have to provide more and more functionality like flashing of electronic control units (ECUs) and sensor calibration. Current end-of-line test systems evolved to complex networked IT-systems, which consist of various components and subsystems from different suppliers. Automotive production maintenance engineers are challenged to keep the availability of the test system on a high level to not cause production delays. In a case study with automotive test experts, we considered fault diagnosis and test case selection as two major tasks to maintain a high system availability. The experts combine their knowledge and experience about fault-prone system parts and former faults to optimize fault diagnosis and test case selection for regression testing. To support the experts to manage the growing complexity, we propose a combined fault diagnosis and test case selection assistance system. The combination of both techniques enables synergy effects by supporting the fault diagnosis with test case selection and by considering fault data in regression testing. This paper presents the concept of that combined assistant system and describes a prototypical realization used in an exemplary scenario.},
  keywords={Fault diagnosis;Monitoring;Production;Automotive engineering;Automobiles;Testing;Quality assurance},
  doi={10.1109/INDIN.2016.7819324},
  ISSN={2378-363X},
  month={July},}@INPROCEEDINGS{8473253,
  author={Ramya, Paruchuri and Sindhura, Vemuri and Vidya Sagar, P.},
  booktitle={2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)}, 
  title={Clustering Based Prioritization of Test Cases}, 
  year={2018},
  volume={},
  number={},
  pages={1181-1185},
  abstract={Regression testing is the procedure of retesting the product and checking whether additional faults or errors have been created in the existing one. It is vital for keeping up programming quality. But it is a costly process. By., utilizing prioritization technique cost can be diminished. Prioritization increases productiveness of regression testing and its main criteria is to build the rate of error detection. Merging requirements information into current testing practice helps the engineers to recognize the source of faults easily. In this paper a research is done on whether the requirements-based grouping methodology can enhance the viability of prioritization techniques. So., here a grouping approach is performed on given requirements and prioritization techniques based on code scope metric.},
  keywords={Testing;Programming;Clustering algorithms;Conferences;Software;Information technology;Tools;Regression testing;Test case prioritization-necessities based grouping;Code scope metric},
  doi={10.1109/ICICCT.2018.8473253},
  ISSN={},
  month={April},}@INPROCEEDINGS{6724209,
  author={Maheswari, R. Uma and JeyaMala, D.},
  booktitle={2013 IEEE International Conference on Computational Intelligence and Computing Research}, 
  title={A novel approach for test case prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  abstract={The process of verifying the modified software in the maintenance phase is called Regression Testing. The size of the regression test suite and its selection process is a complex task for regression testers because of time and budget constraints. In this research paper, new Prioritization technique based on hamming distance has been proposed. It is illustrated using an example and found that it produces good results. Average Percentage of Fault Detection (APFD) metrics and charts has been used to show the effectiveness of proposed algorithm.},
  keywords={Fault detection;Testing;Hamming distance;Bismuth;Conferences;Measurement;Software engineering;APFD;Fault based Test Suite prioritization;Hamming Distance},
  doi={10.1109/ICCIC.2013.6724209},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10764994,
  author={Baz, Abdelrahman and Huang, Minchao and Shi, August},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Prioritizing Tests for Improved Runtime}, 
  year={2024},
  volume={},
  number={},
  pages={2273-2278},
  abstract={Regression testing is important but costly due to the large number of tests to run over frequent changes. Techniques to speed up regression testing such as regression test selection run fewer tests, but they risk missing to run some key tests that detect true faults.In this work, we investigate the effect of running tests in different test-orders on overall test runtime in Java projects. Variance in runtime across different test-orders can be due to various reasons, such as due to dependencies between tests. In our evaluation, we run tests in different, random test-orders, and we find on average that the slowest test-order per project can be slower than the fastest test-order by 31.17%. We also develop a technique for guiding a search for the fastest test-orders by clustering test-orders based on their runtimes and generating test-orders based on observed in-common relations between tests in the fastest test-orders.},
  keywords={Java;Runtime;Testing;Regression testing;test case prioritization;runtime},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10062444,
  author={Chen, Fanliang and Li, Zheng and Shang, Ying and Yang, Yang},
  booktitle={2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Focus on New Test Cases in Continuous Integration Testing based on Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={830-841},
  abstract={In software regression testing, newly added test cases are more likely to fail, and therefore, should be prioritized for execution. In software regression testing for continuous integration, reinforcement learning-based approaches are promising and the RETECS (Reinforced Test Case Prioritization and Selection) framework is a successful application case. RETECS uses an agent composed of a neural network to predict the priority of test cases, and the agent needs to learn from historical information to make improvements. However, the newly added test cases have no historical execution information, thus using RETECS to predict their priority is more like ‘random’. In this paper, we focus on new test cases for continuous integration testing, and on the basis of the RETECS framework, we first propose a priority assignment method for new test cases to ensure that they can be executed first. Secondly, continuous integration is a fast iterative integration method where new test cases have strong fault detection capability within the latest periods. Therefore, we further propose an additional reward method for new test cases. Finally, based on the full lifecycle management, the ‘new’ additional rewards need to be terminated within a certain period, and this paper implements an empirical study. We conducted 30 iterations of the experiment on 12 datasets and our best results were 19.24%, 10.67%, and 34.05 positions better compared to the best parameter combination in RETECS for the NAPFD (Normalized Average Percentage of Faults Detected), RECALL and TTF (Test to Fail) metrics, respectively.},
  keywords={Measurement;Fault detection;Neural networks;Reinforcement learning;Software quality;Software reliability;Security;Continuous integration;new test case;test case prioritization;reinforcement learning;reward function;regression testing},
  doi={10.1109/QRS57517.2022.00088},
  ISSN={2693-9177},
  month={Dec},}@INPROCEEDINGS{9825820,
  author={Da Roza, Enrique A. and Lima, Jackson A. Prado and Silva, Rogério C. and Vergilio, Silvia Regina},
  booktitle={2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Machine Learning Regression Techniques for Test Case Prioritization in Continuous Integration Environment}, 
  year={2022},
  volume={},
  number={},
  pages={196-206},
  abstract={Test Case Prioritization (TCP) techniques are a key factor in reducing the regression testing costs even more when Continuous Integration (CI) practices are adopted. TCP approaches based on failure history have been adopted in this context because they are more suitable for CI environment constraints: test budget and test case volatility, that is, test cases may be added or removed over the CI cycles. Promising approaches are based on Reinforcement Learning (RL), which learns with past prioritization, guided by a reward function. In this work, we introduce a TCP approach for CI environments based on the sliding window method, which can be instantiated with different Machine Learning (ML) algorithms. Unlike other ML approaches, it does not require retraining the model to perform the prioritization and any code analysis. As an alternative for the RL approaches, we apply the Random Forest (RF) algorithm and a Long Short Term Memory (LSTM) deep learning network in our evaluation. We use three time budgets and eleven systems. The results show the applicability of the approach considering the prioritization time and the time between the CI cycles. Both algorithms take just a few seconds to execute. The RF algorithm obtained the best performance for more restrictive budgets compared to the RL approaches described in the literature. Considering all systems and budgets, RF reaches Normalized Average Percentage of Faults Detected (NAPFD) values that are the best or statistically equivalent to the best ones in around 72% of the cases, and the LSTM network in 55% of them. Moreover, we discuss some implications of our results for the usage of the algorithms evaluated.},
  keywords={Radio frequency;Machine learning algorithms;Recurrent neural networks;Software algorithms;Reinforcement learning;Software;History;Recurrent Neural Networks;Machine Learning;Continuous Integration;Regression Testing},
  doi={10.1109/SANER53432.2022.00034},
  ISSN={1534-5351},
  month={March},}@INPROCEEDINGS{7272927,
  author={Marijan, Dusica},
  booktitle={2015 IEEE International Conference on Software Quality, Reliability and Security}, 
  title={Multi-perspective Regression Test Prioritization for Time-Constrained Environments}, 
  year={2015},
  volume={},
  number={},
  pages={157-162},
  abstract={Test case prioritization techniques are widely used to enable reaching certain performance goals during regression testing faster. A commonly used goal is high fault detection rate, where test cases are ordered in a way that enables detecting faults faster. However, for optimal regression testing, there is a need to take into account multiple performance indicators, as considered by different project stakeholders. In this paper, we introduce a new optimal multi-perspective approach for regression test case prioritization. The approach is designed to optimize regression testing for faster fault detection integrating three different perspectives: business perspective, performance perspective, and technical perspective. The approach has been validated in regression testing of industrial mobile device systems developed in continuous integration. The results show that our proposed framework efficiently prioritizes test cases for faster and more efficient regression fault detection, maximizing the number of executed test cases with high failure frequency, high failure impact, and cross-functional coverage, compared to manual practice.},
  keywords={Testing;Fault detection;Manuals;Software;Business;Time factors;Time-frequency analysis;software testing;regression testing;test case prioritization},
  doi={10.1109/QRS.2015.31},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8539203,
  author={Azizi, Maral and Do, Hyunsook},
  booktitle={2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Graphite: A Greedy Graph-Based Technique for Regression Test Case Prioritization}, 
  year={2018},
  volume={},
  number={},
  pages={245-251},
  abstract={To date, various test prioritization techniques have been developed, but the majority of these techniques consider a single objective that could limit the applicability of prioritization techniques by ignoring practical constraints imposed on regression testing. Multi-objective prioritization techniques try to reorder test cases so that they can optimize multiple goals that testers want to achieve. In this paper, we introduced a novel graph-based framework that maps the prioritization task to a graph traversal algorithm. To evaluate our approach, we performed an empirical study using 20 versions of four open source applications. Our results indicate that the use of the graph-based technique can improve the effectiveness and efficiency of test case prioritization technique.},
  keywords={Graphite;Testing;Measurement;Feature extraction;Task analysis;Fault detection;Genetic algorithms;Regression Testing},
  doi={10.1109/ISSREW.2018.00014},
  ISSN={},
  month={Oct},}@ARTICLE{6484067,
  author={Sampath, Sreedevi and Bryce, Renée and Memon, Atif M.},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Uniform Representation of Hybrid Criteria for Regression Testing}, 
  year={2013},
  volume={39},
  number={10},
  pages={1326-1344},
  abstract={Regression testing tasks of test case prioritization, test suite reduction/minimization, and regression test selection are typically centered around criteria that are based on code coverage, test execution costs, and code modifications. Researchers have developed and evaluated new individual criteria; others have combined existing criteria in different ways to form what we--and some others--call hybrid criteria. In this paper, we formalize the notion of combining multiple criteria into a hybrid. Our goal is to create a uniform representation of such combinations so that they can be described unambiguously and shared among researchers. We envision that such sharing will allow researchers to implement, study, extend, and evaluate the hybrids using a common set of techniques and tools. We precisely formulate three hybrid combinations, Rank, Merge, and Choice, and demonstrate their usefulness in two ways. First, we recast, in terms of our formulations, others' previously reported work on hybrid criteria. Second, we use our previous results on test case prioritization to create and evaluate new hybrid criteria. Our findings suggest that hybrid criteria of others can be described using our Merge and Rank formulations, and that the hybrid criteria we developed most often outperformed their constituent individual criteria.},
  keywords={Testing;Fault detection;Educational institutions;Genetic algorithms;Vectors;Loss measurement;Minimization;Test case prioritization;test criteria;hybrid test criteria;web testing;GUI testing},
  doi={10.1109/TSE.2013.16},
  ISSN={1939-3520},
  month={Oct},}@ARTICLE{7362042,
  author={Marchetto, Alessandro and Islam, Md. Mahfuzul and Asghar, Waseem and Susi, Angelo and Scanniello, Giuseppe},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Multi-Objective Technique to Prioritize Test Cases}, 
  year={2016},
  volume={42},
  number={10},
  pages={918-940},
  abstract={While performing regression testing, an appropriate choice for test case ordering allows the tester to early discover faults in source code. To this end, test case prioritization techniques can be used. Several existing test case prioritization techniques leave out the execution cost of test cases and exploit a single objective function (e.g., code or requirements coverage). In this paper, we present a multi-objective test case prioritization technique that determines the ordering of test cases that maximize the number of discovered faults that are both technical and business critical. In other words, our new technique aims at both early discovering faults and reducing the execution cost of test cases. To this end, we automatically recover links among software artifacts (i.e., requirements specifications, test cases, and source code) and apply a metric-based approach to automatically identify critical and fault-prone portions of software artifacts, thus becoming able to give them more importance during test case prioritization. We experimentally evaluated our technique on 21 Java applications. The obtained results support our hypotheses on efficiency and effectiveness of our new technique and on the use of automatic artifacts analysis and weighting in test case prioritization.},
  keywords={Software;Fault diagnosis;Testing;Software engineering;Business;Electronic mail;Optimization;Regression testing;requirements;testing;test case prioritization},
  doi={10.1109/TSE.2015.2510633},
  ISSN={1939-3520},
  month={Oct},}@INPROCEEDINGS{6928903,
  author={Jia, Changjiang and Mei, Lijun and Chan, W.K. and Yu, Y.T. and Tse, T.H.},
  booktitle={2014 IEEE International Conference on Web Services}, 
  title={Is XML-Based Test Case Prioritization for Validating WS-BPEL Evolution Effective in Both Average and Adverse Scenarios?}, 
  year={2014},
  volume={},
  number={},
  pages={233-240},
  abstract={In real life, a tester can only afford to apply one test case prioritization technique to one test suite against a service-oriented workflow application once in the regression testing of the application, even if it results in an adverse scenario such that the actual performance in the test session is far below the average. It is unclear whether the factors of test case prioritization techniques known to be significant in terms of average performance can be extrapolated to adverse scenarios. In this paper, we examine whether such a factor or technique may consistently affect the rate of fault detection in both the average and adverse scenarios. The factors studied include prioritization strategy, artifacts to provide coverage data, ordering direction of a strategy, and the use of executable and non-executable artifacts. The results show that only a minor portion of the 10 studied techniques, most of which are based on the iterative strategy, are consistently effective in both average and adverse scenarios. To the best of our knowledge, this paper presents the first piece of empirical evidence regarding the consistency in the effectiveness of test case prioritization techniques and factors of service-oriented workflow applications between average and adverse scenarios.},
  keywords={Testing;XML;Fault detection;Web services;Educational institutions;Indexes;Cities and towns;XML-based factor;WS-BPEL;adaptation;adverse},
  doi={10.1109/ICWS.2014.43},
  ISSN={},
  month={June},}@INPROCEEDINGS{6895426,
  author={Hettiarachchi, Charitha and Do, Hyunsook and Choi, Byoungju},
  booktitle={2014 Eighth International Conference on Software Security and Reliability (SERE)}, 
  title={Effective Regression Testing Using Requirements and Risks}, 
  year={2014},
  volume={},
  number={},
  pages={157-166},
  abstract={The use of system requirements and their risks enables software testers to identify more important test cases that can reveal faults associated with risky components. Having identified those test cases, software testers can manage the testing schedule more effectively by running such test cases earlier so that they can fix faults sooner. Some work in this area has been done, but the previous approaches and studies have some limitations, such as an improper use of requirements risks in prioritization and an inadequate evaluation method. To address the limitations, we implemented a new requirements risk-based prioritization technique and evaluated it considering whether the proposed approach can detect faults earlier overall. It can also detect faults associated with risky components earlier. Our results indicate that the proposed approach is effective for detecting faults early and even better for finding faults associated with risky components of the system earlier than the existing techniques.},
  keywords={Software;Testing;Mathematical model;Complexity theory;Equations;Security;Measurement;regression testing;requirements risks-based testing;test case prioritization;empirical study},
  doi={10.1109/SERE.2014.29},
  ISSN={},
  month={June},}@INPROCEEDINGS{9825849,
  author={Birchler, Christian and Ganz, Nicolas and Khatiri, Sajad and Gambi, Alessio and Panichella, Sebastiano},
  booktitle={2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Cost-effective Simulation-based Test Selection in Self-driving Cars Software with SDC-Scissor}, 
  year={2022},
  volume={},
  number={},
  pages={164-168},
  abstract={Simulation platforms facilitate the continuous development of complex systems such as self-driving cars (SDCs). However, previous results on testing SDCs using simulations have shown that most of the automatically generated tests do not strongly contribute to establishing confidence in the quality and reliability of the SDC. Therefore, those tests can be characterized as “uninformative”, and running them generally means wasting precious computational resources. We address this issue with SDC-Scissor, a framework that leverages Machine Learning to identify simulation-based tests that are unlikely to detect faults in the SDC software under test and skip them before their execution. Consequently, by filtering out those tests, SDC-Scissor reduces the number of long-running simulations to execute and drastically increases the cost-effectiveness of simulation-based testing of SDCs software. Our evaluation concerning two large datasets and around 12'000 tests showed that SDC-Scissor achieved a higher classification F1-score (between 47% and 90%) than a randomized baseline in identifying tests that lead to a fault and reduced the time spent running uninformative tests (speedup between 107% and 170%). Webpage & Video: https://github.com/ChristianBirchler/sdc-scissor},
  keywords={Fault diagnosis;Filtering;Computational modeling;Transportation;Machine learning;Feature extraction;Software;Self-driving cars;Software Simulation;Regression Testing;Test Case Selection;Continuous Integration},
  doi={10.1109/SANER53432.2022.00030},
  ISSN={1534-5351},
  month={March},}@INPROCEEDINGS{6595798,
  author={Alves, Everton L. G. and Machado, Patricia D. L. and Massoni, Tiago and Santos, Samuel T. C.},
  booktitle={2013 8th International Workshop on Automation of Software Test (AST)}, 
  title={A refactoring-based approach for test case selection and prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={93-99},
  abstract={Refactoring edits, commonly applied during software development, may introduce faults in a previously-stable code. Therefore, regression testing is usually applied to check whether the code maintains its previous behavior. In order to avoid rerunning the whole regression suite, test case prioritization techniques have been developed to order test cases for earlier achievement of a given goal, for instance, improving the rate of fault detection during regression testing execution. However, as current techniques are usually general purpose, they may not be effective for early detection of refactoring faults. In this paper, we propose a refactoring-based approach for selecting and prioritizing regression test cases, which specializes selection/prioritization tasks according to the type of edit made. The approach has been evaluated through a case study that compares it to well-known prioritization techniques by using a real open-source Java system. This case study indicates that the approach can be more suitable for early detection of refactoring faults when comparing to the other prioritization techniques.},
  keywords={Testing;Java;Fault detection;Software;Object oriented modeling;Measurement;Debugging},
  doi={10.1109/IWAST.2013.6595798},
  ISSN={},
  month={May},}@INPROCEEDINGS{7589824,
  author={Jiang, Bo and Chan, W.K.},
  booktitle={2016 IEEE International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Testing and Debugging in Continuous Integration with Budget Quotas on Test Executions}, 
  year={2016},
  volume={},
  number={},
  pages={439-447},
  abstract={In Continuous Integration, a software application is developed through a series of development sessions, each with limited time allocated to testing and debugging on each of its modules. Test Case Prioritization can help execute test cases with higher failure estimate earlier in each session. When the testing time is limited, executing such prioritized test cases may only produce partial and prioritized execution coverage data. To identify faulty code, existing Spectrum-Based Fault Localization techniques often use execution coverage data but without the assumption of execution coverage priority. Is it possible to decompose these two steps for optimization within individual steps? In this paper, we study to what extent the selection of test case prioritization techniques may reduce its influence on the effectiveness of spectrum-based fault localization, thereby showing the possibility to decompose the process of continuous integration for optimization in workflow steps. We present a controlled experiment using the Siemens suite as subjects, nine test case prioritization techniques and four spectrum-based fault localization techniques. The findings showed that the studied test cases prioritization and spectrum-based fault localization can be customized separately, and, interestingly, prioritization over a smaller test suite can enable spectrum-based fault localization to achieve higher accuracy by assigning faulty statements with higher ranks.},
  keywords={Measurement;Testing;Clustering algorithms;Debugging;Computer bugs;Fault diagnosis;Optimization;continuous integration;fault localization;test case prioritization;regression testing;debugging;standardization},
  doi={10.1109/QRS.2016.66},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7091286,
  author={Kwon, Jung-Hyun and Ko, In-Young and Rothermel, Gregg and Staats, Matt},
  booktitle={2014 21st Asia-Pacific Software Engineering Conference}, 
  title={Test Case Prioritization Based on Information Retrieval Concepts}, 
  year={2014},
  volume={1},
  number={},
  pages={19-26},
  abstract={In regression testing, running all a system's test cases can require a great deal of time and resources. Test case prioritization (TCP) attempts to schedule test cases to achieve goals such as higher coverage or faster fault detection. While code coverage-based approaches are typical in TCP, recent work has explored the use of additional information to improve effectiveness. In this work, we explore the use of Information Retrieval (IR) techniques to improve the effectiveness of TCP, particularly for testing infrequently tested code. Our approach considers the frequency at which elements have been tested, in additional to traditional coverage information, balancing these factors using linear regression modeling. Our empirical study demonstrates that our approach is generally more effective than both random and traditional code coverage-based approaches, with improvements in rate of fault detection of up to 4.7%.},
  keywords={Testing;Fault detection;Training;Java;Mathematical model;Linear regression;Information retrieval},
  doi={10.1109/APSEC.2014.12},
  ISSN={1530-1362},
  month={Dec},}@INPROCEEDINGS{8377661,
  author={Jiang, Bo and Wu, Yu and Zhang, Yongfei and Zhang, Zhenyu and Chan, W.K.},
  booktitle={2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={ReTestDroid: Towards Safer Regression Test Selection for Android Application}, 
  year={2018},
  volume={01},
  number={},
  pages={235-244},
  abstract={Mobile applications are widely used in our daily life and Android is the most popular open source mobile operating system. Because mobile applications update frequently, it is important developers to perform regression testing to ensure their quality. Modeling the control flow of an android application based on the activity lifecycle model only is imprecise for regression testing. Because many Android applications use asynchronous tasks, fragments, and native code frequently, which must be considered during change impact analysis. Otherwise, regression test selection techniques may miss some failure-revealing test cases, compromising the safety of these techniques. In this work, we propose a novel approach to model asynchronous task invocations, fragment-based activity lifecycle, and native code within the control flow graph of an Android application. Furthermore, we designed a regression test selection tool ReTestDroid based on our graph model. Our experiments on five real-life Android applications showed that our approach could enable much safer regression test selection while significantly saving regression-testing time.},
  keywords={Androids;Humanoid robots;Testing;Flow graphs;Smart phones;Mobile applications;Task analysis;Test Case Selection, Android, Regression Testing, Impact Analysis},
  doi={10.1109/COMPSAC.2018.00037},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{6606565,
  author={Zhang, Lingming and Hao, Dan and Zhang, Lu and Rothermel, Gregg and Mei, Hong},
  booktitle={2013 35th International Conference on Software Engineering (ICSE)}, 
  title={Bridging the gap between the total and additional test-case prioritization strategies}, 
  year={2013},
  volume={},
  number={},
  pages={192-201},
  abstract={In recent years, researchers have intensively investigated various topics in test-case prioritization, which aims to re-order test cases to increase the rate of fault detection during regression testing. The total and additional prioritization strategies, which prioritize based on total numbers of elements covered per test, and numbers of additional (not-yet-covered) elements covered per test, are two widely-adopted generic strategies used for such prioritization. This paper proposes a basic model and an extended model that unify the total strategy and the additional strategy. Our models yield a spectrum of generic strategies ranging between the total and additional strategies, depending on a parameter referred to as the p value. We also propose four heuristics to obtain differentiated p values for different methods under test. We performed an empirical study on 19 versions of four Java programs to explore our results. Our results demonstrate that wide ranges of strategies in our basic and extended models with uniform p values can significantly outperform both the total and additional strategies. In addition, our results also demonstrate that using differentiated p values for both the basic and extended models with method coverage can even outperform the additional strategy using statement coverage.},
  keywords={Fault detection;Measurement;Java;Testing;Arrays;Software;Educational institutions},
  doi={10.1109/ICSE.2013.6606565},
  ISSN={1558-1225},
  month={May},}@INPROCEEDINGS{10336260,
  author={Zhao, Yifan and Hao, Dan and Zhang, Lu},
  booktitle={2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Revisiting Machine Learning based Test Case Prioritization for Continuous Integration}, 
  year={2023},
  volume={},
  number={},
  pages={232-244},
  abstract={To alleviate the cost of regression testing in continuous integration (CI), a large number of machine learning-based (ML-based) test case prioritization techniques have been proposed. However, it is yet unknown how they perform under the same experimental setup, because they are evaluated on different datasets with different metrics. To bridge this gap, we conduct the first comprehensive study on these ML-based techniques in this paper. We investigate the performance of 11 representative ML-based prioritization techniques for CI on 11 open-source subjects and obtain a series of findings. For example, the performance of the techniques changes across CI cycles, mainly resulting from the changing amount of training data, instead of code evolution and test removal/addition. Based on the findings, we give some actionable suggestions on enhancing the effectiveness of ML-based techniques, e.g., pretraining a prioritization technique with cross-subject data to get it thoroughly trained and then finetuning it with within-subject data dramatically improves its performance. In particular, the pretrained MART achieves state-of-the-art performance, producing the optimal sequence on 80% subjects, while the existing best technique, the original MART, only produces the optimal sequence on 50% subjects.},
  keywords={Measurement;Bridges;Software maintenance;Costs;Codes;Training data;Machine learning;test prioritization;machine learning;continuous integration},
  doi={10.1109/ICSME58846.2023.00032},
  ISSN={2576-3148},
  month={Oct},}@ARTICLE{10478254,
  author={Laaber, Christoph and Yue, Tao and Ali, Shaukat},
  journal={IEEE Transactions on Software Engineering}, 
  title={Evaluating Search-Based Software Microbenchmark Prioritization}, 
  year={2024},
  volume={50},
  number={7},
  pages={1687-1703},
  abstract={Ensuring that software performance does not degrade after a code change is paramount. A solution is to regularly execute software microbenchmarks, a performance testing technique similar to (functional) unit tests, which, however, often becomes infeasible due to extensive runtimes. To address that challenge, research has investigated regression testing techniques, such as test case prioritization (TCP), which reorder the execution within a microbenchmark suite to detect larger performance changes sooner. Such techniques are either designed for unit tests and perform sub-par on microbenchmarks or require complex performance models, drastically reducing their potential application. In this paper, we empirically evaluate single- and multi-objective search-based microbenchmark prioritization techniques to understand whether they are more effective and efficient than greedy, coverage-based techniques. For this, we devise three search objectives, i.e., coverage to maximize, coverage overlap to minimize, and historical performance change detection to maximize. We find that search algorithms (SAs) are only competitive with but do not outperform the best greedy, coverage-based baselines. However, a simple greedy technique utilizing solely the performance change history (without coverage information) is equally or more effective than the best coverage-based techniques while being considerably more efficient, with a runtime overhead of less than $1$1%. These results show that simple, non-coverage-based techniques are a better fit for microbenchmarks than complex coverage-based techniques.},
  keywords={Benchmark testing;Software;Search problems;Runtime;Source coding;Java;Software measurement;Software microbenchmarking;performance testing;JMH;search-based software engineering;multi-objective optimization;regression testing;test case prioritization},
  doi={10.1109/TSE.2024.3380836},
  ISSN={1939-3520},
  month={July},}@INPROCEEDINGS{8719502,
  author={Jung, Pilsu and Kang, Sungwon and Lee, Jihyun and Park, Taehyun},
  booktitle={2018 25th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Automated Code-Based Test Selection for Software Product Line Regression Testing}, 
  year={2018},
  volume={},
  number={},
  pages={663-667},
  abstract={Regression testing for software product line (SPL) is challenging and can be expensive because it must ensure that all the products of a product family are correct whenever changes are made. SPL regression testing can be made efficient by selecting only the test cases that are relevant to the changes. In the past, some approaches for SPL test case selection have been proposed. However, they require requirements specification, architecture and/or traceabilities for test cases that are well managed for selecting test cases for a retest. In this paper, we propose an automated method of source code-based regression test selection for SPLs that selects regression tests, based on the commonality and variability of a product family while leaving out the test cases not affected by the changes to the source code. Preliminary evaluation of our method using five product lines shows that our method reduces without missing any fault-revealing test cases the number of test cases for a retest by 22.4%, 13.4% and 20.4%, on average, compared to, respectively, the retest-all method, the random selection method and the complete selection method.},
  keywords={Testing;Software product lines;Computer architecture;Software maintenance;Computer aided software engineering;Product Lines Testing;Regression Test Selection;Software Maintenance;Software Evolution},
  doi={10.1109/APSEC.2018.00086},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{10304799,
  author={Wang, Dingbang and Zhao, Yu and Xiao, Lu and Yu, Tingting},
  booktitle={2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)}, 
  title={An Empirical Study of Regression Testing for Android Apps in Continuous Integration Environment}, 
  year={2023},
  volume={},
  number={},
  pages={1-11},
  abstract={Continuous integration (CI) has become a popular method for automating code changes, testing, and software project delivery. However, sufficient testing prior to code submission is crucial to prevent build breaks. Additionally, testing must provide developers with quick feedback on code changes, which requires fast testing times. While regression test selection (RTS) has been studied to improve the cost-effectiveness of regression testing for lower-level tests (i.e., unit tests), it has not been applied to the testing of user interfaces (UI) in application domains such as mobile apps. UI testing at the UI level requires different techniques such as impact analysis and automated test execution. In this paper, we examine the use of RTS in CI settings for UI testing across various open-source mobile apps. Our analysis focuses on using Frequency Analysis to understand the need for RTS, Cost Analysis to evaluate the cost of impact analysis and test case selection algorithms, and Test Reuse Analysis to determine the reusability of UI test sequences for automation. The insights from this study will guide practitioners and researchers in developing advanced RTS techniques that can be adapted to CI environments for mobile apps.},
  keywords={Codes;Automation;User interfaces;Software;Mobile applications;Software measurement;Cost benefit analysis;Regression testing;Android apps;Empirical study},
  doi={10.1109/ESEM56168.2023.10304799},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10675987,
  author={Balink, Robert and Wendland, Marc-Florian and Yevstihnyeyev, Yuriy},
  booktitle={2024 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Selecting “good” regression tests based on a classification of side-effects}, 
  year={2024},
  volume={},
  number={},
  pages={309-317},
  abstract={When software systems undergo modifications, regression testing is a prominent risk mitigation technique to safeguard the quality of actually unmodified parts of that system. Being a change-based test type, regression tests should ideally be automatically executed as often as modifications happen to the system. When regression testing takes too long to be executed in its entirety, a selection has to be done to execute only those regression tests that safeguard the unmodified parts of the system the best. The potential to detect side-effects is associated to the type of modification made to the system and varies among regression tests. A selection algorithm must be able to identify “good” regression tests according to the modifications made. A “good” regression test is a regression test that has a higher capability to detect probable unwanted side-effects of a modification. This paper introduces a novel approach to regression test selection based on classification of side-effects and quantification of the side-effect detection potential of each regression test. Two approaches to regression test selection are described. Both approaches were implemented by a prototype and integrated into the CI/CD pipeline of the industrial software system Vaadin. Eventually, the effectiveness of the selection approach is evaluated.},
  keywords={Software testing;Correlation;Instruments;Conferences;Pipelines;Prototypes;Software systems;quality assurance;software testing;regression testing;test case selection},
  doi={10.1109/ICSTW60967.2024.00061},
  ISSN={2159-4848},
  month={May},}@INPROCEEDINGS{10011478,
  author={Altiero, Francesco and Colella, Giovanni and Corazza, Anna and Di Martino, Sergio and Peron, Adriano and Starace, Luigi L. L.},
  booktitle={2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Change-Aware Regression Test Prioritization using Genetic Algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={125-132},
  abstract={Regression testing is a practice aimed at providing confidence that, within software maintenance, the changes in the code base have introduced no faults in previously validated functionalities. With the software industry shifting towards iterative and incremental development with shorter release cycles, the straightforward approach of re-executing the entire test suite on each new version of the software is often unfeasible due to time and resource constraints. In such scenarios, Test Case Prioritization (TCP) strategies aim at providing an effective ordering of the test suite, so that the tests that are more likely to expose faults are executed earlier and fault detection is maximised even when test execution needs to be abruptly terminated due to external constraints. In this work, we propose Genetic-Diff, a TCP strategy based on a genetic algorithm featuring a specifically-designed crossover operator and a novel objective function that combines code coverage metrics with an analysis of changes in the code base. We empirically evaluate the proposed algorithm on several releases of three heterogeneous real-world, open source Java projects, in which we artificially injected faults, and compare the results with other state-of-the-art TCP techniques using fault-detection rate metrics. Findings show that the proposed technique performs generally better than the baselines, especially when there is a limited amount of code changes, which is a common scenario in modern development practices.},
  keywords={Measurement;Software maintenance;Codes;Software algorithms;Software systems;Linear programming;Time factors;Regression Testing;Test Case Prioritization;Genetic Algorithms},
  doi={10.1109/SEAA56994.2022.00028},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9260075,
  author={Shi, Tingting and Xiao, Lei and Wu, Keshou},
  booktitle={2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Reinforcement Learning Based Test Case Prioritization for Enhancing the Security of Software}, 
  year={2020},
  volume={},
  number={},
  pages={663-672},
  abstract={In order to enhance the security of software, each system update needs to perform regression test. Regression testing in a continuous integration environment requires test cases to meet the needs of rapid feedback. Therefore, it is necessary to enable test cases to be effectively sorted within a certain time range so that more failure data could be discovered and the fault detection rate of testing could be improved. Reinforcement learning algorithms interact with the environment, so it is viable to optimize the sorting problem of test case in the process of continuous integration through a reward mechanism. In the development environment of continuous integration, it has been experimentally proven that the execution history of test cases in the last four cycles has a greater impact on the sorting of test cases in the current cycle. Therefore, a new RHE reward function was put forward by using part of weighted information obtained from historical execution result for enhancing the security of the system. Taking the influence of execution time into account, the multi-target sequencing technology for test case is employed with a view to improving the efficiency of defect discovery. It has been found by applying this sorting method to three industrial testing research that: (1) compared with weighted reward function based on the entire historical execution information, the function based on the four historical execution information had a higher capability of detecting faults; (2) The reward function obtained from the weighted historical results could effectively improve the fault detection rate and reduce the time consumed. (3) The multi-objective sorting methods taking execution time into consideration was able to maximize the number of testing cases that had already discovered faults within the available time.},
  keywords={Testing;Reinforcement learning;Sorting;Software;History;Erbium;Security;continuous integration;reinforcement learning;fault detection rate;reward function;historical execution information;multi-objective sorting},
  doi={10.1109/DSAA49011.2020.00076},
  ISSN={},
  month={Oct},}@ARTICLE{9534659,
  author={Mondal, Shouvick and Nasre, Rupesh},
  journal={IEEE Transactions on Software Engineering}, 
  title={${{\sf Colosseum}}$Colosseum: Regression Test Prioritization by Delta Displacement in Test Coverage}, 
  year={2022},
  volume={48},
  number={10},
  pages={4060-4073},
  abstract={The problem of test-case prioritization has been pursued for over three decades now and continues to be one of the active topics in software testing research. In this paper, we focus on a code-coverage based regression test-prioritization solution (${{\sf Colosseum}}$Colosseum) that takes into account the position of changed (delta) code elements (basic-blocks) along the loop-free straight-line execution path of the regression test-cases. We propose a heuristic that logically associates each of these paths with three parameters: (i) the offset (displacement a) of the first delta from the starting basic-block, (ii) the offset (displacement c) of the last delta from the terminating basic block, and (iii) the average scattering (displacement b) within all the intermediate basic-blocks. We hypothesize that a regression test-case path with a shorter overall displacement has a good chance of propagating the affects of the code-changes to the observable outputs in the program. ${{\sf Colosseum}}$Colosseum prioritizes test-cases with smaller overall displacements and executes them early in the regression test-execution cycle. The underlying intuition is that the probability of a test-case revealing a regression fault depends on the probability of the corresponding change propagation. The change in this context can potentially lead to an error. Extending this logic, delta displacement provides an approximation to failed error propagation. Evaluation on 20 open-source C projects from the Software-artifact Infrastructure Repository and GitHub (totaling: 694,512 SLOC, 280 versions, and 69,305 test-cases) against four state-of-the-art prioritizations reveals that: ${{\sf Colosseum}}$Colosseum outperforms the competitors with an overall 84.61% success in terms of 13 prioritization effectiveness metrics, majority of which prefer to execute top-$k\%$k% prioritized test-cases.},
  keywords={Codes;Scattering;Logic gates;Task analysis;Software testing;Open source software;Maintenance engineering;Test-case prioritization;regression testing;code-change displacement;priority distribution;queue interleaving},
  doi={10.1109/TSE.2021.3111169},
  ISSN={1939-3520},
  month={Oct},}@INPROCEEDINGS{10186478,
  author={Shang, Ying and Li, Qianyu and Yang, Yang and Li, Zheng},
  booktitle={2020 IEEE/ACM International Conference on Software and System Processes (ICSSP)}, 
  title={Occurrence Frequency and All Historical Failure Information Based Method for TCP in CI}, 
  year={2020},
  volume={},
  number={},
  pages={105-114},
  abstract={In continuous integration (CI) environments, the program is rapidly and frequently modified and integrated. This feature introduces significant challenges to testing processes conducted in these environments. Based on existing technology, a test case that fails frequently is likely to fail in future tests. Therefore, the historical execution results of test cases are essential to guide the test case prioritization (TCP) in the CI environment. Reinforcement learning involves solving sequential decision-making problems and is suitable for TCP in the CI environment. At present, most of the TCP techniques based on reinforcement learning rely on the current cycle historical failure information of test cases. They rarely consider more historical cycle information, as well as other influencing factors. In this paper, we discussed the occurrence frequency of test cases for the first time. We also considered all historical information of each test case and proposed three new reward function, which employs the percentage of historical failure and the failure distribution of test cases, which can guide the reinforcement learning process. We evaluate our method on five industrial data sets. The experimental results show that our method can effectively prioritize test cases and improve the cost-effectiveness of the CI process.},
  keywords={Time-frequency analysis;Decision making;Reinforcement learning;Software;Testing;Continuous Integration;Test Case Prioritization;Regression Testing;Reinforcement Learning;Historical Failure Information;Occurrence Frequency},
  doi={},
  ISSN={},
  month={June},}@INPROCEEDINGS{8914670,
  author={Silva, Dennis Sávio and Rabelo, Ricardo and Neto, Pedro Santos and Britto, Ricardo and Oliveira, Pedro Almir},
  booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)}, 
  title={A Test Case Prioritization Approach Based on Software Component Metrics}, 
  year={2019},
  volume={},
  number={},
  pages={2939-2945},
  abstract={The most common way of performing regression testing is by executing all test cases associated with a software system. However, this approach is not scalable since time and cost to execute the test cases increase together with the system’s size. A way to address this consists of prioritizing the existing test cases, aiming to maximize a test suite’s fault detection rate. To address the limitations of existing approaches, in this paper we propose a new approach to maximize the rate of fault detection of test suites. Our proposal has three steps: i) infer code components’ criticality values using a fuzzy inference system; ii) calculate test cases’ criticality; iii) prioritize the test cases using ant colony optimization. The test cases are prioritized considering criticality, execution time and history of faults, and the resulting test suites are evaluated according to their fault detection rate. The evaluation was performed in eight programs, and the results show that the fault detection rate of the solutions was higher than in the non-ordered test suites and ones obtained using a greedy approach, reaching the optimal value when possible to verify. A sanity check was performed, comparing the obtained results to the results of a random search. The approach performed better at significant levels of statistic and practical difference, evidencing its true applicability to the prioritization of test cases.},
  keywords={Fault detection;Testing;Software;Fuzzy logic;Measurement;History;Fuzzy sets},
  doi={10.1109/SMC.2019.8914670},
  ISSN={2577-1655},
  month={Oct},}@ARTICLE{10898156,
  author={Li, Tao and Cui, Chenhui and Xu, Yinyin and Huang, Rubing},
  journal={IEEE Transactions on Reliability}, 
  title={Applying Lexicographical Ordering to Software Product Line Testing}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Test case prioritization (TCP) has been widely used in software testing, which aims to execute test cases that are more likely to detect faults earlier than others. Among many proposed TCP approaches, lexicographical ordering-based TCP (LO-TCP) can effectively resolve ties encountered in the prioritization process, leading to better performance than original TCP approaches. However, the current LO-TCP needs to use the white-box information such as the code coverage of the program under test, which may be infeasible in some black-box testing applications such as software product lines (SPLs). In this article, we transfer the traditional LO-TCP to SPL testing by leveraging test configuration coverage instead of code coverage, and also empirically conduct some simulations and evaluate the large-scale real-world programs with real faults. The experimental results show that LO-TCP can have better performance for testing SPLs, as compared with traditional TCP approaches.},
  keywords={Vectors;Testing;Indexes;Time complexity;Glass box;Frequency modulation;Computer science;Codes;Fault diagnosis;Closed box;Lexicographical ordering (LO);regression testing;software product lines (SPL);software testing;test case prioritization (TCP)},
  doi={10.1109/TR.2025.3540479},
  ISSN={1558-1721},
  month={},}@INPROCEEDINGS{10011511,
  author={Siqueira, Vinicius and Miranda, Breno},
  booktitle={2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Investigating the Adoption of History-based Prioritization in the Context of Manual Testing in a Real Industrial Setting}, 
  year={2022},
  volume={},
  number={},
  pages={141-148},
  abstract={Many test case prioritization techniques have been proposed with the ultimate goal of speeding up fault detection. History-based prioritization, in particular, has been shown to be an effective strategy. Most of the empirical studies conducted on this topic, however, have focused on the context of automated testing. Investigating the effectiveness of history-based prioritization in the context of manual testing is important because, despite the popularity of automated approaches, manual testing is still largely adopted in industry. In this work we propose two history-based prioritization heuristics and evaluate them in the context of manual testing in a real industrial setting. For our evaluation we collected historical test execution information for 23 products, spanning over seven years of historical information, accounting for a total of 2,352 unique test cases and 3,993,863 test results. The results of our experiments showed that the effectiveness of the proposed approach is not far from a theoretical optimal prioritization, and that they are significantly better than alternative orderings of the test suite, including the order suggested by the test management tool and the execution order followed by the testers during the real execution of the test suites evaluated as part of our study.},
  keywords={Industries;Fault detection;Manuals;Testing;Software engineering;regression testing;test case prioritization;history-based prioritization;manual testing},
  doi={10.1109/SEAA56994.2022.00030},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{6724206,
  author={Ansari, Ahlam S. A. and Devadkar, Kailas K. and Gharpure, Prachi},
  booktitle={2013 IEEE International Conference on Computational Intelligence and Computing Research}, 
  title={Optimization of test suite-test case in regression test}, 
  year={2013},
  volume={},
  number={},
  pages={1-4},
  abstract={Exhaustive product evolution and testing is required to ensure the quality of product. Regression testing is crucial to ensure software excellence. Regression test cases are applied to assure that new or adapted features do not relapse the existing features. As innovative features are included, new test cases are generated to assess the new functionality, and then included in the existing pool of test cases, thus escalating the cost and the time required in performing regression test and this unswervingly impacts the release, laid plan and the quality of the product. Hence there is a need to select minimal test cases that will test all the functionalities of the engineered product and it must rigorously test the functionalities that have high risk exposure. Test Suite-Test Case Refinement Technique will reduce regression test case pool size, reduce regression testing time, cost & effort and also ensure the quality of the engineered product. This technique is a regression test case optimization technique that is a hybrid of Test Case Minimization based on specifications and Test Case Prioritization based on risk exposure. This approach will facilitate achievement of quality product with decreased regression testing time and cost yet uncover same amount of errors as the original test cases.},
  keywords={Minimization;Testing;Software;Conferences;Fault detection;Optimization;Software reliability;Test Case Optimization;Regression Test;Test Suite Prioritization;Test Suite Minimization;Risk Based Prioritization;Specification Based Selection},
  doi={10.1109/ICCIC.2013.6724206},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10877022,
  author={Moubayed, Abdallah and Alhindawi, Nouh and Alsakran, Jamal and Injadat, MohammadNoor and Kanan, Mohammad},
  booktitle={2024 25th International Arab Conference on Information Technology (ACIT)}, 
  title={A Data-Driven Approach Towards Software Regression Testing Quality Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Software testing is very important in software development to ensure its quality and reliability. As software systems have become more complex, the number of test cases has increased, which presents the challenge of executing all the tests in a limited time frame. Various test case prioritization techniques have been introduced to solve this problem. These methods aim to identify and implement the most critical tests first. In this paper, we propose an implementation of a dynamic test case prioritization strategy to improve software quality by increasing code coverage with special attention to edge case handling. Edge case test prioritization is a technique that improves test efficiency by selecting extreme case scenarios that can reveal critical bugs or unexpected behavior early in development, improving overall software reliability and dependability. In order to prioritize test cases, this paper presents a regression-based method that makes use of machine learning algorithms. The approach leverages previous performance data to optimize regression testing efficiency by examining variables like test time and execution status. Performance evaluations, when compared against industry standards and cutting-edge techniques, show how effective these algorithms are at correctly prioritizing test cases and identifying faults. This study offers simplified yet reliable solutions for regression testing optimization by shedding light on the efficacy of regression algorithms, such as Random Forest and decision trees.},
  keywords={Software testing;Machine learning algorithms;Software algorithms;Software quality;Software systems;Software reliability;Regression tree analysis;Optimization;Standards;Software development management;Software Testing Optimization;Machine Learning;Natural Language Processing},
  doi={10.1109/ACIT62805.2024.10877022},
  ISSN={2831-4948},
  month={Dec},}@INPROCEEDINGS{7724443,
  author={Dhareula, Priyanka and Ganpati, Anita},
  booktitle={2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Identification of attributes for test case reusability in regression test selection techniques}, 
  year={2016},
  volume={},
  number={},
  pages={1144-1147},
  abstract={Regression testing is done after needful changes, ensuring that changes are working as required and does not produce unexpected results for a system under test. Regression testing encounters a significant difficulty of determining the relevant subgroup of test cases for reusability in regression test case selection. This paper performs an exploratory study of Regression Test Selection (RTS) techniques to identify the attributes of test cases for reusability. As the result of this study, the techniques have been categorized under two broad groups' i.e. code-based techniques and requirement based techniques. Further, the attributes for reusability of test cases are identified for code based and requirement based techniques. The study also center around the levels of test granularity for code based techniques used in regression test case selection i.e. fine granularity and coarse granularity. The study revealed that there exists a trade-off between the cost and level of granularity for test case effectiveness.},
  keywords={Testing;Software;Unified modeling language;History;Conferences;Algorithm design and analysis;Software algorithms;Regression testing;reusability;selection techniques;test case},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{6823886,
  author={Groce, Alex and Alipour, Mohammed Amin and Zhang, Chaoqiang and Chen, Yang and Regehr, John},
  booktitle={2014 IEEE Seventh International Conference on Software Testing, Verification and Validation}, 
  title={Cause Reduction for Quick Testing}, 
  year={2014},
  volume={},
  number={},
  pages={243-252},
  abstract={In random testing, it is often desirable to produce a "quick test" -- an extremely inexpensive test suite that can serve as a frequently applied regression and allow the benefits of random testing to be obtained even in very slow or over-subscribed test environments. Delta debugging is an algorithm that, given a failing test case, produces a smaller test case that also fails, and typically executes much more quickly. Delta debugging of random tests can produce effective regression suites for previously detected faults, but such suites often have little power for detecting new faults, and in some cases provide poor code coverage. This paper proposes extending delta debugging by simplifying tests with respect to code coverage, an instance of a generalization of delta debugging we call cause reduction. We show that test suites reduced in this fashion can provide very effective quick tests for real-world programs. For Mozilla's Spider Monkey JavaScript engine, the reduced suite is more effective for finding software faults, even if its reduced runtime is not considered. The effectiveness of a reduction-based quick test persists through major changes to the software under test.},
  keywords={Testing;Debugging;Computer bugs;Fault detection;Hardware;Minimization;Educational institutions;random testing;test case minimization;regression testing},
  doi={10.1109/ICST.2014.37},
  ISSN={2159-4848},
  month={March},}@INPROCEEDINGS{7507977,
  author={Nayak, Soumen and Kumar, Chiranjeev and Tripathi, Sachin},
  booktitle={2016 3rd International Conference on Recent Advances in Information Technology (RAIT)}, 
  title={Effectiveness of prioritization of test cases based on Faults}, 
  year={2016},
  volume={},
  number={},
  pages={657-662},
  abstract={Regression testing (RT) is an expensive activity. It is applied on a modified program to enhance confidence and reliability by ensuring that the changes are accurately true and have not affected the unmodified portions of the SUT. Due to limited resources, it is not practical to re-run each test cases (TC). To improve the regression testing's effectiveness, the TCs should be arranged according to some objective function or criteria. Test case prioritization (TCP) arranges TCs in an order for execution that enhances their effectiveness by satisfying some testing goals. The highest priority assigned to TCs must execute before the TCs with low priority by virtue of some performance goal. Numerous goals are possible to achieve of which one such goal is rate of fault detection (RFT) in which the faults are surfaced as quickly as possible within the testing process. In this paper, a novel technique is suggested to prioritize the TCs that increase its effectiveness in detecting faults. The effectiveness of the proposed method is compared and matched with other prioritization approaches with the help of Average Percentage of Fault Detection (APFD) metric from which charts have been prepared.},
  keywords={Measurement;Software;Algorithm design and analysis;Information technology;Fault detection;Software testing;Regression Testing;TCP;APFD;Severity of Faults},
  doi={10.1109/RAIT.2016.7507977},
  ISSN={},
  month={March},}@INPROCEEDINGS{8305938,
  author={Kwon, Jung-Hyun and Ko, In-Young},
  booktitle={2017 24th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Cost-Effective Regression Testing Using Bloom Filters in Continuous Integration Development Environments}, 
  year={2017},
  volume={},
  number={},
  pages={160-168},
  abstract={Regression testing in continuous integration development environments must be cost-effective and should provide fast feedback on test suite failures to the developers. In order to provide faster feedback on failures to developers while using computing resources efficiently, two types of regression testing techniques have been developed: Regression Testing Selection (RTS) and Test Case Prioritization (TCP). One of the factors that reduces the effectiveness of the RTS and TCP techniques is the inclusion of test suites that fail only once over a period. We propose an approach based on Bloom filtering to exclude such test suites during the RTS process, and to assign such test suites with a lower priority during the TCP process. We experimentally evaluate our approach using a Google dataset, and demonstrate that cost-effectiveness of the proposed RTS and TCP techniques outperforms the state-of-the-art techniques.},
  keywords={Testing;Microsoft Windows;Google;Instruments;History;Fault detection},
  doi={10.1109/APSEC.2017.22},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7100474,
  author={Vedpal and Chauhan, Naresh},
  booktitle={2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Regression test selection for object oriented systems using OPDG and slicing technique}, 
  year={2015},
  volume={},
  number={},
  pages={1372-1378},
  abstract={Regression testing is a selective retesting of software whenever software gets modified or some new functionality is added to it. In this paper a regression test case selection technique is proposed. This technique is based on identification of affected paths, affected functions and dynamic slicing which can be used to reduce the number of test cases for regression testing. This paper considers all three cases of modification to object oriented programs. The proposed approach is evaluated by showing the reduction in total number of test cases to be selected. For each program to be tested, this approach focuses on finding the affected paths, affected functions and on computing the dynamic slice of modified variables. In addition this approach is also open to combine a variety of available information for selection of test cases. For analysis it is applied to the software module in C++.},
  keywords={Testing;Software;Random access memory;Maintenance engineering;Unified modeling language;Software algorithms;Electronic mail;Regression testing;test case reduction;object oriented testing},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{8453107,
  author={Kwon, Jung-Hyun and Ko, In-Young and Rothermel, Gregg},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)}, 
  title={Prioritizing Browser Environments for Web Application Test Execution}, 
  year={2018},
  volume={},
  number={},
  pages={468-479},
  abstract={When testing client-side web applications, it is important to consider different web-browser environments. Different properties of these environments such as web-browser types and underlying platforms may cause a web application to exhibit different types of failures. As web applications evolve, they must be regression tested across these different environments. Because there are many environments to consider this process can be expensive, resulting in delayed feedback about failures in applications. In this work, we propose six techniques for providing a developer with faster feedback on failures when regression testing web applications across different web-browser environments. Our techniques draw on methods used in test case prioritization; however, in our case we prioritize web-browser environments, based on information on recent and frequent failures. We evaluated our approach using four non-trivial and popular open-source web applications. Our results show that our techniques outperform two baseline methods, namely, no ordering and random ordering, in terms of the cost-effectiveness. The improvement rates ranged from -12.24% to 39.05% for no ordering, and from -0.04% to 45.85% for random ordering.},
  keywords={Browsers;Testing;History;Schedules;Optimal scheduling;Operating systems;Production;Web application testing;Regression testing;Browser environments},
  doi={10.1145/3180155.3180244},
  ISSN={1558-1225},
  month={May},}@ARTICLE{10679125,
  author={Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Seferi, Gkerta and Tauseef, Qasim},
  journal={IEEE Access}, 
  title={On the Effectiveness of Feature Selection Techniques in the Context of ML-Based Regression Test Prioritization}, 
  year={2024},
  volume={12},
  number={},
  pages={131556-131575},
  abstract={Regression testing is essential for maintaining software functionality in continuous integration (CI) systems, but it can become increasingly costly as software complexity grows. Machine learning-based Regression Test Prioritization (RTP) techniques have been developed to prioritize test cases based on their likelihood of failure, aiming to detect failures early and optimize resource use. However, the features used in the current state-of-the-art for training machine learning (ML) models often vary widely across different datasets, highlighting the need for further research to identify effective feature sets for RTP. Furthermore, the feature selection techniques are frequently biased toward specific features based on the dataset. Hence, we explored an ensemble technique to utilize three ML-based feature selection techniques in this study to identify and refine key features that enhance test case prioritization. These techniques were applied across four tree-based ML models using data from 15 large-scale open-source software projects. Our analysis identified the most compelling features for predicting failures and assessed their impact on RTP. The results showed that using a refined subset of features could achieve similar or up to a 10% increase in RTP performance, using only one-third of the original feature set. We also empirically evaluated the cost considerations when choosing the three methods and reported the ML models’ performance with the refined feature sets. This underscores the potential of integrating advanced feature selection methods into RTP processes.},
  keywords={Feature extraction;Codes;Measurement;Random forests;Principal component analysis;Predictive models;Training;Continuous integration;Machine learning;Continuous integration;feature selection;machine learning;test case prioritization},
  doi={10.1109/ACCESS.2024.3459656},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9226358,
  author={Al-Sabbagh, Khaled Walid and Staron, Miroslaw and Hebig, Regina and Meding, Wilhelm},
  booktitle={2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Improving Data Quality for Regression Test Selection by Reducing Annotation Noise}, 
  year={2020},
  volume={},
  number={},
  pages={191-194},
  abstract={Big data and machine learning models have been increasingly used to support software engineering processes and practices. One example is the use of machine learning models to improve test case selection in continuous integration. However, one of the challenges in building such models is the identification and reduction of noise that often comes in large data. In this paper, we present a noise reduction approach that deals with the problem of contradictory training entries. We empirically evaluate the effectiveness of the approach in the context of selective regression testing. For this purpose, we use a curated training set as input to a tree-based machine learning ensemble and compare the classification precision, recall, and f-score against a non-curated set. Our study shows that using the noise reduction approach on the training instances gives better results in prediction with an improvement of 37% on precision, 70% on recall, and 59% on f-score.},
  keywords={Training;Testing;Annotations;Predictive models;Noise reduction;Feature extraction;Dictionaries;Annotation Noise;Regression Testing;Machine Learning Models},
  doi={10.1109/SEAA51224.2020.00042},
  ISSN={},
  month={Aug},}@ARTICLE{8735829,
  author={Mukherjee, R. and Patnaik, K. S.},
  journal={IEEE Access}, 
  title={Prioritizing JUnit Test Cases Without Coverage Information: An Optimization Heuristics Based Approach}, 
  year={2019},
  volume={7},
  number={},
  pages={78092-78107},
  abstract={Regression testing is an expensive activity and Test Case Prioritization (TCP) acts as an improvement mechanism for it. TCP techniques for object oriented programs need attention and in our study, we explored prioritization of JUnit test cases. Ten benchmark Java programs with their several mutated versions were studied. As collecting coverage information is a costly effort, we bypassed these steps and used optimization heuristics for ordering JUnit test cases at test method level. Our approach formulated a novel fitness objective which depends on the number of modified lines executed per unit of execution time. As regression testing is performed after some modification is done on an existing program, maximizing the execution of number of modified lines is highly lucrative. The test case prioritization problem was replicated in context of 0/1 Knapsack problem and then it was solved using Genetic Algorithm (GA). Our exploration also included application of Simulated Annealing and Ant Colony Optimization method for determining the best execution ordering of test cases. We examined the usage of Multi-objective GA by building another new fitness metric which aims to maximize the number of inheritance edges covered by a test case. Results indicate the superiority of optimization heuristics over other existing approaches. It appeared that multi-objective GA yielded better result than single objective prioritization. Among the single objective techniques, ACO performed best. To the best of our knowledge, this is the first study which explored all the above mentioned optimization heuristics for ordering JUnit test cases with the newly coined fitness intents.},
  keywords={Testing;Optimization;Genetic algorithms;Java;Fault detection;Ant colony optimization;Measurement;Fault detected;fitness objective;optimization heuristics;regression testing;test method},
  doi={10.1109/ACCESS.2019.2922387},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7552005,
  author={Huang, Rubing and Zong, Weiwen and Chen, Jinfu and Towey, Dave and Zhou, Yunan and Chen, Deng},
  booktitle={2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={Prioritizing Interaction Test Suites Using Repeated Base Choice Coverage}, 
  year={2016},
  volume={1},
  number={},
  pages={174-184},
  abstract={Combinatorial interaction testing is a well-studied testing strategy that aims at constructing an effective interaction test suite (ITS) of a specific generation strength to identify interaction faults caused by the interactions among factors. Due to limited testing resources in practice, for example in combinatorial interaction regression testing, interaction test suite prioritization (ITSP) has been proposed to improve the efficiency of testing. An intuitive ITSP strategy that has been widely used in practice is fixed-strength interaction coverage based prioritization (FICBP). FICBP makes use of a property of the ITS: interaction coverage at a fixed prioritization strength. However, a challenge facing FICBP is that, when the ITS is large, the prioritization cost can be very high. In this paper, we propose a new FICBP method that, by repeatedly using base choice coverage (i.e., one-wise coverage) during the prioritization process, improves testing efficiency while maintaining testing effectiveness. The empirical studies show that our method has fault detection capability comparable to current FICBP methods, but obtains more stable results in many cases. Additionally, our method requires considerably less prioritization time than other FICBP methods at different prioritization strengths.},
  keywords={Testing;Fault detection;Time complexity;Fault diagnosis;Algorithm design and analysis;Computer science;Software;Software testing;combinatorial interaction testing;test case prioritization;fixed-strength interaction coverage based prioritization;base choice coverage},
  doi={10.1109/COMPSAC.2016.167},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{9464569,
  author={Al-Sharif, Ziad A. and Abdalrahman, Wafa F. and Jeffery, Clinton L.},
  booktitle={2021 12th International Conference on Information and Communication Systems (ICICS)}, 
  title={Encoding Test Cases using Execution Traces}, 
  year={2021},
  volume={},
  number={},
  pages={239-244},
  abstract={Test case minimization can be critical to meeting the release date of a software product. Identifying redundant test cases can help improve the quality of the test suite and speed up the testing process. Thus, there is a need to uniquely characterize test cases. This identification can support the test engineer to remove redundancy in the test suite and prioritize test cases that are highly affected by the most recent modification in source code. This paper proposes a test case encoding approach that allows engineers to facilitate execution traces to classify and identify their test cases. It will empower test engineers and allow them to minimize the time and cost of testing by reducing the number of test cases, especially in regression testing. Furthermore, it enhances the documentation of the testing process by providing a one-to-one mapping between test cases and their corresponding execution traces, each of which is a sequence of execution events triggered during the execution of the test case. The one-to-one mapping allows the approach to uniquely represent the control-flow and data-flow within the source code. This trace can be used as a signature for the test case. Whenever a modification occurred in the source code, the newly captured signatures are compared against the previous ones; any mismatch indicates that the test case has been affected by the modification. Repeating this process will help classify the test suite into four groups of test cases. This provides the ability to put the testing efforts where it is needed. Additionally, keeping a hashed value for each of the captured sequences simplifies the comparison and unifies the mapping between test cases and captured traces. It also allows detection of minor modifications in the traced events, and reduces the lengthy traces to a set of fixed size hashed values.},
  keywords={Communication systems;Automatic testing;Redundancy;Focusing;Documentation;Minimization;Software;Test Cases;Regression Testing;Execution Traces},
  doi={10.1109/ICICS52457.2021.9464569},
  ISSN={2573-3346},
  month={May},}@INPROCEEDINGS{6649874,
  author={Huang, Rubing and Chen, Jinfu and Zhang, Tao and Wang, Rongcun and Lu, Yansheng},
  booktitle={2013 IEEE 37th Annual Computer Software and Applications Conference}, 
  title={Prioritizing Variable-Strength Covering Array}, 
  year={2013},
  volume={},
  number={},
  pages={502-511},
  abstract={Combinatorial interaction testing is a well-studied testing strategy, and has been widely applied in practice. Combinatorial interaction test suite, such as fixed-strength and variable-strength interaction test suite, is widely used for combinatorial interaction testing. Due to constrained testing resources in some applications, for example in combinatorial interaction regression testing, prioritization of combinatorial interaction test suite has been proposed to improve the efficiency of testing. However, nearly all prioritization techniques may only support fixed-strength interaction test suite rather than variable-strength interaction test suite. In this paper, we propose two heuristic methods in order to prioritize variable-strength interaction test suite by taking advantage of its special characteristics. The experimental results show that our methods are more effective for variable-strength interaction test suite by comparing with the technique of prioritizing combinatorial interaction test suites according to test case generation order, the random test prioritization technique, and the fixed-strength interaction test suite prioritization technique. Besides, our methods have additional advantages compared with the prioritization techniques for fixed-strength interaction test suite.},
  keywords={Testing;Arrays;Educational institutions;Fault detection;Heuristic algorithms;Computer science;Software;Software testing;combinatorial interaction testing;test case prioritization;fixed-strength interaction test suite;variable-strength interaction test suite;algorithm},
  doi={10.1109/COMPSAC.2013.84},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{9787866,
  author={Becho, João and Cerveira, Frederico and Leitão, João and Oliveira, Rui André},
  booktitle={2022 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={TESRAC: A Framework for Test Suite Reduction Assessment at Scale}, 
  year={2022},
  volume={},
  number={},
  pages={174-184},
  abstract={Regression testing is an important task in any large software project, however as codebase increases, test suites grow and become composed of highly redundant test cases, thus greatly increasing the time required for testing. To solve this problem various test suite reduction tools have been proposed, however their absolute and relative performance are unclear to their prospective users, since there is a lack of a standardized evaluation or approach for choosing the best reduction tool. This work proposes TESRAC, a framework for assessing and comparing test suite reduction tools, which allows users to evaluate and rank a customizable set of tools in terms of reduction performance according to criteria (coverage, dimension, and execution time), and which can be configured to prioritize specific criteria. We used TESRAC to assess and compare three test suite reduction tools and one test suite prioritization tool that has been adapted to perform test suite reduction, across eleven projects of various dimensions and characteristics. Results show that a test suite prioritization tool can be adapted to perform a adequate test suite reduction, and a subset of tools outperforms the remaining tools for the majority of the projects. However, the project and test suite being reduced can have a strong impact on a tool's performance.},
  keywords={Software testing;Ports (computers);Measurement;Technological innovation;Codes;Conferences;Decision making;software testing;test suite reduction;test suite minimization;test case prioritization;evaluation},
  doi={10.1109/ICST53961.2022.00028},
  ISSN={2159-4848},
  month={April},}@ARTICLE{6812226,
  author={Mei, Lijun and Chan, W.K. and Tse, T.H. and Jiang, Bo and Zhai, Ke},
  journal={IEEE Transactions on Services Computing}, 
  title={Preemptive Regression Testingof Workflow-Based Web Services}, 
  year={2015},
  volume={8},
  number={5},
  pages={740-754},
  abstract={An external web service may evolve without prior notification. In the course of the regression testing of a workflow-based web service, existing test case prioritization techniques may only verify the latest service composition using the not-yet-executed test cases, overlooking high-priority test cases that have already been applied to the service composition before the evolution. In this paper, we propose Preemptive Regression Testing  (PRT), an adaptive testing approach to addressing this challenge. Whenever a change in the coverage of any service artifact is detected, PRT recursively preempts the current session of regression test and creates a sub-session of the current test session to assure such lately identified changes in coverage by adjusting the execution priority of the test cases in the test suite. Then, the sub-session will resume the execution from the suspended position. PRT terminates only when each test case in the test suite has been executed at least once without any preemption activated in between any test case executions. The experimental result confirms that testing workflow-based web service in the face of such changes is very challenging; and one of the PRT-enriched techniques shows its potential to overcome the challenge.},
  keywords={Testing;Web services;Electronic mail;Educational institutions;Context;Maintenance engineering;Evolving service composition;adaptive regression testing},
  doi={10.1109/TSC.2014.2322621},
  ISSN={1939-1374},
  month={Sep.},}@INPROCEEDINGS{9616824,
  author={Padmanabhan, Mani},
  booktitle={2021 Fourth International Conference on Electrical, Computer and Communication Technologies (ICECCT)}, 
  title={Test Case Optimization based on Specification Diagrams and Simulation Invocation Relationship}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={The growing usage of software-based products is coupled with day-to-day human life. The software engineering technology can be more eye-catching among artificial intelligent-based software developers. The artificial intelligence systems such as the human machine interaction process are difficult to identify the pre-conditions during the development. Re-engineering is essential for artificial intelligent systems-based applications. Regression testing has assured the quality of products during the re-engineering process. The test cases are a core component in regression testing. Test case optimization and selection is a major activity to reduce the time and cost during regression testing. Many test case selection techniques have solved the problems in regression testing, however, the techniques seem to have much focus on reducing the number of test cases. This research proposes a test case optimization-based specification diagram. In the test, case selections are controlled by the simulation invocation relationship. The proposed simulation invocation methodology identified the simulations to be affected during the reengineering process. The proposed optimization algorithm produced the test cases based on the fault coverage criteria. This approach had validated with three artificial intelligent-based systems during regression testing. The comparative analysis shows that the proposed approach is well suitable for re-engineering in terms of the average percentage of fault detected values.},
  keywords={Measurement;Human computer interaction;Costs;Fault detection;Software;Intelligent systems;Optimization;Software Testing;Test case generation;Test Optimization;Software Validation;Simulation Invocation Relationship},
  doi={10.1109/ICECCT52121.2021.9616824},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8453137,
  author={Liang, Jingjing and Elbaum, Sebastian and Rothermel, Gregg},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)}, 
  title={Redefining Prioritization: Continuous Prioritization for Continuous Integration}, 
  year={2018},
  volume={},
  number={},
  pages={688-698},
  abstract={Continuous integration (CI) development environments allow soft-ware engineers to frequently integrate and test their code. While CI environments provide advantages, they also utilize non-trivial amounts of time and resources. To address this issue, researchers have adapted techniques for test case prioritization (TCP) to CI environments. To date, however, the techniques considered have operated on test suites, and have not achieved substantial improvements. Moreover, they can be inappropriate to apply when system build costs are high. In this work we explore an alternative: prioritization of commits. We use a lightweight approach based on test suite failure and execution history that is highly effcient; our approach "continuously" prioritizes commits that are waiting for execution in response to the arrival of each new commit and the completion of each previously scheduled commit. We have evaluated our approach on three non-trivial CI data sets. Our results show that our approach can be more effective than prior techniques.},
  keywords={Software engineering;continuous integration;regression testing;large scale testing},
  doi={10.1145/3180155.3180213},
  ISSN={1558-1225},
  month={May},}@ARTICLE{9163120,
  author={Ali, Sadia and Hafeez, Yaser and Jhanjhi, N. Z. and Humayun, Mamoona and Imran, Muhammad and Nayyar, Anand and Singh, Saurabh and Ra, In-Ho},
  journal={IEEE Access}, 
  title={Towards Pattern-Based Change Verification Framework for Cloud-Enabled Healthcare Component-Based}, 
  year={2020},
  volume={8},
  number={},
  pages={148007-148020},
  abstract={To survive in the competitive environment, most organizations have adopted component-based software development strategies in the rapid technology advancement era and the proper utilization of cloud-based services. To facilitate the continuous configuration, reduce complexity, and faster system delivery for higher user satisfaction in dynamic scenarios. In cloud services, customers select services from web applications dynamically. Healthcare body sensors are commonly used for diagnosis and monitoring patients continuously for their emergency treatment. The healthcare devices are connected with mobile or laptop etc. on cloud environment with network and frequently change applications. Thus, organizations rely on regression testing during changes and implementation to validate the quality and reliability of the system after the alteration. However, for a large application with limited resources and frequently change component management activities in the cloud computing environment, component-based system verification is difficult and challenging due to irrelevant and redundant test cases and faults. In this study, proposed a test case selection and prioritization framework using a design pattern to increase the faults detection rate. First, we select test cases on frequently accessed components using observer patterns and, secondly, prioritize test cases on adopting some strategies. The proposed framework was validated by an experiment and compared with other techniques (previous faults based and random priority). Hence, experimental results show that the proposed framework successfully verified changes. Subsequently, the proposed framework increases the fault detection rate (i.e., more than 90%) than previous faults based and random priority (i.e., more than 80% respectively).},
  keywords={Cloud computing;Medical services;Testing;Reliability;Fault detection;Electronic mail;Organizations;Body sensor;cloud computing;component-based system;design pattern;healthcare systems;regression testing;TCP},
  doi={10.1109/ACCESS.2020.3014671},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9155903,
  author={Jebbar, Oussama and Saied, Mohamed Aymen and Khendek, Ferhat and Toeroe, Maria},
  booktitle={2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Regression Test Suite Reduction for Cloud Systems}, 
  year={2020},
  volume={},
  number={},
  pages={477-486},
  abstract={Cloud providers offer a wide variety of services to their tenants. Providers share large scale infrastructures to host their services and use configurable software customized with configurations to meet different tenant requirements. These configurations are often the main source of errors. Moreover, they undergo frequent changes, therefore, systems' compliance to requirements needs to be re-evaluated frequently using regression testing. The problem of regression test case selection has been extensively addressed in the literature, however, existing approaches do not tackle the problem from the configuration perspective. In this paper, we propose a configuration-based method for regression test suite reduction for cloud systems. Our method targets a set of faults summarized in a fault model, and it relies on a classification of configuration parameters based on their relation to the deployment environment. Our idea is that the relation of the configuration parameters to the environment can be explored to reduce the regression test suite.},
  keywords={Software;Testing;Computer architecture;Credit cards;Computer science;Production;Conferences;cloud systems;configurable systems;configurations;regression testing;test suite reduction},
  doi={10.1109/ICSTW50294.2020.00084},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10493937,
  author={Li, Rongrong},
  booktitle={2024 5th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI)}, 
  title={Software Quality Testing Framework based on Machine Learning Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={396-401},
  abstract={This research work presents a software quality testing framework based on machine learning analysis. The framework utilizes dynamic symbol technology and integration testing methods to analyze different execution paths, thereby establishing a comprehensive integration testing framework. Technologies such as robot framework, exploration-driven test data generation, and software reliability coupling measurement are employed to improve testing efficiency and ensure thorough verification of software functions and performance. The research demonstrates the application of reinforcement learning to test case sequencing, using Q-learning to optimize API functional test case generation. The proposed methodology involves the integration of machine learning analysis into three aspects: information handling, procedure formulation, and execution flow. The paper explores regression testing, test case prioritization technology (TCP), and reinforcement learning for efficient test case ordering. A comprehensive simulation of 500 software reliability testing use cases shows significant improvements in test efficiency by reducing redundant instances. The research concludes with a discussion of the application of Q-Learning in continuous integration testing, emphasizing the need for flexible memory representations to handle complex states and action sets. The proposed framework effectively addresses the challenges posed by scale expansion in software development, thereby improving the accuracy and efficiency of software testing.},
  keywords={Software testing;Sequential analysis;Q-learning;Symbols;Software quality;Software reliability;Software measurement;Machine learning analysis;software quality;testing framework;robustness testing},
  doi={10.1109/ICMCSI61536.2024.00063},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8728945,
  author={Enoiu, Eduard and Frasheri, Mirgita},
  booktitle={2019 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Test Agents: The Next Generation of Test Cases}, 
  year={2019},
  volume={},
  number={},
  pages={305-308},
  abstract={Growth of software size, lack of resources to perform regression testing, and failure to detect bugs faster have seen increased reliance on continuous integration and test automation. Even with greater hardware and software resources dedicated to test automation, software testing is faced with enormous challenges, resulting in increased dependence on centralized and complex mechanisms for automated test case selection as part of continuous integration. These mechanisms are currently using static entities called test cases that are concretely realized as executable scripts. Our key vision is to provide test cases with more reasoning, adaptive behavior and learning capabilities by using the concepts of software agents. We refer to such test cases as test agents. The model that underlie a test agent is capable of flexible and autonomous actions in order to meet overall testing objectives. Our goal is to increase the decentralization of regression testing by letting test agents to know for themselves when they should be executing, how they should update their purpose, and when they should interact with each other. In this paper, we envision test agents that display such adaptive autonomous behavior. Existing and emerging developments and challenges regarding the use of test agents are explored-in particular, new research that seeks to use adaptive autonomous agents in software testing.},
  keywords={Software;Task analysis;Software testing;Automation;Adaptation models;Switches;software testing;test design;regression;agent;test automation;adaptive;autonomous},
  doi={10.1109/ICSTW.2019.00070},
  ISSN={},
  month={April},}@ARTICLE{9777725,
  author={Zhu, Penghua and Li, Ying and Li, Tongyu and Ren, Huimin and Sun, Xiaolei},
  journal={IEEE Access}, 
  title={Advanced Crowdsourced Test Report Prioritization Based on Adaptive Strategy}, 
  year={2022},
  volume={10},
  number={},
  pages={53522-53532},
  abstract={Crowdsourced testing is an emerging trend in software testing, which takes advantage of the efficiency of crowdsourced and cloud platforms. Crowdsourced testing has gradually been applied in many fields. In crowdsourced software testing, after the crowdsourced workers complete the test tasks, they submit the test results in test reports. Therefore, in crowdsourced software testing, checking a large number of test reports is an arduous but unavoidable software maintenance task. Crowdsourced test reports are numerous, complex, and need to be sorted to improve inspection efficiency. There are no systematic methods for prioritizing reports in crowdsourcing test report prioritization. However, in regression testing, test case prioritization technology has matured. Therefore, we migrate the test case prioritization method to crowdsourced test report prioritization and evaluate the effectiveness of these methods. We use natural language processing technology and word segmentation to process the text in the test reports. Then we use four methods to prioritize the reports: total greedy algorithm, additional greedy algorithm, genetic algorithm, and ART. The results show that these methods all perform well in prioritizing crowdsourced test reports, with an average APFD of more than 0.8.},
  keywords={Task analysis;Greedy algorithms;Crowdsourcing;Software algorithms;Software testing;Encoding;Software;Crowdsourced software testing;test report prioritization;text classification},
  doi={10.1109/ACCESS.2022.3176086},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7828927,
  author={Yang Gao and Bai, Cheng-Gang},
  booktitle={2016 IEEE Chinese Guidance, Navigation and Control Conference (CGNCC)}, 
  title={Selecting test cases by cluster analysis of GUI states}, 
  year={2016},
  volume={},
  number={},
  pages={1024-1029},
  abstract={Nowadays graphical user interface (GUI) has been widely used in software systems, while there is no efficient testing techniques for the rapidly evolving GUI applications. For the GUI applications are modified rapidly and the test suites trend to be huge in size, it is often desirable to select a subset of test cases to fulfill the regression testing. In this paper, a novel GUI state model is presented to address the execution of test case, and then a state-coverage method based on cluster analysis of the GUI states is proposed to select a reliable subset of test cases for GUI regression testing. An empirical study illustrates that the state-coverage method is effective for GUI test case selection.},
  keywords={Graphical user interfaces;Testing;XML;Software;Measurement;Reliability;Sociology},
  doi={10.1109/CGNCC.2016.7828927},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10660677,
  author={Lin, Hongjie},
  booktitle={2024 5th International Conference on Image Processing and Capsule Networks (ICIPCN)}, 
  title={A Novel Software Test Data Generation Framework based on Multi-level Fuzzy Clustering Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={781-786},
  abstract={Software testing plays a crucial role in ensuring the quality and reliability of software products. This study presents a novel software test data generation framework based on the multi-level fuzzy clustering algorithm. The framework aims to optimize the testing process by efficiently generating test cases and prioritizing them for execution. The proposed methodology integrates hierarchical reinforcement learning and hierarchical clustering techniques to improve the effectiveness and comprehensiveness of software testing. A detailed review of recent advances in software testing methodologies is provided, focusing on differential regression testing for REST APIs, test case prioritization, program repair using neural translation models, and other key areas. The proposed framework is evaluated through experiments on real-world software datasets, demonstrating its superiority in terms of non-redundancy rate and vulnerability count detection compared to existing methods. The results highlight the effectiveness and relevance of the proposed framework in improving the efficiency and reliability of software testing.},
  keywords={Software testing;Reviews;Image processing;Software algorithms;Refining;Clustering algorithms;Reinforcement learning;Software Testing;Data Generation;Multi-level Fuzzy Clustering;Algorithm Framework},
  doi={10.1109/ICIPCN63822.2024.00135},
  ISSN={},
  month={July},}

@INPROCEEDINGS{10148705,
  author={Corò, Federico and Verdecchia, Roberto and Cruciani, Emilio and Miranda, Breno and Bertolino, Antonia},
  booktitle={2020 IEEE/ACM 17th International Conference on Mining Software Repositories (MSR)}, 
  title={JTeC: A Large Collection of Java Test Classes for Test Code Analysis and Processing}, 
  year={2020},
  volume={},
  number={},
  pages={578-582},
  abstract={The recent push towards test automation and test-driven development continues to scale up the dimensions of test code that needs to be maintained, analysed, and processed side-by-side with pro-duction code. As a consequence, on the one side regression testing techniques, e.g., for test suite prioritization or test case selection, capable to handle such large-scale test suites become indispensable; on the other side, as test code exposes own characteristics, specific techniques for its analysis and refactoring are actively sought. We present JTeC, a large-scale dataset of test cases that researchers can use for benchmarking the above techniques or any other type of tool expressly targeting test code. JTeC collects more than 2.5M test classes belonging to 31K + GitHub projects and summing up to more than 430 Million SLOCs of ready-to-use real-world test code.},
  keywords={Java;Codes;Automation;Benchmark testing;Software;Data mining;Software development management;GitHub;Java;Large Scale;Software Testing;Test Suite},
  doi={10.1145/3379597.3387484},
  ISSN={2574-3864},
  month={May},}@INPROCEEDINGS{8754416,
  author={Torres, Wesley N. M. and Alves, Everton L. G. and Machado, Patrícia D. L.},
  booktitle={2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={An Empirical Study on the Spreading of Fault Revealing Test Cases in Prioritized Suites}, 
  year={2019},
  volume={1},
  number={},
  pages={129-138},
  abstract={Code edits are very common during software development. Specially for agile development, these edits need constant validation to avoid functionality regression. In this context, regression test suites are often used. However, regression testing can be very costly. Test case prioritization (TCP) techniques try to reduce this burden by reordering the tests of a given suite aiming at fastening the achievement of a certain testing goal. The literature presents a great number of TCP techniques. Most of the work related to prioritization evaluate the performance of TCP techniques by calculating the rate of test cases that fail per fault (the APFD metric). However, other aspects should be considered when evaluating prioritization results. For instance, the ability to reduce the spreading of failing test cases, since a better grouping often provides more information regarding faults. This paper presents an empirical investigation for evaluating the performance of a set of prioritization techniques comparing APFD and spreading results. Our results show that prioritization techniques generate different APFD and spreading results, being total-statement prioritization the one with the lowest spreading.},
  keywords={Measurement;Fault detection;Software;Testing;Mathematical model;Guidelines;Conferences;prioritization;test case;metric;evaluation},
  doi={10.1109/COMPSAC.2019.00027},
  ISSN={0730-3157},
  month={Jul},}@INPROCEEDINGS{7582788,
  author={Guo, Shengjian and Kusano, Markus and Wang, Chao},
  booktitle={2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Conc-iSE: Incremental symbolic execution of concurrent software}, 
  year={2016},
  volume={},
  number={},
  pages={531-542},
  abstract={Software updates often introduce new bugs to existing code bases. Prior regression testing tools focus mainly on test case selection and prioritization whereas symbolic execution tools only handle code changes in sequential software. In this paper, we propose the first incremental symbolic execution method for concurrent software to generate new tests by exploring only the executions affected by code changes between two program versions. Specifically, we develop an inter-thread and inter-procedural change-impact analysis to check if a statement is affected by the changes and then leverage the information to choose executions that need to be re-explored. We also check if execution summaries computed in the previous program can be used to avoid redundant explorations in the new program. We have implemented our method in an incremental symbolic execution tool called Conc-iSE and evaluated it on a large set of multithreaded C programs. Our experiments show that the new method can significantly reduce the overall symbolic execution time when compared with state-of-the-art symbolic execution tools such as KLEE.},
  keywords={Software;Testing;Concurrent computing;Algorithm design and analysis;Software algorithms;Computer bugs;Programming;Symbolic execution;Concurrency;Partial order reduction;Weakest precondition},
  doi={},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{6571593,
  author={},
  booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation Workshops}, 
  title={[Front-cover]}, 
  year={2013},
  volume={},
  number={},
  pages={C4-C4},
  abstract={The following topics are dealt with: software testing; software verification; software validation; engineering safety system; security system; mutation analysis; test case selection; software refactorings; software defect localization; software reachability; software maintainability; data processing; service-oriented architecture; Web services; combinatorial testing; UML; regression testing; and security testing.},
  keywords={},
  doi={10.1109/ICSTW.2013.1},
  ISSN={},
  month={March},}

