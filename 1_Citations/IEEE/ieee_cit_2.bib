@ARTICLE{10144307,
  author={Ufuktepe, Ekincan and Tuglular, Tugkan},
  journal={IEEE Access}, 
  title={Application of the Law of Minimum and Dissimilarity Analysis to Regression Test Case Prioritization}, 
  year={2023},
  volume={11},
  number={},
  pages={57137-57157},
  abstract={Regression testing is one of the most expensive processes in testing. Prioritizing test cases in regression testing is critical for the goal of detecting the faults sooner within a large set of test cases. We propose a test case prioritization (TCP) technique for regression testing called LoM-Score inspired by the Law of Minimum (LoM) from biology. This technique calculates the impact probabilities of methods calculated by change impact analysis with forward slicing and orders test cases according to LoM. However, this ordering doesn’t consider the possibility that consecutive test cases may be covering the same methods repeatedly. Thereby, such ordering can delay the time of revealing faults that exist in other methods. To solve this problem, we enhance the LoM-Score TCP technique with an adaptive approach, namely with a dissimilarity-based coordinate analysis approach. The dissimilarity-based coordinate analysis uses Jaccard Similarity for calculating the similarity coefficients between test cases in terms of covered methods and the enhanced technique called Dissimilarity-LoM-Score (Dis-LoM-Score) applies a penalty with respective on the ordered test cases. We performed our case study on 10 open-source Java projects from Defects4J, which is a dataset of real bugs and an infrastructure for controlled experiments provided for software engineering researchers. Then, we hand-seeded multiple mutants generated by Major, which is a mutation testing tool. Then we compared our TCP techniques LoM-Score and Dis-LoM-Score with the four traditional TCP techniques based on their Average Percentage of Faults Detected (APFD) results.},
  keywords={Software testing;Probabilistic logic;Codes;Fault detection;Computer bugs;Probability;Change impact analysis;regression testing;software testing;test case prioritization},
  doi={10.1109/ACCESS.2023.3283212},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7783254,
  author={Joseph, Abraham Kiran and Radhamani, G. and Kallimani, Vish},
  booktitle={2016 3rd International Conference on Computer and Information Sciences (ICCOINS)}, 
  title={Improving test efficiency through multiple criteria coverage based test case prioritization using Modified heuristic algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={430-435},
  abstract={Test case prioritization involves reordering the test cases in an order that helps in attaining certain performance goals. The rate of fault detection is one of the prime goals that we tend to achieve while doing prioritization. Test cases should run in an order to increase the possibility of fault detection and it should be achieved early during the test life cycle. To reduce the cost and time of regression testing, test case prioritization should be done with the intention of periodically modifying the test suite. The humongous set of test cases makes it redundant and cumbersome for the testers who ensure quality for an end application. The fault detection capability of a prioritized test suite is improved up to 15% using Modified PSO which forms the base algorithms for prioritization. The algorithm illustrated detects serious errors at earlier phases of testing process and effectiveness between prioritized and unprioritized test cases.},
  keywords={Testing;Complexity theory;Software;Fault detection;Electric breakdown;Computers;Software algorithms;Test case prioritization;Heuristic Algorithm;Modified Particle Swarm Optimization;Regression testing},
  doi={10.1109/ICCOINS.2016.7783254},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8854718,
  author={Hettiarachchi, Charitha and Do, Hyunsook},
  booktitle={2019 IEEE 19th International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={A Systematic Requirements and Risks-Based Test Case Prioritization Using a Fuzzy Expert System}, 
  year={2019},
  volume={},
  number={},
  pages={374-385},
  abstract={The use of risk information can help software engineers identify software components that are likely vulnerable or require extra attention when testing. Some studies have shown that the requirements risk-based approaches can be effective in improving the effectiveness of regression testing techniques. However, the risk estimation processes used in such approaches can be subjective, time-consuming, and costly. In this research, we introduce a fuzzy expert system that emulates human thinking to address the subjectivity related issues in the risk estimation process in a systematic and an efficient way and thus further improve the effectiveness of test case prioritization. Further, the required data for our approach was gathered by employing a semi-automated process that made the risk estimation process less subjective. The empirical results indicate that the new prioritization approach can improve the rate of fault detection over several existing test case prioritization techniques, while reducing threats to subjective risk estimation.},
  keywords={Expert systems;Iron;Security;Software;Testing;Estimation;Complexity theory;Regression testing, requirements risks-based testing, fuzzy expert systems, test case prioritization, software requirements},
  doi={10.1109/QRS.2019.00054},
  ISSN={},
  month={July},}@INPROCEEDINGS{8536351,
  author={Paterson, David and Kapfhammer, Gregory and Fraser, Gordon and McMinn, Phil},
  booktitle={2018 IEEE/ACM 13th International Workshop on Automation of Software Test (AST)}, 
  title={Using Controlled Numbers of Real Faults and Mutants to Empirically Evaluate Coverage-Based Test Case Prioritization}, 
  year={2018},
  volume={},
  number={},
  pages={57-63},
  abstract={Used to establish confidence in the correctness of evolving software, regression testing is an important, yet costly, task. Test case prioritization enables the rapid detection of faults during regression testing by reordering the test suite so that effective tests are run as early as is possible. However, a distinct lack of information about the regression faults found in complex real-world software forced prior experimental studies of these methods to use artificial faults called mutants. Using the Defects4J database of real faults, this paper presents the results of experiments evaluating the effectiveness of four representative test prioritization techniques. Since this paper's results show that prioritization is susceptible to high amounts of variance when only one fault is present, our experiments also control the number of real faults and mutants in the program subject to regression testing. Our overall findings are that, in comparison to mutants, real faults are harder for reordered test suites to quickly detect, suggesting that mutants are not a surrogate for real faults.},
  keywords={Software;Tools;Testing;Fault detection;Measurement;Conferences;Automation;test case prioritization;regression testing;real faults;defects4j},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{8730206,
  author={Paterson, David and Campos, Jose and Abreu, Rui and Kapfhammer, Gregory M. and Fraser, Gordon and McMinn, Phil},
  booktitle={2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)}, 
  title={An Empirical Study on the Use of Defect Prediction for Test Case Prioritization}, 
  year={2019},
  volume={},
  number={},
  pages={346-357},
  abstract={Test case prioritization has been extensively re-searched as a means for reducing the time taken to discover regressions in software. While many different strategies have been developed and evaluated, prior experiments have shown them to not be effective at prioritizing test suites to find real faults. This paper presents a test case prioritization strategy based on defect prediction, a technique that analyzes code features - such as the number of revisions and authors - to estimate the likelihood that any given Java class will contain a bug. Intuitively, if defect prediction can accurately predict the class that is most likely to be buggy, a tool can prioritize tests to rapidly detect the defects in that class. We investigated how to configure a defect prediction tool, called Schwa, to maximize the likelihood of an accurate prediction, surfacing the link between perfect defect prediction and test case prioritization effectiveness. Using 6 real-world Java programs containing 395 real faults, we conducted an empirical evaluation comparing this paper's strategy, called G-clef, against eight existing test case prioritization strategies. The experiments reveal that using defect prediction to prioritize test cases reduces the number of test cases required to find a fault by on average 9.48% when compared with existing coverage-based strategies, and 10.4% when compared with existing history-based strategies.},
  keywords={Computer bugs;History;Software;Java;Testing;Fault detection;Genetic algorithms;Regression Testing;Test Case Prioritization;Defect Prediction;Continuous Testing;Empirical Studies},
  doi={10.1109/ICST.2019.00041},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{6918806,
  author={Mohapatra, Sudhir Kumar and Prasad, Srinivas},
  booktitle={2013 International Conference on Machine Intelligence and Research Advancement}, 
  title={Evolutionary Search Algorithms for Test Case Prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={115-119},
  abstract={To improve the effectiveness of certain performance goals, test case prioritization techniques are used. These technique schedule the test cases in particular order for execution so as to increase the efficacy in meeting the performance goals. For every change in the program it is considered inefficient to re-execute each and every test case. Test case prioritization techniques arrange the test cases within a test suite in such a way that the most important test case is executed first. This process enhances the effectiveness of testing. This algorithm during time constraint execution has been shown to have detected maximum number fault while including the sever test cases.},
  keywords={Genetic algorithms;Testing;Software;Sociology;Statistics;Algorithm design and analysis;Fault detection;Regression testing;Test case;Genetic algorithm;prioritization},
  doi={10.1109/ICMIRA.2013.29},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6649820,
  author={Jiang, Bo and Chan, W.K.},
  booktitle={2013 IEEE 37th Annual Computer Software and Applications Conference}, 
  title={Bypassing Code Coverage Approximation Limitations via Effective Input-Based Randomized Test Case Prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={190-199},
  abstract={Test case prioritization assigns the execution priorities of the test cases in a given test suite with the aim of achieving certain goals. Many existing test case prioritization techniques however assume the full-fledged availability of code coverage data, fault history, or test specification, which are seldom well-maintained in many software development projects. This paper proposes a novel family of LBS techniques. They make adaptive tree-based randomized explorations with an adaptive randomized candidate test set strategy to diversify the explorations among the branches of the exploration trees constructed by the test inputs in the test suite. They get rid of the assumption on the historical correlation of code coverage between program versions. Our techniques can be applied to programs with or without any previous versions, and hence are more general than many existing test case prioritization techniques. The empirical study on four popular UNIX utility benchmarks shows that, in terms of APFD, our LBS techniques can be as effective as some of the best code coverage-based greedy prioritization techniques ever proposed. We also show that they are significantly more efficient and scalable than the latter techniques.},
  keywords={Testing;Subspace constraints;Silicon;Software;Approximation methods;History;Equations;regression testing;adaptive test case prioritization},
  doi={10.1109/COMPSAC.2013.33},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{7272924,
  author={Jiang, Bo and Chan, W.K. and Tse, T.H.},
  booktitle={2015 IEEE International Conference on Software Quality, Reliability and Security}, 
  title={PORA: Proportion-Oriented Randomized Algorithm for Test Case Prioritization}, 
  year={2015},
  volume={},
  number={},
  pages={131-140},
  abstract={Effective testing is essential for assuring software quality. While regression testing is time-consuming, the fault detection capability may be compromised if some test cases are discarded. Test case prioritization is a viable solution. To the best of our knowledge, the most effective test case prioritization approach is still the additional greedy algorithm, and existing search-based algorithms have been shown to be visually less effective than the former algorithms in previous empirical studies. This paper proposes a novel Proportion-Oriented Randomized Algorithm (PORA) for test case prioritization. PORA guides test case prioritization by optimizing the distance between the prioritized test suite and a hierarchy of distributions of test input data. Our experiment shows that PORA test case prioritization techniques are as effective as, if not more effective than, the total greedy, additional greedy, and ART techniques, which use code coverage information. Moreover, the experiment shows that PORA techniques are more stable in effectiveness than the others.},
  keywords={Testing;Subspace constraints;Fault detection;Greedy algorithms;Resource management;Clustering algorithms;Genetic algorithms;Test case prioritization;randomized algorithm;proportional sampling strategy;multi-objective optimization},
  doi={10.1109/QRS.2015.28},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9741963,
  author={Hu, Peng and Chaowen, Chang and Ma, Yingying and Wang, Xiaolin},
  booktitle={2021 2nd International Conference on Electronics, Communications and Information Technology (CECIT)}, 
  title={Acceptance Testing Optimization Method for Continuous Delivery}, 
  year={2021},
  volume={},
  number={},
  pages={168-173},
  abstract={From agile to DevOps, development methods have been extended from continuous integration to continuous delivery. In the acceptance testing before software delivery, the constantly changing software configuration, real user environment, and user-led testing, all of these extend the delivery time and increase the risk of testing. How to further optimize the test and shorten the delivery cycle are problem that must be considered to realize the end-to-end value flow in DevOps. In the testing optimization research, the methods are mainly for regression testing. There are few researches on acceptance testing, and the methods for the acceptance testing mainly focus on specific scenario, that almost none research consider how to shorten the continuous delivery cycle. Aiming at the characteristics of acceptance testing, this paper proposes an acceptance testing optimization method for continuous delivery. For different levels of test cases, test case selection and prioritization are used to optimize test cases. Firstly, the test suite related to requirements is constructed, and the test cases are selected according to the requirements. Then, the test suites are divided into two levels to prioritize. During the test execution, the use case execution actions are streamlined to shorten execution time of the acceptance testing, meet user needs as soon as possible and achieve rapid value delivery. Finally, the method is applied to actual industrial projects for experiments. The results show that the method can reduce the scale of test cases, shorten the test execution times and improve the efficiency of demand satisfaction.},
  keywords={Diversity reception;Optimization methods;Software;Information and communication technology;Testing;testing optimization;acceptance testing;test case selection;test case prioritization},
  doi={10.1109/CECIT53797.2021.00037},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8367035,
  author={Pradhan, Dipesh and Wang, Shuai and Ali, Shaukat and Yue, Tao and Liaaen, Marius},
  booktitle={2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)}, 
  title={REMAP: Using Rule Mining and Multi-objective Search for Dynamic Test Case Prioritization}, 
  year={2018},
  volume={},
  number={},
  pages={46-57},
  abstract={Test case prioritization (TP) prioritizes test cases into an optimal order for achieving specific criteria (e.g., higher fault detection capability) as early as possible. However, the existing TP techniques usually only produce a static test case order before the execution without taking runtime test case execution results into account. In this paper, we propose an approach for black-box dynamic TP using rule mining and multi-objective search (named as REMAP). REMAP has three key components: 1) Rule Miner, which mines execution relations among test cases from historical execution data; 2) Static Prioritizer, which defines two objectives (i.e., fault detection capability (FDC) and test case reliance score (TRS)) and applies multi-objective search to prioritize test cases statically; and 3) Dynamic Executor and Prioritizer, which executes statically-prioritized test cases and dynamically updates the test case order based on the runtime test case execution results. We empirically evaluated REMAP with random search, greedy based on FDC, greedy based on FDC and TRS, static search-based prioritization, and rule-based prioritization using two industrial and three open source case studies. Results showed that REMAP significantly outperformed the other approaches for 96% of the case studies and managed to achieve on average 18% higher Average Percentage of Faults Detected (APFD).},
  keywords={Testing;Fault detection;Runtime;Data mining;Search problems;Software;Conferences;dynamic test case prioritization;black-box regression testing;multi-objective optimization;rule-mining;search},
  doi={10.1109/ICST.2018.00015},
  ISSN={},
  month={April},}@ARTICLE{7456343,
  author={Eghbali, Sepehr and Tahvildari, Ladan},
  journal={IEEE Transactions on Software Engineering}, 
  title={Test Case Prioritization Using Lexicographical Ordering}, 
  year={2016},
  volume={42},
  number={12},
  pages={1178-1195},
  abstract={Test case prioritization aims at ordering test cases to increase the rate of fault detection, which quantifies how fast faults are detected during the testing phase. A common approach for test case prioritization is to use the information of previously executed test cases, such as coverage information, resulting in an iterative (greedy) prioritization algorithm. Current research in this area validates the fact that using coverage information can improve the rate of fault detection in prioritization algorithms. The performance of such iterative prioritization schemes degrade as the number of ties encountered in prioritization steps increases. In this paper, using the notion of lexicographical ordering, we propose a new heuristic for breaking ties in coverage based techniques. Performance of the proposed technique in terms of the rate of fault detection is empirically evaluated using a wide range of programs. Results indicate that the proposed technique can resolve ties and in turn noticeably increases the rate of fault detection.},
  keywords={Software testing;Fault detection;Feature extraction;Regression analysis;Fault diagnosis;Regression testing;test case prioritization;lexicographical ordering},
  doi={10.1109/TSE.2016.2550441},
  ISSN={1939-3520},
  month={Dec},}@INPROCEEDINGS{9990713,
  author={A, Mugilan and Totla, Tushar and Renwa, Yash and R, Charanya and Subbiah, Stalin and Dharmaraj, T. B. and Prakash, S. Om},
  booktitle={2022 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)}, 
  title={Comparative Analysis of Ant Colony Optimization and Particle Swarm Optimization for Test Case Prioritization}, 
  year={2022},
  volume={},
  number={},
  pages={680-686},
  abstract={To boost the efficiency of testing and save time and money in the construction of the testing program, the test case prioritization technique prioritizes a subset of the full test suite and optimizes the execution order of the test cases. The goal of this paper is to classify and compare the performance of two nature-based test case prioritization techniques: To overcome the problem of needing to perform the whole test suite at some point, resulting in time and expense limits, we used Ant Colony Optimization and Particle Swarm Optimization. We chose a sample test suite and prioritized the test cases for our research. An experimental investigation of the acquired data will be useful in selecting the best prioritizing technique under various environmental constraints. For our analysis, we selected a sample test suite and prioritized the test cases. In various environmental restrictions, an experimental study of the findings collected will be valuable in determining the optimum prioritization strategy. The findings of both algorithms showed high global optimization abilities, with the ant colony strategy outperforming the particle swarm optimization approach.},
  keywords={Ant colony optimization;Technological innovation;Particle swarm optimization;Informatics;Optimization;Testing;Particle Swarm Optimization;Ant Colony Algorithm;Test Case Prioritization;Regression Testing;Software Testing},
  doi={10.1109/3ICT56508.2022.9990713},
  ISSN={2770-7466},
  month={Nov},}@ARTICLE{8329518,
  author={Luo, Qi and Moran, Kevin and Zhang, Lingming and Poshyvanyk, Denys},
  journal={IEEE Transactions on Software Engineering}, 
  title={How Do Static and Dynamic Test Case Prioritization Techniques Perform on Modern Software Systems? An Extensive Study on GitHub Projects}, 
  year={2019},
  volume={45},
  number={11},
  pages={1054-1080},
  abstract={Test Case Prioritization (TCP) is an increasingly important regression testing technique for reordering test cases according to a pre-defined goal, particularly as agile practices gain adoption. To better understand these techniques, we perform the first extensive study aimed at empirically evaluating four static TCP techniques, comparing them with state-of-research dynamic TCP techniques across several quality metrics. This study was performed on 58 real-word Java programs encompassing 714 KLoC and results in several notable observations. First, our results across two effectiveness metrics (the Average Percentage of Faults Detected APFD and the cost cognizant APFDc) illustrate that at test-class granularity, these metrics tend to correlate, but this correlation does not hold at test-method granularity. Second, our analysis shows that static techniques can be surprisingly effective, particularly when measured by APFDc. Third, we found that TCP techniques tend to perform better on larger programs, but that program size does not affect comparative performance measures between techniques. Fourth, software evolution does not significantly impact comparative performance results between TCP techniques. Fifth, neither the number nor type of mutants utilized dramatically impact measures of TCP effectiveness under typical experimental settings. Finally, our similarity analysis illustrates that highly prioritized test cases tend to uncover dissimilar faults.},
  keywords={Testing;Measurement;Computer bugs;Software systems;Java;Fault detection;Regression testing;test case prioritization;static;dynamic;mutation analysis},
  doi={10.1109/TSE.2018.2822270},
  ISSN={1939-3520},
  month={Nov},}@ARTICLE{8793223,
  author={Lu, Chengyu and Zhong, Jinghui and Xue, Yinxing and Feng, Liang and Zhang, Jun},
  journal={IEEE Transactions on Reliability}, 
  title={Ant Colony System With Sorting-Based Local Search for Coverage-Based Test Case Prioritization}, 
  year={2020},
  volume={69},
  number={3},
  pages={1004-1020},
  abstract={Test case prioritization (TCP) is a popular regression testing technique in software engineering field. The task of TCP is to schedule the execution order of test cases so that certain objective (e.g., code coverage) can be achieved quickly. In this article, we propose an efficient ant colony system framework for the TCP problem, with the aim of maximizing the code coverage as soon as possible. In the proposed framework, an effective heuristic function is proposed to guide the ants to construct solutions based on additional statement coverage among remaining test cases. Besides, a sorting-based local search mechanism is proposed to further accelerate the convergence speed of the algorithm. Experimental results on different benchmark problems, and a real-world application, have shown that the proposed framework can outperform several state-of-the-art methods, in terms of solution quality and search efficiency.},
  keywords={Search problems;Testing;Software engineering;Computer science;Stochastic processes;Graphics processing units;Ant colony system (ACS);regression testing,statement coverage;test case prioritization (TCP)},
  doi={10.1109/TR.2019.2930358},
  ISSN={1558-1721},
  month={Sep.},}@INPROCEEDINGS{10675922,
  author={Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Seferi, Gkerta and Tauseef, Qasim},
  booktitle={2024 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={An End-to-End Test Case Prioritization Framework using Optimized Machine Learning Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Regression testing in software development is challenging due to the large number of test cases and continuous integration (CI) practices. Recently, test case prioritization (TCP) using machine learning (ML) has been shown to efficiently execute regression tests. This study introduces an automated, endto-end, self-contained ML-based framework, TCP-Tune, tailored exclusively for TCP. The framework utilizes open-source version control system data to combine code-change-related features with test execution results. This integration allows the automated optimization of hyperparameters across different ML models to improve the TCP. The framework also effectively visualizes and utilizes multiple evaluation metrics to evaluate the performance of the model over several builds. Unlike existing implementations, which rely on various frameworks, TCP-Tune enables the effortless incorporation of features from multiple sources and fine-tuned models, thereby providing optimum test prioritization in the ever-changing field of software development. Our approach has helped to provide efficient TCP through experimental assessments of a real-life, large-scale CI system.},
  keywords={Software testing;Radio frequency;Measurement;Machine learning;Production;Continuous integration;Market research;test case prioritization;hyperparameter tuning;regression testing;machine learning},
  doi={10.1109/ICSTW60967.2024.00014},
  ISSN={2159-4848},
  month={May},}@INPROCEEDINGS{10229439,
  author={Abdelkarim, Mohamed and ElAdawi, Reem},
  booktitle={2023 IEEE International Conference On Artificial Intelligence Testing (AITest)}, 
  title={TCP-Net++: Test Case Prioritization Using End-to-End Deep Neural Networks - Deployment Analysis and Enhancements}, 
  year={2023},
  volume={},
  number={},
  pages={99-106},
  abstract={The increasing number of test cases and frequency of continuous integration in software projects has created a bottleneck in regression testing. To save time and hardware resources, machine learning techniques can be applied without compromising quality. In this work, we present a case study for deployment analysis and results of using our previous work: TCP-Net: Test Case Prioritization using End-to-End Deep Neural Networks [1] in a real-life industrial environment, showing roadblocks, challenges, and enhancements done to improve its performance and usability, achieving 90% to 100% failure coverage by running an average of 23% to 39% of the test cases.},
  keywords={Software testing;Deep learning;Artificial neural networks;Software;Hardware;Usability;software testing;regression testing;test case prioritization;neural networks;deep learning;AI},
  doi={10.1109/AITest58265.2023.00024},
  ISSN={2835-3560},
  month={July},}@INPROCEEDINGS{8625203,
  author={Carballo, Pablo and Perera, Pablo and Rama, Santiago and Pedemonte, Martín},
  booktitle={2018 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, 
  title={A Biased Random-Key Genetic Algorithm for Regression Test Case Prioritization}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={The Test Case Prioritization Problem (TCPP) is a real-world problem that arises in regression testing. It lies in finding an ordering of the test cases of a test suite, such that test cases ordered first should be run first. The classical approach to solve this problem employing GAs is to use permutational encoding, but it requires specific operators to keep the feasibility of the solutions. The Biased Random-Key Genetic Algorithm (BRKGA) follows a different philosophy for dealing with permutations, using a string of real numbers and a decoder for computing the permutation. In this paper, we propose a BRKGA for solving the TCPP. The experimental evaluation on eleven instances of seven real-world programs shows that BRKGA is able to outperform two different permutational encoding based GAs (with order and cycle crossover operators), and that it has at least a similar performance than another permutational encoding based GA (with partially-mapped crossover) and a GA from a previous work specially conceived for tackling the TCPP.},
  keywords={Genetic algorithms;Encoding;Testing;Software;Springs;Fault detection;Decoding;Regression testing;Search-based software engineering;Biased random-key genetic algorithm;Test case prioritization problem},
  doi={10.1109/LA-CCI.2018.8625203},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10301223,
  author={Querejeta, Miriam Ugarte and Jee, Eunkyoung and Liu, Lingjun and Valle, Pablo and Arrieta, Aitor and Rezabal, Miren Illarramendi},
  booktitle={2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Search-based Test Case Selection for PLC Systems using Functional Block Diagram Programs}, 
  year={2023},
  volume={},
  number={},
  pages={228-239},
  abstract={Programmable Logic Controllers (PLCs) are the core unit of the production system, which frequently need to implement new processes to address customer needs. These changes must be fully tested to ensure the reliability of the PLC code, which is commonly programmed through Functional Block Diagrams (FBDs). This is a tedious task that requires considerable time and effort given the manual nature of the process involved in PLC testing. Hence, we present a cost-effective test selection approach to test FBD programs in dynamic environments. The proposed method uses a search-based multi-objective test case selection algorithm as a regression technique to test recently modified FBD programs. Specifically, we derived a total of 7 fitness function combinations, by combining different cost and quality-based fitness functions. We carried out an empirical evaluation, by employing fitness metrics in the wellknown NSGA-II algorithm to determine the best configuration setup for testing FBD programs. Furthermore, we benchmarked the performance of the NSGA-II with the baseline Random Search (RS). The study was carried out with three case studies of a reactor protection system, and evaluated with two sets of mutants. The results demonstrated that the proposed approach significantly reduces time, while keeping high the overall fault detection capability.},
  keywords={Measurement;Production systems;Programmable logic devices;Process control;Programming;Software;Software reliability;programmable logic controller;functional block diagram;test case selection;regression testing;search-based testing},
  doi={10.1109/ISSRE59848.2023.00040},
  ISSN={2332-6549},
  month={Oct},}@ARTICLE{9900114,
  author={Biswas, Sourav and Bansal, Aman and Mitra, Pabitra and Mall, Rajib},
  journal={IEEE Transactions on Reliability}, 
  title={Fault-Based Regression Test Case Prioritization}, 
  year={2023},
  volume={72},
  number={3},
  pages={1176-1190},
  abstract={We propose a set of four novel fault-based regression test case prioritization (TCP) techniques for object-oriented programs. We seed bugs into a program to create large number of mutants. We execute each mutant with the originally designed test suite. From this, we record the number of mutants for which a test case fails. Based on this, we prioritize the test cases using four base fault-based prioritization techniques that we have proposed. Finally, we combine the results of our four base prioritizers using three ensemble methods. We have conducted experimental studies to determine the effectiveness of our proposed approaches. Our experimental results show that our proposed TCP techniques exhibit superior performance over related techniques.},
  keywords={Computer bugs;Frequency modulation;Codes;Measurement;Fault detection;Java;Bayes methods;Mutation testing;object-oriented (OO) programs;regression test case prioritization (TCP);regression testing},
  doi={10.1109/TR.2022.3205483},
  ISSN={1558-1721},
  month={Sep.},}@ARTICLE{8453036,
  author={Di Nucci, Dario and Panichella, Annibale and Zaidman, Andy and De Lucia, Andrea},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Test Case Prioritization Genetic Algorithm Guided by the Hypervolume Indicator}, 
  year={2020},
  volume={46},
  number={6},
  pages={674-696},
  abstract={Regression testing is performed during maintenance activities to assess whether the unchanged parts of a software behave as intended. To reduce its cost, test case prioritization techniques can be used to schedule the execution of the available test cases to increase their ability to reveal regression faults earlier. Optimal test ordering can be determined using various techniques, such as greedy algorithms and meta-heuristics, and optimizing multiple fitness functions, such as the average percentage of statement and branch coverage. These fitness functions condense the cumulative coverage scores achieved when incrementally running test cases in a given ordering using Area Under Curve (AUC) metrics. In this paper, we notice that AUC metrics represent a bi-dimensional (simplified) version of the hypervolume metric, which is widely used in many-objective optimization. Thus, we propose a Hypervolume-based Genetic Algorithm, namely HGA, to solve the Test Case Prioritization problem when using multiple test coverage criteria. An empirical study conducted with respect to five state-of-the-art techniques shows that (i) HGA is more cost-effective, (ii) HGA improves the efficiency of Test Case Prioritization, (iii) HGA has a stronger selective pressure when dealing with more than three criteria.},
  keywords={Measurement;Greedy algorithms;Genetic algorithms;Testing;Software systems;Fault detection;Test case prioritization;genetic algorithm;hypervolume},
  doi={10.1109/TSE.2018.2868082},
  ISSN={1939-3520},
  month={June},}@ARTICLE{6839018,
  author={Mei, Lijun and Cai, Yan and Jia, Changjiang and Jiang, Bo and Chan, W.K. and Zhang, Zhenyu and Tse, T.H.},
  journal={IEEE Transactions on Services Computing}, 
  title={A Subsumption Hierarchy of Test Case Prioritization for Composite Services}, 
  year={2015},
  volume={8},
  number={5},
  pages={658-673},
  abstract={Many composite workflow services utilize non-imperative XML technologies such as WSDL, XPath, XML schema, and XML messages. Regression testing should assure the services against regression faults that appear in both the workflows and these artifacts. In this paper, we propose a refinement-oriented level-exploration strategy and a multilevel coverage model that captures progressively the coverage of different types of artifacts by the test cases. We show that by using them, the test case prioritization techniques initialized on top of existing greedy-based test case prioritization strategy form a subsumption hierarchy such that a technique can produce more test suite permutations than a technique that subsumes it. Our experimental study of a model instance shows that a technique generally achieves a higher fault detection rate than a subsumed technique, which validates that the proposed hierarchy and model have the potential to improve the cost-effectiveness of test case prioritization techniques.},
  keywords={XML;Fault detection;Semantics;Testing;Business;Educational institutions;Test case prioritization;service orientation;XPath;WSDL;XML messages},
  doi={10.1109/TSC.2014.2331683},
  ISSN={1939-1374},
  month={Sep.},}@INPROCEEDINGS{6676871,
  author={Schwartz, Amanda and Do, Hyunsook},
  booktitle={2013 IEEE International Conference on Software Maintenance}, 
  title={A Fuzzy Expert System for Cost-Effective Regression Testing Strategies}, 
  year={2013},
  volume={},
  number={},
  pages={1-10},
  abstract={Different testing environments and software change characteristics can affect the choice of regression testing techniques. In our prior work, we developed adaptive regression testing (ART) strategies to investigate this problem. While the ART strategies showed promising results, we also found that the multiple criteria decision making processes required for the ART strategies are time-consuming, often inaccurate and inconsistent, and limited in their scalability. To address these issues, in this research, we develop and empirically study a fuzzy expert system (FESART) to aid decision makers in choosing the most cost-effective technique for a particular software version. The results of our study show that FESART is consistently more cost-effective than the previously proposed ART strategies. One of the biggest contributors to FESART being more cost-effective is the reduced time required to apply the strategy. This contribution has significant impact because a strategy that is less time-consuming will be easier for researchers and practitioners to adopt, and will provide even greater cost-savings for regression testing sessions.},
  keywords={Expert systems;Testing;Subspace constraints;Fuzzy logic;Software;Decision making;Fuzzy sets;Regression testing;test case prioritization;adaptive regression testing strategy;AHP;fuzzy AHP;empirical studies},
  doi={10.1109/ICSM.2013.11},
  ISSN={1063-6773},
  month={Sep.},}@ARTICLE{9367020,
  author={Ling, Xiao and Agrawal, Rishabh and Menzies, Tim},
  journal={IEEE Transactions on Software Engineering}, 
  title={How Different is Test Case Prioritization for Open and Closed Source Projects?}, 
  year={2022},
  volume={48},
  number={7},
  pages={2526-2540},
  abstract={Improved test case prioritization means that software developers can detect and fix more software faults sooner than usual. But is there one “best” prioritization algorithm? Or do different kinds of projects deserve special kinds of prioritization? To answer these questions, this article applies nine prioritization schemes to 31 projects that range from (a) highly rated open-source Github projects to (b) computational science software to (c) a closed-source project. We find that prioritization approaches that work best for open-source projects can work worst for the closed-source project (and vice versa). From these experiments, we conclude that (a) it is ill-advised to always apply one prioritization scheme to all projects since (b) prioritization requires tuning to different project types.},
  keywords={Testing;Software;Open source software;Software development management;Measurement;Software algorithms;History;Software testing;regression testing;test case prioritization;open-source software},
  doi={10.1109/TSE.2021.3063220},
  ISSN={1939-3520},
  month={July},}@INPROCEEDINGS{6649891,
  author={Lv, Junpeng and Yin, Beibei and Cai, Kai-Yuan},
  booktitle={2013 IEEE 37th Annual Computer Software and Applications Conference}, 
  title={On the Gain of Measuring Test Case Prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={627-632},
  abstract={Test case prioritization (TCP) techniques aim to schedule the order of regression test suite to maximize some properties, such as early fault detection. In order to measure the abilities of different TCP techniques for early fault detection, a metric named average percentage of faults detected (APFD) is widely adopted. In this paper, we analyze the metric APFD and explore the gain of measuring TCP techniques from a control theory viewpoint. Based on that, we propose a generalized metric for TCP. This new metric focuses on the gain of defining early fault detection and measuring TCP techniques for various needs in different evaluation scenarios. By adopting this new metric, not only flexibility can be guaranteed, but also explicit physical significance for the metric will be provided before evaluation.},
  keywords={Fault detection;Testing;Gain measurement;Software;Weight measurement;Approximation methods;regression testing;test case prioritization;software metric;software cybernetics},
  doi={10.1109/COMPSAC.2013.101},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{10911525,
  author={Pilley, Kunal and Mall, Rajib and Biswas, Sourav and Mamgain, Vishal and Verma, Rajesh and Vishvakarma, S K},
  booktitle={2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={A Regression Test Case Prioritization Technique for Web Application Using User Session Data}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={We propose a novel regression test case prioritization technique (RTCP) for web applications exploiting user session data and hamming code distance. The proposed technique utilises user session data to reorder test cases such that test cases which cover the ‘most frequently accessed subset of pages together’ are given higher priority. The coverage information of user session data along with its frequency appearance and test cases are converted to hamming code. These hamming codes are used to calculate the coverage similarity between user access pattern and the test cases. Further, the hamming code distance is incorporated with frequency of appearance to calculate a weighted average distance among user session data and test cases. Finally, the test cases with a lesser weighted average distance are given higher priority.},
  keywords={Measurement;Codes;Government;Frequency conversion;Testing;Regression Testing;Regression Test Case Prioritization;Web Application;Hamming Code Distance},
  doi={10.1109/ICTBIG64922.2024.10911525},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10196878,
  author={Yang, Yu and Wang, Lu and Cha, Na and Li, Hua},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={A Test Case Prioritization Based on Genetic Algorithm With Ant Colony and Reinforcement Learning Improvement}, 
  year={2023},
  volume={},
  number={},
  pages={1588-1593},
  abstract={In order to improve the efficiency of regression testing in the cloud-network convergence platform, a test case prioritization method based on reinforcement learning and a genetic algorithm is proposed. The classical genetic algorithm of initial population and selection operations are improved by incorporating an ant colony algorithm of solutions to form a part of the starting population in the genetic algorithm. The selection process employs an "elite retention strategy" to avoid the classical genetic algorithm of the problem of getting trapped in locally optimal solutions. The improved algorithm is applied to test the cloud-network convergence platform, and the optimization-seeking abilities of the classical genetic algorithm, the ant colony genetic algorithm, and the reinforcement learning-based ant colony genetic algorithm are compared and analyzed. The findings reveal that the reinforcement learning-based ant colony genetic algorithm outperforms the other two algorithms by finding the best test case for the test case prioritization problem.},
  keywords={Q-learning;Software algorithms;Sociology;Genetics;Software;Statistics;Genetic algorithms;test case prioritization;reinforcement learning;genetic algorithm;ant colony algorithm},
  doi={10.1109/COMPSAC57700.2023.00245},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{7102622,
  author={Noguchi, Tadahiro and Washizaki, Hironori and Fukazawa, Yoshiaki and Sato, Atsutoshi and Ota, Kenichiro},
  booktitle={2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)}, 
  title={History-Based Test Case Prioritization for Black Box Testing Using Ant Colony Optimization}, 
  year={2015},
  volume={},
  number={},
  pages={1-2},
  abstract={Test case prioritization is a technique to improve software testing. Although a lot of work has investigated test case prioritization, they focus on white box testing or regression testing. However, software testing is often outsourced to a software testing company, in which testers are rarely able to access to source code due to a contract. Herein a framework is proposed to prioritize test cases for black box testing on a new product using the test execution history collected from a similar prior product and the Ant Colony Optimization. A simulation using two actual products shows the effectiveness and practicality of our proposed framework.},
  keywords={Software testing;Software;Ant colony optimization;Companies;History;Fault detection},
  doi={10.1109/ICST.2015.7102622},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{7507373,
  author={Banias, Ovidiu},
  booktitle={2016 IEEE 11th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={The drawbacks of statement code coverage test case prioritization related to domain testing}, 
  year={2016},
  volume={},
  number={},
  pages={221-224},
  abstract={In this paper we study the weaknesses of the test case prioritization algorithms based on statement code coverage and applied to the domain test cases. We present the inconsistency between the principles of domain testing and the selection and prioritization practices over domain test cases on criteria unrelated to the scope of the domain testing. We continue the study by discussing the impact of 100% statement code coverage over the suites of domain test cases, studying why this type of code coverage should not produce effects over the domain test cases. Statement code coverage prioritization techniques related to unit testing, integration testing and regression testing phases are discussed, emphasizing the incompatibility between statement code coverage, domain testing and test case prioritization all at once.},
  keywords={Software testing;Software;Computational intelligence;Informatics;Fault detection;Computer aided software engineering},
  doi={10.1109/SACI.2016.7507373},
  ISSN={},
  month={May},}@INPROCEEDINGS{10366665,
  author={Jabbar, Emad and Hemmati, Hadi and Feldt, Robert},
  booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)}, 
  title={Investigating Execution Trace Embedding for Test Case Prioritization}, 
  year={2023},
  volume={},
  number={},
  pages={279-290},
  abstract={Most automated software testing tasks, such as test case generation, selection, and prioritization, can benefit from an abstract representation of test cases. Although test case representation usually is not explicitly discussed in software literature, but traditionally test cases are mostly represented based on what they cover in source code (e.g., which statements or branches), which is in fact an abstract representation. In this paper, we hypothesize that execution traces of test cases, as representations of their behaviour, can be leveraged to better encode test cases compared to code-based coverage information, for automated testing tasks. To validate this hypothesis, we propose an embedding approach, Test2Vec, based on an state-of-the-art neural program embedding (CodeBert), where the encoder maps test execution traces, i.e. sequences of method calls with their inputs and return values, to fixed-length, numerical vectors. We evaluate this representation in automated test case prioritization (TP) task. Our TP method is a classifier trained on the passing and failing vectors of historical test cases, in regression testing. We compare our embedding with multiple baselines and related work including CodeBert itself. The empirical study is based on 250 real faults and 703,353 seeded faults (mutants) over 250 revisions of 10 open-source Java projects from Defects4J, with a total of over 1,407,206 execution traces. Results show that our approach improves all alternatives, significantly, with respect to studied metrics. We also show that both inputs and outputs of a method are important elements of the execution-based embedding.},
  keywords={Software testing;Measurement;Java;Source coding;Software quality;Software reliability;Security;Test Case Prioritization;Transformers;Software Testing;Embedding},
  doi={10.1109/QRS60937.2023.00036},
  ISSN={2693-9177},
  month={Oct},}@INPROCEEDINGS{7589817,
  author={Zhang, Xiaofang and Xie, Xiaoyuan and Chen, Tsong Yueh},
  booktitle={2016 IEEE International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Test Case Prioritization Using Adaptive Random Sequence with Category-Partition-Based Distance}, 
  year={2016},
  volume={},
  number={},
  pages={374-385},
  abstract={Test case prioritization schedules test cases in a certain order aiming to improve the effectiveness of regression testing. Random sequence is a basic and simple prioritization technique, while Adaptive Random Sequence (ARS) makes use of extra information to improve the diversity of random sequence. Some researchers have proposed prioritization techniques using ARS with white-box information, such as code coverage information, or with black-box information, such as string distances of the input data. In this paper, we propose new black-box test case prioritization techniques using ARS, and the diversity of test cases is assessed by category-partition-based distance. Our experimental studies show that these new techniques deliver higher fault-detection effectiveness than random prioritization, especially in the case of smaller ratio of failed test cases. In addition, in the comparison of different distance metrics, techniques with category-partition-based distance generally deliver better fault-detection effectiveness and efficiency, meanwhile in the comparison of different ordering algorithms, our ARS-based ordering algorithms usually have comparable fault-detection effectiveness but much lower computation overhead, and thus are much more cost-effective.},
  keywords={Random sequences;Measurement;Testing;Subspace constraints;Fault detection;Algorithm design and analysis;Semantics;test case prioritization;adaptive random sequence;random sequence;catergory partition;string distance},
  doi={10.1109/QRS.2016.49},
  ISSN={},
  month={Aug},}@ARTICLE{9086053,
  author={Lima, Jackson A. Prado and Vergilio, Silvia Regina},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Multi-Armed Bandit Approach for Test Case Prioritization in Continuous Integration Environments}, 
  year={2022},
  volume={48},
  number={2},
  pages={453-465},
  abstract={Continuous Integration (CI) environments have been increasingly adopted in the industry to allow frequent integration of software changes, making software evolution faster and cost-effective. In such environments, Test Case Prioritization (TCP) techniques play an important role to reduce regression testing costs, establishing a test case execution order that usually maximizes early fault detection. Existing works on TCP in CI environments (TCPCI) present some limitations. Few pieces of work consider CI particularities, such as the test case volatility, that is, they do not consider the dynamic environment of the software life-cycle in which new test cases can be added or removed (discontinued), characteristic related to the Exploration versus Exploitation (EvE) dilemma. To solve such a dilemma an approach needs to balance: i) the diversity of test suite; and ii) the quantity of new test cases and test cases that are error-prone or that comprise high fault-detection capabilities. To deal with this, most approaches use, besides the failure-history, other measures that rely on code instrumentation or require additional information, such as testing coverage. However, to maintain the information updated can be difficult and time-consuming, not scalable due to the test budget of CI environments. In this context, and to properly deal with the TCPCI problem, this work presents an approach based on Multi-Armed Bandit (MAB) called COLEMAN (Combinatorial VOlatiLE Multi-Armed BANdit). The TCPCI problem falls into the category of volatile and combinatorial MAB, because multiple arms (test cases) need to be selected, and they are added or removed over the cycles. We conducted an evaluation considering three time budgets and eleven systems. The results show the applicability of our approach and that COLEMAN outperforms the most similar approach from literature in terms of early fault detection and performance.},
  keywords={Testing;Fault detection;Software;Instruments;Google;Industries;Companies;Test case prioritization;continuous integration;multi-armed bandit},
  doi={10.1109/TSE.2020.2992428},
  ISSN={1939-3520},
  month={Feb},}@INPROCEEDINGS{7381799,
  author={Noor, Tanzeem Bin and Hemmati, Hadi},
  booktitle={2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={A similarity-based approach for test case prioritization using historical failure data}, 
  year={2015},
  volume={},
  number={},
  pages={58-68},
  abstract={Test case prioritization is a crucial element in software quality assurance in practice, specially, in the context of regression testing. Typically, test cases are prioritized in a way that they detect the potential faults earlier. The effectiveness of test cases, in terms of fault detection, is estimated using quality metrics, such as code coverage, size, and historical fault detection. Prior studies have shown that previously failing test cases are highly likely to fail again in the next releases, therefore, they are highly ranked, while prioritizing. However, in practice, a failing test case may not be exactly the same as a previously failed test case, but quite similar, e.g., when the new failing test is a slightly modified version of an old failing one to catch an undetected fault. In this paper, we define a class of metrics that estimate the test cases quality using their similarity to the previously failing test cases. We have conducted several experiments with five real world open source software systems, with real faults, to evaluate the effectiveness of these quality metrics. The results of our study show that our proposed similarity-based quality measure is significantly more effective for prioritizing test cases compared to existing test case quality measures.},
  keywords={Measurement;Testing;Fault detection;History;Context;Software quality;Test case prioritization;Test quality metric;Similarity;Execution trace;Distance function;Historical data;Code coverage;Test size},
  doi={10.1109/ISSRE.2015.7381799},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9103716,
  author={Su, Wenjun and Li, Zhao and Wang, Zhihui and Yang, Dengxin},
  booktitle={2020 International Conference on Computer Engineering and Application (ICCEA)}, 
  title={A Meta-heuristic Test Case Prioritization Method Based on Hybrid Model}, 
  year={2020},
  volume={},
  number={},
  pages={430-435},
  abstract={Software testing is an important and complex part of the software development life cycle. Along with version changes and defect repairs of the software system under test, regression testing is required to ensure that the modified parts have no impact on the unmodified parts. In a resource-constrained environment, it is necessary to select a more valuable test case from the test case library to execute first. However, the existing prioritization methods of test cases are still insufficient in terms of Average Percentage of Faults Detected (APFD) and time execution performance, and there is a problem of large search space. Aiming at the test case priority ranking problem, this paper proposes a meta-heuristic test case prioritization method based on a hybrid model to reduce test cost. This method first establishes a hybrid model by using the correlation between test cases and the importance of test data, and then uses an improved firefly algorithm based on the hybrid model to find an optimal test sequence. This article has carried out experiments on three benchmark test programs. The test suite is from Software-artifact Infrastructure Repository (1SIR). The experimental results show that the method proposed in this paper has better performance in terms of APFD and time execution compared with existing methods, such as Greedy, Particle Swarm Optimization (PSO) and Firefly Algorithm (FA).},
  keywords={Software;Measurement;Brightness;Linear programming;Automation;Telecommunications;Software testing;component;Software testing;test case priority;hybrid model;firefly algorithm},
  doi={10.1109/ICCEA50009.2020.00099},
  ISSN={},
  month={March},}@INPROCEEDINGS{10621714,
  author={Găceanu, Radu and Szederjesi-Dragomir, Arnold and Vescan, Andreea},
  booktitle={2024 IEEE International Conference on Software Analysis, Evolution and Reengineering - Companion (SANER-C)}, 
  title={Leveraging Rough Sets for Enhanced Test Case Prioritization in a Continuous Integration Context}, 
  year={2024},
  volume={},
  number={},
  pages={175-182},
  abstract={In the rapidly evolving landscape of Continuous Integration (CI), test case execution becomes pivotal with every code modification, rendering regression testing strategies essential. Among these, Test Case Prioritization (TCP) has become a popular way to improve the efficiency and effectiveness of software testing. Recently, researchers have been mostly looking at supervised learning methods and reinforcement learning to deal with TCP in CI. However, because of the dynamic nature of these environments, it might be worth exploring unsupervised approaches that can adapt to the inherent uncertainties without labeled data. This paper proposes RoughTCP, a novel approach utilizing a rough sets-based agglomerative clustering algorithm, to prioritize test cases. RoughTCP automatically groups and ranks tests based on their intrinsic patterns and correlations (e.g., faults, tests duration, cycles count, and total runs count) without a predefined model. This improves fault detection without the need for constant supervision and provides a more comprehensive understanding of the results by incorporating rough sets. Three sets of experiments were performed, considering data from continuous integration contexts in industrial projects. Compared to recent related work, our experiments show that the RoughTCP approach yields better results for budgets higher than or equal to 75% on all datasets, while sometimes also outperforming all other methods on lower budgets. This underlines the potential of unsupervised methods and, in particular, the strength of RoughTCP in reshaping the TCP landscape in CI environments.},
  keywords={Software testing;Uncertainty;Heuristic algorithms;Supervised learning;Rough sets;Clustering algorithms;Reinforcement learning;Test Case Prioritization;Continuous Integration;Rough Sets;Clustering;Faults;Duration;Cycles},
  doi={10.1109/SANER-C62648.2024.00030},
  ISSN={},
  month={March},}@INPROCEEDINGS{6598153,
  author={Fuzhen Sun and Yan Li},
  booktitle={2013 Fourth International Conference on Digital Manufacturing & Automation}, 
  title={Regression Testing Prioritization Based on Model Checking for Safety-Crucial Embedded Systems}, 
  year={2013},
  volume={},
  number={},
  pages={979-983},
  abstract={The order in which test-cases are executed has an influence on the rate at which faults can be detected. In this paper we demonstrate how test-case prioritization can be performed with the use of model-checkers. For this, different well known prioritization techniques are adapted for modelbased use. New property based prioritization techniques are introduced. In addition it is shown that prioritization can be done at test-case generation time, thus removing the need for test-suite post-processing. Several experiments for safetycrucial embedded systems are used to show the validity of these ideas.},
  keywords={Manufacturing;Automation;Test Case Prioritization;Software Testing;Model Checking;Property Testing},
  doi={10.1109/ICDMA.2013.229},
  ISSN={},
  month={June},}@INPROCEEDINGS{10216597,
  author={Abdalla, Zeinab and Haring, Kerstin and Andrews, Anneliese},
  booktitle={2022 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Test Case Prioritization for Mobile Apps}, 
  year={2022},
  volume={},
  number={},
  pages={1843-1848},
  abstract={Like for any software, Mobile Applications (Apps) are modified during their specification, implementation, and maintenance phases with the goal to satisfy new requirements, fix defects, and change or add functionality. There is a need to regression test for and detect faults in every phase. However, resource and time constraints may lead to Mobile Apps not being tested. In this paper we present a model-based test approach to prioritize test cases based on the input complexity for each test path of the Mobile App. We argue that this novel approach will significantly improve the efficiency and effectiveness of current techniques.},
  keywords={Scientific computing;Fault detection;Computational modeling;Closed box;Maintenance engineering;Mobile applications;Complexity theory;Model-Based Regression Testing;Test Case Pri-oritization;Mobile Apps},
  doi={10.1109/CSCI58124.2022.00332},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{7943143,
  author={Kaur, Arvinder and Agrawal, Arun Prakash},
  booktitle={2017 7th International Conference on Cloud Computing, Data Science & Engineering - Confluence}, 
  title={A comparative study of Bat and Cuckoo search algorithm for regression test case selection}, 
  year={2017},
  volume={},
  number={},
  pages={164-170},
  abstract={Enhancing the software by either adding new functionality or deleting some obsolete capability or fixing the errors is called software maintenance. As a result, the software may function improperly or unchanged parts of the software may be adversely affected. Testing carried out to validate that no new errors have been introduced during maintenance activity is called Regression Testing. It is acknowledged to be an expensive activity and may account for around 60-70% of the total software life cycle cost. Reducing the cost of regression testing is therefore of vital importance and has the caliber to reduce the cost of maintenance also. This paper evaluates the performance of two metaheuristic algorithms-Bat Algorithm and Cuckoo Search Algorithm for selecting test cases. Factors that we have considered for performance evaluation are the number of faults detected and the execution time. The domain of study is the flex object from the Benchmark repository - Software Artifact and Infrastructure Repository. Extensive experiments have been conducted to collect and analyze the results. A Statistical test, F-test has also been conducted to validate the research hypothesis. Results indicate that the Cuckoo Search Algorithms perform a little better than Bat Algorithm.},
  keywords={Software algorithms;Software;Testing;Optimization;Search problems;Algorithm design and analysis;Estimation;Software Maintenance;Regression Test Case Selection;Bat Algorithm;Cuckoo Search Algorithm},
  doi={10.1109/CONFLUENCE.2017.7943143},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9142966,
  author={Gokilavani, N. and Bharathi, B.},
  booktitle={2020 4th International Conference on Trends in Electronics and Informatics (ICOEI)(48184)}, 
  title={An Enhanced Adaptive Random Sequence (EARS) Based Test Case Prioritization Using K-Mediods Based Fuzzy Clustering}, 
  year={2020},
  volume={},
  number={},
  pages={567-572},
  abstract={The efforts of prioritization method is to maximize the detection of fault rate by organizing the significant test cases which is operated in a sequence of regression tests. Generally, it is implemented to sort down the test cases based on the priorities former than those with minimum priority imparting to an estimated criteria. The faults which gives maximum impacts should be detected at earlier stages in testing practices. The adaptive random testing is implemented to execute arbitrary testing through input triggering clustering errors. It improves the detection ratio of regression testing in software based on object-oriented. In this proposal, an adaptive techniques of test case prioritization relied on fuzzy clustering is implemented. The adjacent matrices is generated and cluster head is chosen within the test cases. It is made by identity precise pairing. Then Enhanced Adaptive random sequence depending on prioritization of test cases detects the flaws which operates to categorize neighboring test cases as varied as possible. Hence the outcomes proved increased efficacy in earlier fault detection rate.},
  keywords={Testing;Random sequences;Software;Fault detection;Ear;Programming;Conferences;Adjacency Matrix;Fuzzy k-medoid;Adaptive Random Sequence (ARS);Average Percentage of Fault Detected},
  doi={10.1109/ICOEI48184.2020.9142966},
  ISSN={},
  month={June},}@INPROCEEDINGS{8530033,
  author={Luo, Qi and Moran, Kevin and Poshyvanyk, Denys and Di Penta, Massimiliano},
  booktitle={2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Assessing Test Case Prioritization on Real Faults and Mutants}, 
  year={2018},
  volume={},
  number={},
  pages={240-251},
  abstract={Test Case Prioritization (TCP) is an important component of regression testing, allowing for earlier detection of faults or helping to reduce testing time and cost. While several TCP approaches exist in the research literature, a growing number of studies have evaluated them against synthetic software defects, called mutants. Hence, it is currently unclear to what extent TCP performance on mutants would be representative of the performance achieved on real faults. To answer this fundamental question, we conduct the first empirical study comparing the performance of TCP techniques applied to both real-world and mutation faults. The context of our study includes eight well-studied TCP approaches, 35k+ mutation faults, and 357 real-world faults from five Java systems in the Defects4J dataset. Our results indicate that the relative performance of the studied TCP techniques on mutants may not strongly correlate with performance on real faults, depending upon attributes of the subject programs. This suggests that, in certain contexts, the best performing technique on a set of mutants may not be the best technique in practice when applied to real faults. We also illustrate that these correlations vary for mutants generated by different operators depending on whether chosen operators reflect typical faults of a subject program. This highlights the importance, particularly for TCP, of developing mutation operators tailored for specific program domains.},
  keywords={Testing;Software;Fault detection;Genetic algorithms;Correlation;Measurement;Data mining;Test Case Prioritization;Empirical Study;TCP;Mutation Analysis;Mutation Testing;Mutants},
  doi={10.1109/ICSME.2018.00033},
  ISSN={2576-3148},
  month={Sep.},}@INPROCEEDINGS{10298714,
  author={Vescan, Andreea and Găceanu, Radu and Szederjesi-Dragomir, Arnold},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW)}, 
  title={Neural Network-Based Test Case Prioritization in Continuous Integration}, 
  year={2023},
  volume={},
  number={},
  pages={68-77},
  abstract={In continuous integration environments, the execution of test cases is performed for every newly added feature or when a bug fix occurs. Therefore, regression testing is performed considering various testing strategies. The Test Case Prioritization (TCP) approach considers reordering test cases so that faults are found earlier with a minimum execution cost. The purpose of the paper is to investigate the impact of neural network-based classification models to assist in the prioritization of test cases. Three different models are employed with various features (duration, fault rate, cycles count, total runs count) and considering information at every 30 cycles or at every 100 cycles. The results obtained emphasize that the NEUTRON approach finds a better prioritization with respect to NAPFD (normalized average percent of the detected fault) than random permutation and is comparable with the solutions that used either duration or faults, considering that it combines both values. Compared to other existing approaches, NEUTRON obtains similar com-petitive results when considering a budget of 50% and the best results when considering budgets of 75% and 100%.},
  keywords={Source coding;Conferences;Computer bugs;Neutrons;Feature extraction;Testing;Software engineering;Test Case Prioritization;Continuous Integration;Neural Network;Faults;Duration;Cycles},
  doi={10.1109/ASEW60602.2023.00014},
  ISSN={2151-0849},
  month={Sep.},}@ARTICLE{6375700,
  author={Zhai, Ke and Jiang, Bo and Chan, W.K.},
  journal={IEEE Transactions on Services Computing}, 
  title={Prioritizing Test Cases for Regression Testing of Location-Based Services: Metrics, Techniques, and Case Study}, 
  year={2014},
  volume={7},
  number={1},
  pages={54-67},
  abstract={Location-based services (LBS) are widely deployed. When the implementation of an LBS-enabled service has evolved, regression testing can be employed to assure the previously established behaviors not having been adversely affected. Proper test case prioritization helps reveal service anomalies efficiently so that fixes can be scheduled earlier to minimize the nuisance to service consumers. A key observation is that locations captured in the inputs and the expected outputs of test cases are physically correlated by the LBS-enabled service, and these services heuristically use estimated and imprecise locations for their computations, making these services tend to treat locations in close proximity homogenously. This paper exploits this observation. It proposes a suite of metrics and initializes them to demonstrate input-guided techniques and point-of-interest (POI) aware test case prioritization techniques, differing by whether the location information in the expected outputs of test cases is used. It reports a case study on a stateful LBS-enabled service. The case study shows that the POI-aware techniques can be more effective and more stable than the baseline, which reorders test cases randomly, and the input-guided techniques. We also find that one of the POI-aware techniques, cdist, is either the most effective or the second most effective technique among all the studied techniques in our evaluated aspects, although no technique excels in all studied SOA fault classes.},
  keywords={Measurement;Entropy;Testing;Semiconductor optical amplifiers;Global Positioning System;Earth;Google;Regression testing;location-based services;black-box metrics;test case prioritization;point-of-interest},
  doi={10.1109/TSC.2012.40},
  ISSN={1939-1374},
  month={Jan},}@INPROCEEDINGS{8300829,
  author={Indumathi, C. P. and Madhumathi, S.},
  booktitle={2017 International Conference on Trends in Electronics and Informatics (ICEI)}, 
  title={Cost aware test suite reduction algorithm for regression testing}, 
  year={2017},
  volume={},
  number={},
  pages={869-874},
  abstract={Regression testing is the process that a recent code change has not adversely affect the existing features. The re-running of all the test cases during regression testing is very expensive as it requires huge time and resources. Test case prioritization techniques are to schedule the test cases in accordance with some criteria such that important test cases are executed with that given period. This study presents test case prioritization using genetic algorithm and their effectiveness is measured using APFD. Then the prioritized test cases are reduced. Test suite reduction techniques aim at identifying and eliminating redundant test cases from test suites in order to reduce the total number of test cases to execute, thereby improving the efficiency of the software testing activity. Our aim is to reduce the cost by reducing the number of test suite after prioritization. MFTS algorithm is used to reduce the given test suite with maximum coverage and it improves the rate of fault detection effectiveness.},
  keywords={Testing;Genetic algorithms;Fault detection;Software;Market research;Informatics;Heuristic algorithms;Regression testing;Genetic Algorithm;APFD;MFTS algorithm},
  doi={10.1109/ICOEI.2017.8300829},
  ISSN={},
  month={May},}@INPROCEEDINGS{9058244,
  author={Kaur, Amandeep},
  booktitle={2020 10th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={An Approach To Extract Optimal Test Cases Using AI}, 
  year={2020},
  volume={},
  number={},
  pages={649-654},
  abstract={Regression testing is the backbone of the functional Software Testing. Unlike any other testing; regression validation evolves the whole suite of code which incorporates the existing code as well as new code or the change request. Validating all the possible scenarios is not effective as it increases the expenditure. This gains the outlook for the researchers to analyze a more efficient way for regression testing by electing a subset from the test suite to spot the defects. Ample research has crop up for this NP-Hard problem and folks are implementing the metaheuristic techniques and dominantly the nature-inspired ones. In this paper, to extract the optimal test cases we have utilized Harris Hawks Optimization (HHO) which is a nature-inspired technique and portrays chasing drive away style of Harris' hawks termed as Surprise Pounce. In this tactic, assorted hawks combine together to pounce a prey through the offbeat directions to surprise the prey. This paper focuses on the Harris Hawks Optimization algorithm and its applications in the domain of software testing.},
  keywords={Optimization;Sociology;Statistics;Rabbits;Software testing;Genetic algorithms;Software testing;Regression testing;Optimization;Harris Hawks Optimization;Test case selection},
  doi={10.1109/Confluence47617.2020.9058244},
  ISSN={},
  month={Jan},}@ARTICLE{9394799,
  author={Bagherzadeh, Mojtaba and Kahani, Nafiseh and Briand, Lionel},
  journal={IEEE Transactions on Software Engineering}, 
  title={Reinforcement Learning for Test Case Prioritization}, 
  year={2022},
  volume={48},
  number={8},
  pages={2836-2856},
  abstract={Continuous Integration (CI) significantly reduces integration problems, speeds up development time, and shortens release time. However, it also introduces new challenges for quality assurance activities, including regression testing, which is the focus of this work. Though various approaches for test case prioritization have shown to be very promising in the context of regression testing, specific techniques must be designed to deal with the dynamic nature and timing constraints of CI. Recently, Reinforcement Learning (RL) has shown great potential in various challenging scenarios that require continuous adaptation, such as game playing, real-time ads bidding, and recommender systems. Inspired by this line of work and building on initial efforts in supporting test case prioritization with RL techniques, we perform here a comprehensive investigation of RL-based test case prioritization in a CI context. To this end, taking test case prioritization as a ranking problem, we model the sequential interactions between the CI environment and a test case prioritization agent as an RL problem, using three alternative ranking models. We then rely on carefully selected and tailored state-of-the-art RL techniques to automatically and continuously learn a test case prioritization strategy, whose objective is to be as close as possible to the optimal one. Our extensive experimental analysis shows that the best RL solutions provide a significant accuracy improvement over previous RL-based work, with prioritization strategies getting close to being optimal, thus paving the way for using RL to prioritize test cases in a CI context.},
  keywords={Testing;History;Training;Reinforcement learning;Software systems;Adaptation models;Software algorithms;Continuous integration;CI;reinforcement learning;test prioritization},
  doi={10.1109/TSE.2021.3070549},
  ISSN={1939-3520},
  month={Aug},}@ARTICLE{10872897,
  author={Rothermel, Gregg and Untch, Roland},
  journal={IEEE Transactions on Software Engineering}, 
  title={On “Prioritizing Test Cases for Regression Testing”}, 
  year={2025},
  volume={51},
  number={3},
  pages={802-807},
  abstract={The paper “Prioritizing Test Cases for Regression Testing”, by Rothermel, Untch, Chu and Harrold, appeared in IEEE Transactions on Software Engineering in 2001. This paper was a seminal paper in the area of test case prioritization, and it set the stage for research on many different topics related to prioritization. In this retrospective, we recount the work presented in the paper, and then reflect on how it has influenced subsequent research and practice.},
  keywords={Testing;Fault detection;Software;Codes;Minimization;Training;Surges;Software measurement;Software engineering;Electronic mail;Test case prioritization; regression testing},
  doi={10.1109/TSE.2025.3538490},
  ISSN={1939-3520},
  month={March},}@INPROCEEDINGS{7819324,
  author={Abele, Sebastian and Weyrich, Michael},
  booktitle={2016 IEEE 14th International Conference on Industrial Informatics (INDIN)}, 
  title={A combined fault diagnosis and test case selection assistant for automotive end-of-line test systems}, 
  year={2016},
  volume={},
  number={},
  pages={1072-1077},
  abstract={With growing complexity of premium cars, the end-of-line test systems also increase in complexity. The test systems have to provide more and more functionality like flashing of electronic control units (ECUs) and sensor calibration. Current end-of-line test systems evolved to complex networked IT-systems, which consist of various components and subsystems from different suppliers. Automotive production maintenance engineers are challenged to keep the availability of the test system on a high level to not cause production delays. In a case study with automotive test experts, we considered fault diagnosis and test case selection as two major tasks to maintain a high system availability. The experts combine their knowledge and experience about fault-prone system parts and former faults to optimize fault diagnosis and test case selection for regression testing. To support the experts to manage the growing complexity, we propose a combined fault diagnosis and test case selection assistance system. The combination of both techniques enables synergy effects by supporting the fault diagnosis with test case selection and by considering fault data in regression testing. This paper presents the concept of that combined assistant system and describes a prototypical realization used in an exemplary scenario.},
  keywords={Fault diagnosis;Monitoring;Production;Automotive engineering;Automobiles;Testing;Quality assurance},
  doi={10.1109/INDIN.2016.7819324},
  ISSN={2378-363X},
  month={July},}@INPROCEEDINGS{8473253,
  author={Ramya, Paruchuri and Sindhura, Vemuri and Vidya Sagar, P.},
  booktitle={2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)}, 
  title={Clustering Based Prioritization of Test Cases}, 
  year={2018},
  volume={},
  number={},
  pages={1181-1185},
  abstract={Regression testing is the procedure of retesting the product and checking whether additional faults or errors have been created in the existing one. It is vital for keeping up programming quality. But it is a costly process. By., utilizing prioritization technique cost can be diminished. Prioritization increases productiveness of regression testing and its main criteria is to build the rate of error detection. Merging requirements information into current testing practice helps the engineers to recognize the source of faults easily. In this paper a research is done on whether the requirements-based grouping methodology can enhance the viability of prioritization techniques. So., here a grouping approach is performed on given requirements and prioritization techniques based on code scope metric.},
  keywords={Testing;Programming;Clustering algorithms;Conferences;Software;Information technology;Tools;Regression testing;Test case prioritization-necessities based grouping;Code scope metric},
  doi={10.1109/ICICCT.2018.8473253},
  ISSN={},
  month={April},}@INPROCEEDINGS{6724209,
  author={Maheswari, R. Uma and JeyaMala, D.},
  booktitle={2013 IEEE International Conference on Computational Intelligence and Computing Research}, 
  title={A novel approach for test case prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  abstract={The process of verifying the modified software in the maintenance phase is called Regression Testing. The size of the regression test suite and its selection process is a complex task for regression testers because of time and budget constraints. In this research paper, new Prioritization technique based on hamming distance has been proposed. It is illustrated using an example and found that it produces good results. Average Percentage of Fault Detection (APFD) metrics and charts has been used to show the effectiveness of proposed algorithm.},
  keywords={Fault detection;Testing;Hamming distance;Bismuth;Conferences;Measurement;Software engineering;APFD;Fault based Test Suite prioritization;Hamming Distance},
  doi={10.1109/ICCIC.2013.6724209},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10764994,
  author={Baz, Abdelrahman and Huang, Minchao and Shi, August},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Prioritizing Tests for Improved Runtime}, 
  year={2024},
  volume={},
  number={},
  pages={2273-2278},
  abstract={Regression testing is important but costly due to the large number of tests to run over frequent changes. Techniques to speed up regression testing such as regression test selection run fewer tests, but they risk missing to run some key tests that detect true faults.In this work, we investigate the effect of running tests in different test-orders on overall test runtime in Java projects. Variance in runtime across different test-orders can be due to various reasons, such as due to dependencies between tests. In our evaluation, we run tests in different, random test-orders, and we find on average that the slowest test-order per project can be slower than the fastest test-order by 31.17%. We also develop a technique for guiding a search for the fastest test-orders by clustering test-orders based on their runtimes and generating test-orders based on observed in-common relations between tests in the fastest test-orders.},
  keywords={Java;Runtime;Testing;Regression testing;test case prioritization;runtime},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10062444,
  author={Chen, Fanliang and Li, Zheng and Shang, Ying and Yang, Yang},
  booktitle={2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Focus on New Test Cases in Continuous Integration Testing based on Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={830-841},
  abstract={In software regression testing, newly added test cases are more likely to fail, and therefore, should be prioritized for execution. In software regression testing for continuous integration, reinforcement learning-based approaches are promising and the RETECS (Reinforced Test Case Prioritization and Selection) framework is a successful application case. RETECS uses an agent composed of a neural network to predict the priority of test cases, and the agent needs to learn from historical information to make improvements. However, the newly added test cases have no historical execution information, thus using RETECS to predict their priority is more like ‘random’. In this paper, we focus on new test cases for continuous integration testing, and on the basis of the RETECS framework, we first propose a priority assignment method for new test cases to ensure that they can be executed first. Secondly, continuous integration is a fast iterative integration method where new test cases have strong fault detection capability within the latest periods. Therefore, we further propose an additional reward method for new test cases. Finally, based on the full lifecycle management, the ‘new’ additional rewards need to be terminated within a certain period, and this paper implements an empirical study. We conducted 30 iterations of the experiment on 12 datasets and our best results were 19.24%, 10.67%, and 34.05 positions better compared to the best parameter combination in RETECS for the NAPFD (Normalized Average Percentage of Faults Detected), RECALL and TTF (Test to Fail) metrics, respectively.},
  keywords={Measurement;Fault detection;Neural networks;Reinforcement learning;Software quality;Software reliability;Security;Continuous integration;new test case;test case prioritization;reinforcement learning;reward function;regression testing},
  doi={10.1109/QRS57517.2022.00088},
  ISSN={2693-9177},
  month={Dec},}@INPROCEEDINGS{9825820,
  author={Da Roza, Enrique A. and Lima, Jackson A. Prado and Silva, Rogério C. and Vergilio, Silvia Regina},
  booktitle={2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Machine Learning Regression Techniques for Test Case Prioritization in Continuous Integration Environment}, 
  year={2022},
  volume={},
  number={},
  pages={196-206},
  abstract={Test Case Prioritization (TCP) techniques are a key factor in reducing the regression testing costs even more when Continuous Integration (CI) practices are adopted. TCP approaches based on failure history have been adopted in this context because they are more suitable for CI environment constraints: test budget and test case volatility, that is, test cases may be added or removed over the CI cycles. Promising approaches are based on Reinforcement Learning (RL), which learns with past prioritization, guided by a reward function. In this work, we introduce a TCP approach for CI environments based on the sliding window method, which can be instantiated with different Machine Learning (ML) algorithms. Unlike other ML approaches, it does not require retraining the model to perform the prioritization and any code analysis. As an alternative for the RL approaches, we apply the Random Forest (RF) algorithm and a Long Short Term Memory (LSTM) deep learning network in our evaluation. We use three time budgets and eleven systems. The results show the applicability of the approach considering the prioritization time and the time between the CI cycles. Both algorithms take just a few seconds to execute. The RF algorithm obtained the best performance for more restrictive budgets compared to the RL approaches described in the literature. Considering all systems and budgets, RF reaches Normalized Average Percentage of Faults Detected (NAPFD) values that are the best or statistically equivalent to the best ones in around 72% of the cases, and the LSTM network in 55% of them. Moreover, we discuss some implications of our results for the usage of the algorithms evaluated.},
  keywords={Radio frequency;Machine learning algorithms;Recurrent neural networks;Software algorithms;Reinforcement learning;Software;History;Recurrent Neural Networks;Machine Learning;Continuous Integration;Regression Testing},
  doi={10.1109/SANER53432.2022.00034},
  ISSN={1534-5351},
  month={March},}@INPROCEEDINGS{7272927,
  author={Marijan, Dusica},
  booktitle={2015 IEEE International Conference on Software Quality, Reliability and Security}, 
  title={Multi-perspective Regression Test Prioritization for Time-Constrained Environments}, 
  year={2015},
  volume={},
  number={},
  pages={157-162},
  abstract={Test case prioritization techniques are widely used to enable reaching certain performance goals during regression testing faster. A commonly used goal is high fault detection rate, where test cases are ordered in a way that enables detecting faults faster. However, for optimal regression testing, there is a need to take into account multiple performance indicators, as considered by different project stakeholders. In this paper, we introduce a new optimal multi-perspective approach for regression test case prioritization. The approach is designed to optimize regression testing for faster fault detection integrating three different perspectives: business perspective, performance perspective, and technical perspective. The approach has been validated in regression testing of industrial mobile device systems developed in continuous integration. The results show that our proposed framework efficiently prioritizes test cases for faster and more efficient regression fault detection, maximizing the number of executed test cases with high failure frequency, high failure impact, and cross-functional coverage, compared to manual practice.},
  keywords={Testing;Fault detection;Manuals;Software;Business;Time factors;Time-frequency analysis;software testing;regression testing;test case prioritization},
  doi={10.1109/QRS.2015.31},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8539203,
  author={Azizi, Maral and Do, Hyunsook},
  booktitle={2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Graphite: A Greedy Graph-Based Technique for Regression Test Case Prioritization}, 
  year={2018},
  volume={},
  number={},
  pages={245-251},
  abstract={To date, various test prioritization techniques have been developed, but the majority of these techniques consider a single objective that could limit the applicability of prioritization techniques by ignoring practical constraints imposed on regression testing. Multi-objective prioritization techniques try to reorder test cases so that they can optimize multiple goals that testers want to achieve. In this paper, we introduced a novel graph-based framework that maps the prioritization task to a graph traversal algorithm. To evaluate our approach, we performed an empirical study using 20 versions of four open source applications. Our results indicate that the use of the graph-based technique can improve the effectiveness and efficiency of test case prioritization technique.},
  keywords={Graphite;Testing;Measurement;Feature extraction;Task analysis;Fault detection;Genetic algorithms;Regression Testing},
  doi={10.1109/ISSREW.2018.00014},
  ISSN={},
  month={Oct},}@ARTICLE{6484067,
  author={Sampath, Sreedevi and Bryce, Renée and Memon, Atif M.},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Uniform Representation of Hybrid Criteria for Regression Testing}, 
  year={2013},
  volume={39},
  number={10},
  pages={1326-1344},
  abstract={Regression testing tasks of test case prioritization, test suite reduction/minimization, and regression test selection are typically centered around criteria that are based on code coverage, test execution costs, and code modifications. Researchers have developed and evaluated new individual criteria; others have combined existing criteria in different ways to form what we--and some others--call hybrid criteria. In this paper, we formalize the notion of combining multiple criteria into a hybrid. Our goal is to create a uniform representation of such combinations so that they can be described unambiguously and shared among researchers. We envision that such sharing will allow researchers to implement, study, extend, and evaluate the hybrids using a common set of techniques and tools. We precisely formulate three hybrid combinations, Rank, Merge, and Choice, and demonstrate their usefulness in two ways. First, we recast, in terms of our formulations, others' previously reported work on hybrid criteria. Second, we use our previous results on test case prioritization to create and evaluate new hybrid criteria. Our findings suggest that hybrid criteria of others can be described using our Merge and Rank formulations, and that the hybrid criteria we developed most often outperformed their constituent individual criteria.},
  keywords={Testing;Fault detection;Educational institutions;Genetic algorithms;Vectors;Loss measurement;Minimization;Test case prioritization;test criteria;hybrid test criteria;web testing;GUI testing},
  doi={10.1109/TSE.2013.16},
  ISSN={1939-3520},
  month={Oct},}@ARTICLE{7362042,
  author={Marchetto, Alessandro and Islam, Md. Mahfuzul and Asghar, Waseem and Susi, Angelo and Scanniello, Giuseppe},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Multi-Objective Technique to Prioritize Test Cases}, 
  year={2016},
  volume={42},
  number={10},
  pages={918-940},
  abstract={While performing regression testing, an appropriate choice for test case ordering allows the tester to early discover faults in source code. To this end, test case prioritization techniques can be used. Several existing test case prioritization techniques leave out the execution cost of test cases and exploit a single objective function (e.g., code or requirements coverage). In this paper, we present a multi-objective test case prioritization technique that determines the ordering of test cases that maximize the number of discovered faults that are both technical and business critical. In other words, our new technique aims at both early discovering faults and reducing the execution cost of test cases. To this end, we automatically recover links among software artifacts (i.e., requirements specifications, test cases, and source code) and apply a metric-based approach to automatically identify critical and fault-prone portions of software artifacts, thus becoming able to give them more importance during test case prioritization. We experimentally evaluated our technique on 21 Java applications. The obtained results support our hypotheses on efficiency and effectiveness of our new technique and on the use of automatic artifacts analysis and weighting in test case prioritization.},
  keywords={Software;Fault diagnosis;Testing;Software engineering;Business;Electronic mail;Optimization;Regression testing;requirements;testing;test case prioritization},
  doi={10.1109/TSE.2015.2510633},
  ISSN={1939-3520},
  month={Oct},}@INPROCEEDINGS{6928903,
  author={Jia, Changjiang and Mei, Lijun and Chan, W.K. and Yu, Y.T. and Tse, T.H.},
  booktitle={2014 IEEE International Conference on Web Services}, 
  title={Is XML-Based Test Case Prioritization for Validating WS-BPEL Evolution Effective in Both Average and Adverse Scenarios?}, 
  year={2014},
  volume={},
  number={},
  pages={233-240},
  abstract={In real life, a tester can only afford to apply one test case prioritization technique to one test suite against a service-oriented workflow application once in the regression testing of the application, even if it results in an adverse scenario such that the actual performance in the test session is far below the average. It is unclear whether the factors of test case prioritization techniques known to be significant in terms of average performance can be extrapolated to adverse scenarios. In this paper, we examine whether such a factor or technique may consistently affect the rate of fault detection in both the average and adverse scenarios. The factors studied include prioritization strategy, artifacts to provide coverage data, ordering direction of a strategy, and the use of executable and non-executable artifacts. The results show that only a minor portion of the 10 studied techniques, most of which are based on the iterative strategy, are consistently effective in both average and adverse scenarios. To the best of our knowledge, this paper presents the first piece of empirical evidence regarding the consistency in the effectiveness of test case prioritization techniques and factors of service-oriented workflow applications between average and adverse scenarios.},
  keywords={Testing;XML;Fault detection;Web services;Educational institutions;Indexes;Cities and towns;XML-based factor;WS-BPEL;adaptation;adverse},
  doi={10.1109/ICWS.2014.43},
  ISSN={},
  month={June},}@INPROCEEDINGS{6895426,
  author={Hettiarachchi, Charitha and Do, Hyunsook and Choi, Byoungju},
  booktitle={2014 Eighth International Conference on Software Security and Reliability (SERE)}, 
  title={Effective Regression Testing Using Requirements and Risks}, 
  year={2014},
  volume={},
  number={},
  pages={157-166},
  abstract={The use of system requirements and their risks enables software testers to identify more important test cases that can reveal faults associated with risky components. Having identified those test cases, software testers can manage the testing schedule more effectively by running such test cases earlier so that they can fix faults sooner. Some work in this area has been done, but the previous approaches and studies have some limitations, such as an improper use of requirements risks in prioritization and an inadequate evaluation method. To address the limitations, we implemented a new requirements risk-based prioritization technique and evaluated it considering whether the proposed approach can detect faults earlier overall. It can also detect faults associated with risky components earlier. Our results indicate that the proposed approach is effective for detecting faults early and even better for finding faults associated with risky components of the system earlier than the existing techniques.},
  keywords={Software;Testing;Mathematical model;Complexity theory;Equations;Security;Measurement;regression testing;requirements risks-based testing;test case prioritization;empirical study},
  doi={10.1109/SERE.2014.29},
  ISSN={},
  month={June},}@INPROCEEDINGS{9825849,
  author={Birchler, Christian and Ganz, Nicolas and Khatiri, Sajad and Gambi, Alessio and Panichella, Sebastiano},
  booktitle={2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Cost-effective Simulation-based Test Selection in Self-driving Cars Software with SDC-Scissor}, 
  year={2022},
  volume={},
  number={},
  pages={164-168},
  abstract={Simulation platforms facilitate the continuous development of complex systems such as self-driving cars (SDCs). However, previous results on testing SDCs using simulations have shown that most of the automatically generated tests do not strongly contribute to establishing confidence in the quality and reliability of the SDC. Therefore, those tests can be characterized as “uninformative”, and running them generally means wasting precious computational resources. We address this issue with SDC-Scissor, a framework that leverages Machine Learning to identify simulation-based tests that are unlikely to detect faults in the SDC software under test and skip them before their execution. Consequently, by filtering out those tests, SDC-Scissor reduces the number of long-running simulations to execute and drastically increases the cost-effectiveness of simulation-based testing of SDCs software. Our evaluation concerning two large datasets and around 12'000 tests showed that SDC-Scissor achieved a higher classification F1-score (between 47% and 90%) than a randomized baseline in identifying tests that lead to a fault and reduced the time spent running uninformative tests (speedup between 107% and 170%). Webpage & Video: https://github.com/ChristianBirchler/sdc-scissor},
  keywords={Fault diagnosis;Filtering;Computational modeling;Transportation;Machine learning;Feature extraction;Software;Self-driving cars;Software Simulation;Regression Testing;Test Case Selection;Continuous Integration},
  doi={10.1109/SANER53432.2022.00030},
  ISSN={1534-5351},
  month={March},}@INPROCEEDINGS{6595798,
  author={Alves, Everton L. G. and Machado, Patricia D. L. and Massoni, Tiago and Santos, Samuel T. C.},
  booktitle={2013 8th International Workshop on Automation of Software Test (AST)}, 
  title={A refactoring-based approach for test case selection and prioritization}, 
  year={2013},
  volume={},
  number={},
  pages={93-99},
  abstract={Refactoring edits, commonly applied during software development, may introduce faults in a previously-stable code. Therefore, regression testing is usually applied to check whether the code maintains its previous behavior. In order to avoid rerunning the whole regression suite, test case prioritization techniques have been developed to order test cases for earlier achievement of a given goal, for instance, improving the rate of fault detection during regression testing execution. However, as current techniques are usually general purpose, they may not be effective for early detection of refactoring faults. In this paper, we propose a refactoring-based approach for selecting and prioritizing regression test cases, which specializes selection/prioritization tasks according to the type of edit made. The approach has been evaluated through a case study that compares it to well-known prioritization techniques by using a real open-source Java system. This case study indicates that the approach can be more suitable for early detection of refactoring faults when comparing to the other prioritization techniques.},
  keywords={Testing;Java;Fault detection;Software;Object oriented modeling;Measurement;Debugging},
  doi={10.1109/IWAST.2013.6595798},
  ISSN={},
  month={May},}@INPROCEEDINGS{7589824,
  author={Jiang, Bo and Chan, W.K.},
  booktitle={2016 IEEE International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Testing and Debugging in Continuous Integration with Budget Quotas on Test Executions}, 
  year={2016},
  volume={},
  number={},
  pages={439-447},
  abstract={In Continuous Integration, a software application is developed through a series of development sessions, each with limited time allocated to testing and debugging on each of its modules. Test Case Prioritization can help execute test cases with higher failure estimate earlier in each session. When the testing time is limited, executing such prioritized test cases may only produce partial and prioritized execution coverage data. To identify faulty code, existing Spectrum-Based Fault Localization techniques often use execution coverage data but without the assumption of execution coverage priority. Is it possible to decompose these two steps for optimization within individual steps? In this paper, we study to what extent the selection of test case prioritization techniques may reduce its influence on the effectiveness of spectrum-based fault localization, thereby showing the possibility to decompose the process of continuous integration for optimization in workflow steps. We present a controlled experiment using the Siemens suite as subjects, nine test case prioritization techniques and four spectrum-based fault localization techniques. The findings showed that the studied test cases prioritization and spectrum-based fault localization can be customized separately, and, interestingly, prioritization over a smaller test suite can enable spectrum-based fault localization to achieve higher accuracy by assigning faulty statements with higher ranks.},
  keywords={Measurement;Testing;Clustering algorithms;Debugging;Computer bugs;Fault diagnosis;Optimization;continuous integration;fault localization;test case prioritization;regression testing;debugging;standardization},
  doi={10.1109/QRS.2016.66},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7091286,
  author={Kwon, Jung-Hyun and Ko, In-Young and Rothermel, Gregg and Staats, Matt},
  booktitle={2014 21st Asia-Pacific Software Engineering Conference}, 
  title={Test Case Prioritization Based on Information Retrieval Concepts}, 
  year={2014},
  volume={1},
  number={},
  pages={19-26},
  abstract={In regression testing, running all a system's test cases can require a great deal of time and resources. Test case prioritization (TCP) attempts to schedule test cases to achieve goals such as higher coverage or faster fault detection. While code coverage-based approaches are typical in TCP, recent work has explored the use of additional information to improve effectiveness. In this work, we explore the use of Information Retrieval (IR) techniques to improve the effectiveness of TCP, particularly for testing infrequently tested code. Our approach considers the frequency at which elements have been tested, in additional to traditional coverage information, balancing these factors using linear regression modeling. Our empirical study demonstrates that our approach is generally more effective than both random and traditional code coverage-based approaches, with improvements in rate of fault detection of up to 4.7%.},
  keywords={Testing;Fault detection;Training;Java;Mathematical model;Linear regression;Information retrieval},
  doi={10.1109/APSEC.2014.12},
  ISSN={1530-1362},
  month={Dec},}@INPROCEEDINGS{8377661,
  author={Jiang, Bo and Wu, Yu and Zhang, Yongfei and Zhang, Zhenyu and Chan, W.K.},
  booktitle={2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={ReTestDroid: Towards Safer Regression Test Selection for Android Application}, 
  year={2018},
  volume={01},
  number={},
  pages={235-244},
  abstract={Mobile applications are widely used in our daily life and Android is the most popular open source mobile operating system. Because mobile applications update frequently, it is important developers to perform regression testing to ensure their quality. Modeling the control flow of an android application based on the activity lifecycle model only is imprecise for regression testing. Because many Android applications use asynchronous tasks, fragments, and native code frequently, which must be considered during change impact analysis. Otherwise, regression test selection techniques may miss some failure-revealing test cases, compromising the safety of these techniques. In this work, we propose a novel approach to model asynchronous task invocations, fragment-based activity lifecycle, and native code within the control flow graph of an Android application. Furthermore, we designed a regression test selection tool ReTestDroid based on our graph model. Our experiments on five real-life Android applications showed that our approach could enable much safer regression test selection while significantly saving regression-testing time.},
  keywords={Androids;Humanoid robots;Testing;Flow graphs;Smart phones;Mobile applications;Task analysis;Test Case Selection, Android, Regression Testing, Impact Analysis},
  doi={10.1109/COMPSAC.2018.00037},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{6606565,
  author={Zhang, Lingming and Hao, Dan and Zhang, Lu and Rothermel, Gregg and Mei, Hong},
  booktitle={2013 35th International Conference on Software Engineering (ICSE)}, 
  title={Bridging the gap between the total and additional test-case prioritization strategies}, 
  year={2013},
  volume={},
  number={},
  pages={192-201},
  abstract={In recent years, researchers have intensively investigated various topics in test-case prioritization, which aims to re-order test cases to increase the rate of fault detection during regression testing. The total and additional prioritization strategies, which prioritize based on total numbers of elements covered per test, and numbers of additional (not-yet-covered) elements covered per test, are two widely-adopted generic strategies used for such prioritization. This paper proposes a basic model and an extended model that unify the total strategy and the additional strategy. Our models yield a spectrum of generic strategies ranging between the total and additional strategies, depending on a parameter referred to as the p value. We also propose four heuristics to obtain differentiated p values for different methods under test. We performed an empirical study on 19 versions of four Java programs to explore our results. Our results demonstrate that wide ranges of strategies in our basic and extended models with uniform p values can significantly outperform both the total and additional strategies. In addition, our results also demonstrate that using differentiated p values for both the basic and extended models with method coverage can even outperform the additional strategy using statement coverage.},
  keywords={Fault detection;Measurement;Java;Testing;Arrays;Software;Educational institutions},
  doi={10.1109/ICSE.2013.6606565},
  ISSN={1558-1225},
  month={May},}@INPROCEEDINGS{10336260,
  author={Zhao, Yifan and Hao, Dan and Zhang, Lu},
  booktitle={2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Revisiting Machine Learning based Test Case Prioritization for Continuous Integration}, 
  year={2023},
  volume={},
  number={},
  pages={232-244},
  abstract={To alleviate the cost of regression testing in continuous integration (CI), a large number of machine learning-based (ML-based) test case prioritization techniques have been proposed. However, it is yet unknown how they perform under the same experimental setup, because they are evaluated on different datasets with different metrics. To bridge this gap, we conduct the first comprehensive study on these ML-based techniques in this paper. We investigate the performance of 11 representative ML-based prioritization techniques for CI on 11 open-source subjects and obtain a series of findings. For example, the performance of the techniques changes across CI cycles, mainly resulting from the changing amount of training data, instead of code evolution and test removal/addition. Based on the findings, we give some actionable suggestions on enhancing the effectiveness of ML-based techniques, e.g., pretraining a prioritization technique with cross-subject data to get it thoroughly trained and then finetuning it with within-subject data dramatically improves its performance. In particular, the pretrained MART achieves state-of-the-art performance, producing the optimal sequence on 80% subjects, while the existing best technique, the original MART, only produces the optimal sequence on 50% subjects.},
  keywords={Measurement;Bridges;Software maintenance;Costs;Codes;Training data;Machine learning;test prioritization;machine learning;continuous integration},
  doi={10.1109/ICSME58846.2023.00032},
  ISSN={2576-3148},
  month={Oct},}@ARTICLE{10478254,
  author={Laaber, Christoph and Yue, Tao and Ali, Shaukat},
  journal={IEEE Transactions on Software Engineering}, 
  title={Evaluating Search-Based Software Microbenchmark Prioritization}, 
  year={2024},
  volume={50},
  number={7},
  pages={1687-1703},
  abstract={Ensuring that software performance does not degrade after a code change is paramount. A solution is to regularly execute software microbenchmarks, a performance testing technique similar to (functional) unit tests, which, however, often becomes infeasible due to extensive runtimes. To address that challenge, research has investigated regression testing techniques, such as test case prioritization (TCP), which reorder the execution within a microbenchmark suite to detect larger performance changes sooner. Such techniques are either designed for unit tests and perform sub-par on microbenchmarks or require complex performance models, drastically reducing their potential application. In this paper, we empirically evaluate single- and multi-objective search-based microbenchmark prioritization techniques to understand whether they are more effective and efficient than greedy, coverage-based techniques. For this, we devise three search objectives, i.e., coverage to maximize, coverage overlap to minimize, and historical performance change detection to maximize. We find that search algorithms (SAs) are only competitive with but do not outperform the best greedy, coverage-based baselines. However, a simple greedy technique utilizing solely the performance change history (without coverage information) is equally or more effective than the best coverage-based techniques while being considerably more efficient, with a runtime overhead of less than $1$1%. These results show that simple, non-coverage-based techniques are a better fit for microbenchmarks than complex coverage-based techniques.},
  keywords={Benchmark testing;Software;Search problems;Runtime;Source coding;Java;Software measurement;Software microbenchmarking;performance testing;JMH;search-based software engineering;multi-objective optimization;regression testing;test case prioritization},
  doi={10.1109/TSE.2024.3380836},
  ISSN={1939-3520},
  month={July},}@INPROCEEDINGS{8719502,
  author={Jung, Pilsu and Kang, Sungwon and Lee, Jihyun and Park, Taehyun},
  booktitle={2018 25th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Automated Code-Based Test Selection for Software Product Line Regression Testing}, 
  year={2018},
  volume={},
  number={},
  pages={663-667},
  abstract={Regression testing for software product line (SPL) is challenging and can be expensive because it must ensure that all the products of a product family are correct whenever changes are made. SPL regression testing can be made efficient by selecting only the test cases that are relevant to the changes. In the past, some approaches for SPL test case selection have been proposed. However, they require requirements specification, architecture and/or traceabilities for test cases that are well managed for selecting test cases for a retest. In this paper, we propose an automated method of source code-based regression test selection for SPLs that selects regression tests, based on the commonality and variability of a product family while leaving out the test cases not affected by the changes to the source code. Preliminary evaluation of our method using five product lines shows that our method reduces without missing any fault-revealing test cases the number of test cases for a retest by 22.4%, 13.4% and 20.4%, on average, compared to, respectively, the retest-all method, the random selection method and the complete selection method.},
  keywords={Testing;Software product lines;Computer architecture;Software maintenance;Computer aided software engineering;Product Lines Testing;Regression Test Selection;Software Maintenance;Software Evolution},
  doi={10.1109/APSEC.2018.00086},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{10304799,
  author={Wang, Dingbang and Zhao, Yu and Xiao, Lu and Yu, Tingting},
  booktitle={2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)}, 
  title={An Empirical Study of Regression Testing for Android Apps in Continuous Integration Environment}, 
  year={2023},
  volume={},
  number={},
  pages={1-11},
  abstract={Continuous integration (CI) has become a popular method for automating code changes, testing, and software project delivery. However, sufficient testing prior to code submission is crucial to prevent build breaks. Additionally, testing must provide developers with quick feedback on code changes, which requires fast testing times. While regression test selection (RTS) has been studied to improve the cost-effectiveness of regression testing for lower-level tests (i.e., unit tests), it has not been applied to the testing of user interfaces (UI) in application domains such as mobile apps. UI testing at the UI level requires different techniques such as impact analysis and automated test execution. In this paper, we examine the use of RTS in CI settings for UI testing across various open-source mobile apps. Our analysis focuses on using Frequency Analysis to understand the need for RTS, Cost Analysis to evaluate the cost of impact analysis and test case selection algorithms, and Test Reuse Analysis to determine the reusability of UI test sequences for automation. The insights from this study will guide practitioners and researchers in developing advanced RTS techniques that can be adapted to CI environments for mobile apps.},
  keywords={Codes;Automation;User interfaces;Software;Mobile applications;Software measurement;Cost benefit analysis;Regression testing;Android apps;Empirical study},
  doi={10.1109/ESEM56168.2023.10304799},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10675987,
  author={Balink, Robert and Wendland, Marc-Florian and Yevstihnyeyev, Yuriy},
  booktitle={2024 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Selecting “good” regression tests based on a classification of side-effects}, 
  year={2024},
  volume={},
  number={},
  pages={309-317},
  abstract={When software systems undergo modifications, regression testing is a prominent risk mitigation technique to safeguard the quality of actually unmodified parts of that system. Being a change-based test type, regression tests should ideally be automatically executed as often as modifications happen to the system. When regression testing takes too long to be executed in its entirety, a selection has to be done to execute only those regression tests that safeguard the unmodified parts of the system the best. The potential to detect side-effects is associated to the type of modification made to the system and varies among regression tests. A selection algorithm must be able to identify “good” regression tests according to the modifications made. A “good” regression test is a regression test that has a higher capability to detect probable unwanted side-effects of a modification. This paper introduces a novel approach to regression test selection based on classification of side-effects and quantification of the side-effect detection potential of each regression test. Two approaches to regression test selection are described. Both approaches were implemented by a prototype and integrated into the CI/CD pipeline of the industrial software system Vaadin. Eventually, the effectiveness of the selection approach is evaluated.},
  keywords={Software testing;Correlation;Instruments;Conferences;Pipelines;Prototypes;Software systems;quality assurance;software testing;regression testing;test case selection},
  doi={10.1109/ICSTW60967.2024.00061},
  ISSN={2159-4848},
  month={May},}@INPROCEEDINGS{10011478,
  author={Altiero, Francesco and Colella, Giovanni and Corazza, Anna and Di Martino, Sergio and Peron, Adriano and Starace, Luigi L. L.},
  booktitle={2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Change-Aware Regression Test Prioritization using Genetic Algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={125-132},
  abstract={Regression testing is a practice aimed at providing confidence that, within software maintenance, the changes in the code base have introduced no faults in previously validated functionalities. With the software industry shifting towards iterative and incremental development with shorter release cycles, the straightforward approach of re-executing the entire test suite on each new version of the software is often unfeasible due to time and resource constraints. In such scenarios, Test Case Prioritization (TCP) strategies aim at providing an effective ordering of the test suite, so that the tests that are more likely to expose faults are executed earlier and fault detection is maximised even when test execution needs to be abruptly terminated due to external constraints. In this work, we propose Genetic-Diff, a TCP strategy based on a genetic algorithm featuring a specifically-designed crossover operator and a novel objective function that combines code coverage metrics with an analysis of changes in the code base. We empirically evaluate the proposed algorithm on several releases of three heterogeneous real-world, open source Java projects, in which we artificially injected faults, and compare the results with other state-of-the-art TCP techniques using fault-detection rate metrics. Findings show that the proposed technique performs generally better than the baselines, especially when there is a limited amount of code changes, which is a common scenario in modern development practices.},
  keywords={Measurement;Software maintenance;Codes;Software algorithms;Software systems;Linear programming;Time factors;Regression Testing;Test Case Prioritization;Genetic Algorithms},
  doi={10.1109/SEAA56994.2022.00028},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9260075,
  author={Shi, Tingting and Xiao, Lei and Wu, Keshou},
  booktitle={2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Reinforcement Learning Based Test Case Prioritization for Enhancing the Security of Software}, 
  year={2020},
  volume={},
  number={},
  pages={663-672},
  abstract={In order to enhance the security of software, each system update needs to perform regression test. Regression testing in a continuous integration environment requires test cases to meet the needs of rapid feedback. Therefore, it is necessary to enable test cases to be effectively sorted within a certain time range so that more failure data could be discovered and the fault detection rate of testing could be improved. Reinforcement learning algorithms interact with the environment, so it is viable to optimize the sorting problem of test case in the process of continuous integration through a reward mechanism. In the development environment of continuous integration, it has been experimentally proven that the execution history of test cases in the last four cycles has a greater impact on the sorting of test cases in the current cycle. Therefore, a new RHE reward function was put forward by using part of weighted information obtained from historical execution result for enhancing the security of the system. Taking the influence of execution time into account, the multi-target sequencing technology for test case is employed with a view to improving the efficiency of defect discovery. It has been found by applying this sorting method to three industrial testing research that: (1) compared with weighted reward function based on the entire historical execution information, the function based on the four historical execution information had a higher capability of detecting faults; (2) The reward function obtained from the weighted historical results could effectively improve the fault detection rate and reduce the time consumed. (3) The multi-objective sorting methods taking execution time into consideration was able to maximize the number of testing cases that had already discovered faults within the available time.},
  keywords={Testing;Reinforcement learning;Sorting;Software;History;Erbium;Security;continuous integration;reinforcement learning;fault detection rate;reward function;historical execution information;multi-objective sorting},
  doi={10.1109/DSAA49011.2020.00076},
  ISSN={},
  month={Oct},}@ARTICLE{9534659,
  author={Mondal, Shouvick and Nasre, Rupesh},
  journal={IEEE Transactions on Software Engineering}, 
  title={${{\sf Colosseum}}$Colosseum: Regression Test Prioritization by Delta Displacement in Test Coverage}, 
  year={2022},
  volume={48},
  number={10},
  pages={4060-4073},
  abstract={The problem of test-case prioritization has been pursued for over three decades now and continues to be one of the active topics in software testing research. In this paper, we focus on a code-coverage based regression test-prioritization solution (${{\sf Colosseum}}$Colosseum) that takes into account the position of changed (delta) code elements (basic-blocks) along the loop-free straight-line execution path of the regression test-cases. We propose a heuristic that logically associates each of these paths with three parameters: (i) the offset (displacement a) of the first delta from the starting basic-block, (ii) the offset (displacement c) of the last delta from the terminating basic block, and (iii) the average scattering (displacement b) within all the intermediate basic-blocks. We hypothesize that a regression test-case path with a shorter overall displacement has a good chance of propagating the affects of the code-changes to the observable outputs in the program. ${{\sf Colosseum}}$Colosseum prioritizes test-cases with smaller overall displacements and executes them early in the regression test-execution cycle. The underlying intuition is that the probability of a test-case revealing a regression fault depends on the probability of the corresponding change propagation. The change in this context can potentially lead to an error. Extending this logic, delta displacement provides an approximation to failed error propagation. Evaluation on 20 open-source C projects from the Software-artifact Infrastructure Repository and GitHub (totaling: 694,512 SLOC, 280 versions, and 69,305 test-cases) against four state-of-the-art prioritizations reveals that: ${{\sf Colosseum}}$Colosseum outperforms the competitors with an overall 84.61% success in terms of 13 prioritization effectiveness metrics, majority of which prefer to execute top-$k\%$k% prioritized test-cases.},
  keywords={Codes;Scattering;Logic gates;Task analysis;Software testing;Open source software;Maintenance engineering;Test-case prioritization;regression testing;code-change displacement;priority distribution;queue interleaving},
  doi={10.1109/TSE.2021.3111169},
  ISSN={1939-3520},
  month={Oct},}@INPROCEEDINGS{10186478,
  author={Shang, Ying and Li, Qianyu and Yang, Yang and Li, Zheng},
  booktitle={2020 IEEE/ACM International Conference on Software and System Processes (ICSSP)}, 
  title={Occurrence Frequency and All Historical Failure Information Based Method for TCP in CI}, 
  year={2020},
  volume={},
  number={},
  pages={105-114},
  abstract={In continuous integration (CI) environments, the program is rapidly and frequently modified and integrated. This feature introduces significant challenges to testing processes conducted in these environments. Based on existing technology, a test case that fails frequently is likely to fail in future tests. Therefore, the historical execution results of test cases are essential to guide the test case prioritization (TCP) in the CI environment. Reinforcement learning involves solving sequential decision-making problems and is suitable for TCP in the CI environment. At present, most of the TCP techniques based on reinforcement learning rely on the current cycle historical failure information of test cases. They rarely consider more historical cycle information, as well as other influencing factors. In this paper, we discussed the occurrence frequency of test cases for the first time. We also considered all historical information of each test case and proposed three new reward function, which employs the percentage of historical failure and the failure distribution of test cases, which can guide the reinforcement learning process. We evaluate our method on five industrial data sets. The experimental results show that our method can effectively prioritize test cases and improve the cost-effectiveness of the CI process.},
  keywords={Time-frequency analysis;Decision making;Reinforcement learning;Software;Testing;Continuous Integration;Test Case Prioritization;Regression Testing;Reinforcement Learning;Historical Failure Information;Occurrence Frequency},
  doi={},
  ISSN={},
  month={June},}@INPROCEEDINGS{8914670,
  author={Silva, Dennis Sávio and Rabelo, Ricardo and Neto, Pedro Santos and Britto, Ricardo and Oliveira, Pedro Almir},
  booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)}, 
  title={A Test Case Prioritization Approach Based on Software Component Metrics}, 
  year={2019},
  volume={},
  number={},
  pages={2939-2945},
  abstract={The most common way of performing regression testing is by executing all test cases associated with a software system. However, this approach is not scalable since time and cost to execute the test cases increase together with the system’s size. A way to address this consists of prioritizing the existing test cases, aiming to maximize a test suite’s fault detection rate. To address the limitations of existing approaches, in this paper we propose a new approach to maximize the rate of fault detection of test suites. Our proposal has three steps: i) infer code components’ criticality values using a fuzzy inference system; ii) calculate test cases’ criticality; iii) prioritize the test cases using ant colony optimization. The test cases are prioritized considering criticality, execution time and history of faults, and the resulting test suites are evaluated according to their fault detection rate. The evaluation was performed in eight programs, and the results show that the fault detection rate of the solutions was higher than in the non-ordered test suites and ones obtained using a greedy approach, reaching the optimal value when possible to verify. A sanity check was performed, comparing the obtained results to the results of a random search. The approach performed better at significant levels of statistic and practical difference, evidencing its true applicability to the prioritization of test cases.},
  keywords={Fault detection;Testing;Software;Fuzzy logic;Measurement;History;Fuzzy sets},
  doi={10.1109/SMC.2019.8914670},
  ISSN={2577-1655},
  month={Oct},}@ARTICLE{10898156,
  author={Li, Tao and Cui, Chenhui and Xu, Yinyin and Huang, Rubing},
  journal={IEEE Transactions on Reliability}, 
  title={Applying Lexicographical Ordering to Software Product Line Testing}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Test case prioritization (TCP) has been widely used in software testing, which aims to execute test cases that are more likely to detect faults earlier than others. Among many proposed TCP approaches, lexicographical ordering-based TCP (LO-TCP) can effectively resolve ties encountered in the prioritization process, leading to better performance than original TCP approaches. However, the current LO-TCP needs to use the white-box information such as the code coverage of the program under test, which may be infeasible in some black-box testing applications such as software product lines (SPLs). In this article, we transfer the traditional LO-TCP to SPL testing by leveraging test configuration coverage instead of code coverage, and also empirically conduct some simulations and evaluate the large-scale real-world programs with real faults. The experimental results show that LO-TCP can have better performance for testing SPLs, as compared with traditional TCP approaches.},
  keywords={Vectors;Testing;Indexes;Time complexity;Glass box;Frequency modulation;Computer science;Codes;Fault diagnosis;Closed box;Lexicographical ordering (LO);regression testing;software product lines (SPL);software testing;test case prioritization (TCP)},
  doi={10.1109/TR.2025.3540479},
  ISSN={1558-1721},
  month={},}@INPROCEEDINGS{10011511,
  author={Siqueira, Vinicius and Miranda, Breno},
  booktitle={2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Investigating the Adoption of History-based Prioritization in the Context of Manual Testing in a Real Industrial Setting}, 
  year={2022},
  volume={},
  number={},
  pages={141-148},
  abstract={Many test case prioritization techniques have been proposed with the ultimate goal of speeding up fault detection. History-based prioritization, in particular, has been shown to be an effective strategy. Most of the empirical studies conducted on this topic, however, have focused on the context of automated testing. Investigating the effectiveness of history-based prioritization in the context of manual testing is important because, despite the popularity of automated approaches, manual testing is still largely adopted in industry. In this work we propose two history-based prioritization heuristics and evaluate them in the context of manual testing in a real industrial setting. For our evaluation we collected historical test execution information for 23 products, spanning over seven years of historical information, accounting for a total of 2,352 unique test cases and 3,993,863 test results. The results of our experiments showed that the effectiveness of the proposed approach is not far from a theoretical optimal prioritization, and that they are significantly better than alternative orderings of the test suite, including the order suggested by the test management tool and the execution order followed by the testers during the real execution of the test suites evaluated as part of our study.},
  keywords={Industries;Fault detection;Manuals;Testing;Software engineering;regression testing;test case prioritization;history-based prioritization;manual testing},
  doi={10.1109/SEAA56994.2022.00030},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{6724206,
  author={Ansari, Ahlam S. A. and Devadkar, Kailas K. and Gharpure, Prachi},
  booktitle={2013 IEEE International Conference on Computational Intelligence and Computing Research}, 
  title={Optimization of test suite-test case in regression test}, 
  year={2013},
  volume={},
  number={},
  pages={1-4},
  abstract={Exhaustive product evolution and testing is required to ensure the quality of product. Regression testing is crucial to ensure software excellence. Regression test cases are applied to assure that new or adapted features do not relapse the existing features. As innovative features are included, new test cases are generated to assess the new functionality, and then included in the existing pool of test cases, thus escalating the cost and the time required in performing regression test and this unswervingly impacts the release, laid plan and the quality of the product. Hence there is a need to select minimal test cases that will test all the functionalities of the engineered product and it must rigorously test the functionalities that have high risk exposure. Test Suite-Test Case Refinement Technique will reduce regression test case pool size, reduce regression testing time, cost & effort and also ensure the quality of the engineered product. This technique is a regression test case optimization technique that is a hybrid of Test Case Minimization based on specifications and Test Case Prioritization based on risk exposure. This approach will facilitate achievement of quality product with decreased regression testing time and cost yet uncover same amount of errors as the original test cases.},
  keywords={Minimization;Testing;Software;Conferences;Fault detection;Optimization;Software reliability;Test Case Optimization;Regression Test;Test Suite Prioritization;Test Suite Minimization;Risk Based Prioritization;Specification Based Selection},
  doi={10.1109/ICCIC.2013.6724206},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10877022,
  author={Moubayed, Abdallah and Alhindawi, Nouh and Alsakran, Jamal and Injadat, MohammadNoor and Kanan, Mohammad},
  booktitle={2024 25th International Arab Conference on Information Technology (ACIT)}, 
  title={A Data-Driven Approach Towards Software Regression Testing Quality Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Software testing is very important in software development to ensure its quality and reliability. As software systems have become more complex, the number of test cases has increased, which presents the challenge of executing all the tests in a limited time frame. Various test case prioritization techniques have been introduced to solve this problem. These methods aim to identify and implement the most critical tests first. In this paper, we propose an implementation of a dynamic test case prioritization strategy to improve software quality by increasing code coverage with special attention to edge case handling. Edge case test prioritization is a technique that improves test efficiency by selecting extreme case scenarios that can reveal critical bugs or unexpected behavior early in development, improving overall software reliability and dependability. In order to prioritize test cases, this paper presents a regression-based method that makes use of machine learning algorithms. The approach leverages previous performance data to optimize regression testing efficiency by examining variables like test time and execution status. Performance evaluations, when compared against industry standards and cutting-edge techniques, show how effective these algorithms are at correctly prioritizing test cases and identifying faults. This study offers simplified yet reliable solutions for regression testing optimization by shedding light on the efficacy of regression algorithms, such as Random Forest and decision trees.},
  keywords={Software testing;Machine learning algorithms;Software algorithms;Software quality;Software systems;Software reliability;Regression tree analysis;Optimization;Standards;Software development management;Software Testing Optimization;Machine Learning;Natural Language Processing},
  doi={10.1109/ACIT62805.2024.10877022},
  ISSN={2831-4948},
  month={Dec},}@INPROCEEDINGS{7724443,
  author={Dhareula, Priyanka and Ganpati, Anita},
  booktitle={2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Identification of attributes for test case reusability in regression test selection techniques}, 
  year={2016},
  volume={},
  number={},
  pages={1144-1147},
  abstract={Regression testing is done after needful changes, ensuring that changes are working as required and does not produce unexpected results for a system under test. Regression testing encounters a significant difficulty of determining the relevant subgroup of test cases for reusability in regression test case selection. This paper performs an exploratory study of Regression Test Selection (RTS) techniques to identify the attributes of test cases for reusability. As the result of this study, the techniques have been categorized under two broad groups' i.e. code-based techniques and requirement based techniques. Further, the attributes for reusability of test cases are identified for code based and requirement based techniques. The study also center around the levels of test granularity for code based techniques used in regression test case selection i.e. fine granularity and coarse granularity. The study revealed that there exists a trade-off between the cost and level of granularity for test case effectiveness.},
  keywords={Testing;Software;Unified modeling language;History;Conferences;Algorithm design and analysis;Software algorithms;Regression testing;reusability;selection techniques;test case},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{6823886,
  author={Groce, Alex and Alipour, Mohammed Amin and Zhang, Chaoqiang and Chen, Yang and Regehr, John},
  booktitle={2014 IEEE Seventh International Conference on Software Testing, Verification and Validation}, 
  title={Cause Reduction for Quick Testing}, 
  year={2014},
  volume={},
  number={},
  pages={243-252},
  abstract={In random testing, it is often desirable to produce a "quick test" -- an extremely inexpensive test suite that can serve as a frequently applied regression and allow the benefits of random testing to be obtained even in very slow or over-subscribed test environments. Delta debugging is an algorithm that, given a failing test case, produces a smaller test case that also fails, and typically executes much more quickly. Delta debugging of random tests can produce effective regression suites for previously detected faults, but such suites often have little power for detecting new faults, and in some cases provide poor code coverage. This paper proposes extending delta debugging by simplifying tests with respect to code coverage, an instance of a generalization of delta debugging we call cause reduction. We show that test suites reduced in this fashion can provide very effective quick tests for real-world programs. For Mozilla's Spider Monkey JavaScript engine, the reduced suite is more effective for finding software faults, even if its reduced runtime is not considered. The effectiveness of a reduction-based quick test persists through major changes to the software under test.},
  keywords={Testing;Debugging;Computer bugs;Fault detection;Hardware;Minimization;Educational institutions;random testing;test case minimization;regression testing},
  doi={10.1109/ICST.2014.37},
  ISSN={2159-4848},
  month={March},}@INPROCEEDINGS{7507977,
  author={Nayak, Soumen and Kumar, Chiranjeev and Tripathi, Sachin},
  booktitle={2016 3rd International Conference on Recent Advances in Information Technology (RAIT)}, 
  title={Effectiveness of prioritization of test cases based on Faults}, 
  year={2016},
  volume={},
  number={},
  pages={657-662},
  abstract={Regression testing (RT) is an expensive activity. It is applied on a modified program to enhance confidence and reliability by ensuring that the changes are accurately true and have not affected the unmodified portions of the SUT. Due to limited resources, it is not practical to re-run each test cases (TC). To improve the regression testing's effectiveness, the TCs should be arranged according to some objective function or criteria. Test case prioritization (TCP) arranges TCs in an order for execution that enhances their effectiveness by satisfying some testing goals. The highest priority assigned to TCs must execute before the TCs with low priority by virtue of some performance goal. Numerous goals are possible to achieve of which one such goal is rate of fault detection (RFT) in which the faults are surfaced as quickly as possible within the testing process. In this paper, a novel technique is suggested to prioritize the TCs that increase its effectiveness in detecting faults. The effectiveness of the proposed method is compared and matched with other prioritization approaches with the help of Average Percentage of Fault Detection (APFD) metric from which charts have been prepared.},
  keywords={Measurement;Software;Algorithm design and analysis;Information technology;Fault detection;Software testing;Regression Testing;TCP;APFD;Severity of Faults},
  doi={10.1109/RAIT.2016.7507977},
  ISSN={},
  month={March},}@INPROCEEDINGS{8305938,
  author={Kwon, Jung-Hyun and Ko, In-Young},
  booktitle={2017 24th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Cost-Effective Regression Testing Using Bloom Filters in Continuous Integration Development Environments}, 
  year={2017},
  volume={},
  number={},
  pages={160-168},
  abstract={Regression testing in continuous integration development environments must be cost-effective and should provide fast feedback on test suite failures to the developers. In order to provide faster feedback on failures to developers while using computing resources efficiently, two types of regression testing techniques have been developed: Regression Testing Selection (RTS) and Test Case Prioritization (TCP). One of the factors that reduces the effectiveness of the RTS and TCP techniques is the inclusion of test suites that fail only once over a period. We propose an approach based on Bloom filtering to exclude such test suites during the RTS process, and to assign such test suites with a lower priority during the TCP process. We experimentally evaluate our approach using a Google dataset, and demonstrate that cost-effectiveness of the proposed RTS and TCP techniques outperforms the state-of-the-art techniques.},
  keywords={Testing;Microsoft Windows;Google;Instruments;History;Fault detection},
  doi={10.1109/APSEC.2017.22},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7100474,
  author={Vedpal and Chauhan, Naresh},
  booktitle={2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Regression test selection for object oriented systems using OPDG and slicing technique}, 
  year={2015},
  volume={},
  number={},
  pages={1372-1378},
  abstract={Regression testing is a selective retesting of software whenever software gets modified or some new functionality is added to it. In this paper a regression test case selection technique is proposed. This technique is based on identification of affected paths, affected functions and dynamic slicing which can be used to reduce the number of test cases for regression testing. This paper considers all three cases of modification to object oriented programs. The proposed approach is evaluated by showing the reduction in total number of test cases to be selected. For each program to be tested, this approach focuses on finding the affected paths, affected functions and on computing the dynamic slice of modified variables. In addition this approach is also open to combine a variety of available information for selection of test cases. For analysis it is applied to the software module in C++.},
  keywords={Testing;Software;Random access memory;Maintenance engineering;Unified modeling language;Software algorithms;Electronic mail;Regression testing;test case reduction;object oriented testing},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{8453107,
  author={Kwon, Jung-Hyun and Ko, In-Young and Rothermel, Gregg},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)}, 
  title={Prioritizing Browser Environments for Web Application Test Execution}, 
  year={2018},
  volume={},
  number={},
  pages={468-479},
  abstract={When testing client-side web applications, it is important to consider different web-browser environments. Different properties of these environments such as web-browser types and underlying platforms may cause a web application to exhibit different types of failures. As web applications evolve, they must be regression tested across these different environments. Because there are many environments to consider this process can be expensive, resulting in delayed feedback about failures in applications. In this work, we propose six techniques for providing a developer with faster feedback on failures when regression testing web applications across different web-browser environments. Our techniques draw on methods used in test case prioritization; however, in our case we prioritize web-browser environments, based on information on recent and frequent failures. We evaluated our approach using four non-trivial and popular open-source web applications. Our results show that our techniques outperform two baseline methods, namely, no ordering and random ordering, in terms of the cost-effectiveness. The improvement rates ranged from -12.24% to 39.05% for no ordering, and from -0.04% to 45.85% for random ordering.},
  keywords={Browsers;Testing;History;Schedules;Optimal scheduling;Operating systems;Production;Web application testing;Regression testing;Browser environments},
  doi={10.1145/3180155.3180244},
  ISSN={1558-1225},
  month={May},}@ARTICLE{10679125,
  author={Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Seferi, Gkerta and Tauseef, Qasim},
  journal={IEEE Access}, 
  title={On the Effectiveness of Feature Selection Techniques in the Context of ML-Based Regression Test Prioritization}, 
  year={2024},
  volume={12},
  number={},
  pages={131556-131575},
  abstract={Regression testing is essential for maintaining software functionality in continuous integration (CI) systems, but it can become increasingly costly as software complexity grows. Machine learning-based Regression Test Prioritization (RTP) techniques have been developed to prioritize test cases based on their likelihood of failure, aiming to detect failures early and optimize resource use. However, the features used in the current state-of-the-art for training machine learning (ML) models often vary widely across different datasets, highlighting the need for further research to identify effective feature sets for RTP. Furthermore, the feature selection techniques are frequently biased toward specific features based on the dataset. Hence, we explored an ensemble technique to utilize three ML-based feature selection techniques in this study to identify and refine key features that enhance test case prioritization. These techniques were applied across four tree-based ML models using data from 15 large-scale open-source software projects. Our analysis identified the most compelling features for predicting failures and assessed their impact on RTP. The results showed that using a refined subset of features could achieve similar or up to a 10% increase in RTP performance, using only one-third of the original feature set. We also empirically evaluated the cost considerations when choosing the three methods and reported the ML models’ performance with the refined feature sets. This underscores the potential of integrating advanced feature selection methods into RTP processes.},
  keywords={Feature extraction;Codes;Measurement;Random forests;Principal component analysis;Predictive models;Training;Continuous integration;Machine learning;Continuous integration;feature selection;machine learning;test case prioritization},
  doi={10.1109/ACCESS.2024.3459656},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9226358,
  author={Al-Sabbagh, Khaled Walid and Staron, Miroslaw and Hebig, Regina and Meding, Wilhelm},
  booktitle={2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Improving Data Quality for Regression Test Selection by Reducing Annotation Noise}, 
  year={2020},
  volume={},
  number={},
  pages={191-194},
  abstract={Big data and machine learning models have been increasingly used to support software engineering processes and practices. One example is the use of machine learning models to improve test case selection in continuous integration. However, one of the challenges in building such models is the identification and reduction of noise that often comes in large data. In this paper, we present a noise reduction approach that deals with the problem of contradictory training entries. We empirically evaluate the effectiveness of the approach in the context of selective regression testing. For this purpose, we use a curated training set as input to a tree-based machine learning ensemble and compare the classification precision, recall, and f-score against a non-curated set. Our study shows that using the noise reduction approach on the training instances gives better results in prediction with an improvement of 37% on precision, 70% on recall, and 59% on f-score.},
  keywords={Training;Testing;Annotations;Predictive models;Noise reduction;Feature extraction;Dictionaries;Annotation Noise;Regression Testing;Machine Learning Models},
  doi={10.1109/SEAA51224.2020.00042},
  ISSN={},
  month={Aug},}@ARTICLE{8735829,
  author={Mukherjee, R. and Patnaik, K. S.},
  journal={IEEE Access}, 
  title={Prioritizing JUnit Test Cases Without Coverage Information: An Optimization Heuristics Based Approach}, 
  year={2019},
  volume={7},
  number={},
  pages={78092-78107},
  abstract={Regression testing is an expensive activity and Test Case Prioritization (TCP) acts as an improvement mechanism for it. TCP techniques for object oriented programs need attention and in our study, we explored prioritization of JUnit test cases. Ten benchmark Java programs with their several mutated versions were studied. As collecting coverage information is a costly effort, we bypassed these steps and used optimization heuristics for ordering JUnit test cases at test method level. Our approach formulated a novel fitness objective which depends on the number of modified lines executed per unit of execution time. As regression testing is performed after some modification is done on an existing program, maximizing the execution of number of modified lines is highly lucrative. The test case prioritization problem was replicated in context of 0/1 Knapsack problem and then it was solved using Genetic Algorithm (GA). Our exploration also included application of Simulated Annealing and Ant Colony Optimization method for determining the best execution ordering of test cases. We examined the usage of Multi-objective GA by building another new fitness metric which aims to maximize the number of inheritance edges covered by a test case. Results indicate the superiority of optimization heuristics over other existing approaches. It appeared that multi-objective GA yielded better result than single objective prioritization. Among the single objective techniques, ACO performed best. To the best of our knowledge, this is the first study which explored all the above mentioned optimization heuristics for ordering JUnit test cases with the newly coined fitness intents.},
  keywords={Testing;Optimization;Genetic algorithms;Java;Fault detection;Ant colony optimization;Measurement;Fault detected;fitness objective;optimization heuristics;regression testing;test method},
  doi={10.1109/ACCESS.2019.2922387},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7552005,
  author={Huang, Rubing and Zong, Weiwen and Chen, Jinfu and Towey, Dave and Zhou, Yunan and Chen, Deng},
  booktitle={2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={Prioritizing Interaction Test Suites Using Repeated Base Choice Coverage}, 
  year={2016},
  volume={1},
  number={},
  pages={174-184},
  abstract={Combinatorial interaction testing is a well-studied testing strategy that aims at constructing an effective interaction test suite (ITS) of a specific generation strength to identify interaction faults caused by the interactions among factors. Due to limited testing resources in practice, for example in combinatorial interaction regression testing, interaction test suite prioritization (ITSP) has been proposed to improve the efficiency of testing. An intuitive ITSP strategy that has been widely used in practice is fixed-strength interaction coverage based prioritization (FICBP). FICBP makes use of a property of the ITS: interaction coverage at a fixed prioritization strength. However, a challenge facing FICBP is that, when the ITS is large, the prioritization cost can be very high. In this paper, we propose a new FICBP method that, by repeatedly using base choice coverage (i.e., one-wise coverage) during the prioritization process, improves testing efficiency while maintaining testing effectiveness. The empirical studies show that our method has fault detection capability comparable to current FICBP methods, but obtains more stable results in many cases. Additionally, our method requires considerably less prioritization time than other FICBP methods at different prioritization strengths.},
  keywords={Testing;Fault detection;Time complexity;Fault diagnosis;Algorithm design and analysis;Computer science;Software;Software testing;combinatorial interaction testing;test case prioritization;fixed-strength interaction coverage based prioritization;base choice coverage},
  doi={10.1109/COMPSAC.2016.167},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{9464569,
  author={Al-Sharif, Ziad A. and Abdalrahman, Wafa F. and Jeffery, Clinton L.},
  booktitle={2021 12th International Conference on Information and Communication Systems (ICICS)}, 
  title={Encoding Test Cases using Execution Traces}, 
  year={2021},
  volume={},
  number={},
  pages={239-244},
  abstract={Test case minimization can be critical to meeting the release date of a software product. Identifying redundant test cases can help improve the quality of the test suite and speed up the testing process. Thus, there is a need to uniquely characterize test cases. This identification can support the test engineer to remove redundancy in the test suite and prioritize test cases that are highly affected by the most recent modification in source code. This paper proposes a test case encoding approach that allows engineers to facilitate execution traces to classify and identify their test cases. It will empower test engineers and allow them to minimize the time and cost of testing by reducing the number of test cases, especially in regression testing. Furthermore, it enhances the documentation of the testing process by providing a one-to-one mapping between test cases and their corresponding execution traces, each of which is a sequence of execution events triggered during the execution of the test case. The one-to-one mapping allows the approach to uniquely represent the control-flow and data-flow within the source code. This trace can be used as a signature for the test case. Whenever a modification occurred in the source code, the newly captured signatures are compared against the previous ones; any mismatch indicates that the test case has been affected by the modification. Repeating this process will help classify the test suite into four groups of test cases. This provides the ability to put the testing efforts where it is needed. Additionally, keeping a hashed value for each of the captured sequences simplifies the comparison and unifies the mapping between test cases and captured traces. It also allows detection of minor modifications in the traced events, and reduces the lengthy traces to a set of fixed size hashed values.},
  keywords={Communication systems;Automatic testing;Redundancy;Focusing;Documentation;Minimization;Software;Test Cases;Regression Testing;Execution Traces},
  doi={10.1109/ICICS52457.2021.9464569},
  ISSN={2573-3346},
  month={May},}@INPROCEEDINGS{6649874,
  author={Huang, Rubing and Chen, Jinfu and Zhang, Tao and Wang, Rongcun and Lu, Yansheng},
  booktitle={2013 IEEE 37th Annual Computer Software and Applications Conference}, 
  title={Prioritizing Variable-Strength Covering Array}, 
  year={2013},
  volume={},
  number={},
  pages={502-511},
  abstract={Combinatorial interaction testing is a well-studied testing strategy, and has been widely applied in practice. Combinatorial interaction test suite, such as fixed-strength and variable-strength interaction test suite, is widely used for combinatorial interaction testing. Due to constrained testing resources in some applications, for example in combinatorial interaction regression testing, prioritization of combinatorial interaction test suite has been proposed to improve the efficiency of testing. However, nearly all prioritization techniques may only support fixed-strength interaction test suite rather than variable-strength interaction test suite. In this paper, we propose two heuristic methods in order to prioritize variable-strength interaction test suite by taking advantage of its special characteristics. The experimental results show that our methods are more effective for variable-strength interaction test suite by comparing with the technique of prioritizing combinatorial interaction test suites according to test case generation order, the random test prioritization technique, and the fixed-strength interaction test suite prioritization technique. Besides, our methods have additional advantages compared with the prioritization techniques for fixed-strength interaction test suite.},
  keywords={Testing;Arrays;Educational institutions;Fault detection;Heuristic algorithms;Computer science;Software;Software testing;combinatorial interaction testing;test case prioritization;fixed-strength interaction test suite;variable-strength interaction test suite;algorithm},
  doi={10.1109/COMPSAC.2013.84},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{9787866,
  author={Becho, João and Cerveira, Frederico and Leitão, João and Oliveira, Rui André},
  booktitle={2022 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={TESRAC: A Framework for Test Suite Reduction Assessment at Scale}, 
  year={2022},
  volume={},
  number={},
  pages={174-184},
  abstract={Regression testing is an important task in any large software project, however as codebase increases, test suites grow and become composed of highly redundant test cases, thus greatly increasing the time required for testing. To solve this problem various test suite reduction tools have been proposed, however their absolute and relative performance are unclear to their prospective users, since there is a lack of a standardized evaluation or approach for choosing the best reduction tool. This work proposes TESRAC, a framework for assessing and comparing test suite reduction tools, which allows users to evaluate and rank a customizable set of tools in terms of reduction performance according to criteria (coverage, dimension, and execution time), and which can be configured to prioritize specific criteria. We used TESRAC to assess and compare three test suite reduction tools and one test suite prioritization tool that has been adapted to perform test suite reduction, across eleven projects of various dimensions and characteristics. Results show that a test suite prioritization tool can be adapted to perform a adequate test suite reduction, and a subset of tools outperforms the remaining tools for the majority of the projects. However, the project and test suite being reduced can have a strong impact on a tool's performance.},
  keywords={Software testing;Ports (computers);Measurement;Technological innovation;Codes;Conferences;Decision making;software testing;test suite reduction;test suite minimization;test case prioritization;evaluation},
  doi={10.1109/ICST53961.2022.00028},
  ISSN={2159-4848},
  month={April},}@ARTICLE{6812226,
  author={Mei, Lijun and Chan, W.K. and Tse, T.H. and Jiang, Bo and Zhai, Ke},
  journal={IEEE Transactions on Services Computing}, 
  title={Preemptive Regression Testingof Workflow-Based Web Services}, 
  year={2015},
  volume={8},
  number={5},
  pages={740-754},
  abstract={An external web service may evolve without prior notification. In the course of the regression testing of a workflow-based web service, existing test case prioritization techniques may only verify the latest service composition using the not-yet-executed test cases, overlooking high-priority test cases that have already been applied to the service composition before the evolution. In this paper, we propose Preemptive Regression Testing  (PRT), an adaptive testing approach to addressing this challenge. Whenever a change in the coverage of any service artifact is detected, PRT recursively preempts the current session of regression test and creates a sub-session of the current test session to assure such lately identified changes in coverage by adjusting the execution priority of the test cases in the test suite. Then, the sub-session will resume the execution from the suspended position. PRT terminates only when each test case in the test suite has been executed at least once without any preemption activated in between any test case executions. The experimental result confirms that testing workflow-based web service in the face of such changes is very challenging; and one of the PRT-enriched techniques shows its potential to overcome the challenge.},
  keywords={Testing;Web services;Electronic mail;Educational institutions;Context;Maintenance engineering;Evolving service composition;adaptive regression testing},
  doi={10.1109/TSC.2014.2322621},
  ISSN={1939-1374},
  month={Sep.},}@INPROCEEDINGS{9616824,
  author={Padmanabhan, Mani},
  booktitle={2021 Fourth International Conference on Electrical, Computer and Communication Technologies (ICECCT)}, 
  title={Test Case Optimization based on Specification Diagrams and Simulation Invocation Relationship}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={The growing usage of software-based products is coupled with day-to-day human life. The software engineering technology can be more eye-catching among artificial intelligent-based software developers. The artificial intelligence systems such as the human machine interaction process are difficult to identify the pre-conditions during the development. Re-engineering is essential for artificial intelligent systems-based applications. Regression testing has assured the quality of products during the re-engineering process. The test cases are a core component in regression testing. Test case optimization and selection is a major activity to reduce the time and cost during regression testing. Many test case selection techniques have solved the problems in regression testing, however, the techniques seem to have much focus on reducing the number of test cases. This research proposes a test case optimization-based specification diagram. In the test, case selections are controlled by the simulation invocation relationship. The proposed simulation invocation methodology identified the simulations to be affected during the reengineering process. The proposed optimization algorithm produced the test cases based on the fault coverage criteria. This approach had validated with three artificial intelligent-based systems during regression testing. The comparative analysis shows that the proposed approach is well suitable for re-engineering in terms of the average percentage of fault detected values.},
  keywords={Measurement;Human computer interaction;Costs;Fault detection;Software;Intelligent systems;Optimization;Software Testing;Test case generation;Test Optimization;Software Validation;Simulation Invocation Relationship},
  doi={10.1109/ICECCT52121.2021.9616824},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8453137,
  author={Liang, Jingjing and Elbaum, Sebastian and Rothermel, Gregg},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)}, 
  title={Redefining Prioritization: Continuous Prioritization for Continuous Integration}, 
  year={2018},
  volume={},
  number={},
  pages={688-698},
  abstract={Continuous integration (CI) development environments allow soft-ware engineers to frequently integrate and test their code. While CI environments provide advantages, they also utilize non-trivial amounts of time and resources. To address this issue, researchers have adapted techniques for test case prioritization (TCP) to CI environments. To date, however, the techniques considered have operated on test suites, and have not achieved substantial improvements. Moreover, they can be inappropriate to apply when system build costs are high. In this work we explore an alternative: prioritization of commits. We use a lightweight approach based on test suite failure and execution history that is highly effcient; our approach "continuously" prioritizes commits that are waiting for execution in response to the arrival of each new commit and the completion of each previously scheduled commit. We have evaluated our approach on three non-trivial CI data sets. Our results show that our approach can be more effective than prior techniques.},
  keywords={Software engineering;continuous integration;regression testing;large scale testing},
  doi={10.1145/3180155.3180213},
  ISSN={1558-1225},
  month={May},}@ARTICLE{9163120,
  author={Ali, Sadia and Hafeez, Yaser and Jhanjhi, N. Z. and Humayun, Mamoona and Imran, Muhammad and Nayyar, Anand and Singh, Saurabh and Ra, In-Ho},
  journal={IEEE Access}, 
  title={Towards Pattern-Based Change Verification Framework for Cloud-Enabled Healthcare Component-Based}, 
  year={2020},
  volume={8},
  number={},
  pages={148007-148020},
  abstract={To survive in the competitive environment, most organizations have adopted component-based software development strategies in the rapid technology advancement era and the proper utilization of cloud-based services. To facilitate the continuous configuration, reduce complexity, and faster system delivery for higher user satisfaction in dynamic scenarios. In cloud services, customers select services from web applications dynamically. Healthcare body sensors are commonly used for diagnosis and monitoring patients continuously for their emergency treatment. The healthcare devices are connected with mobile or laptop etc. on cloud environment with network and frequently change applications. Thus, organizations rely on regression testing during changes and implementation to validate the quality and reliability of the system after the alteration. However, for a large application with limited resources and frequently change component management activities in the cloud computing environment, component-based system verification is difficult and challenging due to irrelevant and redundant test cases and faults. In this study, proposed a test case selection and prioritization framework using a design pattern to increase the faults detection rate. First, we select test cases on frequently accessed components using observer patterns and, secondly, prioritize test cases on adopting some strategies. The proposed framework was validated by an experiment and compared with other techniques (previous faults based and random priority). Hence, experimental results show that the proposed framework successfully verified changes. Subsequently, the proposed framework increases the fault detection rate (i.e., more than 90%) than previous faults based and random priority (i.e., more than 80% respectively).},
  keywords={Cloud computing;Medical services;Testing;Reliability;Fault detection;Electronic mail;Organizations;Body sensor;cloud computing;component-based system;design pattern;healthcare systems;regression testing;TCP},
  doi={10.1109/ACCESS.2020.3014671},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9155903,
  author={Jebbar, Oussama and Saied, Mohamed Aymen and Khendek, Ferhat and Toeroe, Maria},
  booktitle={2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Regression Test Suite Reduction for Cloud Systems}, 
  year={2020},
  volume={},
  number={},
  pages={477-486},
  abstract={Cloud providers offer a wide variety of services to their tenants. Providers share large scale infrastructures to host their services and use configurable software customized with configurations to meet different tenant requirements. These configurations are often the main source of errors. Moreover, they undergo frequent changes, therefore, systems' compliance to requirements needs to be re-evaluated frequently using regression testing. The problem of regression test case selection has been extensively addressed in the literature, however, existing approaches do not tackle the problem from the configuration perspective. In this paper, we propose a configuration-based method for regression test suite reduction for cloud systems. Our method targets a set of faults summarized in a fault model, and it relies on a classification of configuration parameters based on their relation to the deployment environment. Our idea is that the relation of the configuration parameters to the environment can be explored to reduce the regression test suite.},
  keywords={Software;Testing;Computer architecture;Credit cards;Computer science;Production;Conferences;cloud systems;configurable systems;configurations;regression testing;test suite reduction},
  doi={10.1109/ICSTW50294.2020.00084},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10493937,
  author={Li, Rongrong},
  booktitle={2024 5th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI)}, 
  title={Software Quality Testing Framework based on Machine Learning Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={396-401},
  abstract={This research work presents a software quality testing framework based on machine learning analysis. The framework utilizes dynamic symbol technology and integration testing methods to analyze different execution paths, thereby establishing a comprehensive integration testing framework. Technologies such as robot framework, exploration-driven test data generation, and software reliability coupling measurement are employed to improve testing efficiency and ensure thorough verification of software functions and performance. The research demonstrates the application of reinforcement learning to test case sequencing, using Q-learning to optimize API functional test case generation. The proposed methodology involves the integration of machine learning analysis into three aspects: information handling, procedure formulation, and execution flow. The paper explores regression testing, test case prioritization technology (TCP), and reinforcement learning for efficient test case ordering. A comprehensive simulation of 500 software reliability testing use cases shows significant improvements in test efficiency by reducing redundant instances. The research concludes with a discussion of the application of Q-Learning in continuous integration testing, emphasizing the need for flexible memory representations to handle complex states and action sets. The proposed framework effectively addresses the challenges posed by scale expansion in software development, thereby improving the accuracy and efficiency of software testing.},
  keywords={Software testing;Sequential analysis;Q-learning;Symbols;Software quality;Software reliability;Software measurement;Machine learning analysis;software quality;testing framework;robustness testing},
  doi={10.1109/ICMCSI61536.2024.00063},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8728945,
  author={Enoiu, Eduard and Frasheri, Mirgita},
  booktitle={2019 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Test Agents: The Next Generation of Test Cases}, 
  year={2019},
  volume={},
  number={},
  pages={305-308},
  abstract={Growth of software size, lack of resources to perform regression testing, and failure to detect bugs faster have seen increased reliance on continuous integration and test automation. Even with greater hardware and software resources dedicated to test automation, software testing is faced with enormous challenges, resulting in increased dependence on centralized and complex mechanisms for automated test case selection as part of continuous integration. These mechanisms are currently using static entities called test cases that are concretely realized as executable scripts. Our key vision is to provide test cases with more reasoning, adaptive behavior and learning capabilities by using the concepts of software agents. We refer to such test cases as test agents. The model that underlie a test agent is capable of flexible and autonomous actions in order to meet overall testing objectives. Our goal is to increase the decentralization of regression testing by letting test agents to know for themselves when they should be executing, how they should update their purpose, and when they should interact with each other. In this paper, we envision test agents that display such adaptive autonomous behavior. Existing and emerging developments and challenges regarding the use of test agents are explored-in particular, new research that seeks to use adaptive autonomous agents in software testing.},
  keywords={Software;Task analysis;Software testing;Automation;Adaptation models;Switches;software testing;test design;regression;agent;test automation;adaptive;autonomous},
  doi={10.1109/ICSTW.2019.00070},
  ISSN={},
  month={April},}@ARTICLE{9777725,
  author={Zhu, Penghua and Li, Ying and Li, Tongyu and Ren, Huimin and Sun, Xiaolei},
  journal={IEEE Access}, 
  title={Advanced Crowdsourced Test Report Prioritization Based on Adaptive Strategy}, 
  year={2022},
  volume={10},
  number={},
  pages={53522-53532},
  abstract={Crowdsourced testing is an emerging trend in software testing, which takes advantage of the efficiency of crowdsourced and cloud platforms. Crowdsourced testing has gradually been applied in many fields. In crowdsourced software testing, after the crowdsourced workers complete the test tasks, they submit the test results in test reports. Therefore, in crowdsourced software testing, checking a large number of test reports is an arduous but unavoidable software maintenance task. Crowdsourced test reports are numerous, complex, and need to be sorted to improve inspection efficiency. There are no systematic methods for prioritizing reports in crowdsourcing test report prioritization. However, in regression testing, test case prioritization technology has matured. Therefore, we migrate the test case prioritization method to crowdsourced test report prioritization and evaluate the effectiveness of these methods. We use natural language processing technology and word segmentation to process the text in the test reports. Then we use four methods to prioritize the reports: total greedy algorithm, additional greedy algorithm, genetic algorithm, and ART. The results show that these methods all perform well in prioritizing crowdsourced test reports, with an average APFD of more than 0.8.},
  keywords={Task analysis;Greedy algorithms;Crowdsourcing;Software algorithms;Software testing;Encoding;Software;Crowdsourced software testing;test report prioritization;text classification},
  doi={10.1109/ACCESS.2022.3176086},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7828927,
  author={Yang Gao and Bai, Cheng-Gang},
  booktitle={2016 IEEE Chinese Guidance, Navigation and Control Conference (CGNCC)}, 
  title={Selecting test cases by cluster analysis of GUI states}, 
  year={2016},
  volume={},
  number={},
  pages={1024-1029},
  abstract={Nowadays graphical user interface (GUI) has been widely used in software systems, while there is no efficient testing techniques for the rapidly evolving GUI applications. For the GUI applications are modified rapidly and the test suites trend to be huge in size, it is often desirable to select a subset of test cases to fulfill the regression testing. In this paper, a novel GUI state model is presented to address the execution of test case, and then a state-coverage method based on cluster analysis of the GUI states is proposed to select a reliable subset of test cases for GUI regression testing. An empirical study illustrates that the state-coverage method is effective for GUI test case selection.},
  keywords={Graphical user interfaces;Testing;XML;Software;Measurement;Reliability;Sociology},
  doi={10.1109/CGNCC.2016.7828927},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10660677,
  author={Lin, Hongjie},
  booktitle={2024 5th International Conference on Image Processing and Capsule Networks (ICIPCN)}, 
  title={A Novel Software Test Data Generation Framework based on Multi-level Fuzzy Clustering Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={781-786},
  abstract={Software testing plays a crucial role in ensuring the quality and reliability of software products. This study presents a novel software test data generation framework based on the multi-level fuzzy clustering algorithm. The framework aims to optimize the testing process by efficiently generating test cases and prioritizing them for execution. The proposed methodology integrates hierarchical reinforcement learning and hierarchical clustering techniques to improve the effectiveness and comprehensiveness of software testing. A detailed review of recent advances in software testing methodologies is provided, focusing on differential regression testing for REST APIs, test case prioritization, program repair using neural translation models, and other key areas. The proposed framework is evaluated through experiments on real-world software datasets, demonstrating its superiority in terms of non-redundancy rate and vulnerability count detection compared to existing methods. The results highlight the effectiveness and relevance of the proposed framework in improving the efficiency and reliability of software testing.},
  keywords={Software testing;Reviews;Image processing;Software algorithms;Refining;Clustering algorithms;Reinforcement learning;Software Testing;Data Generation;Multi-level Fuzzy Clustering;Algorithm Framework},
  doi={10.1109/ICIPCN63822.2024.00135},
  ISSN={},
  month={July},}
